
[{"content":" CPP Net Standard \u0026amp; The Asio asynchronous model # 因为CPP的Sender \u0026amp; Receiver标准看的比较晚，所以实际上是先写的Asio的网络模型。\n我这几天在看这篇论文《The Asio asynchronous model》，\n我这几天看到有一些人在攻击陈硕的一些观点，甚至reactor proactor模式的观点。个人觉得是比较好笑的，因为空谈设计哲学是最没有意义的。但是有一点说的很对，send事件是需要关注的，因为send比方说100mb，不代表100mb能都发完\n下面的内容，除了我把\n里面会穿插一部分官方文档（https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/overview/core.html），官方文档会打散穿插到这篇论文里面，如果看到标题带有Plus或者++那就是官方文档里面的内容。关于Asio，我认为重点是理解executor，dispatcher，scheduler（dispatcher，这个词在不同的框架中可能有不同的含义。比如在Boost.Asio中，dispatcher可能指代分发事件或消息的机制。io_context既是executor，也负责调度处理程序的执行；scheduler通常与任务调度相关，决定任务执行的顺序、优先级等。）概念理解之后，我们就回去看看源代码，看看背后的设计哲学 一些临时想到的想法，都写为了引用 The Asio asynchronous model # 阅读完了Asio的异步模型之后，可以看看Asio的作者的视频，对应文字翻译请参考这个https://zhuanlan.zhihu.com/p/662972177\n1 引论 # 网络领域长期以来一直采用事件驱动和异步编程设计来开发高效、可扩展、面向网络的软件。基于proactor模型的事件模型，其函数快可视为连续的异步操作，对理解和组合提供了一个很好的概念模型。异步操作可以被连接，每个连接都会启动下一个操作。细粒度的连接可以抽象为单个、更高级别的异步操作连接。 然而，随着异步组合越来越多，纯粹基于回调的方法会大大增加明显的代码复杂度和损害代码可读性。程序员转而使用机制，如状态机、纤程，C++20基于语言的协程，以提高代码清晰度，同时保留异步实现的好处。这里并没有什么银弹。 本文从高层次对Asio库核心的异步模型进行了总结。这种模型将异步操作作为异步组合的基本构建块，但并未使用组合机制。Asio中的异步操作支持回调、future（eager和laze模式）、fiber、协程和尚未想到的方法。从而应用程序程序员根据适当的权衡选择一种方法。\n//代码，未粘贴 2 动机 # 2.1 同步形式作为灵感 # 最简单的网络程序采用 thread-per-connection 方法实现。这里我们来看看基本的 echo 服务器，下面是一个只用同步函数编写的Echo服务器：\n这个程序的结构和流程很清晰，同步操作都是一个个的函数调用。这些函数带来了很多不错的的句法和语义属性，包括：\n组合可以使用该语言来管理控制流（即 for、if、while 等）。 组合可以重构为使用在同一线程上运行的子函数（也就是直接调用子函数）而不改变功能。 如果同步操作需要临时资源（例如内存、文件描述符或线程），此资源在从函数返回之前被释放。 当同步操作是泛型的（就是模板）时，返回类型可以从函数及其参数确定性的推到出来 要传递给同步操作的参数的生命周期是明确的，即使是传递临时变量。 然而，使用每个线程处理一个连接的方法有几个问题限制了其普遍的可用性。\n2.2 线程的可扩展性有限 # 顾名思义，每个线程一个连接的设计使用单独的线程来处理每个连接。对于处理数千或数百万并发连接的服务器，这代表着程序占据巨量的资源使用，尽管近年来64位的广泛可用性操作系统缓解了这种情况。\n从性能敏感的角度考虑，上下文切换的消耗可能更需要考虑在内。在通用操作系统线程之间进行上下文切换的成本以数千个CPU周期来衡量。当可运行线程数量超过执行资源（如 CPU）时，就会发生排队，而最后一个排队的任务会因多次上下文切换的成本而延迟。\n// 差个图片\n即使网络服务器看起来总体负载较轻，时间相关的事件仍然可能产生排队排队。例如，在金融市场中，所有参与者都在处理和响应相同的市场数据流，因此很可能不止一个参与者会通过向服务器发送交易来响应相同的刺激。这种排队增加了参与者所经历的平均延迟和抖动。\n相比之下，专门为事件处理设计的调度程序可以在任务之间“上下文切换”速度提高一到两个数量级，在几十到几百个周期内就结束调度。这里排队可能仍然会发生，但处理相关的队列的总体开销大大减少。\n最后，我们还必须注意到，我们的thread-per-connection回显服务器非常简单：线程一旦启动，就能够独立运行。在现实世界的用例中，服务器程序可能需要访问共享数据以响应客户端，处理同步成本、处理CPU之间的数据移动、并增加代码的复杂度。\n2.3 半双工和全双工协议 # 每个线程一个连接的方法对于简单的协议可能比较试用，比方说上面所示的回显服务器，协议是一个半双工协议。服务器要么发送，要么接收，但绝不能同时处理发送和接受。\n然而，许多现实世界的应用协议是全双工的，这意味着数据可以在任何时候的任何一个方向传输。考虑一些基于FIX协议的消息：\n//插入一些图片\n如你所见，像这样的协议需要响应来自许多不同来源的事件。这里面隐藏几个含义：\n协议逻辑中不同部分，它们可能并发执行（concurrent的含义请自行理解），可能需要访问共享的状态。 复杂事件处理流程可能不容易以线性形式表示（例如基于thread-per-connection机制设计，再比方说使用协程时流程）。 因此，我们经常发现这些协议的作者利用其他组合机制，例如状态机，作为管理复杂性和确保正确性的一种方式（状态机能简化理解和设计难度，对于状态机的应用理解有困难的同学，可以去看TCP状态机和TLS状态机，在RFC后面都有图片看。\nReactor模式的核心是事件循环和非阻塞I/O事件的分发机制，通过解耦事件监听与处理实现高效并发。 Reactor和Proactor模式的区别并不体现在全双工和半双工的区别上，上面实际上想说的是Reactor模式处理一个复杂的协议时，要使用一些非常麻烦（可以理解为不好懂）的实现方法，比方说状态机来确保正确实现了协议。\n2.4 快速执行关乎性能表现 # 一些网络应用程序需要向许多消费者传递一条消息。比方说量化交易需要向所有参与者实时传播市场数据。异步地传递此信息时，一种常见的方法是将消息包装在引用计数指针中（例如shared_ptr）保持内存有效，直到它被传输到所有人再将之释放。\n然而，出于效率原因，任何一个传输操作中都尝试投机性发送。符合期望的情况，从统计来说大概率确实如此（前提是确保未超出硬件和软件的负载能力），即投机发送数据成功并立刻传输数据。这种情况下，则无需再维护有效的共享指针。这避免了维护引用计数的开销。\n相比较而言，原子计数计算成本可衡量为几十个CPU周期，与以数百CPU周期为基本耗时使用系统调用传输数据的操作相比。避免原子计数的额外成本在实践中可以获得5-10%的收益。（可能是金融交易领域会比较关注，对于普通工程从业者，还好）。\n惰性执行模型（lazy execution model）无法避免这种成本，因为它必须在操作第一次时复制共享数据调用。\n这段话到底是想表明什么呢？shared_ptr引用计数带来的成本往往优化很麻烦。boost自己实现了一种buffer。\n除此之外boost给了一种intrusive_ptr，https://www.boost.org/doc/libs/1_88_0/libs/smart_ptr/doc/html/smart_ptr.html#intrusive_ptr 。其实现的方案就是将控制块和对象嵌入到一起。\n实际上针对shared_ptr带来的性能问题，往往就是几种常见的手段\n还是shared_ptr，但是减少原子操作的同步开销 intrusive_ptr，将引用计数嵌入对象内部，消除控制块的内存开销和间接访问 完全放弃引用计数，在极端低延迟场景中，放弃智能指针，改用手动或作用域管理 2.5 设计哲学 # 上述问题激发了以下异步模型的设计理念：\n异步模型需要灵活支持组合机制，因为具体的选择因人（用例）而异。\n尽可能多的支持同步操作的语义和句法属性，因为它们可以更简单地组合和抽象。\n这里实际上是想说，支持所谓的状态机，支持所谓的组合，支持所谓的协程。来简化代码开发的难度\n应用程序代码应该在很大程度上避免线程和同步的复杂性，因为线程 \u0026amp; 同步会带来自不同来源的事件的复杂性。\n这里实际上是想说，要把事件分发机制隐藏。和下面的CPP 标准相比，这里隐藏了dispatcher，而scheduler是CPP标准的重点\n2 Plus # https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/overview/core/async.html\n很明显Asio选择的是Proactor模式，和同步或者Reactor模式相比，Asio的Proactor模式的优缺点都很明显。当然Asio也支持Reactor模式，可以嵌入第三方库，具体不翻译了，参考https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/overview/core/reactor.html\n先看看Asoi的实现当中有哪些东西。\nProactor模式的关键词（改编自[POSA2]）\n异步操作：定义一个异步执行的操作，例如对套接字的异步读或写。 异步操作处理器（Asynchronous Operation Processor）：执行异步操作，并在操作完成时将事件排入完成事件队列。从高层次来看，像reactive_socket_service这样的内部服务是异步操作处理器。 完成事件队列 缓冲完成事件，直到被异步事件解复用器出列。 completion handler 处理异步操作的结果。这些是函数对象，通常使用boost::bind创建（当然我个人有的时候用std::bind)。 异步事件解复用器(Asynchronous Event Demultiplexer)阻塞等待完成事件队列上的事件发生，并将已完成的事件返回给调用者。 Proactor 调用异步事件解复用器出列事件，并分派与事件相关的完成处理程序（即调用函数对象）。这个抽象由io_context类表示。 Initiator 特定于应用程序的代码，启动异步操作。发起者通过像basic_stream_socket这样的高层次接口与异步操作处理器交互，而后者又委托给像reactive_socket_service这样的服务。 Asio的Proactor模式实际上也是在Reactor模式上实现的\n异步操作处理器（Asynchronous Operation Processor）使用select、epoll或kqueue实现的Reactor。当Reactor指示资源准备好执行操作时，处理器执行异步操作，并将相关的completion handler排入完成事件队列。 完成事件队列 完成处理程序（即函数对象）的链表。 异步事件解复用器 这是通过等待事件或条件变量来实现的，直到完成事件队列中有可用的完成处理程序。 可移植性：许多操作系统都提供了原生异步 I/O API（例如Windows上就支持这种），作为开发高性能网络应用程序的首选。这个库可以基于原生异步 I/O 来实现。然而，如果原生支持不可用，这个库也可以使用典型的reactor模式的同步事件解复用器来实现，例如POSIX的select()。 将线程与并发解耦：需要一直跑的complete handler丢在队列里面，由executor执行。因此，应用程序不需要生成许多线程来提高并发性。 性能和可扩展性：诸如每个连接一个线程（只有纯同步通信的情况下会需要这种实现）这样的实现策略会降低系统性能，因为会增加 CPU 之间的上下文切换、同步和数据移动。使用异步操作，可以通过最小化操作系统线程的数量（线程往往是有限的资源），并且只在有活干的时候，再让线程进入运行状态，来避免上下文切换的成本。 简化应用程序同步：异步操作completion handler写起来和单线程同步通信下的代码差不多，因此应用程序逻辑可以在很少或不考虑同步问题的情况下开发。而不是一堆回调飞来飞去 函数组合：函数组合是指completion handler组合以提供更高级别的操作，例如以特定格式发送消息。每个函数都是通过对较低级别读或写操作的多次调用来实现的。 例如，考虑一种协议，其中每个消息由固定长度的头部和可变长度的主体组成，主体的长度在头部中指定。一个假设的 read_message 操作可以使用两个较低级别的读取来实现，第一次读取接收头部，一旦知道长度，第二次读取接收主体。 在异步模型中组合函数时，异步操作可以链接在一起。也就是说，一个操作的完成处理程序可以启动下一个操作。可以封装链中的第一个调用，以便调用者不必知道高级操作是作为异步操作链实现的。 以这种方式组合新操作的能力简化了支持特定协议的时候开发更高层次抽象的流程。 3 模型 # 3.1 异步操作（Operation） # 请注意，这里我将（completion handler)翻译为completion handler，我之所没翻译为句柄，是因为句柄就有点类似鲁棒，属于你懂了才会理解，不懂根本就不理解的词语\n异步操作是Asio异步模型中的基本组合单元。异步操作代表在后台启动和执行的工作，而用户的代码发起的工作可以继续做其他事情。\n从概念上讲，异步操作的生命周期可以用以下事件和阶段来描述。\n//需要插入一张图片\n初始化函数是用户调用以启动异步操作，进行初始化操作的函数。(initiating function这玩意你就当成是什么async_read之类的就行了) completion handler是用户提供的、可移动（move-only)的函数对象，最多被调用一次，通知异步操作的结果。completion handler的调用用于通知用户一些事情已经发生了：操作完成，操作的副作用产生了。 初始化函数和completion handler被嵌入到用户的代码中，用法如下所示：\n// 需要插入一张图片\n同步操作的表现形式为单个函数，具有几个固有的语义属性。异步操作从这些同步操作选取一部分语意以便于灵活高效的组合。（这句话我觉得主要是针对设计哲学第二条说的，是想说Aiso的一步操作采用了同步操作的相同语意）\n同步操作属性 异步操作相同的语意 当同步操作是泛型的（即模板，其返回类型可由派生自函数及其参数确定 当异步操作是泛型时，completion handler的参数类型和顺序可确定地从初始化函数函数及其参数推导。 如果同步操作需要临时资源（例如内存、文件描述符或线程），此资源在函数返回之前被释放。 如果异步操作需要临时资源（例如内存、文件描述符或线程），此资源在调用completion handler之前就被释放掉。 第二个语意是异步操作的一个重要属性，因为它允许completion handler在不重叠资源使用的情况下启动进一步的异步操作。想想下面这种琐碎的（也是相对常见的）的情况，在异步操作链中一遍又一遍地重复相同操作：\n通过确保在completion handler运行之前释放资源，我们避免了峰值翻倍运营链的资源使用。（这句话我也没看懂）\n这里多插一句，Proactor \u0026amp; Reqctor模式是两种传统网络编程模式，这里Boost选择的是Proactor模式。因此这里需要考虑\n3.2 异步Agent # 异步Agent是异步操作的顺序组合。每个异步操作被认为是作为异步Agent的一部分运行，即使该Agent仅包含该单个操作。异步Agent可以与其他异步Agent同时执行工作。异步Agent之于异步操作就像线程之于同步操作一样。\n然而，异步Agent是一个纯粹的概念结构，它允许我们理解异步操作上下文如何组织，异步操作如何组合。库中没有“异步Agent”这个名词 Agent如何组织异步操作也不重要。我们可以视异步Agent工作流程如下\n// 插入图片\n异步Agent交替地等待异步操作完成，然后运行该操作的completion handler。在异步Agent的上下文中，这些completion handler表示不可分割的可调度工作。\n3.3 关联特性和关联器 # 这部分请注意，关联特性是Associated characteristics，关联器是associators\n这部分的概念出现的似乎很突然，实则不然。这东西实际上简化了用户代码，比方说使用了某种executor（比方说，这里用了strand），然后异步操作不断传播，怎么样继续使用这种executor呢，我自己再不断地传递template？\nASIO中的 Associated Characteristics（关联特性）和 Associator Traits（关联器特征）是用于隐式传递异步操作的上下文信息和定制异步操作行为的底层机制。它们的设计目的是在异步操作链中自动传递某些关键属性（如执行器、分配器、取消状态等），从而简化用户代码并提高灵活性。就是\nAssociated Characteristics 避免在异步链中重复传递上下文（如执行器）\nAssociator traits允许自定义特性的提取逻辑。可以associated_executor，可以associated_allocator，可以associated_cancellation_slot\n帮助库自动推断和传递这些属性。例如，当用户编写一个完成处理程序（completion handler）时，ASIO可能需要确定该处理程序应该使用哪个执行器，这时候associator traits会起作用，自动关联正确的执行器，而无需用户显式指定。\n关联特性指的是组合为异步Agent工作流程中的一部分时，异步操作（asynchronous operations）应当如何表现（就是问how），例如（下面这几个都是一种关联特性）：\n一个分配器，指明异步操作如何获取内存资源 取消槽（cancellation slot），指明异步操作取消时采取什么行为 一个执行器（executor），它指明Agent的completion handler（completion handlers）将如何排队和运行。 异步操作在异步Agent的执行流程中运行，每个异步操作都需要使用某些关联特性（可以类比为满足golang里面的接口）。异步操作或者说initing function调用的的completion handler需要满足相应的关联器特征，异步操作会查询某个类型（如 Handler）是否关联了特定特性（实际上是C++ traits）。每种关联特性（characteristic）实际上都具有相应的关联器特征（traits）。\n说的好像都不是人话了，说白了就是每个异步操作调用\n具体的completion handler的关联器特征（associator trait）需要给出下列的信息：\n接受异步操作提供的默认关联特性（characteristic），按原样返回此默认值 返回和关联特性（characteristic）不相关的具体实现，或 调整提供的默认特征（characteristic）以引入completion handler所需的其他行为。 如何定义关联器（associator)\n给定一个名为associated_R的关联器特征，它应当具有：\n默认必须有的S类型的s，用于定义completion handler，定义completion handler类型， 定义关联特性的语法（可以理解为函数原型）和语义要求（可以理解为语法上层做什么）的一组类型要求（或C++ concept），称之为R，以及 满足上面要求R的C类型候选值c，由异步操作提供的，代表默认提供的满足关联特性的实现 异步操作真正计算时使用下述关联器特征：\n类型的定义，associated_R\u0026lt;S， C\u0026gt;::type 实际实现（值）associated_R\u0026lt;S， C\u0026gt;::get（s，c） 上面两个满足R中定义的要求。为方便起见，这些也可以通过类型别名访问associated_R_t\u0026lt;S， C\u0026gt;或调用可能变化的函数get_associated_R(s，c)。\n关联器特征的模板应当定义为：\n如果S::R_type格式良好，定义一个嵌套类型的别名为S::R_type和静态成员函数用于get此类型s.get_R（） 其他情况，如果关联器\u0026lt;associated_R， S，C\u0026gt;::type已经定义清晰，直接继承关联器\u0026lt;associated_R， S，C\u0026gt;即可 其他情况，将嵌套类型别名定义为C，再定义一个静态成员函数get返回c。 3.4 子Agent # 这段的子Agent和父Agent的关系我实际上感觉读起来乖乖的，总觉得是论文有问题\n异步Agent中的异步操作可以组合为子Agent（在Aiso里面，异步操作也被称为组合操作）。就父（异步）Agent而言，它在等待最终异步操作的完成。构成子Agent的异步操作依次运行，子Agent执行完成，最后的completion handler运行时父Agent才继续运行。\n与单个异步操作一样，构成子Agent构建的异步操作必须在调用completion handler之前释放临时资源。我们可以认为这些子Agent的生命周期在调用completion handler之前结束。 当异步操作创建子Agent时，它可能会传播父Agent的特征到子Agent，然后递归传播这些相关特征。这些传递的特征复制了同步操作的另一种属性。\n同步操作 异步操作 同步操作的组合可以重构为在同一个线程使用相同的函数（即简单地调用）而不改变功能 异步Agent可以重构为共享父Agent关联特性的异步操作和子Agent，而无需改变功能。 最终，这些异步操作可以实现为并发运行的多个子Agent。在这种情况下，异步操作可以选择选择性地传播父Agent的关联特性。\n3.5 Executors # 这里请注意，不能将executor认为是某个线程，或者执行者。它是一种抽象的概念\n每个异步Agent都有一个关联的执行器。Agent的执行器决定Agent的completion handler如何排队并最终运行。\n执行器的例子包括：\n协调一组操作共享数据结构的异步Agent，确保Agent的completion handler永远不会同时运行(Aiso里面这种类型的执行器被称为strand)。 确保Agent在靠近数据或数据的指定执行资源（例如CPU）上运行事件源（例如NIC）。 表示一组相关Agent，从而启用动态线程池以进行更智能的调度决策（例如将Agent作为一个单元在执行资源之间移动）。 将所有completion handler排队以在GUI应用程序线程上运行，以便它们可以安全地更新用户交互界面元素。 返回异步操作的默认执行程序，尽可能快地运行completion handler在触发操作完成的事件之后。 调整异步操作的默认执行器，以便在每个之前和之后运行诸如日志记录、用户授权或异常处理等行为 指定异步Agent及其completion handler的优先级。 异步Agent中的异步操作使用Agent的关联执行器来：\n在异步操作未完成时，记录异步操作表示的工作的存在。 在操作完成时，确保completion handler进入执行队列。 确保completion handler不会重新运行，如果这样做可能导致疏忽递归和堆栈溢出。 因此，异步Agent的关联执行器表示Agent应该以何种方式、地点和时间的策略运行，是实际组成Agent的代码的横切关注点。\n这段我觉得读起来也有一些拗口，我目前看到asio的执行器（也包括执行器上下文）就是io_context（执行器上下文），thread_pool等就是单纯的供线程调用的对象，线程在这个上下文上调用boost::asio::io_context::run() 执行相关的任务。如果没有任务，那么boost::asio::io_context::run() 就会直接返回\n3.6 Allocators # 每个异步Agent都有一个关联的分配器。Agent的分配器是组成Agent的异步操作用以获取每个操作的稳定内存资源（POSM）使用的接口。这个名字反映了这样一个事实：内存是per操作的，因为内存仅在该操作的生命周期内保留；并且保证内存在整个异步操作过程中始终可用。\n异步操作可以通过多种不同方式利用POSM：\n该异步操作不需要任何POSM。例如，该操作包裹了一个现有的API执行自己的内存管理，或者将一些数据拷贝进环形队列。 异步操作未完成时，只使用单个固定大小的POSM。例如，将某些状态存储在链表中。 该异步操作使用单个，运行时确定大小的POSM。例如，异步操作存储用户提供的缓冲区的副本，或运行时确定大小的iovec结构数组。 该操作同时使用多个POSM。例如，链表调用固定大小POSM外加一个用于缓冲区的运行时大小的POSM。 操作串行使用多个POSM，大小可能会有所不同 POSM优化是组合异步操作的横切关注点（横切关注点是指在多种模块或组件中重复出现的功能或操作）。此外，使用分配器作为接口来获取POSM授予保证异步操作的实现和调用方的灵活性：\n代码使用方可以忽略分配器的存在并接受应用程序采用的任何默认策略。 代码实现者可以忽略分配器，尤其是在操作不认为是性能的关键点的前提下。 用户可以为相关的异步操作共同定位POSM，以获得更好剧不行。 对于串行使用不同大小的POSM的组合，内存使用只需调用当前现存的POSM即可。例如，考虑一个短期异步操作的组合使用内存需求大POSM（连接建立和握手），然后进行长寿命异步操作它使用小型POSM（在对等点之间传输数据，存储这些数据）。 如前所述，在调用completion handler之前必须释放所有资源，从而为Agent内其他的后续异步操作回收内存。这允许应用程序即使有长寿命异步Agent，也不会热路径（hot-path，“hot path”是指程序或系统中执行频率非常高的代码路径）内存分配，而用户代码并知道关联的分配器存在。\n3.7 Cancellation # 在Asio中，许多对象，例如套接字和计时器，都支持通过它们的关闭或取消成员函数来取消和当前套接字或者计时器相关的未完成的异步操作。但是，某些异步操作还支持单独的、有针对性的取消。这种操作取消的方式通过指定异步Agent关联的取消槽实现。\n为了支持取消，异步操作将取消handler安装到Agent的插槽中。取消handler是一个函数对象，当用户发出取消信号时将调用它进入插槽。由于取消槽与单个Agent相关联，因此该槽最多可容纳一个处理程序时间，安装新的取消handler将覆盖任何以前安装的处理程序。因此，相同的插槽可重用于Agent内的后续异步操作（后面的取消handler直接插进去覆盖就完事了）。\n当异步操作包含多个子Agent时，取消特别有用。例如，一个子Agent可能已完成，另一个随后的子Agent立刻被取消，子Agent不会造成任何后续的副作用。\n3.8 Completion tokens # // 图片\nAsio异步模型的一个关键目标是支持多种组合机制。用户通过将完成令牌（ Completion token）传递给异步操作的初始化函数来调用。按照惯例，完成令牌是异步的操作初始化函数的最后一个参数。\n这段可能读起来有些拗口，实际上参考https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/tutorial/tuttimer2.html的解释，a completion token, which determines how the result will be delivered to a completion handler when an asynchronous operation completes.\n如果觉得看起来还是有点难以理解，可以理解为completion token是对completion handler的一个包裹。在asio初期，initiating function（比方说async_read）的参数必须是completion handler，而initiating function（比方说async_read）的返回值必须是void（也就是说completion handler对ininting function返回值并不关心）。14-15年，asio的作者Christopher Kohlhoff这时候改为initiating function接受completion token。为什么非得用completion token呢？实际上不是非得用completion token，而是为了增加代码的灵活性，让ininting function可以做更多的事情：换言之initiating function可以有返回值，可以嵌套更多的操作。\n什么意思呢？你可以在completion token里面传递use_future，而initiating function（比方说async_read）会返回一个future。这个future你可以用来等待做些事情。实际上asio还支持了诸如协程之类的方法\n当然，这还满足兼容性的要求，如果你原本实现，不处理initing function的completion handler实际上不需要改变。因为它实际上还是让initiating function返回为void。\n完成令牌的实例参考https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/tutorial/tuttimer3.html，如何将一些参数绑定传递至completion handler：使用bind将一些参数绑定为function对象，再将包裹之后的function传递为completion token，这里注意一下需要调用的是boost::bind()，如果调用的是std::bind，那么就需要传递boost::asio::placeholders::error，比方说https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/tutorial/tutdaytime3.html 的\nvoid start_accept() { tcp_connection::pointer new_connection = tcp_connection::create(io_context_); acceptor_.async_accept(new_connection-\u0026gt;socket(), std::bind(\u0026amp;tcp_server::handle_accept, this, new_connection, boost::asio::placeholders::error)); } 例如，如果用户传递一个lambda（或其他函数对象）作为完成令牌，异步操作行为如前所述：操作启动，当操作完成时，结果传递给lambda表达式。\n当用户将use_future作为完成令牌调用（初始化函数）时，该操作的行为就像是调用promise和future一样。初始化函数并不只启动异步操作，还会返回一个future用于等待结果。\nfuture\u0026lt;size_t\u0026gt; f = socket.async_read_some( buffer, use_future ); // ... size_t n = f.get(); 类似地，当用户传递use_awaitable为完成令牌，初始化函数表现的好像它是一个awaitable-based协程。然而，在这种情况下，初始化函数不会启动异步操作。它只返回awaitable对象，只有在进入co_await-ed之后，才启动操作。\nawaitable\u0026lt;void\u0026gt; foo() { size_t n = co_await socket.async_read_some( buffer, use_awaitable ); // ... } 最后一种，将纤程（Fiber）的yield作为完成令牌传递，看起来似乎初始化函数能感知到纤程的同步操作：除了开始异步操作，还会阻塞纤程，直到它完成。对纤程而言，这是一个同步操作。\nvoid foo() { size_t n = socket.async_read_some( buffer, fibers::yield ); // ... } 初始化函数，就是这里的async_read_some，其实现需要支持上述所有这些用途。\n为了实现这一点，异步操作必须首先指定一个完成签名（completion signature ）（或者简写为签名），该签名描述了将传递给completion handler的参数。（注意这里是异步操作指定完成签名）\n然后，异步操作的初始化函数获取完成签名、完成令牌及其内部实现，并将它们传递给 async_result 关联器特征（trait）。async_result 特征是一个自定义点，它结合这些参数先生成一个具体的completion handler（concrete completion handler），然后启动操作。\n这个下面的例子里面，completion signature是 void(error_code, size_t)。\n听上去似乎不可思议，现在让我们实践试试，使用一个分离的线程将同步操作调整为异步操作\ntemplate \u0026lt;class CompletionToken\u0026gt; auto async_read_some(tcp::socket\u0026amp; s, const mutable_buffer\u0026amp; b, CompletionToken\u0026amp;\u0026amp; token) { // 这段代码包含运行异步操作的代码，任何需要传递给async_result 特征的都得在里面给出 auto init = []( auto completion_handler, tcp::socket* s, const mutable_buffer\u0026amp; b) { // 启动一个新线程来执行操作 std::thread( []( auto completion_handler, tcp::socket* s, const mutable_buffer\u0026amp; b ) { error_code ec; size_t n = s-\u0026gt;read_some(b, ec); std::move(completion_handler)(ec, n); }, std::move(completion_handler), s, b ).detach(); }; return async_result\u0026lt; decay_t\u0026lt;CompletionToken\u0026gt;, void(error_code, size_t) \u0026gt;::initiate( init, std::forward\u0026lt;CompletionToken\u0026gt;(token), \u0026amp;s, b ); } 可以将完成令牌视为一种completion handler的原型。如果传递一个函数对象（如 lambda表达式）作为完成令牌，它已经满足completion handler的要求。async_result 主模板通过简单地将参数转发调用我们的“completion handler原型”来处理这种情况：\ntemplate \u0026lt;class CompletionToken, completion_signature... Signatures\u0026gt; struct async_result { template \u0026lt; class Initiation, completion_handler_for\u0026lt;Signatures...\u0026gt; CompletionHandler, class... Args\u0026gt; static void initiate( Initiation\u0026amp;\u0026amp; initiation, CompletionHandler\u0026amp;\u0026amp; completion_handler, Args\u0026amp;\u0026amp;... args) { std::forward\u0026lt;Initiation\u0026gt;(initiation)( std::forward\u0026lt;CompletionHandler\u0026gt;(completion_handler), std::forward\u0026lt;Args\u0026gt;(args)...); } }; 我们可以在这里看到，这个默认实现避免了拷贝所有参数，从而确保尽快初始化来实现尽可能高效。 另一方面，惰性的完成令牌（如上面use_awaitable）可能会捕获这些参数来延迟异步操作的启动。例如，一个简单的延迟令牌的实现（把异步操作打包，用于稍后的操作）看起来可能像这样：\ntemplate \u0026lt;completion_signature... Signatures\u0026gt; struct async_result\u0026lt;deferred_t, Signatures...\u0026gt; { template \u0026lt;class Initiation, class... Args\u0026gt; static auto initiate(Initiation initiation, deferred_t, Args... args) { return [ initiation = std::move(initiation), arg_pack = std::make_tuple(std::move(args)...) ](auto\u0026amp;\u0026amp; token) mutable { return std::apply( [\u0026amp;](auto\u0026amp;\u0026amp;... args) { return async_result\u0026lt;decay_t\u0026lt;decltype(token)\u0026gt;, Signatures...\u0026gt;::initiate( std::move(initiation), std::forward\u0026lt;decltype(token)\u0026gt;(token), std::forward\u0026lt;decltype(args)\u0026gt;(args)... ); }, std::move(arg_pack) ); }; } }; 3.9 Asio库元素有哪些 # RTFM https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/reference.html\ncompletion_signature概念-定义有效的完成签名形式。\ncompletion_handler_for概念-确定completion handler是否满足给定的完成签名。\nasync_result特征-将完成签名和完成令牌转换为具体的完成处理函数，并启动异步操作。\n这里多扯一句，翻译自https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/overview/core/streams.html#boost_asio.overview.core.streams.why_eof_is_an_error\nBoost Asio提供面的向流的 I/O 模型的对象满足以下一种或多种类型要求：\nSyncReadStream，在这里同步读取操作是通过一个名为read_some()的成员函数来执行的。 AsyncReadStream，其中异步读取操作是通过一个名为async_read_some()的成员函数执行的。 SyncWriteStream，在这里同步写入操作通过一个名为write_some()的成员函数来执行。 AsyncWriteStream，其中异步写操作是通过一个名为async_write_some()的成员函数来执行的。在这个函数的注释部分有提到The write operation may not transmit all of the data to the peer. Consider using the async_write function if you need to ensure that all data is written before the asynchronous operation completes. 不过，比方说TCP这种一般是有流的概念的（换言之不确定边界），可能会发生还没读完就触发对应用层的通知。\n但程序通常希望传输确切数量的字节。当出现读取不足或写入不足的情况时，程序必须重新启动操作，并持续进行，直到传输所需数量的字节为止。Boost.Asio 提供了自动执行此操作的通用函数：read()、async_read()、write()和async_write()。所以这里注意，async_write只有两种情况会停止发送，一个是全部要写入的数据发送完了，要不就是写入数据出错了\n许多常用的互联网协议是基于行的，这意味着它们具有由字符序列\u0026quot;\\r\\n\u0026quot;分隔的协议元素。asio可以使用async_read_until来对应这种情况，只需要第三个参数指定终止字符，终止符可以指定为单个char、一个std::string或一个boost::regex。\nasync_initiate函数——帮助函数，以简化如何使用async_result特征。\nassociator trait ——在Agent这个抽象层里通过关联器传播，需要满足特定的trait。\nassociated_executor特征-定义异步Agent关联的执行器。\nassociated_executor_t 模板类型，是上面这个的别名\nget_associated_executor函数\nassociated_allocator特征-定义异步Agent关联的分配器。\nassociated_allocator_t 模板类型，是上面这个的别名\nget_associated_allocator 函数\nassociated_cancellation_slot 特征-定义异步Agent关联的取消槽。\nassociated_cancellation_slot_t 模板类型，是上面这个的别名\nget_associated_cancellation_slot 函数\n3.10 高层次抽象 # 本文提出的异步模型为定义更高级别的抽象提供了基础，但这些概念的定义实际超出了本文的范围。本文的范围仅限于指定用于高层次组合异步操作是什么。\n然而，Asio库在此核心模型的基础上提供一些额外的组件，例如：\n基于此模型，暴露异步操作的IO对象，比方说套接字和计时器。\n我这个时候有个问题，就是这些IO对象对应ASIO的异步模型里面的什么？实际上啥也不对应。IO对象是构建异步Agent的“原子组件”，通过组合多个IO对象的异步操作，形成完整的业务逻辑。也就是说IO对象提供了我们组成ASIO异步模型的抓手。所以不需要疑惑这些玩意是啥\n具体执行器，比方说io_context执行器、thread_pool执行器，还有比方说用来保证completion handler不会并发执行的strand adapter。\n我个人觉得io_context是一个非常奇特的存在，它实际上是上下文，不是单纯的executor：比方说strand就可以通过io_context获得。参考https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/tutorial/tuttimer5.html\nprinter(boost::asio::io_context\u0026amp; io)\r: strand_(boost::asio::make_strand(io)),\rtimer1_(io, boost::asio::chrono::seconds(1)),\rtimer2_(io, boost::asio::chrono::seconds(1)),\rcount_(0)\r{ 这里的概念建议参考Asio的官方文档，https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/overview/basics.html\none I/O execution context, such as an boost::asio::io_context object, boost::asio::thread_pool object, or boost::asio::system_context. This I/O execution context represents your program\u0026rsquo;s link to the operating system\u0026rsquo;s I/O services.\n关于Strand\nStrand被定义为事件处理程序的严格顺序调用（即没有并发调用）。链的使用允许在多线程程序中执行代码而无需显式锁定（例如使用互斥锁）。strand可以显式或者非显式的定义，比方说\n仅从一个线程调用 io_context::run()意味着所有事件处理程序在隐式执行链中执行，因为 io_context 保证处理程序仅从 run()内部被调用，毕竟只有一个线程，所以同时只有一个在运行 如果与连接相关联的一系列异步操作只有单链条，（比方说在像 HTTP 这样的半双工协议实现中），不可能并发执行处理程序。这是一个隐式执行链。 显式执行链是strand\u0026lt;\u0026gt;或io_context::strand的实例。所有事件处理函数对象都需要使用boost::asio::bind_executor()绑定到执行链，或者通过执行链对象进行发布/调度。 在组合异步操作的情况下，例如async_read()或async_read_until()，如果一个completion handler通过一个 strand，那么所有其他处于中间态的completion handler也应该通过相同的 strand。这是为了确保对调用者和组合操作（比方说async_read()，调用者可以close()以取消操作，同时async_read又不会出现和当前操作出现冲突）之间共享的任何对象（比方说Socket）进行线程安全访问。\n使用get_associated_executor来获取对应的executor\nboost::asio::associated_executor_t\u0026lt;Handler\u0026gt; a = boost::asio::get_associated_executor(h); 如果定义这种类型的executor需要定义嵌套类型executor_type和成员函数get_executor()针对特定的处理程序类型进行定制：\n促进不同组合机制的完成令牌，如协程、纤程、future和deferred操作。\n多扯一句，想调试的话，可以定义BOOST_ASIO_ENABLE_HANDLER_TRACKING。具体参考https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/overview/core/handler_tracking.html，就不多赘述了\n对C++协程的高层次支持，将执行器和取消槽结合到一起，以便于协调并发异步Agent的coordination。\n4 例子 # 我建议这部分好好读一读，理解一下，尤其是里面的逻辑或和逻辑与运算符，非常的牛逼，非常的好\n关于Asio对于C++ 20协程的支持，有这个网页https://think-async.com/Asio/asio-1.22.0/doc/asio/overview/core/cpp20_coroutines.html\nAsio对于C++ 20的协程支持通过 awaitable 类模板, use_awaitable completion token, co_spawn()\nco_spawn接受三个参数：\nexecutor that determines the context in which the coroutine is permitted to execute awaitable\u0026lt;R\u0026gt;, that is the result of the coroutine\u0026rsquo;s entry point function 如果觉得使用抛异常的方式不好，可以使用 experimental::as_tuple or redirect_error completion token adapters。就可以这样子调用代码\nstd::tuple\u0026lt;asio::error_code, std::size_t\u0026gt; result = co_await socket.async_read_some(...) 关于Asio的协程，有个好玩的地方。\n逻辑运算符 || 和 \u0026amp;\u0026amp; 已针对 awaitable\u0026lt;\u0026gt; 进行了重载，以便协程可以轻松并行。\n当使用 \u0026amp;\u0026amp; 进行等待时，co_await 表达式会等待两个操作都成功完成。作为一种“短路”求值，如果一个操作因异常而失败，另一个操作将立即被取消。对于这种组合起来的多个co_await表达式，需要使用tuple来获取每个的结果\nstd::tuple\u0026lt;std::size_t, std::size_t\u0026gt; results = co_await ( async_read(socket, input_buffer, use_awaitable) \u0026amp;\u0026amp; async_write(socket, output_buffer, use_awaitable) ); 当使用 || 进行等待时，co_await 表达式会等待，直到其中一个操作成功。作为一种“短路”求值，如果一个操作成功且未抛出异常，另一个操作将立即被取消。这种的结果需要使用variant获取结果\nstd::variant\u0026lt;std::size_t, std::monostate\u0026gt; results = co_await ( async_read(socket, input_buffer, use_awaitable) || timer.async_wait(use_awaitable) ); 使用的时候需要加入这么几句话\n#include \u0026lt;asio/experimental/awaitable_operators.hpp\u0026gt; using namespace asio::experimental::awaitable_operators; 第一个例子是每个连接独占一个线程的echo server，和asio基于协程的代码实现\n#include \u0026lt;asio.hpp\u0026gt; using asio::buffer; using asio::ip::tcp; void echo(tcp::socket s) { try { char data[1024]; for (;;) { std::size_t n = s.read_some( buffer(data) ); write( s, buffer(data, n) ); } } catch (const std::exception\u0026amp; e) { } } void listen(tcp::acceptor a) { for (;;) { std::thread( echo, a.accept() ).detach(); } } int main() { asio::io_context ctx; listen({ctx, {tcp::v4(), 55555}}); } #include \u0026lt;asio.hpp\u0026gt; using asio::awaitable; using asio::buffer; using asio::detached; using asio::ip::tcp; using asio::use_awaitable; awaitable\u0026lt;void\u0026gt; echo(tcp::socket s) { try { char data[1024]; for (;;) { std::size_t n = co_await s.async_read_some( buffer(data), use_awaitable ); co_await async_write( s, buffer(data, n), use_awaitable ); } } catch (const std::exception\u0026amp; e) { } } awaitable\u0026lt;void\u0026gt; listen(tcp::acceptor a) { for (;;) { co_spawn( a.get_executor(), echo(co_await a.async_accept(use_awaitable)), detached ); } } int main() { asio::io_context ctx; co_spawn( ctx, listen({ctx, {tcp::v4(), 55555}}), detached ); ctx.run(); } 下一个示例是来自简单TCP套接字代理的片段。它演示了协程如何组合取消一方面优雅的协调各种异步Agent，另一部分支持高效的取消超时\nconstexpr auto use_nothrow_awaitable = as_tuple(use_awaitable); awaitable\u0026lt;void\u0026gt; transfer(tcp::socket\u0026amp; from, tcp::socket\u0026amp; to, steady_clock::time_point\u0026amp; deadline) { std::array\u0026lt;char, 1024\u0026gt; data; for (;;) { deadline = std::max(deadline, steady_clock::now() + 5s); auto [e1, n1] = co_await from.async_read_some(buffer(data), use_nothrow_awaitable); if (e1) co_return; auto [e2, n2] = co_await async_write(to, buffer(data, n1), use_nothrow_awaitable); if (e2) co_return; } } awaitable\u0026lt;void\u0026gt; watchdog(steady_clock::time_point\u0026amp; deadline) { steady_timer timer(co_await this_coro::executor); auto now = steady_clock::now(); while (deadline \u0026gt; now) { timer.expires_at(deadline); co_await timer.async_wait(use_nothrow_awaitable); now = steady_clock::now(); } } awaitable\u0026lt;void\u0026gt; proxy(tcp::socket client, tcp::endpoint target) { tcp::socket server(client.get_executor()); steady_clock::time_point deadline{}; auto [e] = co_await server.async_connect(target, use_nothrow_awaitable); if (!e) { co_await ( transfer(client, server, deadline) || transfer(server, client, deadline) || watchdog(deadline) ); } } awaitable\u0026lt;void\u0026gt; listen(tcp::acceptor\u0026amp; acceptor, tcp::endpoint target) { for (;;) { auto [e, client] = co_await acceptor.async_accept(use_nothrow_awaitable); if (e) break; auto ex = client.get_executor(); co_spawn(ex, proxy(std::move(client), target), detached); } } 最后，有一段代码片段展示了按名称连接的实现。这个基于协程的算法尝试并行连接多个主机。一旦其中一个连接成功，其余操作将自动取消。\ntcp::socket selected(std::variant\u0026lt;tcp::socket, tcp::socket\u0026gt; v) { switch (v.index()) { case 0: return std::move(std::get\u0026lt;0\u0026gt;(v)); case 1: return std::move(std::get\u0026lt;1\u0026gt;(v)); default: throw std::logic_error(__func__); } } awaitable\u0026lt;tcp::socket\u0026gt; connect(ip::tcp::endpoint ep) { auto sock = tcp::socket(co_await this_coro::executor); co_await sock.async_connect(ep, use_awaitable); co_return std::move(sock); } awaitable\u0026lt;tcp::socket\u0026gt; connect_range( tcp::resolver::results_type::const_iterator first, tcp::resolver::results_type::const_iterator last) { assert(first != last); auto next = std::next(first); if (next == last) co_return co_await connect(first-\u0026gt;endpoint()); else co_return selected(co_await(connect(first-\u0026gt;endpoint()) || connect_range(next, last))); } awaitable\u0026lt;tcp::socket\u0026gt; connect_by_name(std::string host, std::string service) { auto resolver = tcp::resolver(co_await this_coro::executor); auto results = co_await resolver.async_resolve(host, service, use_awaitable); co_return co_await connect_range(results.begin(), results.end()); } 5 # Folly 的异步模式 # CPP Net Standard Sender \u0026amp; Receiver # 草案是这个https://wg21.link/P2300R10。我建议有能力还是直接阅读草案吧。下面的很多内容我都只会节选一部分，所以序号看起来是跳跃的。如果看起来有一些困难，我觉得直接阅读https://www.bilibili.com/video/BV1WrRsYWEjX，更为合适\n1.1 For What？ # 如今，C++软件越来越多地采用异步和并行方式，这种趋势很可能会持续下去。异步和并行性无处不在，从处理器硬件接口到网络、文件 I/O、图形用户界面再到加速器。每个 C++领域和每个平台都需要处理异步和并行性，从科学计算到视频游戏再到金融服务，从最小的移动设备到你的笔记本电脑再到世界上最快的超级计算机中的图形处理器。\n虽然 C++标准库有丰富的并发原语（std::atomic、std::mutex、std::counting_semaphore 等）和较低级别的构建块（std::thread 等），但我们缺乏 C++程序员迫切需要的异步和并行的标准词汇和框架。std::async/std::future/std::promise，作为 C++11 中用于异步的预期特性，效率低下、难以正确使用，并且通用性严重不足，使其在许多情况下无法使用。我们在 C++17 中向 C++标准库引入了并行算法，虽然它们是一个很好的开始，但它们本质上都是同步的，并且不可组合。\n本文提出了一个基于三个关键抽象（调度器、发送器和接收器）和一组可定制异步算法的标准 C++异步模型。\n1.2 前置 # 具有可组合性和通用性，允许用户编写可用于许多不同类型执行资源的代码。 将常见的异步模式封装在可定制和可重用的算法中，这样用户就不必自己去发明。 通过构造使正确性更容易实现（我没看懂这句话啥意思） 支持执行资源和执行Agent的多样性，因为并非所有执行Agent都是平等创建的；有些能力较弱，但并非不重要。 允许执行资源对所有内容进行定制，包括转移到其他执行资源，但不要求执行资源定制所有内容。——关注所有合理的用例、领域和平台。——错误必须传播，但错误处理不能成为负担。——支持取消，这不是错误。——对事物在哪里执行有清晰简洁的答案。——能够异步管理和终止对象的生命周期。 如何理解三种概念？\nSender == lazy value to be compute。核心就是sender，一边传递着sender Receiver == continuation or callback Scheduler == handle to compute resource CPP Standard \u0026amp; Asio 对比 # CPP Coroutines # 如果希望看看简单好理解的教学，看这个\nhttps://theshoemaker.de/posts/yet-another-cpp-coroutine-tutorial 协程的概念基本每个语言都有，C++的稍微需要多说几句：\nC++协程是一种可以暂停执行以便稍后恢复的函数（实际上就这一句话）。协程是无栈的：它们通过返回给调用者来暂停执行，而恢复执行所需的数据则与栈分开存储。这使得顺序代码能够异步执行（例如，在无需显式回调的情况下处理非阻塞I/O），并且还支持对延迟计算的无限序列等的算法和其他用途。 用户用的时候需要自己实现promise类型 \u0026amp; 包裹promise类型的返回值（这个一般还得有个能返回awaitable的co_await operator重载）。 还有另外一点需要注意，coroutine是会在执行完成后流程继续，但是当返回时是否保证执行完成是未必的（我这里主要想说的是网络里面的send事件，不代表全部发送完成），所以如果要求某个执行完成可能需要在外面再包个while循环啥的\n判断C++的协程说白了就三种表达式\nco_await表达式——暂停执行，直到恢复执行。 co_yield表达式——暂停执行并返回一个值。 co_return语句 —— 完成执行并返回一个值。 这里注意，协程必须是明确的，不能使用可变参数、普通的返回语句或占位符返回类型（auto 或概念）。立即求值函数、常量表达式函数、构造函数、析构函数以及主函数不能是协程。\n协程的原理 # 记这三个东西实际上用处不大，重点是理解这东西存在的意义。C++把coroutine frame重命名为coroutine state，而且在这三个玩意后面隐藏了太多的东西，导致阅读起来非常费劲。\nC++用户侧协程需要什么：\nWrapper_t， wrapper_t存储着要和外界交互的数据 promise_type awaitbale type for co_await Task是执行的任务，没有返回值。\nGenerator生成内容，并返回结果。\n简单来说就是coroutine frame存储着用户用到，用不到的东西。这里的东西包括promise对象\npromise对象，每个协程都与promise 对象相关联，协程内部对该对象进行操作以提交其结果或异常。这个promise与std::promise毫无关系。一般我们实现的时候，这个东西都自己写，是某个类型的子类型。而最外层的子类型，既不是协程句柄（handle）也不是协程状态（coroutine state）本身，而是一个协程的返回值包装器，它的核心作用是让协程的调用者能够与协程交互（例如等待结果、恢复执行、检查状态等）。 协程句柄，在协程外部使用“这个非拥有句柄”进行操作。用于恢复协程的执行或销毁协程帧。我看的时候不理解这个handle和promise的对象是什么关系？这里多说一句，就是可以从promise能够获取handle。handle也可以跟promise联系起来，从promise拿到东西 协程状态coroutine state实际上也就是coroutine frame，这是内部的（实际上就是说用户是看不到的）、动态分配的存储（除非分配被优化掉），该对象包含 promise对象、可以理解为通过frame-\u0026gt;promise.get_return_object()获取，就是在frame里面保存 参数（全部按值复制）、 (这里要注意一个事情，promise对象和参数是没有直接关系的） 当前挂起点的某种表示，以便恢复运行时知道从何处继续，销毁时知道哪些局部变量在作用域内 生命周期跨越当前挂起点的局部变量和临时变量。 当协程开始执行时，它执行以下操作：\n使用operator new分配协程状态对象。 将所有函数参数复制到协程状态：按值传递的参数被移动或复制，按引用传递的参数保持为引用（因此，如果在被引用对象的生命周期结束后恢复协程，可能会变成悬空引用 —— 示例见下文）。 调用promise对象的构造函数。如果承诺类型有一个接受所有协程参数的构造函数，则使用复制后的协程参数调用该构造函数。否则，调用默认构造函数。 调用promise.get_return_object()并将结果保存在局部变量中。当协程首次挂起时，该调用的结果将返回给调用者。在此步骤及之前抛出的任何异常都会传播回调用者，而不会放入promise对象中。 调用promise.initial_suspend()并等待其结果。典型的Promise类型要么返回std::suspend_always（用于延迟启动的协程），要么返回std::suspend_never（用于立即启动的协程）。 当co_await promise.initial_suspend()恢复时，开始执行协程体。 当协程到达暂停点时\n如有必要，在隐式转换为协程的返回类型后，先前获得的返回对象将返回给调用者/恢复者。 当协程到达co_return语句时，它会执行以下操作：\n表达式为co_return; \u0026amp; co_return expr; （其中expr的类型为void），调用promise.return_void()； 对于co_return expr; （其中expr的类型为非void），调用promise.return_value(expr)； 以与创建顺序相反的顺序销毁所有具有自动存储期的变量。 调用promise.final_suspend() 并co_await结果。从协程末尾退出等同于co_return; ， 执行到协程末尾等同于co_return，但如果在Promise的作用域中找不到return_void的声明，则行为未定义。\n在其函数体中没有任何定义关键字的函数不是协程，无论其返回类型如何，如果返回类型不是（可能带有cv限定符的）void，则从末尾退出会导致未定义行为。\n协程的动态分配 # 协程状态是通过非数组形式的new运算符动态分配的。\n如果Promise类型定义了类级别的替换函数，将使用该函数，否则将使用全局的new运算符。\n如果Promise类型定义了带额外参数的new运算符的定位形式，且这些参数与一个参数列表匹配，其中第一个参数是请求的大小（类型为std::size_t），其余参数是协程函数的参数，那么这些参数将被传递给new运算符（这使得协程可以使用前导分配器约定）。\n如果满足以下条件，对new运算符的调用可以被优化掉（即使使用了自定义分配器）：\n协程状态的生命周期严格嵌套在调用者的生命周期内； 协程帧的大小在调用点是已知的。 在这种情况下，协程状态会嵌入到调用者的栈帧中（如果调用者是个function，很合理，因为对于普通函数栈是会一直存在直到推出），或者嵌入到调用者的协程状态中（如果调用者是协程，也很合理，协程嵌套协程嘛）。\n如果分配失败，协程会抛出std::bad_alloc，除非Promise类型定义了成员函数Promise::get_return_object_on_allocation_failure()。如果定义了该成员函数，分配将使用new运算符的不抛出异常形式，并且在分配失败时，协程会立即将从Promise::get_return_object_on_allocation_failure()获得的对象返回给调用者，例如：\n看看关键的数据和表达式 # 这里我建议还是看看https://theshoemaker.de/posts/yet-another-cpp-coroutine-tutorial，这个感觉比cppreference说的更好理解，毕竟不会上来就塞你一堆概念，而且重点放到了Task里面\nPromise # co_await # 这里需要注意下，corountine不一定是awaitable的，这样子\n一元运算符 co_await 会暂停协程并将控制权返回给调用方。co_await对应的地方实际上很多时候都执行的是一些根本不知道啥时候执行完成的东西，所以这里有个问题，怎么知道await对象是不是执行完了呢？当第一次执行到co_await的时候，通过awaiter对象的await_ready判断（这里需要重点理解awaitable对象，也就是awaiter是我们需要重点实现的）。但是后面恢复的时候，就不管了。co_await 的核心设计目标是实现异步操作的挂起与恢复，而不是直接暴露“某个暂停点是否完成”的状态。要判断 co_await 暂停的操作是否完成，需依赖 awaitable 对象内部的状态管理。\n部分实现是将awaiter的await_suspend函数里面，把要执行的东西做了，然后调用handle.resume()。handle.resume()会调用awaiter的await_resume函数。\n格式为 co_await expr\nco_await 表达式只能出现在常规函数体（包括 lambda 表达式的函数体）中可能被求值的表达式内，不能出现在\n在处理程序中，在声明语句中（除非它出现在该声明语句的初始化器中），在初始化语句（见 if、switch、for 和 [[../range-for|范围 for]]）的简单声明中（除非它出现在该初始化语句的初始化器中），在默认实参中，或者在具有静态或线程存储期的块作用域变量的初始化器中。 执行1：首先，表达式按如下方式转换为可等待对象（awaitable）：\n如果表达式由初始挂起点、最终挂起点或yield表达式生成，则可等待对象即为该表达式本身。\n否则，如果当前协程的Promise类型具有成员函数await_transform，那么可等待对象为promise.await_transform(expr)。\n否则，可等待对象即为表达式 expr，保持原样。\n执行2：然后，获取等待器（awaiter ）对象（从这里我们就知道了，实际上co_await是返回了一个awaiter对象，并且在awaiter对象上面执行操作），如下所示：\n如果对co_await操作符的重载解析给出单个最佳重载，等待器就是该调用的结果： co_await的对象，重载了co_await运算符，换言之有awaitable.operator co_await()，对于非成员重载为operator co_await(static_cast\u0026lt;Awaitable\u0026amp;\u0026amp;\u0026gt;(awaitable))。否则，如果重载解析找不到co_await操作符，等待器就是awaitable本身。 否则，如果重载解析不明确，程序格式错误。如果上述表达式是一个纯右值，等待器对象是由此具体化的临时对象。 否则，如果上述表达式是一个左值，等待器对象就是它所引用的对象。 执行3：然后，调用awaiter.await_ready()（如果已知结果已准备好或可以同步完成，这是一种避免挂起开销的捷径）。如果其结果在上下文转换为bool类型后为false，则协程被挂起（其协程状态填充有局部变量和当前挂起点）。调用awaiter.await_suspend(handle)，一些具体执行的操作可以在这里执行。其中handle是表示当前协程的协程句柄，这句话的理解实际上很乱，说白了就是谁调用对应awaitable对象，就是谁的handle。假设如果co_await的expr是个协程，那么调用co_await expr这句话的协程，它的句柄会被放到返回Awaiter::await_suspend里面。在该函数内部，通过该句柄可以观察到被挂起的协程状态，并且该函数有责任在某个执行器上调度它恢复执行，或者将其销毁（返回false视为调度）。\n如果await_suspend返回void，控制权立即返回给当前协程的调用者/恢复者（此协程仍保持挂起状态），\n否则，如果await_suspend返回bool， 值true将控制权返回给当前协程的调用者/恢复者， 值false恢复当前协程。 如果await_suspend返回另一个协程的协程句柄，则通过调用handle.resume()恢复该句柄（注意这可能最终导致当前协程恢复）。\n如果await_suspend抛出异常，捕获该异常，恢复协程，并立即重新抛出该异常。\n执行4 ：最后，调用awaiter.await_resume()（无论协程是否被挂起），其结果就是整个co_await expr表达式的结果。如果协程在co_await表达式中被挂起，之后又被恢复，恢复点就在调用awaiter.await_resume()之前。请注意，协程在进入awaiter.await_suspend()之前已完全挂起。它的句柄可以与另一个线程共享，并在await_suspend()函数返回之前恢复。（请注意，默认的内存安全规则仍然适用，因此如果协程句柄在没有锁的情况下跨线程共享，等待器至少应使用释放语义，恢复者至少应使用获取语义。）例如，协程句柄可以放在一个回调函数中，安排在异步I/O操作完成时在线程池上运行。在这种情况下，由于当前协程可能已被恢复并因此执行了等待器对象的析构函数，在await_suspend()在当前线程上继续执行的同时，await_suspend()应将*this视为已销毁，并且在将句柄发布到其他线程后不应再访问它。\n结尾 # 唉，尴尬\n","date":"2025 年 1 月 24 日","externalUrl":null,"permalink":"/posts/asio/","section":"Posts","summary":"","title":"2025-01-24-CPP Net Standard \u0026 The Asio asynchronous model","type":"posts"},{"content":" 微软的Proxy学习 # 这几天看下https://github.com/microsoft/proxy，学习下如何避免使用继承的情况下，高效方便地使用C++多态（ polymorphic programming）的方法。先对着README.md看看怎么阅读这个源代码（实际上就是翻译了一下README.md)。\n用法展示 # 怎么使用Proxy库？这里不展示整个的用法了，只把抽象那块的东西抽出来：\n最关健的用法如下所示，简单来说就是需要组合一些行为（表达式expression）构建出来具体的外观模式\n// 定义一个facade type: Formattable, struct Formattable : pro::facade_builder ... ::build {} 具体的pro::facade_builder请参考https://microsoft.github.io/proxy/docs/ProFacade.html，是Proxy库提供的运行时抽象（这里稍微动一下脑子理解下，代码是compile time的时候制定了runtime满足什么行为）。\n相应的解释请看\npro::facade_builder: 提供在编译时构建外观类型（模式）的能力。 support_format: 相当于concept的概念，支持某种功能 (via standard formatting functions). build: 将上下文构建为具体的facade模式 让我们再看另一个例子struct Streamable : pro::facade_builder ... ::build {}: 定义一个 Streamable 外观模式,相应的功能为\npro::facade_builder: 准备定义另一种外观模式. add_convention: 添加调用约定，调用约定由dispatch和overload构成。这里说起来有一些拗口：什么是dispatch？什么是overload？overload好理解，可以理解为函数签名，就是具体函数的形式。dispatch呢？这里我个人认为就是功能，名字，用法之类的抽象。这里我觉得简单理解为concept就可以了 pro::operator_dispatch\u0026lt;\u0026quot;\u0026lt;\u0026lt;\u0026quot;, true\u0026gt;: Specifies a dispatch for operator \u0026lt;\u0026lt; expressions where the primary operand (proxy) is on the right-hand side (specified by the second template parameter true). Note that polymorphism in the \u0026ldquo;Proxy\u0026rdquo; library is defined by expressions rather than member functions, which is different from C++ virtual functions or other OOP languages. std::ostream\u0026amp;(std::ostream\u0026amp; out) const: 调用约定里面的overload，函数签名部分，和std::move_only_function. 一样的。const 指明这个函数是 const的，不会改动对象内部. build: 将上下文构建为具体的facade模式. .\n如果不清楚到底什么是facade type，可以参考这个解释：\n\u0026ldquo;Facade\u0026rdquo; 是一种软件设计模式，通常被称为 \u0026ldquo;外观模式\u0026rdquo;。这种设计模式提供了一个更高层次的接口，用于简化复杂系统的使用。Facade 模式的核心思想是为子系统中的一组接口提供一个统一的接口，从而让这个子系统更容易使用。\n在软件开发中，Facade 模式的典型特征包括：\n简化接口：通过提供一个简单的接口来隐藏系统的复杂性，从而减少使用者与系统之间的交互复杂度。 分离代码：将客户端与复杂的类库或 API 分离，使客户端代码更简洁，减少对外部复杂系统的依赖。 提高可维护性：通过引入 Facade，可以在不影响客户端的情况下更改子系统。 降低耦合度：客户端与子系统的耦合度降低，因为它们通过 Facade 进行交互，而不是直接依赖子系统的具体实现。 Facade 模式常用于提供简单的接口来处理与库、框架或一组复杂类的交互，是一种结构型设计模式，有助于提高系统的模块化和可维护性。\n除了刚才提到的一些，还有一些其他有用的feature\n重载：facade_builder::add_convention比上面展示的两个例子功能更强大。它可以接受任意数量的重载类型（严格来说，任何满足ProOverloadhttps://microsoft.github.io/proxy/docs/ProOverload.html要求的类型），在调用proxy时执行对函数执行重载解析。 外观模式组合： facade_builder::add_facade允许不同抽象的灵活组合。 概念：为了便于使用“proxy”进行模板编程，从facade类型中导出了三个概念。即，proxiable、proxiable_target和inplace_proxiable_target。 分配器感知： 函数模板allocate_proxy具备从任何自定义分配器的值创建一个proxy对象的能力。在 C++11 中，std::function和std::packaged_task的构造函数接受指定自定义分配器的功能以进行性能调优，但在 C++17 中这些被移除，因为“语义不明确，并且在未存储类型信息的上下文中，后续复制赋值期间如何再次拿到类型信息的技术问题”。这些问题不适用于allocate_proxy 可配置的约束： facade_builder为约束配置提供全面支持，包括内存布局（通过restrict_layout）、可复制性（通过support_copy）、可重定位性（通过support_relocation）以及可析构性（通过support_destruction)\u0026lt;/ 反射：proxy支持基于类型的编译时反射，这个反射支持进行运行时查询。有关更多详细信息，请参考facade_builder::add_reflection和函数模板proxy_reflect。 非接管（管理）代理：尽管proxy可以像智能指针一样有效地管理对象的生命周期，但有时我们希望对其进行解引用传递再传递到非接管上下文。3.2.0 版本以来，将这种能力作为扩展实现。有关更多详细信息，请参考函数模板make_proxy_view 运行时类型信息（RTTI）：运行时类型信息（RTTI，run-time-type-information）自上世纪以来在 C++中提供了“较弱”的反射能力。虽然它不像其他一些语言中的反射那么强大（例如 C#中的 Object.GetType()或 Java 中的 Object.getClass()），但它在运行时为类型安全地强制类型转换提供了基本的基础设施。自 3.2 版本以来，“针对proxy的运行时类型信息”已作为扩展实现，并允许用户为每个外观模式定义决定是否实现rtti。有关更多详细信息，请参考facade_builder::support_rtti。 共享和弱所有权：虽然proxy可以从std::shared_ptr创建，但自 3.3.0 起的拓展支持用户可以更高效地创建具有共享和弱所有权的proxy对象。更多详细信息请参考函数模板make_proxy_shared、allocate_proxy_shared、别名模板weak_proxy 弱dispatch：当一个对象未实现调用约定，而我们不希望它构建的时候直接触发编译错误导致构建失败时，可以指定一个在调用时抛出异常的weak_dispatch。 一些proxy支持的定义的宏\nIn addition to the operator expressions demonstrated in the previous examples, the library supports almost all forms of expressions in C++ and can make them polymorphic. Specifically,\nmacro PRO_DEF_MEM_DISPATCH: Defines a dispatch type for member function call expressions, providing accessibility as member functions. macro PRO_DEF_FREE_DISPATCH: Defines a dispatch type for free function call expressions, providing accessibility as free functions. macro PRO_DEF_FREE_AS_MEM_DISPATCH: Defines a dispatch type for free function call expressions, providing accessibility as member functions. class template pro::operator_dispatch: Dispatch type for operator expressions. class explicit_conversion_dispatch (aka. conversion_dispatch) and class implicit_conversion_dispatch: Dispatch type for conversion expressions. 看看源码 # 看看这个https://zhuanlan.zhihu.com/p/22307747744，理解一些基础概念\n直接阅读https://deepwiki.com/microsoft/proxy，岂不是更妙？\n想解释怎么调用到的具体函数，就是dispatch怎么实现的？\n简答来说就是facade类型用来添加具体的关键用法（加met）a，proxy包裹facade，作为容器（pro::proxy\u0026lt;Facade\u0026gt;）\n三个关键的数据结构，注意这几个看完了，最后才能全体拼起来。拼起来之前先看几个helper的函数\ntemplate \u0026lt;class F\u0026gt; struct proxy_helper { // get meta static inline const auto\u0026amp; get_meta(const proxy\u0026lt;F\u0026gt;\u0026amp; p) noexcept { assert(p.has_value()); return *p.meta_.operator-\u0026gt;(); } // reset meta static inline void reset_meta(proxy\u0026lt;F\u0026gt;\u0026amp; p) noexcept { p.meta_.reset(); } // get_ptr是做类型转换的关键，类型转换调用就是在这里实现的 template \u0026lt;class P, qualifier_type Q\u0026gt; static add_qualifier_t\u0026lt;P, Q\u0026gt; get_ptr(add_qualifier_t\u0026lt;proxy\u0026lt;F\u0026gt;, Q\u0026gt; p) { if constexpr (std::is_same_v\u0026lt;P, proxy\u0026lt;F\u0026gt;\u0026gt;) { return std::forward\u0026lt;add_qualifier_t\u0026lt;P, Q\u0026gt;\u0026gt;(p); } else { return static_cast\u0026lt;add_qualifier_t\u0026lt;P, Q\u0026gt;\u0026gt;( *std::launder(reinterpret_cast\u0026lt;add_qualifier_ptr_t\u0026lt;P, Q\u0026gt;\u0026gt;(p.ptr_))); } } }; 接下来看下三个关键的数据结构\nThe invocation system uses:\ncomposite_meta: Combines multiple invocation metadata into a single structure invocation_meta: Contains dispatch information for specific method signatures meta_ptr: A pointer to compile-time generated metadata about implementations。报在pro::proxy\u0026lt;Facade\u0026gt;里面， 按照上面的顺序，来看看到底这三个是什么东西，先看composite_meta。这个需要先看这几个的定义\n// 可以理解为type_identity\u0026lt;T\u0026gt;就是类型T（就是别名），只不过编译器不会试图主动优先推导被std::type_identity_t\u0026lt;T\u0026gt;所遮蔽的类型，而优先推导T为何种类型，然后看看带入能不能合适（再推导std::type_identity_t\u0026lt;T\u0026gt;代表何种类型），从而避免了冲突 std::type_identity // 类型定义的终点，实际上对应于迭代的终点，这里recursive_reduction::就是类型O template \u0026lt;template \u0026lt;class, class\u0026gt; class R, class O, class... Is\u0026gt; struct recursive_reduction : std::type_identity\u0026lt;O\u0026gt; {}; // 从这里就可以理解了，R是template template，这里recursive_reduction会不断地将O和I类型传递到R里面，并且新生成的O是调用的结果。Is...里面再去掉刚才床底的I template \u0026lt;template \u0026lt;class, class\u0026gt; class R, class O, class I, class... Is\u0026gt; struct recursive_reduction\u0026lt;R, O, I, Is...\u0026gt; : recursive_reduction\u0026lt;R, R\u0026lt;O, I\u0026gt;, Is...\u0026gt; {}; // 实际上是个简写，对应于上面的recursive_reduction最终的类型 template \u0026lt;template \u0026lt;class, class\u0026gt; class R, class O, class... Is\u0026gt; using recursive_reduction_t = typename recursive_reduction\u0026lt;R, O, Is...\u0026gt;::type; // 可以理解为萃取，固定了template template R和参数包Args以后，只需要传递O \u0026amp; I就能调用了，算个快捷写法 template \u0026lt;template \u0026lt;class...\u0026gt; class R, class... Args\u0026gt; struct reduction_traits { template \u0026lt;class O, class I\u0026gt; using type = typename R\u0026lt;Args..., O, I\u0026gt;::type; }; 依赖的东西搞完了，看看怎么组成的composite_meta\n// 原地构建，实际上 in_place_type_t template \u0026lt;class... Ms\u0026gt; struct composite_meta_impl : Ms... { // composite_meta_impl的默认构造啥也没干 constexpr composite_meta_impl() noexcept = default; // composite_meta_impl实际上是让继承的参数包（Ms...)的每个构造函数都对着P做原地构建 template \u0026lt;class P\u0026gt; constexpr explicit composite_meta_impl(std::in_place_type_t\u0026lt;P\u0026gt;) noexcept : Ms(std::in_place_type\u0026lt;P\u0026gt;)... {} }; // meta_reduction对于两个类型的情况，实际上是前一个类型 template \u0026lt;class O, class I\u0026gt; struct meta_reduction : std::type_identity\u0026lt;O\u0026gt; {}; // meta_reduction如果第一个参数命中传递composite_meta_impl\u0026lt;Ms...\u0026gt;，且第二个参数不为空，实际上就是composite_meta_impl\u0026lt;Ms..., I\u0026gt;类型 template \u0026lt;class... Ms, class I\u0026gt; requires(!std::is_void_v\u0026lt;I\u0026gt;) struct meta_reduction\u0026lt;composite_meta_impl\u0026lt;Ms...\u0026gt;, I\u0026gt; : std::type_identity\u0026lt;composite_meta_impl\u0026lt;Ms..., I\u0026gt;\u0026gt; {}; // 两个都是composite_meta_impl，那么就合并为一个composite_meta_impl template \u0026lt;class... Ms1, class... Ms2\u0026gt; struct meta_reduction\u0026lt;composite_meta_impl\u0026lt;Ms1...\u0026gt;, composite_meta_impl\u0026lt;Ms2...\u0026gt;\u0026gt; : std::type_identity\u0026lt;composite_meta_impl\u0026lt;Ms1..., Ms2...\u0026gt;\u0026gt; {}; // 这里我们就拿到了composite_meta的定义了简单解释下面的含义就是，对于传递的参数包... Ms，使用 // 1 先看reduction_traits\u0026lt;meta_reduction\u0026gt;::template type，对应于reduction_traits只传递了template template R，还缺两个类型。 // 2 recursive_reduction_t调用的三个参数，分别对应R, O, Is...。其中reduction_traits\u0026lt;meta_reduction\u0026gt;::template type对应于需要传递两个模板参数的template \u0026lt;class, class\u0026gt; class R，O就是composite_meta_impl\u0026lt;\u0026gt;，而Ms...就是Is... 。所以 // 3 这段composite_meta就是对Ms不断地调用meta_reduction，拼接为一个composite_meta_impl继承Ms...,而且把每个函数拍扁 template \u0026lt;class... Ms\u0026gt; using composite_meta = recursive_reduction_t\u0026lt;reduction_traits\u0026lt; meta_reduction\u0026gt;::template type, composite_meta_impl\u0026lt;\u0026gt;, Ms...\u0026gt;; 看上面的代码的时候，我实际上有个问题，干嘛非得绕着么一大圈，不直接让composite_meta_impl继承所有的Ms\u0026hellip;完事呢？\n有几个点：\n如果直接继承 Ms...，当 Ms... 中包含嵌套的 composite_meta_impl 时，会导致多层继承结构。例如：\nusing Inner = composite_meta_impl\u0026lt;B, C\u0026gt;; using Outer = composite_meta_impl\u0026lt;A, Inner, D\u0026gt;; 此时，Outer 的基类结构是 A, Inner, D，而 Inner 的基类又是 B, C。这会形成嵌套结构：\nOuter -\u0026gt; A -\u0026gt; Inner -\u0026gt; B -\u0026gt; C -\u0026gt; D 但通过 meta_reduction 和递归折叠，代码会将 Inner 展开，最终生成：\ncomposite_meta_impl\u0026lt;A, B, C, D\u0026gt; 基类直接继承所有类型，结构扁平化：\nOuter -\u0026gt; A -\u0026gt; B -\u0026gt; C -\u0026gt; D 因为拍平了，所以调用具体的元素起来就会方便不少。\n避免二义性，避免因为不同层级的元素具备有同名成员，可能引发的二义性错误。\n总结，好处：\n扁平化结构：无论输入类型是否嵌套，最终结果均为单层继承。（看到下面就明白了为啥必须得扁平化了，因为有继承自composite_meta_impl) 统一处理逻辑：无论是单个类型还是复合类型，均通过同一套规则合并。 可扩展性：若未来需要修改合并逻辑（例如过滤某些类型），只需调整 meta_reduction 的特化规则，无需改动外部代码。 invocation_meta\ninvocation_meta只有一个dispatcher_type，这个里面就会看到我们是需要传递一个P的类型的，剩下的几个模板参数，比方说F，IsDirect，D，O实际上都是invocation_meta构造时就确定了的。\nThe dispatcher field is initialized with a function pointer returned by overload_traits\u0026lt;O\u0026gt;::template get_dispatcher\u0026lt;F, IsDirect, D, P\u0026gt;(). This function pointer is specific to:\nThe facade type F Whether the operation is direct or indirect (IsDirect) The dispatch type D The actual type P stored in the proxy 而使用不同的ptr初始化的时候，proxy_helper::template get_ptr\u0026lt;P, Q\u0026gt;会根据P的类型来生成真正的cov_disapatcher。总之how does this shit work?\n这里还需要理解下，O是什么？output\ntemplate \u0026lt;class F, bool IsDirect, class D, class O\u0026gt; struct invocation_meta { constexpr invocation_meta() noexcept : dispatcher(nullptr) {} //通过 std::in_place_type_t\u0026lt;P\u0026gt; 构造时，从 overload_traits\u0026lt;O\u0026gt; 获取特定分发器。 template \u0026lt;class P\u0026gt; constexpr explicit invocation_meta(std::in_place_type_t\u0026lt;P\u0026gt;) noexcept : dispatcher(overload_traits\u0026lt;O\u0026gt; ::template get_dispatcher\u0026lt;F, IsDirect, D, P\u0026gt;()) {} typename overload_traits\u0026lt;O\u0026gt;::template dispatcher_type\u0026lt;F\u0026gt; dispatcher; }; template \u0026lt;class O\u0026gt; struct overload_traits : inapplicable_traits {}; template \u0026lt;qualifier_type Q, bool NE, class R, class... Args\u0026gt; struct overload_traits_impl : applicable_traits { using return_type = R; template \u0026lt;class F\u0026gt; using dispatcher_type = R (*)(add_qualifier_t\u0026lt;proxy\u0026lt;F\u0026gt;, Q\u0026gt;, Args...) noexcept(NE); template \u0026lt;class F, bool IsDirect, class D, class P\u0026gt; static consteval bool is_applicable_ptr() { if constexpr (invocable_dispatch_ptr\u0026lt;IsDirect, D, P, Q, NE, R, Args...\u0026gt;) { return true; } else { return invocable_dispatch_ptr\u0026lt;IsDirect, D, proxy\u0026lt;F\u0026gt;, Q, NE, R, Args...\u0026gt;; } } template \u0026lt;class F, bool IsDirect, class D, class P\u0026gt; static consteval dispatcher_type\u0026lt;F\u0026gt; get_dispatcher() { if constexpr (invocable_dispatch_ptr\u0026lt;IsDirect, D, P, Q, NE, R, Args...\u0026gt;) { return \u0026amp;conv_dispatcher\u0026lt;F, IsDirect, D, P, Q, R, Args...\u0026gt;; } else { return \u0026amp;conv_dispatcher\u0026lt;F, IsDirect, D, proxy\u0026lt;F\u0026gt;, Q, R, Args...\u0026gt;; } } static constexpr qualifier_type qualifier = Q; }; meta_ptr，这段就不再多解释了，简单来说就是:\nmetadata比较大，meta_ptr实际上是meta_ptr_indirect_impl - Uses indirect storage with a pointer to static metadata metadata够小，meta_ptr实际上是meta_ptr_direct_impl - Embeds the metadata directly in the proxy 所以实际上meta_ptr保存了metadata，要么用static对象，要么用原地存储\nusing ptr_prototype = void*[2]; // 非原地元素 template \u0026lt;class M\u0026gt; struct meta_ptr_indirect_impl { // 默认构造 constexpr meta_ptr_indirect_impl() noexcept : ptr_(nullptr) {}; template \u0026lt;class P\u0026gt; constexpr explicit meta_ptr_indirect_impl(std::in_place_type_t\u0026lt;P\u0026gt;) noexcept : ptr_(\u0026amp;storage\u0026lt;P\u0026gt;) {} bool has_value() const noexcept { return ptr_ != nullptr; } void reset() noexcept { ptr_ = nullptr; } const M* operator-\u0026gt;() const noexcept { return ptr_; } private: // 指向真正的元素 const M* ptr_; template \u0026lt;class P\u0026gt; static constexpr M storage{std::in_place_type\u0026lt;P\u0026gt;}; }; template \u0026lt;class M, class DM\u0026gt; struct meta_ptr_direct_impl : private M { using M::M; bool has_value() const noexcept { return this-\u0026gt;DM::dispatcher != nullptr; } void reset() noexcept { this-\u0026gt;DM::dispatcher = nullptr; } const M* operator-\u0026gt;() const noexcept { return this; } }; template \u0026lt;class M\u0026gt; struct meta_ptr_traits_impl : std::type_identity\u0026lt;meta_ptr_indirect_impl\u0026lt;M\u0026gt;\u0026gt; {}; template \u0026lt;class F, bool IsDirect, class D, class O, class... Ms\u0026gt; struct meta_ptr_traits_impl\u0026lt; composite_meta_impl\u0026lt;invocation_meta\u0026lt;F, IsDirect, D, O\u0026gt;, Ms...\u0026gt;\u0026gt; : std::type_identity\u0026lt;meta_ptr_direct_impl\u0026lt;composite_meta_impl\u0026lt; invocation_meta\u0026lt;F, IsDirect, D, O\u0026gt;, Ms...\u0026gt;, invocation_meta\u0026lt;F, IsDirect, D, O\u0026gt;\u0026gt;\u0026gt; {}; template \u0026lt;class M\u0026gt; struct meta_ptr_traits : std::type_identity\u0026lt;meta_ptr_indirect_impl\u0026lt;M\u0026gt;\u0026gt; {}; template \u0026lt;class M\u0026gt; requires(sizeof(M) \u0026lt;= sizeof(ptr_prototype) \u0026amp;\u0026amp; alignof(M) \u0026lt;= alignof(ptr_prototype) \u0026amp;\u0026amp; std::is_nothrow_default_constructible_v\u0026lt;M\u0026gt; \u0026amp;\u0026amp; std::is_trivially_copyable_v\u0026lt;M\u0026gt;) struct meta_ptr_traits\u0026lt;M\u0026gt; : meta_ptr_traits_impl\u0026lt;M\u0026gt; {}; template \u0026lt;class M\u0026gt; using meta_ptr = typename meta_ptr_traits\u0026lt;M\u0026gt;::type; 然后在看一个基础类，这段的作用说白了是将某个模板类 T 的参数列表扩展为 用户提供的参数（Args...） + 从类型列表 TL 中提取的所有元素，从而生成最终的模板实例化类型。可以理解为实际上是个胶水。实际上又是经典的转发参数包\n// 一个只声明，未定义的具体类 template \u0026lt;template \u0026lt;class...\u0026gt; class T, class TL, class Is, class... Args\u0026gt; struct instantiated_traits; //基础知识tuple_element_t, refer to the type of Ith element of the tuple, where I is in [​0​, sizeof...(Types)) // 这个实际上是个非常有意思的东西，如果传递的参数是一堆std::index_sequence\u0026lt;size_t数字一堆\u0026gt;，也就是Is是一堆size_t的时候 // 用T包裹一些参数，这些参数将Args的每个类展开在前，然后分别对TL调用std::tuple_element_t来获取对应的元素的类型 template \u0026lt;template \u0026lt;class...\u0026gt; class T, class TL, std::size_t... Is, class... Args\u0026gt; struct instantiated_traits\u0026lt;T, TL, std::index_sequence\u0026lt;Is...\u0026gt;, Args...\u0026gt; : std::type_identity\u0026lt;T\u0026lt;Args..., std::tuple_element_t\u0026lt;Is, TL\u0026gt;...\u0026gt;\u0026gt; {}; // 这里就可以发现实际上是将参数和一些特定类型的Tuple展开后拼接为一起，所以这是个C++的胶水 template \u0026lt;template \u0026lt;class...\u0026gt; class T, class TL, class... Args\u0026gt; using instantiated_t = typename instantiated_traits\u0026lt; T, TL, std::make_index_sequence\u0026lt;std::tuple_size_v\u0026lt;TL\u0026gt;\u0026gt;, Args...\u0026gt;::type; 最后我们可以看Proxy对象了，Proxy对象这里不全部展示，只看一点，它实际上是包含了模板参数为_Traits::meta的meta_ptr，而_Traits::meta实际上是facade_traits\u0026lt;F\u0026gt;的composite_meta，初始化的时候我们传递了类型P，所以P的类型信息被放到了meta里面\n这里的重点是：\ncomposite_meta包裹了facade_traits::conv_meta facade_traits::conv_meta，This means conv_meta is itself a composite of metadata from each convention (Cs) that\u0026rsquo;s part of the facade.所以这里conv_meta实际上是存储了conv_traits类模板对每个类和范型类型生效的组合 每种conv_meta实际上是conv_traits_impl拼接为一个大的类型，并且做参数包转发，而起内里就是invocation_meta，所以可以理解为conv_traits_impl就是invocation_meta。 // meta存储了基本的类型信息 meta_ = details::meta_ptr\u0026lt;typename _Traits::meta\u0026gt;{std::in_place_type\u0026lt;P\u0026gt;}; ... details::meta_ptr\u0026lt;typename _Traits::meta\u0026gt; meta_; alignas(F::constraints.max_align) std::byte ptr_[F::constraints.max_size]; }; struct facade_traits\u0026lt;F\u0026gt; : instantiated_t\u0026lt;facade_conv_traits_impl, typename F::convention_types, F\u0026gt;, instantiated_t\u0026lt;facade_refl_traits_impl, typename F::reflection_types, F\u0026gt; { using meta = composite_meta\u0026lt; lifetime_meta_t\u0026lt;F, copy_dispatch, void(proxy\u0026lt;F\u0026gt;\u0026amp;) const noexcept, void(proxy\u0026lt;F\u0026gt;\u0026amp;) const, F::constraints.copyability\u0026gt;, lifetime_meta_t\u0026lt;F, copy_dispatch, void(proxy\u0026lt;F\u0026gt;\u0026amp;) \u0026amp;\u0026amp; noexcept, void(proxy\u0026lt;F\u0026gt;\u0026amp;) \u0026amp;\u0026amp;, F::constraints.relocatability\u0026gt;, lifetime_meta_t\u0026lt;F, destroy_dispatch, void() noexcept, void(), F::constraints.destructibility\u0026gt;, typename facade_traits::conv_meta, typename facade_traits::refl_meta\u0026gt;; ... // conv_meta的定义 struct facade_conv_traits_impl\u0026lt;F, Cs...\u0026gt; : applicable_traits { using conv_meta = composite_meta\u0026lt;typename conv_traits\u0026lt;Cs, F\u0026gt;::meta...\u0026gt;; // conv_traits template \u0026lt;class C, class F\u0026gt; struct conv_traits : instantiated_t\u0026lt;conv_traits_impl, typename C::overload_types, C, F\u0026gt; {}; struct conv_traits_impl\u0026lt;C, F, Os...\u0026gt; : applicable_traits { using meta = composite_meta_impl\u0026lt;invocation_meta\u0026lt;F, C::is_direct, typename C::dispatch_type, substituted_overload_t\u0026lt;Os, F\u0026gt;\u0026gt;...\u0026gt;; 好啦，到现在我let\u0026rsquo;s put it together。问题是结构怎么存储的invocation_meta？\n每个proxy\u0026lt;F\u0026gt;对象都有details::meta_ptr\u0026lt;typename Traits::meta\u0026gt; meta; 这个meta_ptr，实际上就是使用meta_ptr_indirect_impl或者meta_ptr_direct_impl包裹的_Traits::meta。\n_Traits::meta是啥？对应于facade_traits\u0026lt;F\u0026gt;，使用composite_meta（composite_meta_impl)包裹（继承）了facade_traits::conv_meta。这个东西间接藏着invocation_meta\nfacade_traits::conv_meta是个什么东西？直接搜索conv_meta实际上会发现这到底是个啥？实际上是这句话，instantiated_t刚才我们看了实际上是拼接新的类型和tuple，所以这里就是说facade_traits\u0026lt;F\u0026gt;继承了facade_conv_traits_impl\u0026lt;F，F::convention_types\u0026gt;。因此facade_traits\u0026lt;F\u0026gt;的conv_meta就是facade_conv_traits_impl\u0026lt;F，F::convention_types\u0026gt;的conv_meta，就是composite_meta\u0026lt;typename conv_traits\u0026lt;Cs, F\u0026gt;::meta\u0026hellip;\u0026gt;;，换言之，compositet_meta包裹了一堆conv_traits\u0026lt;Cs, F\u0026gt;::meta。也就是将F::convention_types中的每个类型和F当成模板参数传递给conv_traits的meta。\nstruct facade_traits\u0026lt;F\u0026gt; : instantiated_t\u0026lt;facade_conv_traits_impl, typename F::convention_types, F\u0026gt;, instantiated_t\u0026lt;facade_refl_traits_impl, typename F::reflection_types, F\u0026gt; ... struct facade_conv_traits_impl\u0026lt;F, Cs...\u0026gt; : applicable_traits { using conv_meta = composite_meta\u0026lt;typename conv_traits\u0026lt;Cs, F\u0026gt;::meta...\u0026gt;; conv_traits\u0026lt;Cs, F\u0026gt;::meta又是什么？这里一看就发现了，实际上是conv_traits_impl\u0026lt;C, F, C::overload_types\u0026gt;。所以实际上上facade_traits\u0026lt;F\u0026gt;的conv_meta是继承自传递的composite_meta_impl继承了一堆F::convention_types里面每个元素的conv_traits_impl\u0026lt;C, F, C::overload_types\u0026gt;。接着看conv_traits_impl类型\ntemplate \u0026lt;class C, class F\u0026gt; struct conv_traits : instantiated_t\u0026lt;conv_traits_impl, typename C::overload_types, C, F\u0026gt; {}; conv_traits_imple我们就看到了，实际上是composite_meta_impl继承了将Os里面每个元素当成模板参数传递到invocation_meta\u0026lt;C::is_direct, typename C::dispatch_type, substituted_overload_t\u0026lt;Os, F\u0026raquo;里面。\ntemplate \u0026lt;class C, class F, class... Os\u0026gt; requires(overload_traits\u0026lt;substituted_overload_t\u0026lt;Os, F\u0026gt;\u0026gt;::applicable \u0026amp;\u0026amp; ...) struct conv_traits_impl\u0026lt;C, F, Os...\u0026gt; : applicable_traits { using meta = composite_meta_impl\u0026lt;invocation_meta\u0026lt;C::is_direct, typename C::dispatch_type, substituted_overload_t\u0026lt;Os, F\u0026gt;\u0026gt;...\u0026gt;; 绕了着么一大圈，让我们来总结下到底这个invocation_meta怎么存储的。怎么找到的对应的dispatcher？\nmeta_ptr存储了一个meta类型，这里我们假设初始化的时候传递的是P类型 这个meta类型是将F::convention_types中的每个类型和F当成模板参数传递给conv_traits，然后将每个这个类型的meta作为模板参数，让composite_meta_impl继承。 conv_traits实际上是调用了conv_traits_impl\u0026lt;F::convention_types中的某个类型，F，typename F::convention_types中的某个类型::overload_types\u0026gt;。C实际上就是convention_types的简写 总结就是composite_meta_impl，包裹了一堆invocation_meta带着\u0026lt;C::is_direct,typename C::dispatch_type, substituted_overload_t\u0026lt;Os, F\u0026gt;初始化，其中C就是F::convention_types中的某个类型，而Os就是typename F::convention_types中的某个类型::overload_types。也就是说invocation_meta构造的基本类型都可以了，而真正的对象的P实际上是meta_ptr初始化的时候作为参数传递进来的。接下来只需要看看上面的invocation_meta是什么意思就行了。invocation_meta初始化的时候给了P，而P就会作为meta存储到proxy\u0026lt;F\u0026gt;的invocation_meta里面了。 补充一个问题，invocation_meta作为被继承的类被composite_meta_impl包裹，它的内存布局里面实际上是个typename overload_traits\u0026lt;O\u0026gt;::template dispatcher_type\u0026lt;F\u0026gt; dispatcher。这个东西做了类型擦除，但是实际上存储的函数是带了P的类型的meta。意思是说Type Information is Encoded in the Dispatcher Function！即\ntemplate \u0026lt;class F, bool IsDirect, class D, class P, qualifier_type Q, class R, class... Args\u0026gt; R conv_dispatcher(add_qualifier_t\u0026lt;proxy\u0026lt;F\u0026gt;, Q\u0026gt; self, Args... args) noexcept(invocable_dispatch_ptr\u0026lt;IsDirect, D, P, Q, true, R, Args...\u0026gt;) { if constexpr (Q == qualifier_type::rv) { proxy_resetting_guard\u0026lt;F, P\u0026gt; guard{self}; return invoke_dispatch\u0026lt;D, R\u0026gt;( // 注意这里的get_ptr\u0026lt;P, Q\u0026gt;，对它而言模板参数是清楚的，所以可以在被调用之后再把P的类型给压缩回去 get_operand\u0026lt;IsDirect\u0026gt;(proxy_helper\u0026lt;F\u0026gt;::template get_ptr\u0026lt;P, Q\u0026gt;( std::move(self))), std::forward\u0026lt;Args\u0026gt;(args)...); } else { return invoke_dispatch\u0026lt;D, R\u0026gt;( get_operand\u0026lt;IsDirect\u0026gt;(proxy_helper\u0026lt;F\u0026gt;::template get_ptr\u0026lt;P, Q\u0026gt;( std::forward\u0026lt;add_qualifier_t\u0026lt;proxy\u0026lt;F\u0026gt;, Q\u0026gt;\u0026gt;(self))), std::forward\u0026lt;Args\u0026gt;(args)...); } } runtime怎么调用？\nLet\u0026rsquo;s walk through a concrete example:\nYou define a facade with a ToString operation:\nstruct StringableFacade : pro::facade_builder ::add_convention\u0026lt;FreeToString, std::string() const\u0026gt; ::build {}; You create a proxy with an integer:\npro::proxy\u0026lt;StringableFacade\u0026gt; p = 42; During creation, the initialize method sets up the metadata with std::in_place_type\u0026lt;int\u0026gt;.\nEach invocation_meta in the metadata is constructed with std::in_place_type\u0026lt;int\u0026gt;, which calls get_dispatcher to get the appropriate dispatcher function for integers.\nThe get_dispatcher method returns a pointer to conv_dispatcher\u0026lt;StringableFacade, IsDirect, FreeToString, int, Q, std::string\u0026gt;.\nWhen you call ToString(*p), the call is routed to proxy_invoke。这里实际上先调用了获取了真正的meta。然后拿了刚才初始化的时候有传递P的dispatcher函数。就是invocation_meta\u0026lt;F, IsDirect, D, O\u0026gt;::dispatcher\nstruct proxy_helper { static inline const auto\u0026amp; get_meta(const proxy\u0026lt;F\u0026gt;\u0026amp; p) noexcept { assert(p.has_value()); return *p.meta_.operator-\u0026gt;(); } proxy_invoke retrieves the metadata and finds the invocation_meta for the ToString operation.\nIt gets the dispatcher function pointer and calls it with the proxy and arguments.\nThe dispatcher calls std::to_string(42) to get the result.\n结尾 # 唉，尴尬\n","date":"2025 年 1 月 24 日","externalUrl":null,"permalink":"/posts/2025-03-21-%E5%BE%AE%E8%BD%AF%E7%9A%84proxy%E5%BA%93%E5%AD%A6%E4%B9%A0/","section":"Posts","summary":"","title":"2025-03-21-微软的Proxy学习","type":"posts"},{"content":"","date":"2025 年 1 月 24 日","externalUrl":null,"permalink":"/tags/c++/","section":"Tags","summary":"","title":"C++","type":"tags"},{"content":"","date":"2025 年 1 月 24 日","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2025 年 1 月 24 日","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2025 年 1 月 24 日","externalUrl":null,"permalink":"/","section":"菜狗的blog","summary":"","title":"菜狗的blog","type":"page"},{"content":"","date":"2025 年 1 月 24 日","externalUrl":null,"permalink":"/tags/%E5%AD%A6%E4%B9%A0/","section":"Tags","summary":"","title":"学习","type":"tags"},{"content":"","date":"2024 年 8 月 9 日","externalUrl":null,"permalink":"/tags/hkdf/","section":"Tags","summary":"","title":"HKDF","type":"tags"},{"content":"","date":"2024 年 8 月 9 日","externalUrl":null,"permalink":"/tags/key-schedule/","section":"Tags","summary":"","title":"KEY SCHEDULE","type":"tags"},{"content":"","date":"2024 年 8 月 9 日","externalUrl":null,"permalink":"/tags/tls/","section":"Tags","summary":"","title":"TLS","type":"tags"},{"content":"","date":"2024 年 8 月 9 日","externalUrl":null,"permalink":"/tags/tls1.3/","section":"Tags","summary":"","title":"TLS1.3","type":"tags"},{"content":" TLS1.3 密钥衍生计算方法和功能 # 前言 # Tls1.3的RFC（RFC8446）中规定了各种密钥的算法和用途，虽然我打算在不久的将来翻译TLS1.3的RFC，出于方便的考虑，还是简单讲讲TLS1.3中的各种密钥计算方法。因为RFC的密钥衍生流程中没有画出PSK的计算过程，我也会在本文附加PSK的计算流程如果文章帮到了你/或者依然存在一些问题，欢迎给我一些反馈。\n密钥衍生流程 # 密钥衍生流程中一些计算方法 # 密钥衍生的流程依赖于RFC5869定义的HKDF-Extract和HKDF-Expand操作流程，这两个流程结合到一起才算是从密钥原始材料（key material)衍生出安全的符合长度需求的密钥。TLS1.3定义了一个HKDF-Expand-Label即带衍生标签的HKDF-Expand操作，这个操作的流程是：\nDerive-Secret(Secret, Label, Messages) = HKDF-Expand-Label(Secret, Label,Transcript-Hash(Messages), Hash.length) = HKDF-Expand(Secret, HkdfLabel, Hash.length)\n如果你知道HKDF-Expand的操作（我会不久翻译RFC5869并且讲解HKDF的两个操作），问题就变成了HkdfLabel是如何拼接的。按照RFC，HkdfLabel的拼接方式如下：\nstruct { uint16 length = Length; opaque label\u0026lt;7..255\u0026gt; = \u0026ldquo;tls13 \u0026quot; + Label; opaque context\u0026lt;0..255\u0026gt; = Context; } HkdfLabel;\n首先拼接一个uint16_t的“长度”，也就是两个字节，该“长度”的数值等于当前算法使用的hash算法的长度，比方说你使用ciphersuite是TLS_AES_256_GCM_SHA384，所以该“长度的数值”等于SHA384计算结果的长度，也就是384/8=48字节。之后先拼接上一个uint8_t的“字符串长度”，这个长度用来标识整个字符串的长度，包括\u0026quot;tls1.3\u0026rdquo;+Label的长度，然后附加上字符串\u0026quot;tls13\u0026quot;（我这里附加的时候可不包括两个双引号啊），再拼接上Label，比方说你此时在计算复用主密钥(resumption_master_secret)，那么这时候的Label就是\u0026quot;res master\u0026quot;。最后拼接一个uint8_t的Context长度，再拼接Context。Context一般是对消息做hash计算得出的。\n密钥衍生流程及每个密钥的作用 # 这部分我是直接粘贴的TLS1.3 RFC的内容，见下，由于翻译可能产生争议，这部分我用的是原图。 密钥衍生流程中有两个用于计算的基础密钥，分别是PSK和ECDHE secret。PSK通过上次连接由复用主密钥计算得出/带外数据传输建立，(EC)DHE密钥则是完整握手时协商产生。这两个密钥并不一定每次都存在，比方说完整握手的情况下，计算初期密钥（Early Secret）的时候可能不存在PSK，那么PSK就由一串长度等同于当前ciphersuite使用的hash算法结果的长度的0x00代替，比方说ciphersuite是TLS_AES_256_GCM_SHA384，那么PSK就用长度等于48的0x00内容替代。我在写TLS1.3 自动机的时候就直接写了个\nstatic const unsigned char default_zeros[EVP_MAX_MD_SIZE];\n来替代。\n流程当中HKDF-Extract顶部的数据充当“盐”的角色，左侧是原始密钥材料（IKM），其输出结果为衍生出来的密钥。我们熟悉了HKDF-Extract和Derive-Secret之后，就会发现TLS1.3中是结合了HKDF-Extract和HKDF-Expand一起计算出来各种密钥的，这点比TLS1.2更符合RFC的要求，更安全。\n还有一点值得注意，整个密钥衍生流程是不可以跳过任何一步的，每一步都必须进行（这里的必须进行只针对需要的数据，比方说你不开复用，那么就没必要计算PSK，复用主密钥之类的）。举个简单的例子，完整握手的情况下，仍然需要计算初期密钥，计算的方式就是HKDF-Extract(0, 0)。\n最后一个需要注意的是，我们计算出来的密钥并不直接参与到会话/握手当中去，是要经过一论演算的。也就是说从secret到key是有一个过程的，举个例子说，客户端握手密钥（client_handshake_traffic_secret）计算到客户端会话key是有个过程的，如下：\nclient_handshake_write_key = HKDF-Expand-Label(client_handshake_traffic_secret, \u0026ldquo;key\u0026rdquo;, \u0026ldquo;\u0026rdquo;, key_length) client_handshake_write_iv = HKDF-Expand-Label(client_handshake_traffic_secret, \u0026ldquo;iv\u0026rdquo;, \u0026ldquo;\u0026rdquo;, iv_length)\n我这里之所以写client_handshake_write_key的时候加了write是因为客户端发送握手消息使用的key和客户端接受握手消息（服务端发送握手消息）的key是不一样的。这一点在TLS1.2中也是如此。\nPSK的计算过程 # 这次只简单写写PSK的计算过程，复用时如何计算binder value，恢复会话的操作以后单独写。 PSK由复用主密钥（resumption_master_secret）计算得出，公式如下：\nPSK = HKDF-Expand-Label(resumption_master_secret,\u0026ldquo;resumption\u0026rdquo;, ticket_nonce, Hash.length)\n这里复用主密钥不需要多说，而ticket_nonce需要简单说说：ticket_nonce每个连接只有一个，其值应当每个都不一样。ticket_nonce需要明文发给客户端，让客户端计算出来PSK。包含ticket_nonce的报文就是new session ticket报文，简写为NST报文。\n直接对照“密钥衍生流程中一些计算方法”就可以清晰的计算出来PSK，实际上从PSK到HMAC key，再到binder key的计算过程非常简单，完全可以一次算完。为了节省复用时的时间，可以直接计算存储binder key。但是由于涉及到操作都是hmac/hash，所以本质上时间减少的很少。这东西我第一个想出来以后被我司拿去申请了专利，还给了点奖金。\n密钥衍生中的一些细节 # 这里写的东西是我当初踩到的一些坑，有的我注意到避开了，有的没注意到踩了进去。 1 计算HKDF-Extract和HKDF-Extract时，需要注意，对于空消息的hash结果并不为空。其结果时有值的。因为忘了hash计算的流程，就容易踩这个坑。目前tls1.3的cipher只有两种hash长度一个是sha384的48,另一个时sha256的32。直接把当时写的结果贴上来了，各位也不用自己算了。\nuint8_t zero_sha384_hash[TLSV13_SHA384_HASH_LEN] = {0x38, 0xb0, 0x60, 0xa7,0x51, 0xac, 0x96, 0x38, 0x4c, 0xd9, 0x32, 0x7e,0xb1, 0xb1, 0xe3, 0x6a, 0x21, 0xfd, 0xb7, 0x11,0x14, 0xbe, 0x07, 0x43, 0x4c, 0x0c, 0xc7, 0xbf,0x63, 0xf6, 0xe1, 0xda, 0x27, 0x4e, 0xde, 0xbf,0xe7, 0x6f, 0x65, 0xfb, 0xd5, 0x1a, 0xd2, 0xf1,0x48, 0x98, 0xb9, 0x5b}; uint8_t zero_sha256_hash[TLSV13_SHA256_HASH_LEN] = {0xe3, 0xb0, 0xc4, 0x42,0x98, 0xfc, 0x1c, 0x14, 0x9a, 0xfb, 0xf4, 0xc8,0x99, 0x6f, 0xb9, 0x24, 0x27, 0xae, 0x41, 0xe4,0x64, 0x9b, 0x93, 0x4c, 0xa4, 0x95, 0x99, 0x1b,0x78, 0x52, 0xb8, 0x55};\n2 对于每个TLS1.3的连接，需要自己保存ticket_nonce。踩这个坑是因为写的自动机时异步，计算PSK时候用的ticket_nonce和写NST报文的时候的ticket_nonce可能会变化。因此需要每个连接自己保存自己的ticket_nonce。\n结尾 # 写到这里差不多就可以结束了，TLS这块还有啥不明白的直接告诉我就成了 ","date":"2024 年 8 月 9 日","externalUrl":null,"permalink":"/posts/2020-08-27-tls1.3%E5%AF%86%E9%92%A5%E8%A1%8D%E7%94%9F%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E5%92%8C%E5%8A%9F%E8%83%BD/","section":"Posts","summary":"","title":"TLS1.3 密钥衍生计算方法和功能","type":"posts"},{"content":" C++20 设计模式 # 这本书的代码如果自己写的有问题就直接去看下https://github.com/Apress/design-patterns-in-modern-cpp怎么写的，我发现某个实现者在github写的胡说八道的代码，然后自己标注有问题还上传。。。。\n0 基础概念 # 1 （CRTP）奇异递归模板 # 如何理解CRTP，CRTP我觉得最大的问题是理解难度：一个类怎么能继承自己（是派生类参数）呢？阅读这个链接https://stackoverflow.com/questions/49708984/why-curiously-recurring-template-pattern-crtp-works\n什么是CRTP，如何理解CRTP呢？\n继承自模板类 派生类将自身作为参数传递给模板类 如何理解CRTP的继承关系？一般来说继承的语义是说派生类是一种基类，将对基类的调用定向到派生类上。\n然而CRTP是完全不同的，派生类并不是基类，它实际上是通过继承手段拓展了基类来增加更多函数性（With the CRTP the situation is radically different. The derived class does not express the fact it “is a” base class. Rather, it expands its interface by inherting from the base class, in order to add more functionality.）。\n这种情况下，直接使用派生类才有意义，绝不要使用基类，当然只适合CRTP的前几种用法，不适合静态接口情况 (which is true for this usage of the CRTP, but not the one described below on static interfaces).\n所以实际上基类不是接口，派生类也不是实现。恰恰相反，基类使用派生类的接口函数，是派生类给基类提供接口，这种CRTP的继承和传统继承关系不是相反的（ In this regard, the derived class offers an interface to the base class. This illustrates again the fact that inheritance in the context of the CRTP can express quite a different thing from classical inheritance）\nCRTP的目的是什么？\n可以使用static_cast静态绑定将基类转换成派生类使用，而普通基类转派生类用的是dynamic_cast动态绑定。避免了虚函数的消耗 创建静态接口 换言之CRTP是基类对子类的调用，一种反向调用\n1.1 CRTP的用处 # CRTP的用法简单来说有以下几种：\nSome classes provide generic functionality, that can be re-used by many other classes. The second usage of the CRTP is, as described in this answer on Stack Overflow, to create static interfaces. In this case, the base class does represent the interface and the derived one does represent the implementation, as usual with polymorphism. 1.1.1 添加通用函数 # CRTP的作用之一是添加通用函数，比方说下面的代码\nclass Sensitivity { public: double getValue() const; void setValue(double value); // rest of the sensitivity\u0026#39;s rich interface... }; 如果我要添加几个函数，那么需要改成这样子\nclass Sensitivity { public: double getValue() const; void setValue(double value); void scale(double multiplicator) { setValue(getValue() * multiplicator); } void square() { setValue(getValue() * getValue()); } void setToOpposite() { scale(-1); }; // rest of the sensitivity\u0026#39;s rich interface... }; 那么我可以直接使用CRTP写一个通用函数类然后让每个其它类别继承基础类\ntemplate \u0026lt;typename T\u0026gt; struct NumericalFunctions { void scale(double multiplicator) { T\u0026amp; underlying = static_cast\u0026lt;T\u0026amp;\u0026gt;(*this); underlying.setValue(underlying.getValue() * multiplicator); } void square() { T\u0026amp; underlying = static_cast\u0026lt;T\u0026amp;\u0026gt;(*this); underlying.setValue(underlying.getValue() * underlying.getValue()); } void setToOpposite() { scale(-1); }; }; 换言之，只要让每个类别成为一个CRTP的类别，就可以实现通用代码了，不需要再手动给每个类别添加类了。\nclass Sensitivity : public NumericalFunctions\u0026lt;Sensitivity\u0026gt; { public: double getValue() const; void setValue(double value); // rest of the sensitivity\u0026#39;s rich interface... }; 当然这带来一个问题，为啥不使用函数模板而使用CRTP呢？很简单，因为CRTP不会像函数模板一样子隐藏实现。\n1.2.2 static interface # 静态多态，没有虚函数表参与。\n比方说一个基础类型为\ntemplate \u0026lt;typename T\u0026gt; class Amount { public: double getValue() const { return static_cast\u0026lt;T const\u0026amp;\u0026gt;(*this).getValue(); } }; 然后两个类别可以分别继承\nclass Constant42 : public Amount\u0026lt;Constant42\u0026gt; { public: double getValue() const {return 42;} }; class Variable : public Amount\u0026lt;Variable\u0026gt; { public: explicit Variable(int value) : value_(value) {} double getValue() const {return value_;} private: int value_; }; 这两个类别就变成了兼容两种Amount了，虽然这里有多态参与，但是并没有运行时多态，反而为编译时多态\ntemplate\u0026lt;typename T\u0026gt; void print(Amount\u0026lt;T\u0026gt; const\u0026amp; amount) { std::cout \u0026lt;\u0026lt; amount.getValue() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 1.3 如何简单使用CRTP # 简单来说包括两种用法：\ntemplate \u0026lt;typename T\u0026gt; struct crtp { T\u0026amp; underlying() { return static_cast\u0026lt;T\u0026amp;\u0026gt;(*this); } T const\u0026amp; underlying() const { return static_cast\u0026lt;T const\u0026amp;\u0026gt;(*this); } }; 1.4 CRTP的误用 # 使用CRTP并不是无代价\n2 MixIn inherence # Mixin Inherence实际上是在派生类里调用传递的类型T的某个方法，这种方法不会对基类T造成干扰，但是可能会造成拷贝成本。CRTP是给传入的类添加函数，而Mixin inherence是给传入的类生成派生类并进行调用。所以实际上Mixin inherence往往用来做拓展模式，说的感觉不像是人话，简单解释下：\nCRTP是使用“包含派生类的typename的基类”给“派生类”（实际上是我们传递的typename）添加功能。我们最终获得的类，就是我们传入的类，也就是派生类。 MixIn Inherence则是“包含基类的typename“，派生出来真正要使用的新类别。我们最终获得的类，不是我们传入的类（我们传入的是基类），而是基类添加了新的信息的派生类。 template \u0026lt;typename T\u0026gt; Struct Mixin: T { } 1 构造模式 # 构造模式基本是最简单的模式通信模式了，基本上稍微复杂点的类别都会调用“构造模式”（虽然可能并没有这个含义）\n1.1 Fluent Builder # By returning a reference to the builder itself, the builder calls can now be chained. This is what’s called a fluent interface:\nHtmlBuilder* add_child(string child_name, string child_text) { root.elements.emplace_back(child_name, child_text); return this; } 1.2 强制使用构造模式提供的函数 # 怎样强制用户使用我们提供的创建新模式的函数，而不是直接使用构造函数呢？很简单，隐藏构造函数，暴露static的函数出来\nstruct HtmlElement { string name; string text; vector\u0026lt;HtmlElement\u0026gt; elements; const size_t indent_size = 2; static unique_ptr\u0026lt;HtmlBuilder\u0026gt; create(const string\u0026amp; root_name) { return make_unique\u0026lt;HtmlBuilder\u0026gt;(root_name); } protected: // hide all constructors HtmlElement() {} HtmlElement(const string\u0026amp; name, const string\u0026amp; text) : name{name}, text{text} { } }; 1.3 Groovy-Style Builder # 将构造函数改成Protected，通过让派生类的构造函数调用特定的构造函数来简化API使用难度\nstruct Tag { ... protected: Tag(const string\u0026amp; name, const string\u0026amp; text) : name{name}, text{text} {} Tag(const string\u0026amp; name, const vector\u0026lt;Tag\u0026gt;\u0026amp; children) : name{name}, children{children} {} }; struct P : Tag { explicit P(const string\u0026amp; text) : Tag{\u0026#34;p\u0026#34;, text} {} P(initializer_list\u0026lt;Tag\u0026gt; children) : Tag(\u0026#34;p\u0026#34;, children) {} }; struct IMG : Tag { explicit IMG(const string\u0026amp; url) : Tag{\u0026#34;img\u0026#34;, \u0026#34;\u0026#34;} { attributes.emplace_back({\u0026#34;src\u0026#34;, url}); } }; 1.4 Composite Builder # Composite Builder的目的是为了简化各个模块组合起来构造对象的难度，There are two aspects to Person: their address and employment information. What if we want to have separate builders for each – how can we provide the most convenient API?\nclass PersonBuilderBase { protected: Person\u0026amp; person; explicit PersonBuilderBase(Person\u0026amp; person) : person{person} {} public: operator Person() { return move(person); } // builder facets PersonAddressBuilder lives() const; PersonJobBuilder works() const; }; This is much more complicated than our simple Builder earlier, so let’s discuss each member in turn:\nperson is a reference to the object that’s being built. This may seem rather strange, but it’s done deliberately for the sub-builders. Note that the physical storage of Person is not present in this class. This is critical! The root class only holds a reference, not the constructed object. The reference-assigning constructor is protected so that only the inheritors (PersonAddressBuilder and PersonJobBuilder) can use it. operator Person is a trick that we’ve done before. I’m making the assumption that Person has a properly defined move constructor – it’s easy to generate one in an IDE. lives() and works() are functions returning builder facets: those sub-builders that initialize the address and employment information separately. class PersonBuilder : public PersonBuilderBase { Person p; // object being built public: PersonBuilder() : PersonBuilderBase{p} {} }; class PersonAddressBuilder : public PersonBuilderBase { typedef PersonAddressBuilder self; public: explicit PersonAddressBuilder(Person\u0026amp; person) : PersonBuilderBase{ person } {} self\u0026amp; at(string street_address) { person.street_address = street_address; return *this; } self\u0026amp; with_postcode(string post_code) { ... } self\u0026amp; in(string city) { ... } }; Person p = Person::create() .lives().at(\u0026#34;123 London Road\u0026#34;) .with_postcode(\u0026#34;SW1 1GB\u0026#34;) .in(\u0026#34;London\u0026#34;) .works().at(\u0026#34;PragmaSoft\u0026#34;) .as_a(\u0026#34;Consultant\u0026#34;) .earning(10e6); 1.5 Builder Inheritance # 是否可以继承Fluent Builder？这个有一些难度，因为类型不同很难继承，比方说下面的代码\nclass PersonBuilder { protected: Person person; public: [[nodiscard]] Person build() const { return person; } }; class PersonInfoBuilder : public PersonBuilder { public: PersonInfoBuilder\u0026amp; called(const string\u0026amp; name) { person.name = name; return *this; } }; class PersonJobBuilder : public PersonInfoBuilder { public: PersonJobBuilder\u0026amp; works_as(const string\u0026amp; position) { person.position = position; return *this; } }; // Why won’t the preceding code compile? It’s simple: called() returns *this, which is of type PersonInfoBuilder\u0026amp;; this simply doesn’t have the works_as() method! PersonJobBuilder pb; auto person = pb.called(\u0026#34;Dmitri\u0026#34;) .works_as(\u0026#34;Programmer\u0026#34;) // will not compile .build(); 这个之所以有问题是因为，called函数不是虚函数，返回的this还是自己的类型\n解决办法也非常简单，调用CRTP即可，简单来说，一层一层的CRTP\ntemplate \u0026lt;typename TSelf\u0026gt; class PersonInfoBuilder : public PersonBuilder { public: TSelf\u0026amp; called(const string\u0026amp; name) { person.name = name; return static_cast\u0026lt;TSelf\u0026amp;\u0026gt;(*this); // alternatively, *static_cast\u0026lt;TSelf*\u0026gt;(this) } }; template \u0026lt;typename TSelf\u0026gt; class PersonJobBuilder : public PersonInfoBuilder\u0026lt;PersonJobBuilder\u0026lt;TSelf\u0026gt;\u0026gt; { public: TSelf\u0026amp; works_as(const string\u0026amp; position) { this-\u0026gt;person.position = position; return static_cast\u0026lt;TSelf\u0026amp;\u0026gt;(*this); } }; 2 工厂模式 # 为什么需要工厂模式？答案很简单，因为很多时候构造出来的东西需要和其它的类型产生关联，可能会造成影响，因此需要调用一个统一的工厂入口\n3 原型模式 # The fact is the Prototype pattern is all about copying objects. And, of course, we do not have a universal way of actually copying an object, but there are options, and we’ll choose some of them.\n简单来说就是涉及到对象拷贝的时候，到底如何满足拷贝的要求（比方说重复拷贝，比方说深度拷贝啥的应该如何实现），这个之所以复杂是因为涉及到了继承，派生什么的奇特情况。所以一种见的解决方法就是虚函数！\nclass ExtendedAddress : public Address { public: string country, postcode; ExtendedAddress(const string \u0026amp;street, const string \u0026amp;city, const int suite, const string \u0026amp;country, const string \u0026amp;postcode) : Address(street, city, suite) , country{country}, postcode{postcode} {} }; ExtendedAddress ea = ...; Address\u0026amp; a = ea; // how do you deep-copy `a`? 解决办法\nvirtual Address clone() { return Address{street, city, suite}; } virtual Address* clone() { return new Address{street, city, suite}; } ExtendedAddress* clone() override { return new ExtendedAddress(street, city, suite,country, postcode); } ExtendedAddress ea{\u0026#34;123 West Dr\u0026#34;, \u0026#34;London\u0026#34;, 123, \u0026#34;UK\u0026#34;, \u0026#34;SW101EG\u0026#34;}; Address\u0026amp; a = ea; // upcast auto cloned = a.clone(); 另外一个方面，如果希望信息可以多类型共享，那么直接建一个工厂模式，存储这些不同的地址，避免拷贝+避免重复。\n4 单例模式 # 4.1 单例模式的问题 # 单例模式不需要多说了，非常经典，单例模式的问题有两种\n如果需要使用其他static对象，那么初始化的顺序是不能控制的，可能会出现依赖未初始化导致程序崩溃的问题 对基于单例模式的代码写UT会非常脆弱和dummy 针对第二种问题的解决方式很简单，简单来说就是让代码不再依赖具体的类，而是依赖plungable的组件，或者说单例真正包含内部的代码。比方说我现在有个database类型，拓展为单例，\nclass Database{ public: virtual intget_population(const string\u0026amp; name) = 0; }; class SingletonDatabase : public Database{ SingletonDatabase() { /* read data from database */ } map\u0026lt;string, int\u0026gt; capitals; public: SingletonDatabase(SingletonDatabase const\u0026amp;) = delete; void operator=(SingletonDatabase const\u0026amp;) =delete; static SingletonDatabase\u0026amp; get() { staticSingletonDatabase db; return db; } int get_population(const string\u0026amp; name) override { return capitals[name]; } }; 那么我写一个工具函数来从Database里面拿数据，然后取出来的时候就会导致问题。因为它依赖单例，而单例里面的任何数据的改变都会导致它依赖项的变化。实际上这种做法相当于要去拿真正的数据库连接做操作。下面的代码就很糟糕。\nstruct SingletonRecordFinder { int total_population(vector\u0026lt;string\u0026gt; names){ int result = 0; for (auto\u0026amp; name : names) result +=SingletonDatabase::get().get_population(name); returnresult; } }; TEST(RecordFinderTests,SingletonTotalPopulationTest){ SingletonRecordFinderrf; vector\u0026lt;string\u0026gt; names{ \u0026#34;Seoul\u0026#34;, \u0026#34;Mexico City\u0026#34; }; inttp = rf.total_population(names); EXPECT_EQ(17500000 + 17400000, tp); } 所以应该怎么写呢？简单来说，写pluginable的东西。这个应该稍微有点经验的工程师都会，说实话。。。\nstruct ConfigurableRecordFinder{ explicitConfigurableRecordFinder(Database\u0026amp; db) : db{db} {} int total_population(vector\u0026lt;string\u0026gt; names) { int result= 0; for (auto\u0026amp; name : names) result += db.get_population(name); return result; } Database\u0026amp; db; }; class DummyDatabase : public Database{ map\u0026lt;string,int\u0026gt; capitals; public:DummyDatabase(){ capitals[\u0026#34;alpha\u0026#34;] = 1; capitals[\u0026#34;beta\u0026#34;] = 2; capitals[\u0026#34;gamma\u0026#34;] = 3; } int get_population(const string\u0026amp; name) override { return capitals[name]; } }; TEST(RecordFinderTests, DummyTotalPopulationTest){ DummyDatabase db{}; ConfigurableRecordFinder rf{db }; EXPECT_EQ(4, rf.total_population(vector\u0026lt;string\u0026gt;{\u0026#34;alpha\u0026#34;, \u0026#34;gamma\u0026#34;})); } 4.2 Per thread单例模式 # 实际上实现起来很简单，就是加个thread_local的标志。这里多说一句，static thread_local和thread_local是一样的。\ntemplate \u0026lt;typename T\u0026gt; class SingletonCRTP { public: static T\u0026amp; GetInstance() { thread_local T instance; return instance; } // why must be protected? Derived Singleton will call implicited protected: SingletonCRTP() = default; ~SingletonCRTP() = default; // 禁止拷贝构造和赋值操作 SingletonCRTP(const SingletonCRTP\u0026amp;) = delete; SingletonCRTP\u0026amp; operator=(const SingletonCRTP\u0026amp;) = delete; }; 结构相关模式 # 6 适配器模式 # 这个就不多说了，适配器实际上就是要使用的函数接口只支持特定格式，需要转换一层\n7 桥接模式 # 8 Composite（组合）模式 # composite模式从名字来说是组合模式（Composite Pattern），我个人觉得实际上是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。但是这里有个问题，本质来说，组合模式组合的对象是功能一致的对象，还是说只是接口相同的对象呢？\n按照查询到的资料来说，接口相同即可。但是功能相同放到一起实际上更符合DDD之类的概念，那么这里应该如何取舍呢？这个我也没想明白。\n话说回来，C++怎么实现Composite模式呢？追求能够将不同的组件组合到一起，这里（实际上也有我个人的理解）有三种方式：\n方法1 ： 利用传统的C++ 多态的方式，composite的组合 \u0026amp; 整体部分都使用整体的代码。代码如下：\nlass Graphic { public: virtual void draw() const = 0; virtual ~Graphic() = default; }; // 叶子节点，具体图形：圆 class Circle : public Graphic { public: void draw() const override { std::cout \u0026lt;\u0026lt; \u0026#34;Drawing a Circle\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // 叶子节点，具体图形：正方形 class Square : public Graphic { public: void draw() const override { std::cout \u0026lt;\u0026lt; \u0026#34;Drawing a Square\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // 组合节点，图形组合 class CompositeGraphic : public Graphic { public: void add(std::shared_ptr\u0026lt;Graphic\u0026gt; graphic) { children.push_back(graphic); } void draw() const override { for (const auto\u0026amp; child : children) { child-\u0026gt;draw(); } } private: std::vector\u0026lt;std::shared_ptr\u0026lt;Graphic\u0026gt;\u0026gt; children; }; /* 具体用法就得靠调用包裹Graphic的add方法来做 std::shared_ptr\u0026lt;CompositeGraphic\u0026gt; compositeGraphic = std::make_shared\u0026lt;CompositeGraphic\u0026gt;(); compositeGraphic-\u0026gt;add(circle1); compositeGraphic-\u0026gt;add(circle2); compositeGraphic-\u0026gt;add(square); */ 方法2: 使用类似CRTP的方式，这种方法就适合实现静态的composite模式。好处是，坏处是需要多实现一些东西，比方说begin \u0026amp; end。这里实际上已经可以使用C++ 17 的Fold Expression了\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;vector\u0026gt; class Component; template \u0026lt;typename Self\u0026gt; struct SomeComponents { template\u0026lt;typename T\u0026gt; void ConnectTo(T \u0026amp;other) { for (Component \u0026amp;from: *static_cast\u0026lt;Self*\u0026gt;(this)) { for (Component \u0026amp;to: other) { from.out.push_back(\u0026amp;to); to.in.push_back(\u0026amp;from); } } } virtual Component* begin() = 0; virtual Component* end() = 0; }; struct Component : SomeComponents\u0026lt;Component\u0026gt;{ vector\u0026lt;Component*\u0026gt; in, out; unsigned int id; //默认的构造函数，提供了 Component() { // do something } Component *begin() override { return this; } Component *end() override { return this + 1; } }; struct ComponentLayer : vector\u0026lt;Component\u0026gt;, SomeComponents\u0026lt;ComponentLayer\u0026gt; { ComponentLayer(int count) { while (count-- \u0026gt; 0) { emplace_back(Component{}); } } }; int main() { Component com, com2; ComponentLayer layer, layer2; com.connect_to(com2); com.connect_to(layer); layer.connect_to(com); layer.connect_to(layer2); return 0; } 方法3: 让我们使用微软提供的Proxy库+facade模式来实现这个蛋疼的问题。这里假设我们实现的多种模式\n9 装饰器模式 # 装饰器模式主要解决什么问题？装饰器模式（Decorator Pattern）是一种结构型设计模式，主要用于动态地给对象添加新的功能，而不改变其结构。这一模式通过创建一个装饰对象，也就是包装原始对象，实现了功能的扩展。\n怎么样？是不是听起来就和Mixin Inherence非常的对应？写起来也确实如此。这里注意我们没有使用继承基类，里面包一个基类的引用来实现Dynamic Decorator，而是使用Mixin Inherence来实现Static Decorator\n这里给出两种Static Decorator，一种就是拓展某个对象，另一种是拓展某个函数或者功能\n拓展对象，这里假设我们的基础对象是Shape，我们要拓展出来ColorShape和TransparentShape，那么使用Mixin inherence就可以拓展。这里请注意，使用了std::forward，即完美转发，来实现调用基类的方法。这里实际上还有一个问题，就是我们需要限制T必须是继承自最基础的Shape类型，方法有两个\nstatic_assert(is_base_of_v\u0026lt;Shape, T\u0026gt; 用Concept，这里我使用的是concept struct Shape { virtual string str() const = 0; }; template \u0026lt;typename T\u0026gt; struct TransparentShape : T { uint8_t transparency; template\u0026lt;typename...Args\u0026gt; TransparentShape(const uint8_t transparency, Args...args) : T(std::forward\u0026lt;Args\u0026gt;(args)...) , transparency{ transparency } {} ... }; 拓展函数/功能，这里注意，暂存了result这个，来实现及时原先的函数直接返回，也可以插入进入和出来的代码。\ntemplate \u0026lt;typename R, typename... Args\u0026gt; struct Logger3\u0026lt;R(Args...)\u0026gt; { Logger3(function\u0026lt;R(Args...)\u0026gt; func, const string\u0026amp; name) : func{func}, name{name} {} R operator() (Args ...args) { cout \u0026lt;\u0026lt; \u0026#34;Entering \u0026#34; \u0026lt;\u0026lt; name \u0026lt;\u0026lt; endl; R result = func(args...); cout \u0026lt;\u0026lt; \u0026#34;Exiting \u0026#34; \u0026lt;\u0026lt; name \u0026lt;\u0026lt; endl; return result; } function\u0026lt;R(Args ...)\u0026gt; func; string name; }; 10 Facade模式 # 19 观察者模式 # 观察者模式有很多种不同的类型，一种是属性观察，就是跟踪某个属性的变化。方法很简单，收敛对属性的写操作，每次写操作发生做通知\n通用的实现类型如下\n// 实现方法1.0，这种方法的问题是field_name可能会发生变化 template\u0026lt;typename T\u0026gt; struct Observer { virtual void field_changed(T\u0026amp; source, const string\u0026amp; field_name) = 0; }; 有观察者，必然就有被观察者。被观察者需要实现通知，订阅功能\ntemplate \u0026lt;typename T\u0026gt; struct Observable { void notify(T\u0026amp; source, const string\u0026amp; name) { ... } void subscribe(Observer\u0026lt;T\u0026gt;* f) { observers.push_back(f); } void unsubscribe(Observer\u0026lt;T\u0026gt;* f) { ... } private: vector\u0026lt;Observer\u0026lt;T\u0026gt;*\u0026gt; observers; }; // CRTP丢给Persion struct Person : Observable\u0026lt;Person\u0026gt; { void set_age(const int age) { if (this-\u0026gt;age == age) return; this-\u0026gt;age = age; notify(*this, \u0026#34;age\u0026#34;); } private: int age; }; 将观察者和被观察者结合到一起\nstruct ConsolePersonObserver : Observer\u0026lt;Person\u0026gt; { void field_changed(Person\u0026amp; source, const string\u0026amp; field_name) override { cout \u0026lt;\u0026lt; \u0026#34;Person\u0026#39;s \u0026#34; \u0026lt;\u0026lt; field_name \u0026lt;\u0026lt; \u0026#34; has changed to \u0026#34; \u0026lt;\u0026lt; source.get_age() \u0026lt;\u0026lt; \u0026#34;.\\n\u0026#34;; } }; 对于观察者模式，有个非常经典的依赖问题。对于由一个属性变化引起的观察，可以直接在设置函数的时候做变化，但如果是需要依赖两个乃至多个属性呢？甚至如果一个属性的变化会引起多个依赖更新，那么这函数岂不是天天修改？\nReentrancy问题\n简化观察者内核，使用Decrator来包裹观察者模式简化使用修改代码的难度。参看下面的内容，PersionView是真正的被观察者\nstruct Person { string name; }; struct PersonView : Observable\u0026lt;Person\u0026gt; { explicit PersonView(const Person\u0026amp; person) : person(person) {} string\u0026amp; get_name() { return person.name; } void set_name(const string\u0026amp; value) { if (value != person.name) return; person.name = value; property_changed(person, \u0026#34;name\u0026#34;); } protected: Person\u0026amp; person; }; Template Metaprograming with C++ # 建议看看这个 https://www.bilibili.com/video/BV1JK4y1D7Yz/\n1 基础模板概念 # 有下面几种概念，\n类模板 函数模板 区分类模板的成员函数 区分类成员函数模板 区分类模板的类成员函数模板 还有关于类型的一些概念\n类型模板参数\n非类型模板参数\n双重模板参数\n这两天我在写一个非常扭曲的代码，简单来说就是两个类型互相依赖，最后的解决方法实际上是使用双重模板参数。 可变参数模板\n关于参数包\n可变参数函数模板\n关于展开参数包有什么作用，这里注意区分argument和parameter的区别：\n模板参数列表（parameter），为模板指定参数\n模板参数（argument）列表，为模板指定参数\n函数参数（parameter）列表，为函数模板指定参数\n函数参数（argument）列表，\n圆括号初始化列表，展开包出现在直接初始化列表里面、函数样式强制转换或者，成员初始化里面\n大括号初始化表达式\n基类说明\n使用声明\nLambda表达式，用于捕获lambda表达式\n折叠表达式\nsizeof···操作符\n可变参数类模板\n定义 可变参数函数模板需要指定带有两个带有重载的递归模式，一个用于一般模式，另一个用于结束 可变参数类模板也需要同样的方法。 看代码感觉不太对，看看这个https://medium.com/@r.siddhesh96/lets-learn-recursive-templates-by-implementing-std-tuple-b490933206d0 可变参数模板太麻烦，所以有了折叠表达式。 一元左折叠 一元右折叠 二元左折叠 二元右折叠 可变参数别名模板 可变参数变量模板 1.S 关于模板互相依赖的问题 # 可以直接看这几个stackoverflow的问题：\nhttps://stackoverflow.com/questions/213761/what-are-some-uses-of-template-template-parameters/23930985#23930985 https://cplusplus.com/forum/general/115940/ https://stackoverflow.com/questions/34128529/breaking-template-circular-dependencies-by-using-template-template-parameters 简单来说，一般情况下，我们写代码都是单向依赖，即A依赖B，B依赖C。但是有的时候我们需要让B存储指向A的指针，这种情况下不算严格破坏依赖。如果写的是CC和.h分离的代码，那么具体实现依赖还没什么可说的，但是如果是模板文件，就引发一个问题，即依赖回出现循环\n比方说写几个不同的类型，它们相互依赖。\ntemplate \u0026lt;typename S, typename TaskType\u0026gt; class TCPStream依赖类型S和类型TaskType。其中S需要存储在TCPStream，而TaskType它实际上只是在代码实现中用到了它的代码。 template \u0026lt;typename TCPStreamType\u0026gt; class Task 它又依赖类型TCPStream，这个类型里面存储了一个指向TCPStream的智能指针。注意，这里如果两者都互相存储了对端对象，那是不能相互引用的！会造成循环引用，因为必须都先知道具体的内存布局，参考CRTP的解释那部分 最终出现了一个经典的问题，两个模板类互相依赖，实例化的时候开始报错。 这个具体的过程可以理解为\n实例化TCPStream且未使用Handle的代码时，暂时不需要实例化TaskType，继续 某阶段需要用到Handle的代码，实例化TaskType，发现Tasktype实际上也是个模板类。此时去实例化TaskType 发现TaskType还需要参数，此时如果把TCPStream再传递进去就无穷无尽了。 可以简化为如下的代码\n// TCPStream 需要使用Task，而Task又需要使用TCPStream template \u0026lt;typename S, typename TaskType\u0026gt; class TCPStream S socket_; public: S \u0026amp;GetSocket() { return socket_; } void Handle() { std::shared_ptr\u0026lt;TaskType\u0026gt; task = TaskType::Create(req, this); task-\u0026gt;xxx(); // do something with task } }; template \u0026lt;typename TCPStreamType\u0026gt; class Task { public: ... std::shared_ptr\u0026lt;TCPStreamType\u0026gt; GetConnection() { return connection_; } private: std::shared_ptr\u0026lt;TCPStreamType\u0026gt; connection_= nullptr; }; 那么如何解决呢？双重模板参数或许是个好的选择。按照下面的方式进行代码更新\nTask的代码不变，还是存储指向TCPStreamType的类型\ntemplate \u0026lt;typename TCPStreamType\u0026gt; class Task { public: ... std::shared_ptr\u0026lt;TCPStreamType\u0026gt; GetConnection() { return connection_; } private: std::shared_ptr\u0026lt;TCPStreamType\u0026gt; connection_= nullptr; }; 修改TCPStream的类型，指明它的第二个参数是个模板类。简单来说就是，这是一个双重模板参数\ntemplate \u0026lt;typename S, template\u0026lt;typename\u0026gt; class DetectionTaskType\u0026gt; class TCPStream S socket_; public: S \u0026amp;GetSocket() { return socket_; } void Handle() { std::shared_ptr\u0026lt;TaskType\u0026gt; task = TaskType::Create(req, this); task-\u0026gt;xxx(); // do something with task } }; 注意，这里有个点，需要在类的内部定义DetectionTaskType包裹自己的情况。可以看到这里将DetectionTaskType包裹住了TCPStream\n// TCPStream 需要使用Task，而Task又需要使用TCPStream template \u0026lt;typename S, template\u0026lt;typename\u0026gt; class TaskType\u0026gt; class TCPStream { public: // 注意这里的TaskType\u0026lt;TCPStream\u0026gt; typedef TaskType\u0026lt;TCPStream\u0026gt; WrapperTask; ... }; 到这里就出现了好玩的东西。接下来是显式实例化。让我们一句一句看。首先在用到两个类的地方使用using显式实例化TCPStream，定义为WrapperTCPStreamT类型。这里注意，首先\n首先typename S，或者说Socket是TCPStream的类成员，它的实例化的时候，已经是一个完整的类型了。实际上除了TCPStream::Handle需要用Task类型，其它都不用 但是TCPStream::Handle函数还没使用到，换言之，这个时候就不会实例化TCPStream::Handle。所以这个时候对TCPStream的内存布局，类定义的实例化已经结束了。所以此时TCPStream的类定义可以认为完成了。 using WrapperTCPStreamT = TCPStream\u0026lt;Socket, Task\u0026gt;; 接下来，再使用另一个using来显式实例化Task类型。这个时候，实际上我们也没有实例化刚才的TCPStream::Handle函数。时候我们拿到了的WrapperTaskT，实际上是TaskType\u0026lt;TCPStream\u0026gt;。而这个时候TCPStream已经完成了类定义。这个时候TaskType内部需要的TCPStreamType类型已经是具体的类了，它并不依赖Task类型。所以TaskType实例化完成。\nusing WrapperTaskT = WrapperTCPStreamT::WrapperTask; 解释了上面的东西，我们来改一下代码，做点好玩的东西。假设TaskType内部存储的不是shared_ptr\u0026lt;TCPStreamType\u0026gt;，存储的就是TCPStreamType。那么这段代码还能实例化吗？首先使用理论分析TCPStream可以实例化，因为它的内存布局不需要依赖Task。然后Task依赖的TCPStream已经实例化，所以理论上应该可以实例化。\n具体实现的代码就不写了。\n2 模板的基本概念 # 模板实例化是理解模板能够工作的重点，需要重点理解\n模板只是蓝图，编译器在遇到模板时，会根据模板创建实际代码。从模板声明中为函数、类或 变量创建定义的行为称为模板实例化。这可以是显式的 (告诉编译器何时应该生成定义时)，也可以 是隐式的 (编译器根据需要生成新定义时)\n2.1 隐式实例化 # 对于函数模板，当用户代码在需要函数定义存在的上下文中引用函数时，就会发生隐式实例化。\n对于类模板，当用户代码在需要完整类型的上下文中引用模板时，或者当类型的完整性影响代码时， 也会隐式实例化。此类上下文是构造此类类型的对象，\n声明指向类模板的指针时就是另外一种 情况了\n比方说\ntemplate \u0026lt;typename T\u0026gt; struct foo { void f() {} void g() {} }; int main() { foo\u0026lt;int\u0026gt;* p; foo\u0026lt;int\u0026gt; x; foo\u0026lt;double\u0026gt;* q; x.f(); q-\u0026gt;g(); } 通过这些更改，编译器需要实例化以下内容:\n当声明 x 变量时，实例化 foo\u0026lt;int\u0026gt; 当 x.f() 调用发生时，实例化 foo\u0026lt;int\u0026gt;::f() 当 q-\u0026gt;g() 调用发生时，实例化 foo\u0026lt;double\u0026gt; 和 foo\u0026lt;double\u0026gt;::g()。 另外，当声明指针 p 时，编译器不需要实例化 foo\u0026lt;int\u0026gt;;当声明指针 q 时，也不需要实例化 foo\u0026lt;double\u0026gt;\n简单总结就是，隐式实例化声明指针时不会实例化，声明对象时只实例化内存部分。只有实例化函数调用才会显示实例化对应的函数（和内存布局，如果原先没实例化内存布局）\n2.2 显式实例化 # 可以显式地告诉编译器实例化类模板或函数模板，这称为显式实例化。它有两种形式: 显式实例化定义和显式实例化声明。\n2.2.1 显式实例化定义 # 显式实例化定义实际上是传入类模板参数，定义出来类型。语法如下（如果包含namepsace，那么显示实例化定义需要包含namespace之类的信息，也叫做完全限定）。其中[1]和[2]是显式的定义。函数定义同样如此，\n// 类定义显式实例化 template class-key template-name \u0026lt;argument-list\u0026gt;; // 函数定义显式实例化 template return-type name\u0026lt;argument-list\u0026gt;(parameter-list); template return-type name(parameter-list); namespace ns { template \u0026lt;typename T\u0026gt; struct wrapper { T value; }; template struct wrapper\u0026lt;int\u0026gt;; // [1] template struct ns::wrapper\u0026lt;double\u0026gt;; // [2] int main() {} 2.2.2 显式实例化声明 # 4 高级模板概念 # 4.1 名称绑定和依赖名称 # 首先需要理解名称绑定和依赖名称\n名称绑定和依赖名称：\n依赖名称和非依赖名称的定义\n依赖名称：依赖模板参数的类型或值的名称，可以是类型参数、非类型形参或模板参数。•依赖名称，在模板实例化时执行。 非依赖名称：不依赖于模板参数的名称称为非依赖名称。• 非依赖名称，则在模板定义时执行。 依赖名称和非依赖名称的绑定\nFor a non-dependent name used in a template definition, unqualified name lookup takes place when the template definition is examined. The binding to the declarations made at that point is not affected by declarations visible at the point of instantiation. For a dependent name used in a template definition, the lookup is postponed until the template arguments are known, at which time ADL examines function declarations with external linkage(until C++11) that are visible from the template definition context as well as in the template instantiation context, while non-ADL lookup only examines function declarations with external linkage(until C++11) that are visible from the template definition context (in other words, adding a new function declaration after template definition does not make it visible except via ADL). The behavior is undefined if there is a better match with external linkage in the namespaces examined by the ADL lookup, declared in some other translation unit, or if the lookup would have been ambiguous if those translation units were examined. In any case, if a base class depends on a template parameter, its scope is not examined by unqualified name lookup (neither at the point of definition nor at the point of instantiation).\n看下这个解释：https://stackoverflow.com/questions/63392144/when-is-adl-lookup-is-considered-for-unqualified-dependent-name\n理解两种名称之后，就需要知道名称查找的流程\n4.2 两阶段名称查找 # 模板的实例化会分为两个阶段:\n第一个阶段发生在定义时，检查模板语法并将名称分类为依赖或非依赖。 第二个阶段发生在实例化时，此时模板实参替换为模板参数。依赖名称的绑定这时发生。 这个分为两步的过程称为两阶段名称查找\n4.3 如果依赖名称是一个类型？ # 需要显示指定这个类型是谁的类型。\n4.4 依赖模板的名称？ # 某些情况下，依赖名称是模板，例如函数模板或类模板。但编译器的默认行为是将依赖项名称解释为非类型\n4.5 模板特化 # 转发引用 decltype：这个下面是简单理解的方式，想要精确理解看https://en.cppreference.com/w/cpp/language/decltype。注意delcltype只是查询操作数的类型，如果操作数是表达式，并不会真的执行对应的表达式 解析过程 若表达式是标识符或类成员访问,则结果是由表达式命名的实体类型。若实体不存在,或者是具有重载集的函数(存在多个同名函数),编译器将报错。 若表达式是函数调用或重载操作符函数,则结果为函数白的返回类型。若重载的操作符括在括号中,则忽略这些操作符。 若表达式是左值,则结果类型是对表达式类型的左值引用。 若表达式为其他类型,则结果类型为表达式的类型。 decltype表达式中使用的对象的const或volatile说明符不构成推导的类型。 对象或指针表达式是左值还是右值并不影响推导的类型。 若数据成员访问表达式括号括起来,例如decltype((expression),则前两条规则不适用。对象的const或volatile限定符确实会影响推导的类型,包括对象的值。这个说白了就是左值右值会影响表达式的类型，现在可能出现decltype是右值的情况，原先的操作数包上了（）就变成了表达式 注意事项,参考https://cplusplus.com/forum/general/285738/，注意decltype(auto) 和auto区分的情况。这里使用decltype隐藏着传递引用回来，而如果是auto实际上是隐藏copy declval 模板的友情：如果希望严格控制模板友元的使用，参考律师客户模式 模板实例化 5 类型特征和条件编译 # 类型特征\nSFINAE：\nSFINAE表示替换失败而不是错误。给一个SFINAE的例子，这里第二个参数是char(*)[1]或者是char(*)[0]，char(*)[0]对应SFINAE错误\ntemplate \u0026lt;typename T, size t N\u0026gt; void handle(T(\u0026amp;arr) [N], char(*) [N % 2 == 0] = 0) { std::cout \u0026lt;\u0026lt; \u0026#34;handle even array\\n\u0026#34;; } template \u0026lt;typename T, size t N\u0026gt; void handle(T(\u0026amp;arr) [N], char(*) [N % 2 == 1]= 0) { std::cout \u0026lt;\u0026lt; \u0026#34;handle odd array\\n\u0026#34;; } int arr1[]{ 1,2,3,4,5 }; handle (arr1); int arr2[]{ 1,2,3,4 }; handle (arr2); SFINAE只适用用模板声明（模板参数列表，函数返回类型，函数参数列表）\nenable_if：只有定义出来的东西为真才能使用对应type的东西。这里需要注意template \u0026lt; typename T = void \u0026gt;的含义，参考https://stackoverflow.com/questions/34459640/what-does-typename-enable-void-mean。这里参考https://en.cppreference.com/w/cpp/types/enable_if也可。这里给一个经典的错误\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;type_traits\u0026gt; template \u0026lt;typename T, typename std::enable_if\u0026lt;std::is_integral_v\u0026lt;T\u0026gt;\u0026gt;::type* = nullptr\u0026gt; void output(T const \u0026amp;value){ std::cout \u0026lt;\u0026lt; \u0026#34;value is \u0026#34; \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; } void f() { std::cout \u0026lt;\u0026lt; \u0026#34;hahahaha\u0026#34; \u0026lt;\u0026lt; std::endl; } int main() { int a = 100; output\u0026lt;int\u0026gt;(a); output\u0026lt;int, nullptr\u0026gt;(a); // 这里注意，对函数取地址是void(*)()，即函数指针 // void*是通用指针 output\u0026lt;int, (void*)(\u0026amp;f)\u0026gt;(a); static_assert(std::same_as\u0026lt;decltype(\u0026amp;f), void(*)()\u0026gt;, \u0026#34;void(*)()\u0026#34;); return 0; } 用途\n定义具有默认参数的模板参数。参考\n定义具有默认参数的函数参数。参考\n指定函数的返回类型。\n//std::enable_if_t，是 constexpr if\n使用模板来构建范型函数，std::void_t 参考https://en.cppreference.com/w/cpp/types/void_t。这里有个很好玩的点，参考\ntemplate \u0026lt;typename, typename... Ts\u0026gt; struct has_common_type : std::false_type {}; template \u0026lt;typename... Ts\u0026gt; struct has_common_type\u0026lt;std::void_t\u0026lt;std::common_type_t\u0026lt;Ts...\u0026gt;\u0026gt;, Ts...\u0026gt; : std::true_type {}; template \u0026lt;typename... Ts\u0026gt; constexpr bool has_common_type_v = sizeof...(Ts) \u0026lt; 2 || has_common_type\u0026lt;void, Ts...\u0026gt;::value; // 如果std::common_type_t\u0026lt;Ts...\u0026gt;有结果， // 为什么这里的has_common_type\u0026lt;void, Ts...\u0026gt;不会直接解析到 // 上面的template \u0026lt;typename, typename... Ts\u0026gt; struct has_common_type : std::false_type {}; 解释如下：\ntemplate \u0026lt;typename, typename... Ts\u0026gt; struct has_common_type : std::false_type {}; 默认情况下，has_common_type继承自std::false_type，意味着如果没有找到特定的特化版本，它将返回false。 template \u0026lt;typename... Ts\u0026gt; struct has_common_type\u0026lt;std::void_t\u0026lt;std::common_type_t\u0026lt;Ts...\u0026gt;\u0026gt;, Ts...\u0026gt; : std::true_type {}; 这个特化版本用来检测std::common_type_t\u0026lt;Ts...\u0026gt;是否有效。std::void_t\u0026lt;...\u0026gt;是一种典型的SFINAE技巧，它将类型转换为void，以便进行特化匹配。\n如果std::common_type_t\u0026lt;Ts...\u0026gt;是一个有效类型，那么std::void_t\u0026lt;std::common_type_t\u0026lt;Ts...\u0026gt;\u0026gt;也是一个有效类型，从而使得该特化匹配，并has_common_type继承std::true_type。这里注意，在std::common_type_t\u0026lt;Ts...\u0026gt;是否有效时，这个特化的例子实际上是被变成了。\ntemplate \u0026lt;typename... Ts\u0026gt; struct has_common_type\u0026lt;void, Ts...\u0026gt; : std::true_type {}; 所以命中的时候会优先命中这种代码\nhas_common_type\u0026lt;void, Ts...\u0026gt;::value需要判断std::common_type_t\u0026lt;Ts...\u0026gt;的可用性：\n如果std::common_type_t\u0026lt;Ts...\u0026gt;可以成功计算，那么在积分该特化时，std::void_t\u0026lt;std::common_type_t\u0026lt;Ts...\u0026gt;\u0026gt;是有效类型。因此has_common_type的这一特化将被选择为最匹配的特化，并导致has_common_type\u0026lt;void, Ts...\u0026gt;::value为true。\n如果std::common_type_t\u0026lt;Ts...\u0026gt;不能成功计算，那么std::void_t\u0026lt;std::common_type_t\u0026lt;Ts...\u0026gt;\u0026gt;将导致类型替换失败（但由于SFINAE，这不是一个编译错误）。在这种情况下，特化匹配失败，编译器将退回至基本模板，导致has_common_type\u0026lt;void, Ts...\u0026gt;::value为false。\n在看has_common_type\u0026lt;void, Ts\u0026hellip;\u0026gt;的时候，我实际上犯了一个错误，也就是我认为是直接把void, Ts\u0026hellip;带入到has_common_type的第二个表达式里面，变成has_common_type\u0026lt;std::void_t\u0026lt;std::common_type_t\u0026lt;void, Ts\u0026hellip;\u0026raquo;, void, Ts\u0026hellip;\u0026gt;。实际上我后来又看了下https://stackoverflow.com/questions/27687389/how-do-we-use-void-t-for-sfinae 才反应过来哪里错了。因为特化本质是比较因为很有意思，所以另起一段：\n在将类型实例化之后，对于默认的类型template \u0026lt;typename, typename... Ts\u0026gt; struct has_common_type : std::false_type {};是必然吻合的，因为此时第一个类型是占位符。所以主模板必然匹配。\n接下来进行特化模板的匹配，这个时候注意并不是将直接把void, Ts\u0026hellip;带入到has_common_type的第二个表达式里面，变成has_common_type\u0026lt;std::void_t\u0026lt;std::common_type_t\u0026lt;void, Ts\u0026hellip;\u0026raquo;, void, Ts\u0026hellip;\u0026gt;。恰恰相反，这个时候匹配的是将所谓的\nhas_common_type\u0026lt; // 这个Ts...是下面那个Ts... void, Ts... \u0026gt; 和\n// 上面的代码块的Ts不和这个跟在template \u0026lt;typename...之后的Ts\u0026gt;对应 template \u0026lt;typename... Ts\u0026gt; has_common_type\u0026lt; // 上面的代码块的Ts...和下面的这个Ts... std::void_t\u0026lt;std::common_type_t\u0026lt;Ts...\u0026gt;\u0026gt;, Ts... \u0026gt; 也就是说这个时候执行的是template argument deduction.。这里的重点是理解下面代码块的Ts\u0026hellip;和上面代码块的Ts\u0026hellip;对应，而不是和这个地方认为是作为模板参数的，即跟在template \u0026lt;typename...之后的Ts\u0026gt;对应。\n编译器这个时候开始推测了，因为编译器并不能确定void和std::void_t\u0026lt;std::common_type_t\u0026lt;Ts...\u0026gt;\u0026gt;对应，所以这个时候，实际上编译器只能deduce出来Ts\u0026hellip;是后面的Ts\u0026hellip;\n知道Ts\u0026hellip;和后面匹配后，放到std::void_t\u0026lt;std::common_type_t\u0026lt;Ts...\u0026gt;\u0026gt;里面看看能不能匹配，这个时候执行替换发现，欸嘿，刚好匹配。\n最后一步，是选择匹配的模板，确定和哪个一致\n这里用个例子来说明，假设我现在要判断\u0026lt;uint32_t, int, double\u0026gt;的情况，自然就有\nhas_common_type_v\u0026lt;uint32_t, int, double\u0026gt; = has_common_type\u0026lt;void, Ts...\u0026gt;::value; = has_common_type\u0026lt;void, uint32_t, int, double\u0026gt;::value; 首先，has_common_type\u0026lt;void,uint32_t, int, double\u0026gt;和主模板必然匹配\n接下来判断能不能命中部分类型\n接下来判断has_common_type\u0026lt;void, uint32_t, int, double\u0026gt;能不能特化。先试试看是匹配\ntemplate \u0026lt;typename uint32_t, int, double\u0026gt; has_common_type\u0026lt; std::void_t\u0026lt;std::common_type_t\u0026lt;uint32_t, int, double\u0026gt;\u0026gt;, uint32_t, int, double \u0026gt; 发现std::void_t\u0026lt;std::common_type_t\u0026lt;uint32_t, int, double\u0026raquo;,就是void。所以如果Ts\u0026hellip;当成uint32_t, int, double，是可以命中特化的。\n接下来判断has_common_type\u0026lt;void,uint32_t, int, double\u0026gt;是不是和下面这个东西匹配，也就是Ts\u0026hellip;能不能是除了uint32_t, int, double，之外的任何东西，比方说int, double。肯定不可能，因为要匹配必须数量一致，而且类型一致（前提是能有common type，否则就回退到别的地方去了）\ntemplate \u0026lt;typename int, double\u0026gt; has_common_type\u0026lt; std::void_t\u0026lt;std::common_type_t\u0026lt;int, double\u0026gt;\u0026gt;, int, double \u0026gt; // 也就是这个东西，绝对不可能 has_common_type \u0026lt; void, int , double \u0026gt; 现在可以确定几个模板里面，特化模板可以确定，就选它了。\n可以看看这个https://gist.github.com/jefftrull/ff6083e2e92fdabb62f6\n6 概念和约束 # requires\n定义 requires子句 requires表达式 requires内的内容 简单需求： 类型需求： concept: 这里注意有个问题。就是Concept和CRTP冲突了。比方说下面的代码\ntemplate\u0026lt;typename T\u0026gt; concept JobImpl = requires(T a, std::shared_ptr\u0026lt;std::string\u0026gt; b, size_t s) { { a.GetJobDone() } -\u0026gt; std::convertible_to\u0026lt;size_t\u0026gt;; { a.OutputName(b, s) } -\u0026gt; std::convertible_to\u0026lt;size_t\u0026gt;; }; template \u0026lt;JobImpl T\u0026gt; class Job { public: template \u0026lt;typename... Args\u0026gt; static T CreateJob(Args\u0026amp;\u0026amp;... args) { return T(std::forward\u0026lt;Args\u0026gt;(args)...); } void Done() { static_cast\u0026lt;T*\u0026gt;(this)-\u0026gt;GetJobDone } }; 执行构建的话，会报错：\nnote: because \u0026#39;a.GetJobDone()\u0026#39; would be invalid: member access into incomplete type \u0026#39;XXX\u0026#39; 什么原因呢？解释起来，原因就是在派生类继承基类时，其类型尚未完整，导致直接约束基类模板参数时概念检查失败。\n那么怎么解决呢？很简单，因为类的定义incomplete，所以把检查滞后就可以了。这里改成检查在函数滞后就可以了\ntemplate\u0026lt;typename T\u0026gt; concept JobImpl = requires(T a, std::shared_ptr\u0026lt;std::string\u0026gt; b, size_t s) { { a.GetJobDone() } -\u0026gt; std::convertible_to\u0026lt;size_t\u0026gt;; { a.OutputName(b, s) } -\u0026gt; std::convertible_to\u0026lt;size_t\u0026gt;; }; // 注意这里 template \u0026lt;typename T\u0026gt; class Job { public: template \u0026lt;typename... Args\u0026gt; static T CreateJob(Args\u0026amp;\u0026amp;... args) { return T(std::forward\u0026lt;Args\u0026gt;(args)...); } //注意这里 void Done() requires JobImpl\u0026lt;T\u0026gt; { static_cast\u0026lt;T*\u0026gt;(this)-\u0026gt;GetJobDone } }; 7 模式和习语 # MIXIN Inheritence\ntemplate\u0026lt;typename T\u0026gt; struct MyT : T { ... }; MyT\u0026lt;int\u0026gt; int_my_t; CRTP\ntemplate \u0026lt;typename T\u0026gt; class Amount { public: double getValue() const { return static_cast\u0026lt;T const\u0026amp;\u0026gt;(*this).realGetValue(); } }; class MyAmount : Amount\u0026lt;MyAmount\u0026gt; { public: int realGetValue() { return 100; } } 关于CRTP和Mixin Inherience有两个经典的问题，即： 为什么CRTP传递进去的派生类是不完整的，它可以被派生类继承呢？简单解释就是C++对于模板的实例化是分阶段的，它只需要知道内存布局，而函数的实例化是在真正调用的位置才触发的。参考上面CRTP的例子来说，它的实例化流程如下，因此CRTP成立。但是如果Amount里面需要存储传递进去的T，它需要知道内存布局的时候，就不行了\nAmount将MyAmount作为模板参数的时候，它并不需要知道MyAmount的内存布局，因为它不是继承，只是一个类型，它只有函数，不需要存储MyAmount的内存。 MyAmount提供了Amount函数实现里面的realGetValue。 Amount拿到了MyAmount的realGetValue函数，其getValue完整了。 MyAmount此时继承Amount的时候，它知道自己的内存布局，也拿到了Amount包裹之后的函数 为什么Mixin Inherience的派生类，就必须是完整定义的呢？因为MyT继承自T，它必须知道T的内存布局，所以T必须是一个完整定义的类型\n类型擦除\n标记分派\n表达式模板\n8 范围和算法 # 结尾 # 唉，尴尬\n","date":"2024 年 7 月 4 日","externalUrl":null,"permalink":"/posts/2024-07-04-c++20%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","section":"Posts","summary":"","title":"2024-07-04-C++20设计模式","type":"posts"},{"content":"","date":"2024 年 7 月 4 日","externalUrl":null,"permalink":"/tags/%E5%85%AB%E8%82%A1/","section":"Tags","summary":"","title":"八股","type":"tags"},{"content":" Suricate # 0 Suricata原理解释 # 0.1 Suricata提供的App检测关键字解释 # Suricata有非常多方便的检测关键字，这些关键字可以针对Payload或者Applayer的内容。下面列出来这些关键字的含义，我理解如果基于这些关键字做匹配，那么需要知道能提供的能力范畴\ncontent：conten关键字提供匹配能力，可打印的自负可以直接匹配，比方说content:\u0026ldquo;abc\u0026rdquo;，不可匹配字符使用|xx|来匹配，这里的||就类比十六进制的0x。一些特殊字符只能使用这种方式匹配，参考下面的内容。这里可能需要注意，content默认区分大小写\n\u0026#34; |22| ; |3B| : |3A| | |7C| #用法范例 content:\u0026#34;a|0D|bc\u0026#34;; content:\u0026#34;|61 0D 62 63|\u0026#34;; content:\u0026#34;a|0D|b|63|\u0026#34;; nocase：用于指示不区分大小写，常常和content一块使用\ndepth：depth关键字必须放在content之后，depth后面必须跟一个数字，depth后面的数字表示将从代检查的数据的开头检查多少字节，包含content的内容。\n# Payload # abcdefhjlj # 这个命中不了，depth为3，只检查头三位，这个明显头三位不包含def content: \u0026#34;def\u0026#34;; depth:3; # 这个可以命中，depth为3，只检查头三位，包含abc content: \u0026#34;abc\u0026#34;; depth:3; startswith：和depth类似，不过这个要求匹配必须就在payload的开始部分。该关键字必须跟着content的内容，且这个关键字不能和 depth, offset, within or distance组合使用。\nendswith：顾名思义，和startswith类似，就不解释了\noffset：offset关键字指定将从payload中的哪个字节开始检查以查找匹配项。这个和depth组合到一起的时候注意下，offset是从某个字符往后面找匹配，depth是从某个字符前面找。\n# Payload # abcdefhjlj # 这个命中不了，depth为3，只检查头三位，这个明显头三位不包含def content: \u0026#34;def\u0026#34;; offset:3; depth:6; distance：distance表明content匹配的内容与之前content匹配的内容之间的关系。content紧跟的值决定了将从payload中的哪个字节开始相对于前一个匹配进行检查以查找匹配项。比方说distance:5;”意味着可以在前一个匹配的content+ 5 字节之后的任何位置匹配。distance紧跟的值可以为负数\nwithin：和distance不同，distance是第一个content匹配之后多少去找匹配第二个content，within是第一个content之内多少的字符去匹配第二个content。\nrawbytes：没啥用，纯粹兼容snort\nisdataat：“isdataat”关键字的目的是查看payload的特定部分是否仍有数据。该关键字以一个数字（位置）开头，然后可选地跟着由逗号分隔的“relative”以及“rawbytes”选项。使用“relative”这个词是为了了解有效负载的特定部分相对于上次匹配是否仍有数据。\n# Payload # abcdefghij # 这个可以命中，相对abc的第六个字符是i,还有数据 content: \u0026#34;abc\u0026#34;; isdataat:6; relative; bsize: 用于检测detection buffer的长度是否满足特定条件，具体写法如下\nbsize:\u0026lt;number\u0026gt;; bsize:=\u0026lt;number\u0026gt;; bsize:\u0026lt;\u0026lt;number\u0026gt;; bsize:\u0026gt;\u0026lt;number\u0026gt;; bsize:\u0026lt;lo-number\u0026gt;\u0026lt;\u0026gt;\u0026lt;hi-number\u0026gt;; dsize:用来检查payload/data的总的长度，用法为dsize:[\u0026lt;\u0026gt;!]number; || dsize:min\u0026lt;\u0026gt;max;\nbyte_test：“byte_test”关键字提取的内容，并且用和位于偏移的做比较。的值会先做一遍mask。这里注意它的用法，byte_test是可以用来做relative的，也就是说它可以相对前面match的内容，做relative比较。比方说我可以直接先content匹配一个报文里面的key，然后在相对这个content匹配内容\nbyte_test:\u0026lt;num of bytes\u0026gt; | \u0026lt;variable_name\u0026gt;, [!]\u0026lt;operator\u0026gt;, \u0026lt;test value\u0026gt;, \u0026lt;offset\u0026gt; [,relative] \\ [,\u0026lt;endian\u0026gt;][, string, \u0026lt;num type\u0026gt;][, dce][, bitmask \u0026lt;bitmask value\u0026gt;]; The number of bytes selected from the packet to be converted or the name of a byte_extract/byte_math variable. [!] Negation can prefix other operators\u0026lt; less than\u0026gt; greater than= equal\u0026lt;= less than or equal\u0026gt;= greater than or equal\u0026amp; bitwise AND^ bitwise OR Value to test the converted value against [hex or decimal accepted] Number of bytes into the payload [relative] Offset relative to last content match [endian] Type of number being read: - big (Most significant byte at lowest address) - little (Most significant byte at the highest address) [string] hex - Converted string represented in hexdec - Converted string represented in decimaloct - Converted string represented in octal [dce] Allow the DCE module to determine the byte order [bitmask] Applies the AND operator on the bytes converted byte_math:用来对提取出来的关键字做数学运算，用法为，就不多讲了。这里可能注意一点，它的oper的操作对象可以是使用byte_extract出来的对象\nbyte_math:bytes \u0026lt;num of bytes\u0026gt; | \u0026lt;variable-name\u0026gt; , offset \u0026lt;offset\u0026gt;, oper \u0026lt;operator\u0026gt;, rvalue \u0026lt;rvalue\u0026gt;, \\ result \u0026lt;result_var\u0026gt; [, relative] [, endian \u0026lt;endian\u0026gt;] [, string \u0026lt;number-type\u0026gt;] \\ [, dce] [, bitmask \u0026lt;value\u0026gt;]; byte_jump:\nbyte_extract:byte_extract关键字在特定的\u0026lt;num of bytes\u0026gt;和\u0026lt;offset\u0026gt;处提取，并将其存储在\u0026lt;var_name\u0026gt;中。\u0026lt;var_name\u0026gt;中的值可用于参与计算，作为byte_test \u0026amp; byte_math的运算符。\nreplace：这个说实话基本没用过，不提\npcre：pcre这个正则匹配对性能往往有负面影响，因此一般推荐和content一起使用，至于pcre可以提供什么匹配参考http://en.wikipedia.org/wiki/Regular_expression。语法参考\npcre:\u0026#34;/\u0026lt;regex\u0026gt;/opts\u0026#34;; Suricata新添加的改动 1 Suricata支持新协议 # 1.1 Suricata应用协议识别原理 # 说白了就是识别端口，识别关键字，或者识别二进制magic\nProbing parser alproto detection Pattern matcher alproto detection Expectation alproto detection 调用scripts/setup-app-layer.py生成新的基于TCP或者UDP协议的应用层协议解析，比方说，我现在想生成一个叫做IOT的协议，生成新协议支持时默认生成\u0026ndash;logger（协议记录日志），\u0026ndash;parser（协议解析）。还需要生成buffer，buffer可以理解为对IOT协议里面的协议字段匹配的名称。buffer可以多次调用生成不同的协议。\n使用下面的代码，可以看到生成的一些新文件，rust文件夹里面的代码，是协议解析器，detect-iot-iot_header_type文件是C语言注册的Buffer类型。所以这里我们需要首先完成rust协议解析器的部分。\n# 调用命令 [root@iZ2ze7889ommtwxghsyd0iZ]/home/ops/vgdog/suricata_2# scripts/setup-app-layer.py --logger --parser --detect IOT iot_header_type # git查看新文件/修改文件，可以看到下面的内容 On branch vgdog/support_iot Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: rust/src/lib.rs modified: src/Makefile.am modified: src/app-layer-parser.c modified: src/app-layer-protos.c modified: src/app-layer-protos.h modified: src/detect-engine-register.h modified: src/output.c modified: suricata.yaml.in Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) rust/src/applayeriot/ src/detect-iot-iot_header_type.c src/detect-iot-iot_header_type.h src/output-json-iot.c src/output-json-iot.h no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 1.1 Rust部分代码的编写 # 打开文件夹rust/src/applayeriot，可以发现里面包含四个文件，每个文件的功能为：\nmod.rs总结该文件夹下的rust模块如何组织 logger.rs针对IOT报文的协议transcation变化或者解析做日志记录，我只做一些type转换的时候记录，其它基本不做什么 parser.rs是针对单个IOT报文解析的关键文件，诸如IOT报文的结构都在这里完成，这里的数据结构需要暴露出来给同文件夹下面的其它文件使用。 iot.rs是针对IOT报文做transcation转换的代码文件，这里transcation可以理解为请求 \u0026amp; 回答的模式，不过处于简单，我这里认为一个单个报文就是一个完整的transcation，DHCP协议的transcation也是单报文transcation。 将来写针对MPM的从transcation里面提取关键字的时候，还要再增加一个detect.rs，detect.rs负责从一个transcation里面提取出来待匹配的关键字内容。\n[root@iZ2ze7889ommtwxghsyd0iZ]/home/ops/vgdog/suricata_2# ll rust/src/applayeriot total 28 -rw-r--r-- 1 root root 1347 Jul 9 08:58 logger.rs -rw-r--r-- 1 root root 807 Jul 9 08:58 mod.rs -rw-r--r-- 1 root root 2022 Jul 9 08:58 parser.rs -rw-r--r-- 1 root root 15927 Jul 9 08:58 iot.rs mod.rs内部是对其它组件可见性的定义，其中detect的定义被注释掉，将来写MPM的时候再涉及到这个。\npub mod iot; pub mod logger; // pub mod detect; mod parser; 1.1.1 parser.rs的编写 # 先完成parser的编写，这里假设IOT协议包含两部分，header和payload，我们基本就是完成两部分的编解码操作。\nuse nom7::{ bytes::streaming::take, combinator::map_res, IResult, Needed, error::{ErrorKind, ParseError}, error::Error, Err, error::make_error, bytes::streaming::tag, }; use std; use serde_json; use serde_json::Value; use serde::{Serialize, Deserialize}; #[derive(Debug, PartialEq, Eq, Serialize, Deserialize)] pub struct IOTHeader { ... } #[derive(Debug, PartialEq, Eq, Serialize, Deserialize)] pub struct IOTPayload { ... } #[derive(Debug, PartialEq, Eq, Serialize, Deserialize)] pub struct IOTMessage { ... } pub fn parse_header(i: \u0026amp;[u8]) -\u0026gt; IResult\u0026lt;\u0026amp;[u8], IOTHeader\u0026gt; { // For IOT, first char must be 0x5f, aka 0b01011111 let (i, _) = tag([0xff])(i)?; let (i, version_string) = ...(i)?; let (i, iot_type_string) = ...(i)?; let iot_header = IOTHeader { ... }; return Ok((i, iot_header)); } pub fn parse_payload(i: \u0026amp;[u8]) -\u0026gt; IResult\u0026lt;\u0026amp;[u8], IOTPayload\u0026gt; { ... } pub fn parse_message(i: \u0026amp;[u8]) -\u0026gt; IResult\u0026lt;\u0026amp;[u8], IOTMessage\u0026gt; { let (i, header) = parse_header(i)?; let (i, payload) = parse_payload(i)?; let message = IOTMessage { ... }; return Ok((i, message)); } 1.1.2 对iot.rs的编写 # 接下来，完成对协议状态转换的代码编写，很多协议transcation一般是一问一答，这么一个来回才算是完成，出于简单维度考虑，这里只实现单个报文就是一个transcation的代码，或者说一个报文就会导致iot完成一个transcation，对应的英文术语为uni-direction。\n默认生成的IOTTransaction的结构就是内部包含一个一个request和response，这里内部替换为单个的IOTMessage就可以了。\npub struct IOTTransaction { tx_id: u64, // pub request: Option\u0026lt;String\u0026gt;, // pub response: Option\u0026lt;String\u0026gt;, pub message: Option\u0026lt;IOTMessage\u0026gt;, tx_data: AppLayerTxData, } 接下来就是每一个IOT报文的消息转换，这里我们直接将IOT报文的具体类型，比方说Hello，Deny啥的报文类型认为是一个TranscationEvent即可。自然就可以得到下面的内容，这里的Event可以理解为transcation发生了状态转换，当transcation发生了状态转换，对tx做匹配就会发生。\n这里我们还需要注意的是IOTState，里面保存着一系列相同状态的Transcation，检索事务时，它会匹配出来具体的tx是谁。这里要注意的是，在IOTState里面，完成了对报文的匹配，如果发现了一个报文，就会推动Event的变化，再将Transcation存储进入IOTState里面。\n因为只认为包含单个消息，且状态必然转换，因此这里实际上删除掉了用不到的函数\n#[derive(AppLayerEvent)] enum IOTEvent { TooManyTransactions, IOTHelloEvent, IOTHelloResEvent, ... IOTAlertEvent, } impl IOTState { ...... fn parse(\u0026amp;mut self, input: \u0026amp;[u8]) -\u0026gt; AppLayerResult { // We\u0026#39;re not interested in empty requests. if input.is_empty() { return AppLayerResult::ok(); } let mut start = input; while !start.is_empty() { match parser::parse_message(start) { Ok((rem, message)) =\u0026gt; { start = rem; // SCLogNotice!(\u0026#34;Message: {:?}\u0026#34;, message); let mut tx = self.new_tx(); if self.transactions.len() \u0026gt;= unsafe { IOT_MAX_TX } { tx.tx_data.set_event(IOTEvent::TooManyTransactions as u8); } match message.header.iot_type.as_ref() { \u0026#34;Hello\u0026#34; =\u0026gt; tx.tx_data.set_event(IOTEvent::IOTHelloEvent as u8), ... _ =\u0026gt; { SCLogNotice!(\u0026#34;Inpossible message header cmd not valid: {:?}\u0026#34;, message); }, } tx.message = Some(message); self.transactions.push_back(tx); if self.transactions.len() \u0026gt;= unsafe { IOT_MAX_TX } { return AppLayerResult::err(); } } Err(nom::Err::Incomplete(_)) =\u0026gt; { // Not enough data. This parser doesn\u0026#39;t give us a good indication // of how much data is missing so just ask for one more byte so the // parse is called as soon as more data is received. let consumed = input.len() - start.len(); let needed = start.len() + 1; return AppLayerResult::incomplete(consumed as u32, needed as u32); } Err(_) =\u0026gt; { return AppLayerResult::err(); } } } // Input was fully consumed. return AppLayerResult::ok(); } ... } 接下来就要在iot.rs里面写上注册parser，和判断是否为iot协议的代码了。注册parser就是写明白底层是TCP还是UDP，而判断用户态代码就是看一下magic number是否匹配，这里可以严格一些，比方说判断Header是否可以正常解析出来。\nrs_iot_probing_parser用于检查报文是不是一个合法的iot报文。\nrs_iot_tx_get_alstate_progress用于通知是否发生协议变化。\nrs_iot_register_parser就是注册对iot的解析器。\n/// C entry point for a probing parser. unsafe extern \u0026#34;C\u0026#34; fn rs_iot_probing_parser( _flow: *const Flow, _direction: u8, input: *const u8, input_len: u32, _rdir: *mut u8, ) -\u0026gt; AppProto { // SCLogError!(\u0026#34;Inside iot probing parser\u0026#34;); // Need at least 2 bytes. if input_len \u0026gt; 1 \u0026amp;\u0026amp; !input.is_null() { // SCLogError!(\u0026#34;Hit parse input\u0026#34;); let slice = build_slice!(input, input_len as usize); if parse_header(slice).is_ok() { // SCLogNotice!(\u0026#34;Parse iot message success\u0026#34;); return ALPROTO_IOT; } } return ALPROTO_UNKNOWN; } unsafe extern \u0026#34;C\u0026#34; fn rs_iot_tx_get_alstate_progress(tx: *mut c_void, _direction: u8) -\u0026gt; c_int { // uni-direction, stateless parser, simply use 1. return 1; } #[no_mangle] pub unsafe extern \u0026#34;C\u0026#34; fn rs_iot_register_parser() { let default_port = CString::new(\u0026#34;[7000]\u0026#34;).unwrap(); let parser = RustParser { name: PARSER_NAME.as_ptr() as *const c_char, default_port: default_port.as_ptr(), ipproto: IPPROTO_TCP, probe_ts: Some(rs_iot_probing_parser), probe_tc: Some(rs_iot_probing_parser), min_depth: 0, max_depth: 16, state_new: rs_iot_state_new, state_free: rs_iot_state_free, tx_free: rs_iot_state_tx_free, parse_ts: rs_iot_parse, parse_tc: rs_iot_parse, get_tx_count: rs_iot_state_get_tx_count, get_tx: rs_iot_state_get_tx, tx_comp_st_ts: 1, tx_comp_st_tc: 1, tx_get_progress: rs_iot_tx_get_alstate_progress, get_eventinfo: Some(IOTEvent::get_event_info), get_eventinfo_byid: Some(IOTEvent::get_event_info_by_id), localstorage_new: None, localstorage_free: None, get_tx_files: None, get_tx_iterator: Some(applayer::state_get_tx_iterator::\u0026lt;IOTState, IOTTransaction\u0026gt;), get_tx_data: rs_iot_get_tx_data, get_state_data: rs_iot_get_state_data, apply_tx_config: None, flags: APP_LAYER_PARSER_OPT_ACCEPT_GAPS, truncate: None, get_frame_id_by_name: None, get_frame_name_by_id: None, }; let ip_proto_str = CString::new(\u0026#34;tcp\u0026#34;).unwrap(); if AppLayerProtoDetectConfProtoDetectionEnabled(ip_proto_str.as_ptr(), parser.name) != 0 { let alproto = AppLayerRegisterProtocolDetection(\u0026amp;parser, 1); ALPROTO_IOT = alproto; if AppLayerParserConfParserEnabled(ip_proto_str.as_ptr(), parser.name) != 0 { let _ = AppLayerRegisterParser(\u0026amp;parser, alproto); } if let Some(val) = conf_get(\u0026#34;app-layer.protocols.iot.max-tx\u0026#34;) { if let Ok(v) = val.parse::\u0026lt;usize\u0026gt;() { IOT_MAX_TX = v; } else { SCLogError!(\u0026#34;Invalid value for iot.max-tx\u0026#34;); } } SCLogNotice!(\u0026#34;Rust iot parser registered.\u0026#34;); } else { SCLogNotice!(\u0026#34;Protocol detector and parser disabled for IOT.\u0026#34;); } } 对iot.rs最后一步，就是提取具体的buffer，这个buffer可以理解为SPM（单模态匹配）提取关键字，这一步完成对iot.rs的改造就进入了最后一步。\n/// Get the header type buffer for a transaction from C. /// /// No required for parsing, but an example function for retrieving a /// pointer to the request buffer from C for detection. #[no_mangle] pub unsafe extern \u0026#34;C\u0026#34; fn rs_iot_get_header_type_buffer( tx: *mut c_void, buf: *mut *const u8, len: *mut u32, ) -\u0026gt; u8 { let tx = cast_pointer!(tx, IOTTransaction); if let Some(ref message) = tx.message { if !message.header.iot_type.is_empty() { *len = message.header.iot_type.len() as u32; *buf = message.header.iot_type.as_ptr(); return 1; } } return 0; } 1.1.3 对logger.rs的编写 # logger.rs就没什么好说了，可以认为就是记录一个json对象，只需要状态转变时记录一下内容即可\nfn log_iot(tx: \u0026amp;IOTTransaction, js: \u0026amp;mut JsonBuilder) -\u0026gt; Result\u0026lt;(), JsonError\u0026gt; { js.open_object(\u0026#34;iot\u0026#34;)?; if let Some(ref message) = tx.message { match message.header.iot_type.as_ref() { \u0026#34;Hello\u0026#34; =\u0026gt; js.set_string(\u0026#34;type\u0026#34;, \u0026#34;Connect\u0026#34;)?, ... _ =\u0026gt; js.set_string(\u0026#34;cmd\u0026#34;, \u0026#34;unknown\u0026#34;)? }; } ... js.close()?; Ok(()) } 1.1.4 Rust部分代码的编译和测试 # Rust要求代码必须都正常编译才能执行具体的测试，所以直接在parser.rs里面写个UT，然后进入Suricata下面的Rust目录，执行Cargo test就可以测试代码是否正确了，比方说我的代码里面有一个编码网络字节序的函数，那么我就写上一个编码比较即可。\n#[cfg(test)] mod tests { use super::*; use nom7::Err; use std::time::{Instant, Duration}; #[test] fn test_encode_bigendian_u16() { let size = 2; ... let u16_1024 = 1024; let expect_u16_1024_bigendian: [u8; 2] = [0x04, 0x00]; ... match encode_bigendian_u16(u16_1024) { Ok((_, array)) =\u0026gt; { assert_eq!(\u0026amp;array[..size], \u0026amp;expect_u16_1024_bigendian); }, Err(e) =\u0026gt; panic!(\u0026#34;Encoding u16 1024 failed: {:?}\u0026#34;, e), } } } 这种调用cargo test test_encode_bigendian_u16，如果函数编写都正常，test也没问题就会出现下面的内容\nwarning: `suricata` (lib test) generated 27 warnings (run `cargo fix --lib -p suricata --tests` to apply 20 suggestions) Finished test [unoptimized + debuginfo] target(s) in 9.78s Running unittests src/lib.rs (target/debug/deps/suricata-08d6b4a748e9dd8e) running 1 test test applayeriot::parser::tests::test_encode_bigendian_u16 ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 430 filtered out; finished in 0.00s 1.2 C语言部分代码的编写 # 现在我们回来看C语言部分的代码怎么写，还有如下文件需要修改。\n使用git diff就可以发现，这里diff的的文件实际上是加了一些通用的定义或者声明：\n比方说定义protocol iot的({ ALPROTO_IOT, \u0026ldquo;iot\u0026rdquo; },) 注册协议解析器rs_iot_register_parser 注册Detection Buffer ：DETECT_AL_IOT_IOT_HEADER_TYPE 注册日志JsonIOTLogRegister 真正需要做的东西要么在untracked files里面，要么没有显示在diff文件里面。我们一点一点看\n[root@iZ2ze7889ommtwxghsyd0iZ]/home/ops/vgdog/suricata_2# git status On branch vgdog/support_iot Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: src/Makefile.am modified: src/app-layer-parser.c modified: src/app-layer-protos.c modified: src/app-layer-protos.h modified: src/detect-engine-register.h modified: src/output.c modified: suricata.yaml.in Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) src/detect-iot-iot_header_type.c src/detect-iot-iot_header_type.h src/output-json-iot.c src/output-json-iot.h no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 先看Detection Buffer注册解析器，函数为\n// 注册解析器 void DetectIOTiot_header_typeRegister(void) { sigmatch_table[DETECT_AL_IOT_BUFFER].name = \u0026#34;iot_iot_header_type\u0026#34;; sigmatch_table[DETECT_AL_IOT_BUFFER].desc = \u0026#34;IOT content modifier to match on the iot buffers\u0026#34;; sigmatch_table[DETECT_AL_IOT_BUFFER].Setup = DetectIOTiot_header_typeSetup; #ifdef UNITTESTS sigmatch_table[DETECT_AL_IOT_BUFFER].RegisterTests = DetectIOTiot_header_typeRegisterTests; #endif sigmatch_table[DETECT_AL_IOT_BUFFER].flags |= SIGMATCH_NOOPT; /* register inspect engines */ DetectAppLayerInspectEngineRegister(\u0026#34;iot_buffer\u0026#34;, ALPROTO_IOT, SIG_FLAG_TOSERVER, 0, DetectEngineInspectIOTiot_header_type, NULL); DetectAppLayerInspectEngineRegister(\u0026#34;iot_buffer\u0026#34;, ALPROTO_IOT, SIG_FLAG_TOCLIENT, 0, DetectEngineInspectIOTiot_header_type, NULL); g_iot_rust_id = DetectBufferTypeGetByName(\u0026#34;iot_buffer\u0026#34;); SCLogNotice(\u0026#34;IOT application layer detect registered.\u0026#34;); } //真正的解析器 static uint8_t DetectEngineInspectIOTiot_header_type(DetectEngineCtx *de_ctx, DetectEngineThreadCtx *det_ctx, const struct DetectEngineAppInspectionEngine_ *engine, const Signature *s, Flow *f, uint8_t flags, void *alstate, void *txv, uint64_t tx_id) { uint8_t ret = DETECT_ENGINE_INSPECT_SIG_NO_MATCH; const uint8_t *data = NULL; uint32_t data_len = 0; if (flags \u0026amp; STREAM_TOSERVER) { rs_iot_get_request_buffer(txv, \u0026amp;data, \u0026amp;data_len); } else if (flags \u0026amp; STREAM_TOCLIENT) { rs_iot_get_response_buffer(txv, \u0026amp;data, \u0026amp;data_len); } if (data != NULL) { const bool match = DetectEngineContentInspection(de_ctx, det_ctx, s, engine-\u0026gt;smd, NULL, f, data, data_len, 0, DETECT_CI_FLAGS_SINGLE, DETECT_ENGINE_CONTENT_INSPECTION_MODE_STATE); if (match) { ret = DETECT_ENGINE_INSPECT_SIG_MATCH; } } SCLogNotice(\u0026#34;Returning %u.\u0026#34;, ret); return ret; } 有很多地方需要改动：\n”注册解析器“函数里面将通用的DETECT_AL_IOT_BUFFER改为具体的Detection Buffer名字，这里比方说我要检查的是IOT里面Header的type字段，那就改名为DETECT_AL_IOT_IOT_HEADER_TYPE ”注册解析器“函数里面把iot_buffer这个通用的名字，改成具体的类型名字 ”真正的解析器“里面，把rs_iot_get_request_buffer，改成我们刚才在rust里面写的提取函数 在两个函数之后，写上对IOT报文范例解析的Unit Test。 这两个地方改完了就高枕无忧，万事大吉了吗？并非如此还有如下操作要做：\nuntracked files的两个文件实际上没在编译路径里面，还需要添加到Makefile.am里面 DetectIOTiot_header_typeRegister函数需要添加到SigTableSetup函数里，注册这个detection buffer之后才能让signature做真正的匹配。这里记得把函数的头文件加到代码里面，否则就会报错 上面修改完成了，Suricata的SPM匹配就算是完成了，调用make执行构建即可。\n因为我们开启了Unittest，所以可以通过验证UnitTest是否运行正常，来判断我们的代码是否正确\n# 好的，这里看来我们新加入的Unit Test正确地注册了 [root@iZ2ze7889ommtwxghsyd0iZ]/home/ops/vgdog/suricata_2# ./src/suricata --list-unittests | grep IOT Notice: detect-iot-iot_header_type: IOT application layer detect registered. [DetectIOTiot_header_typeRegister:detect-iot-iot_header_type.c:73] Notice: output-json-iot: IOT JSON logger registered. [JsonIOTLogRegister:output-json-iot.c:170] DetectIOTiot_header_typeTest # 好的，看来我们的UT正确执行了 [root@iZ2ze7889ommtwxghsyd0iZ]/home/ops/vgdog/suricata_2# ./src/suricata -u -U DetectIOTiot_header_typeTest Notice: limesh: Rust limesh parser registered. [suricata::applayerlimesh::limesh::rs_limesh_register_parser:limesh.rs:409] Notice: iot: Rust iot parser registered. [suricata::applayeriot::iot::rs_iot_register_parser:iot.rs:338] ... pass ==== TEST RESULTS ==== PASSED: 1 FAILED: 0 ====================== 2 Suricata特殊功能支持 # 2.1 支持多模式匹配 # 多模式匹配的地方说起来很简单，如果是针对Applayer的transcation做多模态匹配，那就需要看看检测(detect)的时候，对Applayer执行多模态匹配注册的函数。除此之外，一般还需要实现对应的detection buffer从报文当中解析获得待匹配内容的能力。具体的实例很多代码都有，比方说对tls的某些关键字匹配，等等。\n2.2 支持频率匹配 # 频率匹配的调用栈需要先看一下，这里假设我们需要对一些特殊的关键字做匹配，实际上也是地址，比方说针对某种特殊协议的地址，它实际上是字符串类型。\nPacketAlertFinalize { PacketAlertHandle { # 先获取DetectThresholdData数据 SigGetThresholdTypeIter { } # 再根据threshold数据判断是否触发告警，这里姑且先分析TRACK_DST PacketAlertThreshold { ... # Host是 Host *dst = HostGetHostFromHash(\u0026amp;p-\u0026gt;dst); if (dst) { # 查到了就进行匹配 ret = ThresholdHandlePacketHost(dst,p,td,s-\u0026gt;id,s-\u0026gt;gid,pa); HostRelease(dst); } ... } } } 3 Suricata规则加载流程 # 规则处理顺序\n按照顺序注册Signature注册函数，先注册的比较函数会挂载到比较函数前面，\nSigLoadSignatures { ... SCSigRegisterSignatureOrderingFuncs { # 挂载一串函数到de_ctx-\u0026gt;sc_sig_order_funcs，后面挂载的后面用。先挂载OrderByAction，再挂载OrderByPriority SCSigRegisterSignatureOrderingFunc(de_ctx, SCSigOrderByActionCompare); ... SCSigRegisterSignatureOrderingFunc(de_ctx, SCSigOrderByPriorityCompare); } ... SCSigOrderSignatures { # 排序，递归比较时使用de_ctx-\u0026gt;sc_sig_order_funcs上面注册的顺序判断，用第一个能判断出来大小的比较。都相等的话用SID比较小的ID在前面。最终挂载到检测上下文det_ctx sigw_list = SCSigOrder(sigw_list, de_ctx-\u0026gt;sc_sig_order_funcs) ... } ... # 真正构建signature组 # 需了解SGH和MPM的含义，参考https://forum.suricata.io/t/mpm-context-explanation/1463/3 # SGH理解为Signature HEAD Group，共享pattern的一堆signature SigGroupBuild { # 针对每条规则使用RetrieveFPForSig提取single pattern，用于后面构建MPM。这里注意s-\u0026gt;init_data-\u0026gt;mpm_sm-\u0026gt;ctx，这个就是fast pattern。 SigPrepareStage1 # 按照TCP/UDP/IP做大的分组。开始初步分配sgh SigPrepareStage2 # 针对无法按照协议，端口，地址分类构建SGH分组 SigPrepareStage3 # 在这里真正调用每个detection buffer注册的mpm \u0026amp; spm的函数，挂载prefilter engine。开始在sgh的tx_engine里面挂prefilter engine SigPrepareStage4 { PrefilterSetupRuleGroup { PatternMatchPrepareGroup { # 给已经建好的sgh的pktpayload分配mpm_store结构，包着一个mpm_ctx，准备对per sig附加signature MpmStorePrepareBuffer # 注册pktpayload的mpm PrefilterPktPayloadRegister { # 每个函数 PrefilterAppendPayloadEngine } # 该注册applayer的tx mpm了 PrepareMpms { for 遍历 DetectBufferMpmRegistry *a = de_ctx-\u0026gt;app_mpms_list { # 如果有对应的同样direction呀，协议呀啥的mpm直接利用mpm。把自己的fast pattern加到mpm ctx里面 MpmStorePrepareBufferAppLayer { # 这里开始将每个提取出来的fp添加到de_ctx的mpm store里面，可以理解为往hyperscan的db里面添加patter，存储id MpmStoreSetup { # for s = de_ctx-\u0026gt;sig_array[sig] { # 添加fp PopulateMpmHelperAddPattern\t} } # 把内部mpmstore加到de_ctx-\u0026gt;mpm_hash_table MpmStoreAdd } # 这里实际上是spm，单模匹配加函数 a-\u0026gt;PrefilterRegisterWithListId(PrefilterGenericMpmRegister) { # 挂载到sgh-\u0026gt;init-\u0026gt;tx_engines上面 PrefilterAppendTxEngine { # 分配prefilter引擎，附加到de_ctx的enginelist } }\t} } } } } ... } } 至于规则自己，为了支持MPM需要，下面在不断的注册具体的Detection Buffer的MPM引擎（可以理解为注册回调函数用于提取内容）。\nDetectAppLayerMpmRegister { # 注册PrefilterRegisterWithListId，实际上注册的是PrefilterGenericMpmRegister。PrefilterRegisterWithListId在PrepareMpms里面调用 # PrefilterGenericMpmRegister在运行时调用PrefilterAppendTxEngine，然后调用PrefilterGenericMpmFree # 这里挂载buffer id到sm list，用于一会拿fastpattern SupportFastPatternForSigMatchList } 4 suricata检测模式 # 真正的检测流程如下，这里注意我写的是针对app layer的检测函数。这里注意一点上面是PrepareMpms，这里是PrepareMpm别搞混了。。。\n// 参考src/detect-engine-prefilter.c // 单模式匹配用的是DetectRunPrefilterTx DetectFlow { DetectRun { DetectRunTx { # 判断下是否发生了一次完整的事务， GetDetectTx { # 调用prefilterengine来先过滤一批检测，这里实际上调用的是engine-\u0026gt;cb.PrefilterTx来处理函数，这里的engine-\u0026gt;pectx是一个mpm_ctx DetectRunPrefilterTx { # 这里才是真正的执行MPM prefilter的地方 engine-\u0026gt;cb.PrefilterTx(AKA PrefilterMpm) { # 这里实际上是真正执行search的操作，说白了就是hyperscan的多模式匹配 mpm_table[mpm_ctx-\u0026gt;mpm_type].Search } # 已经确定了命中的规则后，这里来了一次quicksort排序 QuickSortSigIntId } # 请注意，这里返回的时候实际上是prefilter，还都是所有的规则都有的状态，也就是说即使命中的规则的action是pass，也有返回值 # 这里开始单条单条匹配，逐个规则判断是不是命中。 for (uint32_t i = 0; i \u0026lt; array_idx { # 逐条检测命中，如果命中了还要把det_ctx-\u0026gt;alert_queue DetectRunTxInspectRule{ # 追加alert，增加alert_queue_size，追加alert到alert_queue AlertQueueAppend }\t} } ... # 这里开始整理alert了 DetectRunPostRules { # 在这里处理了pass类型的函数 # 在这个里面检查命中的signature的threshold，实际上对threshold就是在这里进行的比较 PacketAlertFinalize { # 先排序，这个排序 qsort(det_ctx-\u0026gt;alert_queue, det_ctx-\u0026gt;alert_queue_size, sizeof(PacketAlert), AlertQueueSortHelper); PacketAlertHandle { PacketAlertThreshold { } } } } } } } 5 说说Suricata的flowbits # flow match或者说flowbits实际上和上述的匹配流程基本是一致的，只是多了一步，对于保存好的Flow，如果命中set会给Flow-\u0026gt;flowvar挂上对应的bit，下一次走MPM命中再走单命中的时候再检查是不是isbitset\n下面看一下suricata的flow match是怎么调用的，假设是两个报文，先连接，后丢弃\nalert tcp any any -\u0026gt; any any (msg:\u0026#34;flow usage test first packet\u0026#34;;buffer; content:\u0026#34;Connect\u0026#34;;flowbits:set,connect;flowbits:noalert;sid: 6; rev: 1;) alert tcp any any -\u0026gt; any any (msg:\u0026#34;flow usage test second packet\u0026#34;;buffer; content:\u0026#34;Connect\u0026#34;;flowbits:isset,connect; sid: 7; rev: 1;) 第一个set, connect事件，实际上是\n第二个isset,connect事件。一开始\nRunDetection { DetectRun { DetectRunTx { DetectRunTxInspectRule { DetectEnginePktInspectionRun { DetectEngineInspectRulePacketMatches { FlowBitIsset { FlowBitGet { } } } } } } } } 第二个没匹配因为StreamTcpDisableAppLayer将flow终止了，理论上不应该终止才对，问题出在哪里？387685\nNum Type Disp Enb Address What 1 breakpoint keep y 0x00007ffff6b9ae01 in AppLayerParserParse at app-layer-parser.c:1311 breakpoint already hit 2 times 2 breakpoint keep y 0x00007ffff6fd5d4f in suricata::applayershwp::shwp::SHWPState::parse at src/applayershwp/shwp.rs:132 breakpoint already hit 1 time 3 breakpoint keep y 0x00007ffff6b9b27b in AppLayerParserParse at app-layer-parser.c:1399 breakpoint already hit 2 times 4 breakpoint keep y 0x00007ffff6b9aad2 in AppLayerParserStateIssetFlag at app-layer-parser.c:1807 breakpoint already hit 2 times 5 Suricata的启动流程 # 6 Suricata的源码分析 # InitGlobal { //注册runmodes，这里面需要添加各种新添加的module RunModeRegisterRunModes { // 注册各种模式，每个模式都有一个RunModeFunc函数注册来执行真正的注册 RunModeIdsAFPRegister RunModeIdsNetmapRegister ... RunModeDpdkRegister } } // 执行诸如检查注册模式，设定权限，解析yaml等操作 ... PostConfLoadedSetup { // 加载诸如hyperscan等多模态匹配的库准备函数 MpmTableSetup {} SpmTableSetup {} ... // tmqh是thread module queue handler的简写， TmqhSetup { TmqhSimpleRegister //用于每个线程分配packet TmqhPacketpoolRegister {} TmqhFlowRegister } RegisterAllModules { // 填充tmm_modules， TmModuleUnixManagerRegister // ...各种个样的decoder \u0026amp; receiver TmModuleReceivePcapFileRegister TmModuleDecodePcapFileRegister } } RunModeDispatch { } 结尾 # 唉，尴尬\n","date":"2024 年 5 月 10 日","externalUrl":null,"permalink":"/posts/2024-05-10-suricata/","section":"Posts","summary":"","title":"2024-05-10-suricata","type":"posts"},{"content":" bazel从入门到中级 # 这个本来是写在gitbook上的内容，发现编辑起来很费劲，就写到了博客。因为历史比较久，所以可能有一些地方有些陈旧，我会后面逐渐更新。\n另外，一些具体名词我不会翻译为中文，因为英文更明确，避免二义性。但是其意义我会用中文表达，从而方便理解。下面的内容可能有点多，可以先大致浏览理解概念，以后再回来细看。\n为什么使用Bazel # 有些人喜欢争辩Cmake比Bazel如何如何好，如何如何兼容，我承认Cmake的历史更久远，用的人更多，但是Bazel的设计理念个人认为是更先进或者说更明确化：让专业的人做专业的事情，拆分代码编写工程师和鸡架工程师（哈）。\n因此，使用Bazel的人，我建议先阅读https://bazel.build/basics中的这篇文章https://bazel.build/basics/artifact-based-builds，展示了bazel背后的设计理念，理解了bazel背后的设计理念，对于增量编译，可复现性等概念就会有本质的理解。\n如果偷懒的话，可以不看原本内容，直接看下面我总结的对比\nWhy Bazel # Bazel是一种比较先进的构建平台，提供了多种便利:\n支持高级构建语言. Bazel自身使用一种抽象的、易读的语言，在高语义级别上描述项目的构建属性。与其他工具不同，Bazel基于库、二进制文件、脚本和数据集的概念进行操作，使您免于编写诸如编译器和链接器等工具的单独调用的复杂性。 bazel高效且可靠. Bazel缓存了所有先前完成的工作，并跟踪文件内容和构建命令的更改。这样，Bazel就知道何时需要重新构建，并仅重新构建需要的部分。可以设置项目以高度并行和增量的方式构建，从而进一步加快构建速度 bazel本身支持多平台. Bazel可以在Linux、macOS和Windows上运行。Bazel可以为多个平台构建二进制文件和可部署包，包括桌面、服务器和移动设备，而这些构建可以来自同一个项目。 bazel可以应对不同的构建规模. 无论是针对多个代码仓库还是处理成千上万个用户基础，Bazel都能够应对，并保持其灵活性和高效性。它通过并行化和增量构建的策略来实现高效的构建过程，并且能够有效地管理大型项目的构建需求。 bazel是可拓展的. 它支持许多编程语言，并且您可以扩展Bazel以支持任何其他语言或框架。 一部分人认为，相比bazel，Cmake不是更成熟吗？恰恰相反，我个人认为，成熟，只是随大流的一种说法而言，Cmake实际上是在没有工具使用，只能找一种解决问题的方法的情况下选择的工具。它为了解决一个问题，而引入了更多的问题，最终把自己复杂化，有点类似早期的python。\n而Bazel设计明确，理念清楚，这种为了解决特定的问题而做的实践，总是比乱七八糟的凑到一起解决某些不确定的问题要方便很多，其开发愿景就是为了\n**保证工程师聚焦于代码开发。**软件开发人员可以专注于编写代码的创造性过程，因为构建和测试的过程已经native 支持，即使是想编辑语言相关的工具链，也有相对应一整套机制方便拓展 工程师可以无视本地环境的影响。环境是“可移动”的，简单来说工程师不用再被一堆莫名其妙的环境配置工作所耽误。 项目可以扩展到任何规模的代码库、任何规模的团队。bazel原生支持的增量测试使团队能够在提交之前充分验证每个更改。无论是增加多语言支持，异或跨平台编译，或者引入更多的代码数量，都不会造成breaking级别的编译灾难（当然，不能有效控制代码的量级，这也是工程人员的失误） 综上，对于软件工程而言，保证开发效率并不是只是说“研发想怎么写，就瞎tm怎么写”，而是如何降低在多人参与开发，且能力不同的情况下所带来的复杂度和依赖复杂度。相比于Cmake的拓展支持，Bazel的原生支持，提供了一种有效的切入点。\n综上，我认为bazel是一种目前比较先进的编译方向，当然除了bazel还有please build之类的东西，只不过，我实践bazel比较久。。。 末尾是Bazel和Cmake的优势对比。\nBazel Cmake Remote Cache/Execution CMake没有内置支持增量编译和分布式编译，但是CMake对增量编译工具ccache/sccache和分布式编译工具distcc/icecc支持良好 Deterministic build 灵活性更高，用户可在CMakeLists中调用其他command(shell, built-in commands等)实现自定义功能。 使用较难，但是依赖分析，使用方式非常清楚 简单，易于修改和维护 如果想了解更多，阅读https://bazel.build/basics\n基础篇 # 这一部分主要面向bazel体系的用户。希望读者能够明白\nBazel是构建平台，不能简单地理解为编译平台，错误理解这一点会导致无法快速找到对应的解决方案。有个用户曾经抱怨：bazel编译报错，而g++编译同样代码不报错，仔细一看报错如下图，这个是非常明显的bazel的工具链启用-Werror和-Wuninitialized选项导致的结果，如果g++启用同样的选项，也会报错。\nBazel提供的是一种抽象的package，target，库依赖的关系，具体如何构建这些target和package，是对应的bazel rule的实现范畴。具体构建的细节，麻烦用户自己去看工具链的配置。\nBazel的执行模式有多种：sandbox模式，本地模式等。因此使用sandbox模式的时候，本地临时文件如果不明确地指定到BUILD文件中，就无法在构建过程中看到（调用到）\n这部分我建议读者先把C++那部分的例子看了，再根据需求选择使用的语言，选择对应的阅读章节。\n1 Bazel基础概念通识 # 这部分会给出Bazel的设计理念，基础概念和输出布局。Bazel体系的用户在交流的时候需要有明确的名词来统一上下文，我看到很多次研发在别人给出具体的开发建议的时候，不知道怎么写BUILD的情况。因此，确定基础术语的概念会很有用。我建议阅读者重点看这部分，这部分搞明白，bazel的基本用法就不会有问题了。\n在执行构建或者test任务的时候，bazel可以拆分为一下几个流程:\nLoads 加载BUILD文件，并且将外部依赖 Analyzes 分析输入和输出的依赖，在内存中生成对应的action图. Executes 执行真正的构建操作并输出相应的文件和日志 下面给出一些术语，方便统一上下文：\nAction # 执行构建过程的命令，比方说将一个完整的调用过程，改过程将其它Action的产物作为输入，并产生对应的其它编译产物。需要包含包括命令行参数、action索引（action key）、环境变量和在BUILD中声明的输入/输出工件等元数据\n参考 Rules documentation\nAction cache # 磁盘上的缓存，存储执行的操作到它们创建的输出的映射。缓存键称为action索引(action key)。Bazel 增量模型的核心组件。缓存存储在输出根目录（output base directory）中，因为是文件形式存储，所以在 Bazel 服务器重新启动后仍然存在。\nAction graph # 内存中的action关系图，表明action和具体的action读取和生成的产物。该图读取BUILD。生成，从本质来说是一种依赖/生成关系的具象化。该图在分析阶段产生并在执行阶段使用。目前还不需要了解分析阶段，执行阶段的作用是什么\nAction graph query (aquery) # 一个查询工具，可以查询action的依赖关系等。用户就可以了解从具体的规则，到转化为实际构建工作的过程是如何的。\nAction key # action的缓存索引。根据action元数据计算得出，其中可能包括要在操作中执行的命令、编译器标志、库位置或系统头文件，具体取决于action的实现。从而使 Bazel 能够确定性地缓存或使单个action无效。\nAnalysis phase # 构建的第二阶段。处理BUILD文件 中指定的target之间的关系，并根据该目标图以生成内存中action graph。当前阶段是规则的实现被真正的解析的阶段。\nArtifact # 成品，指的是源文件或者代指生成的文件。也可以是文件目录，称为 tree artifacts\n成品可以作为多个action的输入，参与到构建中，但最多只能由一个操作生成。\n与文件目标相对应的成品可以通过label来寻址。\nAspect # 一种在现有rule的基础上拓展以执行更多action的机制，这种机制会传递到具体规则的依赖上，对于初级用户用不到，不过bazel-clang-tidy是用这个实现的。如果目标 A 依赖于 B，则可以在 A 上应用一个aspect，该aspect向上遍历到B中，并在 B 中运行其他action来生成和收集其他输出文件。这些附加操作同样被缓存并在重用。\n参考**:** Aspects documentation\nAspect-on-aspect # A composition mechanism whereby aspects can be applied to the results of other aspects. For example, an aspect that generates information for use by IDEs can be applied on top of an aspect that generates .java files from a proto.\nFor an aspect A to apply on top of aspect B, the providers that B advertises in its provides attribute must match what A declares it wants in its required_aspect_providers attribute.\nAttribute # rule的属性，用于表达每个目标的构建信息。例如，srcs（源文件）、deps（依赖项）和copts（自定义编译选项）分别声明了目标的源文件、依赖项和自定义编译选项。对于特定目标而言，可用的属性取决于其规则类型。\n.bazelrc # Bazel的配置文件用于更改启动标志和命令标志的默认值，并定义常见选项组，可以使用\u0026ndash;config标志在Bazel命令行上一起设置。Bazel可以从多个bazelrc文件（系统范围、工作空间范围、用户范围或自定义位置）中组合设置，而bazelrc文件也可以从其他bazelrc文件导入设置。\nBlaze # google内部的编译构建系统，说实在的，google的infra真是令人羡慕呀\nBUILD File # BUILD文件是Bazel的主要配置文件，用于告诉Bazel要构建哪些软件输出，它们的依赖关系是什么，以及如何构建它们。Bazel将BUILD文件作为输入，并使用该文件创建依赖图，并推导出构建中间和最终软件输出所必须完成的操作。BUILD文件将目录以及不包含BUILD文件的任何子目录标记为一个包（package），并且可以包含由规则创建的目标（targets）。该文件也可以被命名为BUILD.bazel。\nBUILD.bazel File # 参考 BUILD File.优先级高于同目录的BUILD\n.bzl File # 一个文件，用Starlark语言编写，用于定义规则（rules）、宏（macros）和常量（constants）。然后可以使用load()函数将其导入到BUILD文件中。实际上后面看什么bazel管理C++，bazel管理GO就能看到类似的load使用方法。\nBuild graph # Bazel构建过程中构建和遍历的依赖图。包括目标（targets）、配置后的目标（configured targets）、操作（actions）和构件（artifacts）等节点。当所有被请求的目标所依赖的构件都被验证为最新时，构建被视为完成。\nBuild setting # 一个由Starlark定义的部分配置。transitions（配置传递）可以设置构建设置以更改子图的配置。对用户而言，这个可以理解为一种编译配置，比方说\u0026ndash;config=cpu\nClean build # 一个不使用之前构建结果的构建过程。这通常比增量构建更慢，但通常被认为更正确。保证无论是清理构建（clean build）还是增量构建（incremental build），都始终是正确的是Bazel的功能，不过确定性这点bazel在极低情况下确实会出问题，我明确遇到过在aliyun的内部pod下载的外部依赖版本不正确的问题，最后是通过指定url的下载地址避免这个问题。\nClient-server model # bazel会自动在本地机器上启动一个后台服务器来执行Bazel命令。该服务器在命令之间保持持续存在，但在一段时间的无活动后（或通过bazel shutdown显式停止）会自动关闭。将Bazel拆分为服务器和客户端有助于分摊JVM启动时间，并支持更快的增量构建，因为操作图在命令之间保留在内存中。说白了，分离控制端和策略端\nCommand # 简单理解就是Bazel的子函数，例如bazel build、bazel test、bazel run和bazel query。\nCommand flags # 一组影响相关命令的标志（flags）。先指定具体命令，再指定flag（例如：先bazel build，然后在\u0026ndash;keep going啥的 ）。这些标志可以适用于一个或多个命令。例如，\u0026ndash;configure是仅用于bazel sync命令的标志，而\u0026ndash;keep_going适用于sync、build、test等多个命令。command flag通常用于配置目的，因此command flag的更改可能会导致Bazel内存中存储的action graph无效，并重新启动分析阶段。\nConfiguration # 配置，rule定义之外的信息，会影响rule生成action的方式。每个build都至少有一个配置，用于指定目标平台、操作环境变量和命令行选项。 Transitions可能会创建额外的配置，例如用于指定主机的工具链或交叉编译。\n参考**:** Configurations\nConfiguration trimming # 配置建材，简单来说就是只包含目标实际需要的配置的过程。例如，如果你使用C++依赖项//:c构建Java二进制文件//:j，在//:c的配置中包含\u0026ndash;javacopt的值是不必要的，因为更改\u0026ndash;javacopt会不必要地破坏C++构建的缓存性能。因此，按需配置确保每个目标仅包含其自身所需的配置信息，以避免不必要的配置冗余和影响构建缓存性能。\nConfigured query (cquery) # 检索启用了配置之后的 configured targets的检索工具，select() and build flags (such as --platforms)的选择是已经明确化了。这个在analysis phase之后才执行\n参考**:** cquery documentation\nConfigured target # 启用了某种配置的target\nCorrectness # 当构建的输出忠实地反映其传递输入的状态时，构建就是正确的。为了实现正确的构建，Bazel努力做到具有隔离性、可重现性，并使构建分析和操作执行具有确定性。这意味着在构建过程中，Bazel会尽力确保每次构建都以一致的方式处理输入，从而产生可预测和可重复的结果。这样可以确保构建的正确性，并减少不确定性带来的问题。\n不过这个概念对用户一般来说没啥用，毕竟正确性大部分永不不会涉及到，很多时候问题也不是bazel的问题。\nDependency # 依赖关系，一般是指两个target直接的依赖关系，就是BUILD文件里面规则的deps\nDepset # 一种用于收集传递依赖关系数据的数据结构。它经过优化，使得合并依赖集（depset）在时间和空间上更加高效，因为依赖集往往非常大（成千上万个文件）。为了节省空间，该数据结构被实现为可以递归引用其他依赖集。规则实现在不是构建图顶层的情况下，不应将依赖集“展开”为列表形式。展开大型依赖集会导致巨大的内存消耗。在Bazel的内部实现中，它也被称为嵌套集合（nested sets）\n参考: Depset documentation\nDisk cache # 本地磁盘的Blob存储用于远程缓存功能。它可以与实际的远程Blob存储结合使用。在构建过程中，Bazel会将构建输出结果转换为Blob，并将其存储在本地磁盘的Blob存储中。这样可以提高后续构建的速度，因为它可以避免重复构建相同的输出结果。实际的远程Blob存储通常用于分布式构建环境，可以将Blob存储在远程服务器上，以便多个构建节点共享和访问这些Blob。\nDistdir # 只读目录，包含了Bazel本来会通过代码库规则从互联网获取的文件。它使得构建可以完全离线运行，不需要依赖于网络资源。通过将这些文件预先存储在只读目录中，Bazel可以在没有网络连接的情况下执行构建过程，并使用本地文件来满足构建所需的依赖。这种方式对于处于隔离环境或无法访问互联网的构建系统非常有用。不过说起来，distdir对于我的实践过程而言，最重要的还是提供对第三方依赖的缓存\nDynamic execution # 动态执行策略是根据各种启发式规则，在本地和远程执行之间进行选择，并使用更快速成功的方法的执行结果。某些操作在本地执行速度更快（例如链接操作），而其他操作在远程执行速度更快（例如高度可并行化的编译操作）。动态执行策略可以提供最佳的增量构建和清理构建时间。通过动态地选择本地或远程执行，Bazel可以根据操作类型和执行环境的特点，最大程度地优化构建过程，从而获得更快的构建时间。\nExecution phase # 构建的第三个阶段，执行在分析阶段创建的操作图中的操作。这些操作调用可执行文件（编译器、脚本）来读取和写入构件。生成策略控制这些操作的执行方式：本地执行、远程执行、动态执行、沙盒化执行、使用Docker等等。\n注意，具体执行的环境很多时候都是用户显示指定，其中配置的传递是个很蛋疼的东西，因为很多本地的配置是不能在sandbox环境完全一致的。\nExecution root # 执行根目录（Execution Root）是workspace的输出目录中的一个目录，这里的action是在在非沙盒的环境中执行。该目录的内容主要放的是各种输入产物的hard link。执行根目录还包含指向外部依赖的符号软链接作为输入，以及用于存储输出的bazel-out目录。\n在加载阶段通过创建大量符号软链接的方式来生成该根目录。可以通过在命令行中使用\u0026quot;bazel info execution_root\u0026quot;来访问该目录。\n实际上，在buildfarm里面这个execution root的概念比较常用，因为有大量的分发的执行任务。\nFile # 参考 Artifact.\nHermeticity # 如果构建和测试操作没有外部影响，那么构建就是隔离的（hermetic），这有助于确保结果具有确定性和正确性。例如，隔离的构建通常禁止操作访问网络，限制对声明的输入的访问，使用固定的时间戳和时区，限制对环境变量的访问，并为随机数生成器使用固定的种子。\n通过确保构建过程中没有外部的不可控因素干扰，隔离的构建可以消除构建结果的不确定性，并提高构建的可靠性和可重复性。这样可以更容易地定位和解决构建中的问题，并确保不同环境下的构建结果一致，从而提高构建的可移植性和可靠性。\nIncremental build # 我一般叫做，增量编译。更标准应该是增量构建。增量构建是通过重复使用先前构建的结果来减少构建时间和资源使用的一种方式。依赖检查和缓存旨在为此类型的构建生成正确的结果。增量构建是清理构建的反义词。\n在增量构建中，Bazel会检查先前构建生成的构件，并根据构建过程中的依赖关系来确定哪些构件是最新的和有效的。只有在需要更新的构件上才会执行必要的操作，从而避免不必要的重新构建。这种方式可以显著减少构建时间，提高开发效率，并降低资源消耗。\nLabel # 标签（label）是用于唯一标识Bazel构建系统中的目标的方式。通过标签，可以准确定位和引用构建过程中所涉及的不同目标。标签的结构使得能够精确指定目标所在的位置，并指定目标的名称。这种标识符的使用使得Bazel可以在构建和依赖管理过程中准确地追踪和处理不同的目标\n完全限定的标签（fully-qualified label），例如//path/to/package:target，由以下部分组成：//用于标记工作空间的根目录，path/to/package表示包含声明该目标的BUILD文件的目录，:target表示在前述BUILD文件中声明的目标的名称。也可以在前面添加@my_repository//\u0026lt;..\u0026gt;，表示该目标在名为my_repository的外部依赖代码库中声明。\nLoading phase # 构建的第一阶段，Bazel在此阶段解析WORKSPACE、BUILD和.bzl文件，创建包（packages）。在此阶段，还会评估宏（macros）和某些函数，如glob()。该阶段与构建的第二阶段，即分析阶段，交替进行，以建立目标图（target graph）。\n在加载阶段，Bazel会解析工作空间（WORKSPACE）文件，确定项目的配置和依赖关系。同时，它会解析BUILD文件和.bzl文件，创建和配置目标（targets）。宏和函数的评估也在此阶段进行，这有助于在构建过程中执行各种动态操作。加载阶段与分析阶段交替进行，以逐步构建目标图，为后续的构建阶段做好准备。\nMacro # 这个机制允许开发者将多个规则目标的声明逻辑封装在一个自定义的Starlark函数中，以提高代码的可重用性和可维护性。通过定义这样的函数，可以在多个BUILD文件中调用该函数来创建相同的规则目标，从而避免了重复编写相似的规则声明代码。在加载阶段，Bazel会将这些组合规则函数展开为实际的规则目标声明，以便后续的构建阶段使用。这种机制使得规则声明的复用变得更加方便和灵活。\n参考: Macro documentation\nMnemonic # 通过使用助记符，规则作者可以为规则中的操作赋予具有描述性和易记性的名称，使其更容易理解和识别。助记符通常与特定的操作类型或规则相关联，帮助开发者快速了解操作的用途和功能。这种命名方式有助于提高代码的可读性和可维护性，并促进团队之间的协作和理解。\nNative rules # 内置规则（Built-in rules）是Bazel中内置的、由Java实现的规则。这些规则在.bzl文件中以原生模块中的函数形式出现（例如native.cc_library或native.java_library）。而用户定义的规则（非原生规则）则是使用Starlark创建的。\nOutput base # 在Bazel中，工作空间专用目录（workspace-specific directory）通常被称为\u0026quot;bazel-out\u0026quot;。它是一个由Bazel自动创建的目录，用于存储构建过程中生成的各种输出文件，如编译生成的二进制文件、中间文件、测试结果、日志文件等。该目录的位置位于Bazel的输出用户根目录下，用于将构建过程中产生的文件与源代码目录分离开，以保持项目结构的清晰性和可维护性。\nOutput groups # 输出组（Output group）是指在Bazel完成构建一个目标后，预计将生成的一组文件。规则通常会将其常规输出放在\u0026quot;default output group\u0026quot;中（例如，Java规则的.jar文件、C++规则目标的.a和.so文件）。默认输出组是在命令行上请求目标时构建的输出组。\n规则可以定义更多的命名输出组，可以在BUILD文件（使用filegroup规则）或命令行（\u0026ndash;output_groups标志）中显式指定。命名输出组允许开发者将特定类型的输出文件分组，以便在构建过程中对其进行特定的处理或操作。\n通过输出组的概念，Bazel提供了一种灵活的机制来管理构建过程中生成的文件。开发者可以根据需要将文件分组，以便更好地组织、处理和操作构建输出。这样可以提高构建过程的灵活性和可定制性，并为构建系统的构建结果提供更好的结构和组织。\nOutput user root # 用户特定的目录，用于存储Bazel的输出。目录名称来自于用户系统的用户名。如果多个用户同时在系统上构建同一项目，这样的目录结构可以避免输出文件冲突。它包含与各个工作空间的构建输出相对应的子目录，也被称为输出基目录（output bases）。\nPackage # 一个BUILD文件定义的目标集合。一个包（package）的名称是相对于工作空间根目录的BUILD文件路径。一个包可以包含子包，或者包含BUILD文件的子目录，从而形成一个包的层级结构。\n在Bazel中，每个BUILD文件定义了一个或多个目标。这些目标可以是编译的二进制文件、库、测试等。一个包是一组相关目标的集合，用于组织和管理相关代码和资源。包的名称是BUILD文件相对于工作空间根目录的路径，通过名称可以唯一标识和引用该包。\n一个包可以包含多个子包，这些子包可以是在包内部的子目录，每个子目录都包含一个或多个BUILD文件。这种层级结构的组织方式使得代码和资源可以按照逻辑和功能进行分组，便于项目的管理和维护。通过包的层级结构，可以在构建过程中方便地引用和操作不同级别的目标，从而形成灵活和可扩展的项目结构.\nPackage group # 一个目标，代表一组包（packages）。通常在可见性属性（visibility attribute）的值中使用。\nPlatform # 在构建过程中涉及的“机器类型”（machine type）。这包括Bazel运行的主机平台（\u0026ldquo;host\u0026quot;平台）、构建工具在其上执行的机器（\u0026ldquo;exec\u0026quot;平台）以及构建目标的目标机器（\u0026ldquo;target\u0026quot;平台）。\n主机平台（host platform）指的是运行Bazel的计算机系统，它提供了构建环境和资源。\n执行平台（exec platform）是指在构建过程中实际执行构建工具的机器。这些构建工具可以是编译器、链接器、测试运行器等。执行平台可能与主机平台不同，特别是在跨平台构建或远程构建的情况下。\n目标平台（target platform）是指构建的目标所要运行的目标机器。它可以是不同的操作系统、处理器架构或设备。Bazel支持在不同的目标平台上构建和运行代码，这使得跨平台开发和构建成为可能。\n通过区分主机平台、执行平台和目标平台，Bazel可以根据不同的平台要求和配置，有效地管理和执行构建过程，并生成适用于特定目标平台的构建结果。\nProvider # 提供者（Provider）是一种描述在依赖关系中在规则目标之间传递的信息单元的模式。通常，它包含编译器选项、传递的源文件或输出文件以及构建元数据等信息。它通常与依赖集（depsets）结合使用，以高效地存储累积的传递数据。内置的提供者之一是DefaultInfo。\n需要注意的是，针对特定规则目标保存具体数据的对象被称为“提供者实例”（provider instance），尽管有时它与“提供者”（provider）这个术语混淆使用。\n提供者的概念用于在Bazel构建系统中传递和共享关于目标的相关信息。通过定义和使用提供者，不同的规则目标之间可以传递和访问彼此所需的数据和元数据。提供者实例是提供者模式的具体实现，用于为特定的规则目标提供特定的数据。这种机制使得规则目标之间可以有效地共享和传递信息，并为构建系统提供了更灵活和可扩展的方式来处理目标之间的依赖关系和数据传递。\n参考: Provider documentation\nQuery (concept) # 构建分析是指对构建图进行分析，以了解目标属性和依赖关系结构的过程。Bazel支持三种查询变体：query、cquery和aquery。\nquery：这是最常用的查询命令，用于从构建图中获取目标的属性信息、依赖关系、输出文件等。可以使用query命令来查询目标的属性值、依赖的目标以及目标的输出文件等详细信息。\ncquery：这是一个更复杂和强大的查询命令，用于执行复杂的构建图查询操作。它支持使用复杂的查询条件和过滤器来获取目标的详细信息，并可以根据查询结果执行特定的操作。\naquery：这是一个用于分析构建图的高级查询命令。它可以提供有关目标之间依赖关系、构建过程和执行过程的详细信息。通过aquery命令，可以深入了解构建图的结构和执行细节，有助于进行构建性能分析和优化。\nRepository cache # 共享内容寻址缓存（Content-Addressable Cache）是Bazel为构建过程中下载的文件提供的一个共享缓存，可以跨工作空间共享。它使得在初始下载后可以进行离线构建成为可能。通常用于缓存通过repository rules（如http_archive）和repository rule APIs（如repository_ctx.download）下载的文件。只有在下载时指定了文件的SHA-256校验和，才会将文件缓存起来。\n共享内容寻址缓存是一种通过文件内容的哈希值来寻址和存储文件的机制。在Bazel中，通过将文件的SHA-256校验和用作其唯一标识符，将文件存储在共享缓存中。当下次构建需要相同文件时，Bazel会首先检查共享缓存，如果缓存中已存在相应的文件，则可以直接使用缓存中的副本，而无需重新下载。\nReproducibility # 无论环境，时间或者具体调用方式的变化，结果总是确定的，且可复现的。\nRule # 规则（Rule）是用于在BUILD文件中定义规则目标（rule targets）的一种模式，例如cc_library。从BUILD文件作者的角度来看，规则由一组属性和黑盒逻辑组成。逻辑告诉规则目标如何生成输出构件并将信息传递给其他规则目标。从.bzl文件作者的角度来看，规则是扩展Bazel以支持新的编程语言和环境的主要方式。\n在加载阶段，规则被实例化为规则目标，用于生成构建图。在分析阶段，规则目标通过提供者（providers）的形式向下游依赖传递信息，并注册描述如何生成输出构件的操作。这些操作在执行阶段运行。\n参考: Rules documentation\nRunfiles # Runfiles是指测试在运行时所需的文件和目录。这些文件和目录可以是测试执行过程中需要访问的数据文件、配置文件、资源文件等。Bazel会根据构建规则中指定的运行时依赖项，将相应的Runfiles复制到与测试可执行文件并列的目录结构中。这样，在运行测试时，可执行文件就可以访问其所需的运行时数据。\n参考: Runfiles documentation\nSandboxing # 沙盒，这个不用介绍了\nSkyframe # Skyframe Bazel的核心框架，用来提供并发，执行等功能\nStarlark # Starlark是用于编写规则和宏的扩展语言。它是Python的一个受限子集（在语法和语法上），旨在用于配置目的和提高性能。Starlark文件使用.bzl扩展名。BUILD文件使用Starlark的一个更受限制的版本（例如，不支持def函数定义），曾被称为Skylark。\n参考: Starlark language documentation\nStartup flags # The set of flags specified between bazel and the command, for example, bazel --host_jvm_debug build. These flags modify the configuration of the Bazel server, so any modification to startup flags causes a server restart. Startup flags are not specific to any command.\nTarget # 目标（Target）是在BUILD文件中定义的对象，由标签（label）标识。从最终用户的角度来看，目标代表了工作空间的可构建单元。\n通过实例化规则而声明的目标称为规则目标（rule target）。根据规则的不同，这些目标可以是可执行的（如cc_binary）或可测试的（如cc_test）。规则目标通常通过其属性（如deps）依赖于其他目标；这些依赖关系构成了目标图的基础。\n除了规则目标，还有文件目标和包组目标。文件目标对应于在BUILD文件中引用的构件。作为特例，任何包的BUILD文件始终被视为该包中的源文件目标。\n在加载阶段，目标被发现和解析。在分析阶段，目标与构建配置关联起来，形成配置目标（configured target）。\nTarget graph # 构建图（Build graph）是一种目标及其依赖关系的内存中表示形式。它在加载阶段生成，并作为分析阶段的输入。\n构建图是一个有向无环图（Directed Acyclic Graph，DAG），其中节点表示目标，边表示依赖关系。通过构建图，Bazel可以了解每个目标之间的依赖关系，以及构建过程中各个目标的顺序和执行逻辑\nTarget pattern # 用于指定针对哪些target的方式，常用的模式有:all（所有规则目标），:*（所有规则目标 + 文件目标），\u0026hellip;（当前包和所有子包递归）。可以组合使用，例如，//\u0026hellip;:*表示从工作空间根目录递归地包含所有包中的所有规则和文件目标。\nTests # 这个不用多介绍了吧，测试规则，一般要包含一个可执行对象，返回码啥的\nToolchain # 用于构建某种语言输出的一组工具。通常，工具链包括编译器、链接器、解释器或/和代码检查工具。工具链也可以根据平台的不同而有所变化，也就是说，Unix编译器工具链的组件可能与Windows的不同，尽管工具链是用于相同的语言。选择适合平台的正确工具链称为工具链解析（toolchain resolution）。\nTransition # 将配置变换的过程。即使从同一个规则实例化，build graph中的目标也可以具有不同的配置，这就是转换的作用。\n参考: User-defined transitions\nTree artifact # 表示一堆产物的集合。由于这些文件本身不是artifacts，因此对它们进行操作的action必须将Tree artifact明确为其输入或输出。\nVisibility # 构建系统中防止不必要的依赖关系的两种机制之一：目标可见性用于控制一个目标是否可以被其他目标依赖；加载可见性用于控制BUILD或.bzl文件是否可以加载给定的.bzl文件。通常情况下，没有上下文的情况下，\u0026ldquo;可见性\u0026quot;通常指的是目标可见性。\n参考: Visibility documentation\nWorkspace # 工作区，实际上就是包含WORKSPACE文件的目录\nWORKSPACE file # 用来定义工作区的文件，一般来说还包含一些外部信息和初始化流程\n2 核心基础概念 # 这部分实际上会针对性地重点讲一下最常用的术语，和最常见的问题。很多Bazel体系的用户经常遇到的错误都是比较\u0026quot;简单”的错误，往往是对核心概念理解不到位导致。这里的概念很多都是剥离了语言层面，只关注通用领域。\n建议直接看https://blog.aspect.dev/avoid-eager-fetches 获取最直接的理解。\n核心基础术语 # 介绍术语之前，先看看bazel的一次执行过程，都有什么阶段？\nLoading Phase: Bazel会加载工作目录里面的 BUILD文件，解析这些文件的内容来创建创建package和target graph。此阶段涉及评估宏、从glob到具体文件的映射关系（因为bazel支持glob，就那个什么**/*.txt的语法）和解析target之间的依赖关系。\n需要注意的是，如果在workspace里面写了一些外部依赖的命令，那么在LOAD阶段就会直接下载这些外部依赖，比方说下面的写在WORKSPACE里面的代码，一旦开始做构建，就会去下载对应的依赖（即使这些依赖目前并不需要），这个可能会导致bazel eager fetch的问题\nload(\u0026#34;@rules_python//python:pip.bzl\u0026#34;, \u0026#34;pip_parse\u0026#34;)\rpip_parse(\rname = \u0026#34;my_deps\u0026#34;,\rrequirements_lock = \u0026#34;//path/to:requirements_lock.txt\u0026#34;,\r)\rload(\u0026#34;@my_deps//:requirements.bzl\u0026#34;, \u0026#34;install_deps\u0026#34;)\rinstall_deps() Analysis Phase: Bazel分析目标图，确定构建所需的操作步骤。它会检查目标的依赖项或源文件是否发生了变化，以确定是否需要重新构建。在此阶段，Bazel创建一个操作图，表示生成所需输出的构建步骤的顺序。\n这里依然存在bazel eager fetch的问题，因为在BUILD文件里面同样包含Load语句，看下面的例子，只要需要涉及构建到这个对应BUILD文件，或者说这个package的某个target，就会引入npm的拉取\n# Content of //pkg1:BUILD\rload(\u0026#34;@npm//@bazel/typescript:index.bzl\u0026#34;, \u0026#34;ts_project\u0026#34;)\rpackage(default_visibility = [\u0026#34;//visibility:public\u0026#34;])\rts_project(\rname = \u0026#34;a\u0026#34;,\rsrcs = glob([\u0026#34;*.ts\u0026#34;]),\rdeclaration = True,\rtsconfig = \u0026#34;//:tsconfig.json\u0026#34;,\rdeps = [\r\u0026#34;@npm//@types/node\u0026#34;,\r\u0026#34;@npm//tslib\u0026#34;,\r],\r)\rfilegroup(name = \u0026#34;b\u0026#34;) Execution Phase: Bazel执行action graph中的操作（这里注意，不是target graph），以构建目标。该阶段涉及调用编译器、链接器和其他构建所需的工具。Bazel会尽可能并行执行这些操作，利用可用资源加快构建过程。\nOutput Generation: 随着操作的执行，Bazel生成目标指定的输出文件。这些文件可以是二进制可执行文件、库文件、测试结果或在BUILD文件中定义的其他构建产物。\nCaching and Incremental Build: Bazel利用缓存机制来提高构建性能。它会缓存先前构建的结果，并使用它们来避免重新执行未更改的操作。这种增量构建的特性使得Bazel只需重新构建项目中必要的部分，节省时间和资源。\n注意，bazel的\u0026ldquo;repository cache\u0026rdquo; 是不会缓存外部依赖的，如果外部依赖的下载规则里面有sha256 的hash它才会缓存，否则就是很简单的cvs拉取 Build Success or Failure: 构建结束啦，这个时候如果是编译就是输出具体文件的路径，如果测试（成功）就是成功了，没啥别的信息\n下面的术语，我会把影响到的阶段也一并列出\nLABEL # loading phase，analysis phase\n所有target都属于一个包。目标的名称称为其标签。每个标签都唯一标识一个目标。一般来说推荐提供完整路径用来标识特定的target，比方说下面的例子，第一部分是仓库名字@myrepo//. 因为大部分代码都是同样代码库，所以可以直接写//，省略最前面的代码库。标签第二部分表示package 名字， my/app/main 用路径来表示。我推荐用户使用完整的路径来标识target，而不是相对地方式，来避免问题\n@myrepo//my/app/main:app_binary BUILD 文件 # loading phase，analysis phase\n一般研发平时需要写的都是BUILD文件，简单来说就是如何定义Package。Build是Bazel的主要配置文件，用于告诉Bazel要构建哪些软件输出，它们的依赖关系是什么，以及如何构建它们。\n大多数构建规则都依托于具体的语言，比方说cc_binary、cc_library和cc_test分别是用于构建C++二进制文件、库和测试的构建规则。其他编程语言使用相同的命名方案，只是前缀不同，例如Java的规则以java_*开头。\nbazel的规则一部分是native支持，另一部分就是拓展方式支持，因为bazel的拓展大部分命名为 .bzl格式，因此使用类似下面的语句来加载规则\nload(\u0026#34;//foo/bar:file.bzl\u0026#34;, \u0026#34;some_library\u0026#34;) Bazel的规则分类\n*_binary规则用于构建特定语言的可执行程序。在构建完成后，可执行文件将位于构建工具的输出目录里面中，路径与规则的标签相对应。例如，//my:program将出现在二进制输出树的$(BIN_DIR)/my/program路径下，bazel会明确地输出编译出来的文件的路径，我原先测试的时候默认的BIN_DIR是bazel-bin\n在某些语言中，这些规则还会创建一个runfiles目录，其中包含属于该规则的data属性中提到的所有文件，或者依赖项的传递闭包中的任何规则所提到的文件。这些文件集合会集中在一个位置，方便部署到生产环境中。\n*_test规则是_binary规则的一种特殊形式，用于自动化测试。测试只是在成功时返回零的程序，所以不要再问，为什么我的测试程序成功了，但是没看到日志呀？\n与二进制文件一样，测试也有runfiles目录，其中的文件是测试在运行时合法打开的唯一文件。例如，一个名为cc_test(name=\u0026lsquo;x\u0026rsquo;, data=[\u0026rsquo;//foo:bar\u0026rsquo;])的程序在执行过程中可以打开和读取$TEST_SRCDIR/workspace/foo/bar。（每种编程语言都有自己的实用函数用于访问$TEST_SRCDIR的值，但它们都等同于直接使用环境变量。）如果违反此规则，当在远程测试主机上执行测试时，测试将失败。runfiles目录的可见性对应于BUILD文件中明确指定的可见性\n*_library规则用于指定在给定编程语言中单独编译的模块。库可以依赖其他库，而*_binary和*_test可以依赖库。\nDependencies # loading phase，analysis phase\n在写BUILD的时候，真正要解决的问题往往是依赖关系的修正，正常情况下，如果你依赖了什么东西，你就应该直接添加到deps或者data里面。而不是让自己依赖的组件来提供这种依赖，参考下面的例子\na直接依赖c，但忘记在构建文件中声明它时， 就会引入潜在风险。\na / a.in import b; import c; b.foo(); c.garply(); 声明的依赖关系不再符合实际的依赖关系。这种情况下构建可能会正常运行，因为依赖关系被闭包封锁了的，但掩盖了一个问题：a直接依赖c。如果b哪一天不依赖c了，那构建就崩了，这个问题实际上现在C++也开始治理了，禁止implicit include某个函数。\n大多数构建规则都具有三个属性，用于指定不同类型的通用依赖项：srcs、deps和data。下面对此进行解释。详细的相关信息，请参阅 所有规则通用的属性。\n这几种依赖关系提供不同的功能\nsrc依赖：构建时一个或多个规则直接使用的文件。\ndeps依赖：指向提供头文件、符号、库、数据等的单独编译模块的规则。\ndata依赖：常见情况时test或者binary需要的运行或者测试数据文件。编译单元测试执行文件时，不需要该文件，但在运行测试时确实需要它。简单来说就是在执行期间用到的工具。这种文件一般加在data里面，因为构建系统在一个隔离目录中运行测试（实际上就是沙盒），其中只有列到 data的文件可用。因此，如果二进制/库/测试需要运行一些文件，请在data.里面加这些东西。下面的代码就显示了两种情况，分别是本目录引用文件，和其它目录的test引用文件。\n# I need a config file from a directory named env:\rjava_binary(\rname = \u0026#34;setenv\u0026#34;,\r...\rdata = [\u0026#34;:env/default_env.txt\u0026#34;],\r)\r# I need test data from another directory\rsh_test(\rname = \u0026#34;regtest\u0026#34;,\rsrcs = [\u0026#34;regtest.sh\u0026#34;],\rdata = [\r\u0026#34;//data:file1.txt\u0026#34;,\r\u0026#34;//data:file2.txt\u0026#34;,\r...\r],\r) 想引用这些文件可通过相对路径path/to/data/file获得。在测试中，使用拼接的最终目录或者使用相对路径来引用这些文件，例如 ${TEST_SRCDIR}/workspace/path/to/data/file.\nVisibility # loading phase，analysis phase\n上面的提到了BUILD，提到了依赖，这里面自然而然就引出了一个问题，怎么控制我的target是否可以被别人依赖？可见性就解决这个问题：目标可见性控制谁可以依赖于具体的target，即谁可以在deps添加（例如 ）内使用对应的target。\n这个东西，目前看起来是一种很好的规范，但是不一定能立刻推广开。感觉可能大家第一反应就是所有的都是public。。。\n下面有一些具体的例子\n\u0026quot;//visibility:public\u0026quot;: 所有的外部packet都能看到这个target。实际上目前的代码基本都是这种情况。\n\u0026quot;//visibility:private\u0026quot;: 只有当前package的target可以看到这个target\n\u0026quot;//foo/bar:__pkg__\u0026quot;: //foo/bar 可以看到这个target(但子packages看不到).\n\u0026quot;//foo/bar:__subpackages__\u0026quot;: //foo/bar 和它的间接或直接 subpackages都可以看到\n\u0026quot;//some_pkg:my_package_group\u0026quot;: Grants access to all of the packages that are part of the given package_group.\nsandbox # execution phase\nbazel使用沙盒有多种原因\n不使用沙盒，如果使用了未声明的输入文件（即未在BUILD的规则的deps或者data里面明确列出的文件），那么本应该构建失败但是可能成功了反而。\n不正确地重用缓存条目会在远程缓存期间引发问题。共享缓存中的错误缓存条目会影响项目中的每个开发人员，而清除整个远程缓存不是可行的解决方案。\n沙盒隔离模拟了远程执行的行为 - 如果使用沙盒隔离进行构建运行良好，那么它很可能也适用于远程执行。通过使远程执行上传所有必需的文件（包括本地工具）。注意啊，沙盒只是个过程，最后还是进程，在buildfarm的环境里面，我已经看到好几次本地执行命令的副作用了，比方说什么创建文件不删除的奇葩代码\n那么，我们就需要按照情况，选择在何种模式下执行命令，简单来说就是选择用不用沙盒，用哪种沙盒\nlocal（也叫做standalone）策略不会进行任何类型的沙盒隔离。它只是将操作的命令行设置为工作目录，并在工作区的execroot中执行。\nprocesswrapper-sandbox是一种不需要任何“高级”功能的沙盒策略，它应该可以在任何POSIX系统上正常工作。它会构建一个沙盒目录，其中包含指向原始源文件的符号链接，然后使用该目录代替execroot设置操作的工作目录来执行操作的命令行，然后将输出文件移出沙盒并放入execroot中，最后删除沙盒。这样可以防止操作意外使用未声明的输入文件，并避免在execroot中留下未知的输出文件。\nlinux-sandbox更进一步，在processwrapper-sandbox的基础上进行了扩展。类似于Docker在底层所做的工作，它使用Linux命名空间（用户、挂载、PID、网络和IPC命名空间）将操作与主机隔离开来。也就是说，除了沙盒目录以外，它将整个文件系统设置为只读，因此操作不能意外修改主机文件系统上的任何内容。这样可以防止出现像是一个有错误的测试意外删除了您的$HOME目录的情况。您还可以选择禁止操作访问网络（非常棒的特征，总有一些奇怪的用户会写测试访问数据库）。\ndarwin-sandbox与之类似，但用于macOS。它使用苹果的sandbox-exec工具实现了与Linux沙盒大致相同的功能。\n请注意linux-sandbox和darwin-sandbox都无法在“套娃”场景中工作，因为不推荐docker使用privileged模式，就是 docker run --privileged，所以如果你想在docker里面调用linux-sandbox，做不到啊。所以一般docker里面是fallback到processwrapper-sandbox\n3 实践 快速浏览Bazel配置 # 现在我们来做一些实践，如何快速看配置相关的东西。\n简单来讲，看配置的方法基本就是三步\n先看WORKSPACE看工具链\nWORKSPACE中工具链的配置可以方便理解具体的规则上下文，配置是否移动化，阅读WORKSPACE中的配置就能看出来 递归地看.bazelrc里面的通用配置组\n配置组.bazelrc的阅读过程中，要注意try-import语句，正确的情况下会拆分为\n# Missing CI section\rtry-import %workspace%/abc.bazelrc 递归地看BUILD文件里面load的各种语句的实现\n具体的各种语句，比方说rules docker的规则细节什么的，都可以直接对应到starlark语句。 简单地看一个例子\nWORKSPACE如下，可以发现这是一个go的仓库，其初始化了GO的依赖，同时引入了rules_docker\nworkspace(name = \u0026#34;debug\u0026#34;)\rload(\u0026#34;@bazel_gazelle//:deps.bzl\u0026#34;, \u0026#34;gazelle_dependencies\u0026#34;)\rload(\u0026#34;//bazel:go_deps.bzl\u0026#34;, \u0026#34;go_dependencies\u0026#34;)\r# gazelle:repository_macro bazel/go_deps.bzl%go_dependencies\rgo_dependencies()\rload(\u0026#34;@io_bazel_rules_docker//repositories:deps.bzl\u0026#34;, rules_docker_go_deps = \u0026#34;deps\u0026#34;)\rrules_docker_go_deps() .bazelrc如下，可以发现环境默认使用python3，编译的C++选项默认为C++17，且开启了fpic，release模式下，开启了thin级别的flto。\nbuild --java_runtime_version=remotejdk_11\rbuild --host_force_python=PY3\rbuild --python_version=PY3\rbuild --cxxopt=-std=c++17\rbuild --experimental_cc_shared_library\rbuild --experimental_link_static_libraries_once\r# This is to avoid building both PIC and non-PIC versions in opt mode,\r# which doubles the build time.\rbuild --force_pic\rbuild:release --copt=\u0026#34;-g1\u0026#34; --copt=\u0026#34;-flto=thin\u0026#34; 4 Bazel的输出布局 # 这部分普通的研发应该遇不到，对于普通研发用户而言，输出布局一般是固定的，他们常常遇到的问题都是权限错误的问题，可以通过对输出布局的理解来定位具体是什么原因导致的问题，最常见也是最简单的解决方法就是chown。\n对Infra研发而言，这部分就比较重要，输出布局需要根据业务需要做变化，尤其在CI环境下，比方说输出目录，CACHE在哪里。还有如何排查一些确定性的问题的时候输出布局知识就体现其重要性\n输出布局 # 目前Bazel的文件布局是怎么实现的呢？\nBazel命令行必须在WORKSPACE文件所在的目录，或者子目录调用 Linux默认的outputRoot目录设置为~/.cache/bazel Bazel用户编译状态位于 outputRoot/_bazel_$USER. 在 outputUserRoot 目录有个 install 目录，里面放了一堆MD5的编译产物文件 在 outputUserRoot 目录, an outputBase 目录会根据workspace directory的MD5创建 .比方说workspace路径为 /home/user/src/my-project (or in a directory symlinked to that one), 就会创建/home/user/.cache/bazel/_bazel_user/7ffd56a6e4cb724ea575aba15733d113. 目录。 通过配置Bazel\u0026rsquo;s --output_base 启动选项来覆盖默认的output base 目录,举个例子 bazel --output_base=/tmp/bazel/output build x/y:z. 通过配置Bazel\u0026rsquo;s --output_user_root 启动选项来覆盖默认的install base 和 output base 目录，比方说bazel --output_user_root=/tmp/bazel build x/y:z. Copy\n\u0026lt;workspace-name\u0026gt;/ \u0026lt;== workspace文件路径\rbazel-my-project =\u0026gt; \u0026lt;...my-project\u0026gt; \u0026lt;== Symlink to execRoot\rbazel-out =\u0026gt; \u0026lt;...bin\u0026gt; \u0026lt;== Convenience symlink to outputPath\rbazel-bin =\u0026gt; \u0026lt;...bin\u0026gt; \u0026lt;== Convenience symlink to most recent written bin dir $(BINDIR)\rbazel-testlogs =\u0026gt; \u0026lt;...testlogs\u0026gt; \u0026lt;== Convenience symlink to the test logs directory\r/home/user/.cache/bazel/ \u0026lt;== Root for all Bazel output on a machine: outputRoot\r_bazel_$USER/ \u0026lt;== Top level directory for a given user depends on the user name:\routputUserRoot\rinstall/\rfba9a2c87ee9589d72889caf082f1029/ \u0026lt;== Hash of the Bazel install manifest: installBase\r_embedded_binaries/ \u0026lt;== Contains binaries and scripts unpacked from the data section of\rthe bazel executable on first run (such as helper scripts and the\rmain Java file BazelServer_deploy.jar)\r7ffd56a6e4cb724ea575aba15733d113/ \u0026lt;== Hash of the client\u0026#39;s workspace directory (such as\r/home/user/src/my-project): outputBase\raction_cache/ \u0026lt;== Action cache directory hierarchy\rThis contains the persistent record of the file\rmetadata (timestamps, and perhaps eventually also MD5\rsums) used by the FilesystemValueChecker.\raction_outs/ \u0026lt;== Action output directory. This contains a file with the\rstdout/stderr for every action from the most recent\rbazel run that produced output.\rcommand.log \u0026lt;== A copy of the stdout/stderr output from the most\rrecent bazel command.\rexternal/ \u0026lt;== The directory that remote repositories are\rdownloaded/symlinked into.\rserver/ \u0026lt;== The Bazel server puts all server-related files (such\ras socket file, logs, etc) here.\rjvm.out \u0026lt;== The debugging output for the server.\rexecroot/ \u0026lt;== The working directory for all actions. For special\rcases such as sandboxing and remote execution, the\ractions run in a directory that mimics execroot.\rImplementation details, such as where the directories\rare created, are intentionally hidden from the action.\rEvery action can access its inputs and outputs relative\rto the execroot directory.\r\u0026lt;workspace-name\u0026gt;/ \u0026lt;== Working tree for the Bazel build \u0026amp; root of symlink forest: execRoot\r_bin/ \u0026lt;== Helper tools are linked from or copied to here.\rbazel-out/ \u0026lt;== All actual output of the build is under here: outputPath\rlocal_linux-fastbuild/ \u0026lt;== one subdirectory per unique target BuildConfiguration instance;\rthis is currently encoded\rbin/ \u0026lt;== Bazel outputs binaries for target configuration here: $(BINDIR)\rfoo/bar/_objs/baz/ \u0026lt;== Object files for a cc_* rule named //foo/bar:baz\rfoo/bar/baz1.o \u0026lt;== Object files from source //foo/bar:baz1.cc\rother_package/other.o \u0026lt;== Object files from source //other_package:other.cc\rfoo/bar/baz \u0026lt;== foo/bar/baz might be the artifact generated by a cc_binary named\r//foo/bar:baz\rfoo/bar/baz.runfiles/ \u0026lt;== The runfiles symlink farm for the //foo/bar:baz executable.\rMANIFEST\r\u0026lt;workspace-name\u0026gt;/\r...\rgenfiles/ \u0026lt;== Bazel puts generated source for the target configuration here:\r$(GENDIR)\rfoo/bar.h such as foo/bar.h might be a headerfile generated by //foo:bargen\rtestlogs/ \u0026lt;== Bazel internal test runner puts test log files here\rfoo/bartest.log such as foo/bar.log might be an output of the //foo:bartest test with\rfoo/bartest.status foo/bartest.status containing exit status of the test (such as\rPASSED or FAILED (Exit 1), etc)\rinclude/ \u0026lt;== a tree with include symlinks, generated as needed. The\rbazel-include symlinks point to here. This is used for\rlinkstamp stuff, etc.\rhost/ \u0026lt;== BuildConfiguration for build host (user\u0026#39;s workstation), for\rbuilding prerequisite tools, that will be used in later stages\rof the build (ex: Protocol Compiler)\r\u0026lt;packages\u0026gt;/ \u0026lt;== Packages referenced in the build appear as if under a regular workspace 5 实践 GRPC的Bazel集成 # 俗话说“知行合一”，没有了实践，仅有理论或者思维的前行是不能得到正确的结论的，下面开始实际的写一套代码，来理解bazel的实际运用。不过这部分都是我写的mock代码，可以跳过\n创建WORKSPACE文件 # 开始利用bazel体系构建一个继承C++,Golang,Rust,Python的monorepo，该仓库需要支持grpc,glog,absiel,boost,gtest等外部仓库，我将这个仓库命名为cyber_security。\n新建一个folder，写入下面的内容到WORKSPACE文件，这里我们先引入llvm c++ \u0026amp; grpc的支持，写一个grpc的同步模式服务器。下面的代码可以看到注释掉了protobuf的引入（因为有个bug还没解决），引入了grpc和llvm toolchain。\n我之所以不使用llvm 16是因为在mac m1上会报错，所以使用的是15的llvm版本\nworkspace(name = \u0026#34;cyber_security\u0026#34;)\rload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\r# portable llvm toolchain\rBAZEL_TOOLCHAIN_TAG = \u0026#34;0.8.2\u0026#34;\rBAZEL_TOOLCHAIN_SHA = \u0026#34;0fc3a2b0c9c929920f4bed8f2b446a8274cad41f5ee823fd3faa0d7641f20db0\u0026#34;\rhttp_archive(\rname = \u0026#34;com_grail_bazel_toolchain\u0026#34;,\rsha256 = BAZEL_TOOLCHAIN_SHA,\rstrip_prefix = \u0026#34;bazel-toolchain-{tag}\u0026#34;.format(tag = BAZEL_TOOLCHAIN_TAG),\rcanonical_id = BAZEL_TOOLCHAIN_TAG,\rurl = \u0026#34;https://github.com/grailbio/bazel-toolchain/archive/refs/tags/{tag}.tar.gz\u0026#34;.format(tag = BAZEL_TOOLCHAIN_TAG),\r)\rload(\u0026#34;@com_grail_bazel_toolchain//toolchain:deps.bzl\u0026#34;, \u0026#34;bazel_toolchain_dependencies\u0026#34;)\rbazel_toolchain_dependencies()\rload(\u0026#34;@com_grail_bazel_toolchain//toolchain:rules.bzl\u0026#34;, \u0026#34;llvm_toolchain\u0026#34;)\rllvm_toolchain(\rname = \u0026#34;llvm_toolchain\u0026#34;,\rllvm_version = \u0026#34;15.0.0\u0026#34;,\r)\rload(\u0026#34;@llvm_toolchain//:toolchains.bzl\u0026#34;, \u0026#34;llvm_register_toolchains\u0026#34;)\rllvm_register_toolchains()\r# protobuf and grpc section\r# http_archive(\r# name = \u0026#34;rules_proto\u0026#34;,\r# sha256 = \u0026#34;dc3fb206a2cb3441b485eb1e423165b231235a1ea9b031b4433cf7bc1fa460dd\u0026#34;,\r# strip_prefix = \u0026#34;rules_proto-5.3.0-21.7\u0026#34;,\r# urls = [\r# \u0026#34;https://github.com/bazelbuild/rules_proto/archive/refs/tags/5.3.0-21.7.tar.gz\u0026#34;,\r# ],\r# )\r# load(\u0026#34;@rules_proto//proto:repositories.bzl\u0026#34;, \u0026#34;rules_proto_dependencies\u0026#34;, \u0026#34;rules_proto_toolchains\u0026#34;)\r# rules_proto_dependencies()\r# rules_proto_toolchains()\rhttp_archive(\rname = \u0026#34;com_github_grpc_grpc\u0026#34;,\rstrip_prefix = \u0026#34;grpc-1.57.0\u0026#34;,\rsha256 = \u0026#34;8393767af531b2d0549a4c26cf8ba1f665b16c16fb6c9238a7755e45444881dd\u0026#34;,\rurls = [\u0026#34;https://github.com/grpc/grpc/archive/refs/tags/v1.57.0.tar.gz\u0026#34;],\r)\rload(\u0026#34;@com_github_grpc_grpc//bazel:grpc_deps.bzl\u0026#34;, \u0026#34;grpc_deps\u0026#34;)\rgrpc_deps()\rload(\u0026#34;@com_github_grpc_grpc//bazel:grpc_extra_deps.bzl\u0026#34;, \u0026#34;grpc_extra_deps\u0026#34;)\rgrpc_extra_deps() 编写BUILD文件和代码 # 环境初始化好了以后新建proto文件和BUILD文件\n# experimental/sync_grpc_server/protos/stream.proto\rsyntax=\u0026#34;proto3\u0026#34;;\rpackage stream;\r// The service definition.\rservice Parser {\r// Sends a request\rrpc SendRequest (Request) returns (Response) {}\r}\rmessage Request {\rbytes client_ip = 1;\r}\rmessage Response {\rbytes event_id = 1;\r}\r# experimental/sync_grpc_server/protos/BUILD\r```starlark\rpackage(default_visibility = [\u0026#34;//visibility:public\u0026#34;])\rload(\u0026#34;@rules_proto//proto:defs.bzl\u0026#34;, \u0026#34;proto_library\u0026#34;)\rload(\u0026#34;@rules_cc//cc:defs.bzl\u0026#34;, \u0026#34;cc_proto_library\u0026#34;)\rload(\u0026#34;@com_github_grpc_grpc//bazel:cc_grpc_library.bzl\u0026#34;, \u0026#34;cc_grpc_library\u0026#34;)\r# The following three rules demonstrate the usage of the cc_grpc_library rule in\r# in a mode compatible with the native proto_library and cc_proto_library rules.\rproto_library(\rname = \u0026#34;stream_proto\u0026#34;,\rsrcs = [\u0026#34;stream.proto\u0026#34;],\r)\rcc_proto_library(\rname = \u0026#34;stream_cc_proto\u0026#34;,\rdeps = [\u0026#34;:stream_proto\u0026#34;],\r)\rcc_grpc_library(\rname = \u0026#34;stream_cc_grpc\u0026#34;,\rsrcs = [\u0026#34;:stream_proto\u0026#34;],\rgrpc_only = True,\rdeps = [\u0026#34;:stream_cc_proto\u0026#34;],\r)\r``` 接着新建server和client的代码\n#experimental/sync_grpc_server/src/sync_client.cc\r```cpp\r#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;memory\u0026gt;\r#include \u0026lt;string\u0026gt;\r#include \u0026#34;grpcpp/grpcpp.h\u0026#34;\r#ifdef BAZEL_BUILD\r#include \u0026#34;experimental/sync_grpc_server/protos/stream.grpc.pb.h\u0026#34;\r#else\r#include \u0026#34;stream.grpc.pb.h\u0026#34;\r#endif\rusing grpc::Channel;\rusing grpc::ClientContext;\rusing grpc::Status;\rusing stream::Parser;\rusing stream::Response;\rusing stream::Request;\rclass ParserClient {\rpublic:\rParserClient(std::shared_ptr\u0026lt;Channel\u0026gt; channel)\r: stub_(Parser::NewStub(channel)) {}\r// Assembles the client\u0026#39;s payload, sends it and presents the response back\r// from the server.\rstd::string SendRequest() {\r// Data we are sending to the server.\rRequest request;\rrequest.set_client_ip(\u0026#34;127.0.0.1\u0026#34;);\r// Container for the data we expect from the server.\rResponse response;\r// Context for the client. It could be used to convey extra information to\r// the server and/or tweak certain RPC behaviors.\rClientContext context;\r// The actual RPC.\rStatus status = stub_-\u0026gt;SendRequest(\u0026amp;context, request, \u0026amp;response);\r// Act upon its status.\rif (status.ok()) {\rreturn std::string(response.event_id());\r} else {\rstd::cout \u0026lt;\u0026lt; status.error_code() \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; status.error_message() \u0026lt;\u0026lt; std::endl;\rreturn \u0026#34;RPC failed\u0026#34;;\r}\r}\rprivate:\rstd::unique_ptr\u0026lt;Parser::Stub\u0026gt; stub_;\r};\rint main(int argc, char** argv) {\rstd::string address = \u0026#34;localhost\u0026#34;;\rstd::string port = \u0026#34;50051\u0026#34;;\rstd::string server_address = address + \u0026#34;:\u0026#34; + port;\rstd::cout \u0026lt;\u0026lt; \u0026#34;Client querying server address: \u0026#34; \u0026lt;\u0026lt; server_address \u0026lt;\u0026lt; std::endl;\r// Instantiate the client. It requires a channel, out of which the actual RPCs\r// are created. This channel models a connection to an endpoint (in this case,\r// localhost at port 50051). We indicate that the channel isn\u0026#39;t authenticated\r// (use of InsecureChannelCredentials()).\rParserClient Parser(grpc::CreateChannel(\rserver_address, grpc::InsecureChannelCredentials()));\rstd::string response = Parser.SendRequest();\rstd::cout \u0026lt;\u0026lt; \u0026#34;Parser received: \u0026#34; \u0026lt;\u0026lt; response \u0026lt;\u0026lt; std::endl;\rreturn 0;\r}\r```\r#experimental/sync_grpc_server/src/sync_server.cc\r```cpp\r#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;memory\u0026gt;\r#include \u0026lt;string\u0026gt;\r#include \u0026lt;grpcpp/grpcpp.h\u0026gt;\r#ifdef BAZEL_BUILD\r#include \u0026#34;experimental/sync_grpc_server/protos/stream.grpc.pb.h\u0026#34;\r#else\r#include \u0026#34;stream.grpc.pb.h\u0026#34;\r#endif\rusing grpc::Server;\rusing grpc::ServerBuilder;\rusing grpc::ServerContext;\rusing grpc::Status;\rusing stream::Request;\rusing stream::Response;\rusing stream::Parser;\r// Logic and data behind the server\u0026#39;s behavior.\rclass ParserServiceImpl final : public Parser::Service {\rStatus SendRequest(ServerContext* context, const Request* request,\rResponse* response) override {\rresponse-\u0026gt;set_event_id(\u0026#34;47F1F2FF-7679-4378-ACC7-051F72D5679A\u0026#34;);\rreturn Status::OK;\r}\r};\rvoid RunServer() {\rstd::string address = \u0026#34;0.0.0.0\u0026#34;;\rstd::string port = \u0026#34;50051\u0026#34;;\rstd::string server_address = address + \u0026#34;:\u0026#34; + port;\rParserServiceImpl service;\rServerBuilder builder;\r// Listen on the given address without any authentication mechanism.\rbuilder.AddListeningPort(server_address, grpc::InsecureServerCredentials());\r// Register \u0026#34;service\u0026#34; as the instance through which we\u0026#39;ll communicate with\r// clients. In this case it corresponds to an *synchronous* service.\rbuilder.RegisterService(\u0026amp;service);\r// Finally assemble the server.\rstd::unique_ptr\u0026lt;Server\u0026gt; server(builder.BuildAndStart());\rstd::cout \u0026lt;\u0026lt; \u0026#34;Server listening on \u0026#34; \u0026lt;\u0026lt; server_address \u0026lt;\u0026lt; std::endl;\r// Wait for the server to shutdown. Note that some other thread must be\r// responsible for shutting down the server for this call to ever return.\rserver-\u0026gt;Wait();\r}\rint main(int argc, char** argv) {\rRunServer();\rreturn 0;\r}\r```\r#experimental/sync_grpc_server/src/BUILD\r```starlark\rpackage(default_visibility = [\u0026#34;//visibility:public\u0026#34;])\rload(\u0026#34;@rules_cc//cc:defs.bzl\u0026#34;, \u0026#34;cc_binary\u0026#34;)\rcc_binary(\rname = \u0026#34;sync_client\u0026#34;,\rsrcs = [\u0026#34;sync_client.cc\u0026#34;],\rdefines = [\u0026#34;BAZEL_BUILD\u0026#34;],\rdeps = [\r\u0026#34;//experimental/sync_grpc_server/protos:stream_cc_grpc\u0026#34;,\r\u0026#34;@com_github_grpc_grpc//:grpc++\u0026#34;,\r],\r)\rcc_binary(\rname = \u0026#34;sync_server\u0026#34;,\rsrcs = [\u0026#34;sync_server.cc\u0026#34;],\rdefines = [\u0026#34;BAZEL_BUILD\u0026#34;],\rdeps = [\r\u0026#34;//experimental/sync_grpc_server/protos:stream_cc_grpc\u0026#34;,\r\u0026#34;@com_github_grpc_grpc//:grpc++\u0026#34;,\r],\r)\r``` 运行 # # 窗口1 运行server\rbazel run experimental/sync_grpc_server/src:sync_server\r# 窗口2 运行client\rbazel run experimental/sync_grpc_server/src:sync_client\r#输出结果\r➜ cyber_security git:(main) bazel run experimental/sync_grpc_server/src:sync_client\rINFO: Analyzed target //experimental/sync_grpc_server/src:sync_client (0 packages loaded, 0 targets configured).\rINFO: Found 1 target...\rTarget //experimental/sync_grpc_server/src:sync_client up-to-date:\rbazel-bin/experimental/sync_grpc_server/src/sync_client\rINFO: Elapsed time: 0.168s, Critical Path: 0.00s\rINFO: 1 process: 1 internal.\rINFO: Build completed successfully, 1 total action\rINFO: Running command line: bazel-bin/experimental/sync_grpc_server/src/sync_client\rClient querying server address: localhost:50051\rParser received: 47F1F2FF-7679-4378-ACC7-051F72D5679A 6 使用Bazel管理C++ # 使用Bazel管理C++实际上并没有什么本质的不同，转变思想，从task based build system转移到artifacts build system，仅此而已。C++本身代码构建和Bazel的依赖呀，src啥的属性也非常匹配。我们先看看基础命令\nC++基础规则 # CC_IMPORT # cc_import(\rname = \u0026#34;mylib\u0026#34;,\rhdrs = [\u0026#34;mylib.h\u0026#34;],\rstatic_library = \u0026#34;libmylib.a\u0026#34;,\r# If alwayslink is turned on,\r# libmylib.a will be forcely linked into any binary that depends on it.\r# alwayslink = 1,\r) cc_import是用来解决外部依赖的问题的，一般用来将C++头文件和静态库从外部包或存储库导入到项目里，这个可以提供给跨平台编译使用\nCC_LIBRARY # cc_library(\rname = \u0026#34;my_library\u0026#34;,\rsrcs = [\u0026#34;file1.cpp\u0026#34;, \u0026#34;file2.cpp\u0026#34;],\rhdrs = [\u0026#34;header1.h\u0026#34;, \u0026#34;header2.h\u0026#34;],\rvisibility = [\u0026#34;//visibility:public\u0026#34;],\rdeps = [\u0026#34;//path/to/dependency\u0026#34;],\rdefines = [\u0026#34;DEBUG\u0026#34;],\rcopts = [\u0026#34;-Wall\u0026#34;, \u0026#34;-O2\u0026#34;],\r) cc_library 是 Bazel 中专门用于构建 C++ 库的构建规则，有以下属性。\nname：指定库目标的名称。 srcs：列出库的 C++ 源文件（.cpp 文件）。 hdrs：列出库的 C++ 头文件（.h 文件）。 visibility：设置库目标的可见性，以控制其他目标是否可以依赖它。它使用标签模式，如 \u0026quot;//path/to/package:target\u0026quot;。 deps：指定库的依赖项。这可以是其他 cc_library 目标或库所依赖的其他类型的目标。 defines：定义预处理宏，用于编译过程中使用。 copts：设置库的编译选项，如警告标志或优化级别。 CC_BINARY # cc_binary(\rname = \u0026#34;my_binary\u0026#34;,\rsrcs = [\u0026#34;main.cpp\u0026#34;, \u0026#34;util.cpp\u0026#34;],\rhdrs = [\u0026#34;util.h\u0026#34;],\rvisibility = [\u0026#34;//visibility:public\u0026#34;],\rdeps = [\u0026#34;//path/to/dependency\u0026#34;],\rcopts = [\u0026#34;-Wall\u0026#34;, \u0026#34;-O2\u0026#34;],\r) 参数因为和cc_library过分类似就不写了，就多赘述一句，除了编译，可以使用 Bazel 的 bazel run 命令，执行对应的Binary，这个执行一般是在sandbox里\nbazel run //path/to/package:my_binary CC_TEST # cc_test(\rname = \u0026#34;my_test\u0026#34;,\rsrcs = [\u0026#34;test.cpp\u0026#34;, \u0026#34;util.cpp\u0026#34;],\rhdrs = [\u0026#34;util.h\u0026#34;],\rvisibility = [\u0026#34;//visibility:public\u0026#34;],\rdeps = [\u0026#34;//path/to/dependency\u0026#34;],\rsize = \u0026#34;small\u0026#34;,\rcopts = [\u0026#34;-Wall\u0026#34;, \u0026#34;-O2\u0026#34;],\r) 重复的东西不写了，只看几个关键点\nsize属性用于指定测试的时间和内存使用约束。它用来限制测试运行的时间和内存，防止测试用例运行时间过长或占用过多的系统内存资源，下面的表格给出来了一些约定俗成的资源消耗规格。一般来说，如果cc_test是单元测试，那么size指定为small；如果是集成测试，size指定为medium，如果是接受性测试或者端到端测试，一般size指定为large或者enormous Size RAM (in MB) CPU (in CPU cores) Default timeout small 20 1 short (1 minute) medium 100 1 moderate (5 minutes) large 300 1 long (15 minutes) enormous 800 1 eternal (60 minutes) 一般调用的时候都是直接\nbazel test //path/to/package:my_test 例子 # 这里只提供BUILD文件作为例子参考了，针对C++一般也是直接用Gtest，直接一套集成。。。\nload(\u0026#34;//bazel:cpplint.bzl\u0026#34;, \u0026#34;cpplint\u0026#34;)\rload(\u0026#34;//bazel:rules_cc.bzl\u0026#34;, \u0026#34;cc_library\u0026#34;, \u0026#34;cc_test\u0026#34;)\rpackage(default_visibility = [\u0026#34;//visibility:public\u0026#34;])\rcc_library(\rname = \u0026#34;file_debug\u0026#34;,\rsrcs = [\u0026#34;file_debug.cc\u0026#34;],\rhdrs = [\u0026#34;file_debug.h\u0026#34;],\rdeps = [\r\u0026#34;@boost//:filesystem\u0026#34;,\r\u0026#34;@com_github_google_glog//:glog\u0026#34;,\r\u0026#34;@com_google_absl//absl/strings\u0026#34;,\r\u0026#34;@com_google_absl//absl/strings:str_format\u0026#34;,\r\u0026#34;@com_googlesource_code_re2//:re2\u0026#34;,\r],\r)\rfilegroup(\rname = \u0026#34;file_pointer_file\u0026#34;,\r# only two mock file pointer file, will never add new, so use glob\rsrcs = glob([\r\u0026#34;*.txt\u0026#34;,\r]),\r)\rcc_test(\rname = \u0026#34;file_debug_test\u0026#34;,\rsrcs = [\r\u0026#34;file_debug_test.cc\u0026#34;,\r],\rdata = [\r\u0026#34;:file_pointer_file\u0026#34;,\r],\rdeps = [\r\u0026#34;:file_debug\u0026#34;,\r\u0026#34;@com_google_googletest//:gtest\u0026#34;,\r\u0026#34;@com_google_googletest//:gtest_main\u0026#34;,\r],\r)\rcpplint() 常见问题 # 写几个常见的问题，我目前看到很多研发都问过\ncc_test可以管理什么样子的test？理论上只要是C++的测试程序，有返回值来判断是否执行成功，就都可以写为cc_test，因此无论写单元测试，集成测试，acceptance-check都是可以的。使用什么层级的测试，做哪些事情属于CI系统或者程序员自己的层面 为什么cc_test超时了？参考cc_test那部分的size属性，如果size不合适可能会报错TIMEOUT。 为什么cc_test好像没测试，直接就输出了成功？我希望用户能理解，bazel本身是有缓存机制的，如果不希望使用已经缓存过的结果，建议在test的时候加上\u0026ndash;nocache_test_results，来强行reruntest 为什么cc_test没输出日志？在test运行成功的情况下（或者说期望情况下），可以认为逻辑正确执行，输入测试用例都得到了正确的输出，那么我们不需要关心具体的细节，bazel就不会输出任何问题。只有test执行失败，才会输出对应的日志 为什么我写的cc_test找不到文件？检查写的BUILD文件里面的deps和data是不是都写全了，路径是不是写的相对路径，将依赖的数据路径加到BUILD里的时候，数据依赖应该是使用相对路径，而不是本地绝对路径。 下面来看看一套从0开始的C++集成教程，这个实际上是官方教程，我直接抄的\nC++ 集成入门 # 先决条件 # 装好bazel和git以后，先把bazel官方给的代码库clone下来\ngit clone https://github.com/bazelbuild/examples 本教程的示例项目位于该examples/cpp-tutorial目录中。\n下面看一下它的结构：\nexamples\r└── cpp-tutorial\r├──stage1\r│ ├── main\r│ │ ├── BUILD\r│ │ └── hello-world.cc\r│ └── WORKSPACE\r├──stage2\r│ ├── main\r│ │ ├── BUILD\r│ │ ├── hello-world.cc\r│ │ ├── hello-greet.cc\r│ │ └── hello-greet.h\r│ └── WORKSPACE\r└──stage3\r├── main\r│ ├── BUILD\r│ ├── hello-world.cc\r│ ├── hello-greet.cc\r│ └── hello-greet.h\r├── lib\r│ ├── BUILD\r│ ├── hello-time.cc\r│ └── hello-time.h\r└── WORKSPACE 共有三组文件，每组代表本教程中的一个阶段。在第一阶段，构建驻留在单个包中的单个目标。在第二阶段，您将从单个包构建二进制文件和库。在第三个也是最后一个阶段，您将构建一个包含多个包的项目并使用多个目标构建它。\n设置WorkSpace # 在构建项目之前，需要设置WorkSpace。一般将工作区理解为一个保存源代码和 Bazel 构建输出的目录。它必须包含下面两种文件：\nWORKSPACE file文件，标识一个 Bazel 工作区，一般是位于代码根目录下。 BUILD files``，告诉 Bazel 如何构建项目的不同部分。工作区中包含文件的目录BUILD是package。（本教程稍后将详细介绍包。） 在将来的项目中，要将目录指定为 Bazel 工作区，请创建一个WORKSPACE在该目录中命名的空文件。\n注意：当 Bazel 构建项目时，所有输入必须位于同一工作区中。驻留在不同工作区中的文件彼此独立，除非显式地链接到一起。有关工作区规则的更多详细信息可以在本指南中找到。\n了解 BUILD 文件 # 一个BUILD文件包含多种不同类型的 Bazel 指令。每个 BUILD文件至少需要一个规则 作为一组指令，告诉 Bazel 如何构建目标，这些目标包括，例如可执行二进制binary或库。BUILD文件中构建rule的每个实例（）称为目标 ，并指向一组特定的源文件和依赖项。一个目标也可以指向其他目标。\n查看目录BUILD下的文件cpp-tutorial/stage1/main：\ncc_binary(\rname = \u0026#34;hello-world\u0026#34;,\rsrcs = [\u0026#34;hello-world.cc\u0026#34;],\r) 在我们的示例中，hello-world目标实例化 Bazel 的内置 cc_binary rule. 该规则告诉 Bazel 从源文件构建一个独立的linux binary， hello-world.cc没有依赖项。\n接下来构建单一目标，且不会出现多包以来的代码。\n第一阶段：单一目标、单一包 # 现在是构建项目第一部分的时候了。这部分的代码结构为：\nexamples\r└── cpp-tutorial\r└──stage1\r├── main\r│ ├── BUILD\r│ └── hello-world.cc\r└── WORKSPACE 首先切换目录到cpp-tutorial/stage1目录：\ncd cpp-tutorial/stage1 接下来，运行：\nbazel build //main:hello-world 可以看到如下的输出内容，Bazel 生成的东西看起来像这样：\nINFO: Found 1 target...\rTarget //main:hello-world up-to-date:\rbazel-bin/main/hello-world\rINFO: Elapsed time: 2.267s, Critical Path: 0.25s 恭喜，使用bazel很简单。Bazel 将构建的目标target文件，放置在 bazel-bin工作区根目录中。\n现在即可运行您新构建的二进制文件，即：\nbazel-bin/main/hello-world 这会导致打印“ Hello world”消息。\n这是第一阶段的依赖关系图：\nhello-world 的依赖关系图显示具有单个源文件的单个目标。\n第二阶段：多个构建目标 # 虽然单个目标对于小型项目来说就足够了，但较大的项目，无论是从效率的角度，还是逻辑的角度，需要拆分为多个目标和包，。\n第 2 阶段使用的目录：\n├──stage2\r│ ├── main\r│ │ ├── BUILD\r│ │ ├── hello-world.cc\r│ │ ├── hello-greet.cc\r│ │ └── hello-greet.h\r│ └── WORKSPACE 下面看一下目录BUILD中的文件cpp-tutorial/stage2/main：\ncc_library(\rname = \u0026#34;hello-greet\u0026#34;,\rsrcs = [\u0026#34;hello-greet.cc\u0026#34;],\rhdrs = [\u0026#34;hello-greet.h\u0026#34;],\r)\rcc_binary(\rname = \u0026#34;hello-world\u0026#34;,\rsrcs = [\u0026#34;hello-world.cc\u0026#34;],\rdeps = [\r\u0026#34;:hello-greet\u0026#34;,\r],\r) 使用此BUILD文件，Bazel 首先构建hello-greet库（使用 Bazel 的内置cc_library rule），然后构建hello-world二进制文件。deps目标中的属性告诉hello-worldBazelhello-greet 构建二进制文件需要该库hello-world。\n在构建该项目的新版本之前，您需要更改目录，cpp-tutorial/stage2通过运行以下命令切换到该目录：\ncd ../stage2 现在您可以使用以下熟悉的命令构建新的二进制文件：\nbazel build //main:hello-world Bazel 再一次生成了如下所示的内容：\nINFO: Found 1 target...\rTarget //main:hello-world up-to-date:\rbazel-bin/main/hello-world\rINFO: Elapsed time: 2.399s, Critical Path: 0.30s 现在您可以测试新构建的二进制文件，它返回另一个“ Hello world”：\nbazel-bin/main/hello-world 如果您现在修改hello-greet.cc并重建项目，Bazel 只会重新编译该文件。\n查看依赖关系图，您可以看到它hello-world依赖于名为 的额外输入hello-greet：\n“hello-world”的依赖关系图显示文件修改后的依赖关系更改。\n# 第三阶段：多包 # 下一阶段又增加了一层复杂性，并构建了一个包含多个包的项目。下面看一下该 cpp-tutorial/stage3目录的结构和内容：\n└──stage3\r├── main\r│ ├── BUILD\r│ ├── hello-world.cc\r│ ├── hello-greet.cc\r│ └── hello-greet.h\r├── lib\r│ ├── BUILD\r│ ├── hello-time.cc\r│ └── hello-time.h\r└── WORKSPACE 您可以看到现在有两个子目录，每个子目录都包含一个BUILD 文件。因此，对于 Bazel 来说，工作区现在包含两个包：lib和 main。\n看一下lib/BUILD文件：\ncc_library(\rname = \u0026#34;hello-time\u0026#34;,\rsrcs = [\u0026#34;hello-time.cc\u0026#34;],\rhdrs = [\u0026#34;hello-time.h\u0026#34;],\rvisibility = [\u0026#34;//main:__pkg__\u0026#34;],\r) 看一下main/BUILD文件中：\ncc_library(\rname = \u0026#34;hello-greet\u0026#34;,\rsrcs = [\u0026#34;hello-greet.cc\u0026#34;],\rhdrs = [\u0026#34;hello-greet.h\u0026#34;],\r)\rcc_binary(\rname = \u0026#34;hello-world\u0026#34;,\rsrcs = [\u0026#34;hello-world.cc\u0026#34;],\rdeps = [\r\u0026#34;:hello-greet\u0026#34;,\r\u0026#34;//lib:hello-time\u0026#34;,\r],\r) 主包中的目标hello-world依赖包hello-time中的目标lib（因此是目标标签//lib:hello-time）——Bazel 通过deps属性知道这一点。依赖关系图中看到这一点：\n“hello-world”的依赖关系图显示了主包中的目标如何依赖于“lib”包中的目标。\n为了成功构建，需要使用 Visibility 属性使//lib:hello-time目标lib/BUILD 对目标显式可见。main/BUILD这是因为默认情况下目标仅对同一文件中的其他目标可见 BUILD。Bazel 使用目标可见性来防止诸如包含实现细节的库泄漏到公共 API 等问题。\n现在构建该项目的最终版本。cpp-tutorial/stage3 通过运行以下命令切换到目录：\ncd ../stage3 再次运行以下命令：\nbazel build //main:hello-world Bazel 生成的东西看起来像这样：\nINFO: Found 1 target...\rTarget //main:hello-world up-to-date:\rbazel-bin/main/hello-world\rINFO: Elapsed time: 0.167s, Critical Path: 0.00s 好的，大功告成啦\nC++如何引用外部库 # 接下来提到的东西就是Bazel被人诟病已久的传播性，理论上用Bazel管理的外部依赖都需要用Bazel的方式构建，实际上这个很合理，因为一致的从源码构建，才能保证flag的正确性，我有时候用Cmake也很无奈，构建外部库对当前的系统造成了污染。。。。\n言归正传，目前Bazel还是提供了使用不同的构建方式依赖外部库的方法。\n方法1 直接找到对应的实现 # 很多著名的库实际上要么本身支持了bazel，要么有人已经写好了对应的bazel规则。这个最直接的例子就是boost了，参考链接为https://github.com/nelhage/rules_boost，直接在WORKSPACE文件里面写入下面的内容。PS 记得更新url和sha256来使用新一些的版本。\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\r# Boost\r# Famous C++ library that has given rise to many new additions to the C++ Standard Library\r# Makes @boost available for use: For example, add `@boost//:algorithm` to your deps.\r# For more, see https://github.com/nelhage/rules_boost and https://www.boost.org\rhttp_archive(\rname = \u0026#34;com_github_nelhage_rules_boost\u0026#34;,\r# Replace the commit hash in both places (below) with the latest, rather than using the stale one here.\r# Even better, set up Renovate and let it do the work for you (see \u0026#34;Suggestion: Updates\u0026#34; in the README).\rurl = \u0026#34;https://github.com/nelhage/rules_boost/archive/96e9b631f104b43a53c21c87b01ac538ad6f3b48.tar.gz\u0026#34;,\rstrip_prefix = \u0026#34;rules_boost-96e9b631f104b43a53c21c87b01ac538ad6f3b48\u0026#34;,\r# When you first run this tool, it\u0026#39;ll recommend a sha256 hash to put here with a message like: \u0026#34;DEBUG: Rule \u0026#39;com_github_nelhage_rules_boost\u0026#39; indicated that a canonical reproducible form can be obtained by modifying arguments sha256 = ...\u0026#34;\r)\rload(\u0026#34;@com_github_nelhage_rules_boost//:boost/boost.bzl\u0026#34;, \u0026#34;boost_deps\u0026#34;)\rboost_deps() 写代码的时候如果想使用boost对应的库，就可以在对应的规则的deps里面加上对boost依赖即可@boost即可。举个简单例子，比方说我要在一个C++ library里面使用boost的算法库，就直接在在deps里面加上@boost//:algorithm\n如果你是用的是std17的C++，那么可能一部分功能直接用标准库即可，不一定要引用boost。\n另一个例子是rules_folly，这个是（前）同事，也是工程治理大佬写的，参考链接为https://github.com/storypku/rules_folly\n按照github链接的方式，安装好必要的依赖，下面是ubuntu的例子\nsudo apt-get update \\\r\u0026amp;\u0026amp; sudo apt-get -y install --no-install-recommends \\\rautoconf \\\rautomake \\\rlibtool \\\rlibssl-dev 接着在WORKSPACE文件里面添加好对应的依赖，使用\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\rhttp_archive(\rname = \u0026#34;com_github_storypku_rules_folly\u0026#34;,\rsha256 = \u0026#34;16441df2d454a6d7ef4da38d4e5fada9913d1f9a3b2015b9fe792081082d2a65\u0026#34;,\rstrip_prefix = \u0026#34;rules_folly-0.2.0\u0026#34;,\rurls = [\r\u0026#34;https://github.com/storypku/rules_folly/archive/v0.2.0.tar.gz\u0026#34;,\r],\r)\rload(\u0026#34;@com_github_storypku_rules_folly//bazel:folly_deps.bzl\u0026#34;, \u0026#34;folly_deps\u0026#34;)\rfolly_deps()\rload(\u0026#34;@com_github_nelhage_rules_boost//:boost/boost.bzl\u0026#34;, \u0026#34;boost_deps\u0026#34;)\rboost_deps() 这个库有一个点可能需要注意，\n方法2 手动改写BUILD文件 # 手动改写BUILD文件，需要用户自己能够看明白Cmake的构建稳健是怎么生效的，有的时候做编译还得去考虑native编译工具链的事情，总之是个比较麻烦的事情。但也不失为一种办法。这种方法只需要注意：\n首先需要用http_archive的方式，将第三方库下载下来 其次，用指定Build的方式，指定为自己编写的BUILD文件 给一个简单的例子，将hiredis转换为bazel的库，这里面我就不写指定Build的部分了，只简单写写怎么写BUILD文件。\n首先看hiredis的cmakelists.txt文件，重点就是找到对应的SRC和对应的头文件，确定哪些应该暴露，哪些不应该暴露。除此之外，还要关注一些编译选项的东西，构建应该是统一的一套，即依赖hiredis的库编译用的是release模式，那么hiredis也是release模式。\n# Hiredis requires C99\rSET(CMAKE_C_STANDARD 99) #C99标准，添加到copt里面即可\rSET(CMAKE_POSITION_INDEPENDENT_CODE ON) #fpic标记，编译静态库时需要加上，这样子才能生成的静态库被第三方引用\rSET(CMAKE_DEBUG_POSTFIX d)\rSET(hiredis_sources #下面的.c文件对应于bazel src文件，我们可以看到目前的代码实际上是包含sync和async的，\ralloc.c\rasync.c\rdict.c\rhiredis.c\rnet.c\rread.c\rsds.c\rsockcompat.c)\rSET(hiredis_sources ${hiredis_sources})\r...\rADD_LIBRARY(hiredis SHARED ${hiredis_sources}) #要生成这两个库文件\rADD_LIBRARY(hiredis_static STATIC ${hiredis_sources})\rSET_TARGET_PROPERTIES(hiredis\rPROPERTIES WINDOWS_EXPORT_ALL_SYMBOLS TRUE\rVERSION \u0026#34;${HIREDIS_SONAME}\u0026#34;)\rSET_TARGET_PROPERTIES(hiredis_static\rPROPERTIES COMPILE_PDB_NAME hiredis_static)\rSET_TARGET_PROPERTIES(hiredis_static\rPROPERTIES COMPILE_PDB_NAME_DEBUG hiredis_static${CMAKE_DEBUG_POSTFIX})\r#INSTALL_INTERFACE用于给install的时候指定使用的引用文件，那么INSTALL_INTERFACE又是怎么指定的？看这个https://ravenxrz.ink/archives/e40194d1.html\rTARGET_INCLUDE_DIRECTORIES(hiredis PUBLIC $\u0026lt;INSTALL_INTERFACE:include\u0026gt; $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}\u0026gt;)\rTARGET_INCLUDE_DIRECTORIES(hiredis_static PUBLIC $\u0026lt;INSTALL_INTERFACE:include\u0026gt; $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}\u0026gt;)\r#CONFIGURE_FILE替换原本的普通文件的内容，给pkg用的，不需要了，所以去掉\rCONFIGURE_FILE(hiredis.pc.in hiredis.pc @ONLY)\r...\r#Cpack打包的内容，直接省略了，关系并不大\r...\rIF(ENABLE_SSL)\rIF (NOT OPENSSL_ROOT_DIR) #这个是export的openssl根目录，用来判断找openssl\rIF (APPLE)\rSET(OPENSSL_ROOT_DIR \u0026#34;/usr/local/opt/openssl\u0026#34;)\rENDIF()\rENDIF()\rFIND_PACKAGE(OpenSSL REQUIRED) #找到依赖的openssl库\rSET(hiredis_ssl_sources #编译hiredis_ssl库的源文件\rssl.c)\rADD_LIBRARY(hiredis_ssl SHARED ${hiredis_ssl_sources}) #设定生成的库文件\rADD_LIBRARY(hiredis_ssl_static STATIC\r${hiredis_ssl_sources})\r...\rSET_TARGET_PROPERTIES(hiredis_ssl_static\rPROPERTIES COMPILE_PDB_NAME hiredis_ssl_static)\rSET_TARGET_PROPERTIES(hiredis_ssl_static\rPROPERTIES COMPILE_PDB_NAME_DEBUG hiredis_ssl_static${CMAKE_DEBUG_POSTFIX})\rTARGET_INCLUDE_DIRECTORIES(hiredis_ssl PRIVATE \u0026#34;${OPENSSL_INCLUDE_DIR}\u0026#34;) #引入openssl包裹的头文件，只给自己用。不会暴露给hiredis_ssl的使用者\rTARGET_INCLUDE_DIRECTORIES(hiredis_ssl_static PRIVATE \u0026#34;${OPENSSL_INCLUDE_DIR}\u0026#34;)\rTARGET_LINK_LIBRARIES(hiredis_ssl PRIVATE ${OPENSSL_LIBRARIES})\r...\rINSTALL(TARGETS hiredis_ssl hiredis_ssl_static\rEXPORT hiredis_ssl-targets\rRUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR} #安装bin文件的位置\rLIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR} #安装动态库的位置\rARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}) #安装静态库的位置\r...\rINSTALL(FILES hiredis_ssl.h DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/hiredis) #可以看到安装头文件的位置，将hiredis_ssl.h搞到了安装头文件hiredis里面\rINSTALL(FILES ${CMAKE_CURRENT_BINARY_DIR}/hiredis_ssl.pc #提供给pkg安装用的，不用关注\rDESTINATION ${CMAKE_INSTALL_LIBDIR}/pkgconfig)\rexport(EXPORT hiredis_ssl-targets\rFILE \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/hiredis_ssl-targets.cmake\u0026#34;\rNAMESPACE hiredis::)\rSET(CMAKE_CONF_INSTALL_DIR share/hiredis_ssl)\r...\rENDIF()\r... 按照上面的cmakelist里面写的注释的解析过程，最终得出BUILD文件如下。这个是非SSL的版本，SSL的版本也非常简单，就不写了。\nCopy\ncc_library(\rname = \u0026#34;hiredis\u0026#34;,\rsrcs = [\r\u0026#34;alloc.c\u0026#34;,\r\u0026#34;dict.c\u0026#34;,\r\u0026#34;async.c\u0026#34;,\r\u0026#34;hiredis.c\u0026#34;,\r\u0026#34;net.c\u0026#34;,\r\u0026#34;read.c\u0026#34;,\r\u0026#34;sds.c\u0026#34;,\r\u0026#34;sockcompat.c\u0026#34;,\r],\rhdrs = glob([\u0026#34;*.h\u0026#34;])+glob([\u0026#34;adapters/*.h\u0026#34;])+[\u0026#34;dict.c\u0026#34;,], #dict.c的引入是因为被async.c引了，而adapters是编译async时候别的库要使用\rinclude_prefix = \u0026#34;hiredis\u0026#34;,\rvisibility = [\u0026#34;//visibility:public\u0026#34;],\r) 方法3 rules_foreign_cc # rules_foreign_cc好用吗？好用，但是没有充分测试，且不被bazel的官方认可在我看来问题就比较大了，所以我个人不是特别喜欢rules_foreign_cc这套，不过也是个用法。\n我个人拿rules_foreign_cc做测试比较早，所以下面的内容我推荐用最新版，直接参考https://bazelbuild.github.io/rules_foreign_cc/main/index.htmlopenssl和libuv做例子\n首先需要配置引入rules_foreign_cc，并且下载openssl和libuv的源代码\nworkspace(name = \u0026#34;cmake2bazel\u0026#34;)\rload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\rhttp_archive(\rname = \u0026#34;rules_foreign_cc\u0026#34;,\rstrip_prefix = \u0026#34;rules_foreign_cc-4010620160e0df4d894b61496d3d3b6fc8323212\u0026#34;,\rsha256 = \u0026#34;07e3414cc841b1f4d16e5231eb818e5c5e03e2045827f5306a55709e5045c7fd\u0026#34;,\rurl = \u0026#34;https://github.com/bazelbuild/rules_foreign_cc/archive/4010620160e0df4d894b61496d3d3b6fc8323212.zip\u0026#34;,\r)\rload(\u0026#34;@rules_foreign_cc//foreign_cc:repositories.bzl\u0026#34;, \u0026#34;rules_foreign_cc_dependencies\u0026#34;)\rrules_foreign_cc_dependencies()\rall_content = \u0026#34;\u0026#34;\u0026#34;filegroup(name = \u0026#34;all\u0026#34;, srcs = glob([\u0026#34;**\u0026#34;]), visibility = [\u0026#34;//visibility:public\u0026#34;])\u0026#34;\u0026#34;\u0026#34;\r# openssl\rhttp_archive(\rname = \u0026#34;openssl\u0026#34;,\rbuild_file_content = all_content,\rstrip_prefix = \u0026#34;openssl-OpenSSL_1_1_1d\u0026#34;,\rurls = [\u0026#34;https://github.com/openssl/openssl/archive/OpenSSL_1_1_1d.tar.gz\u0026#34;]\r)\rall_content = \u0026#34;\u0026#34;\u0026#34;filegroup(name = \u0026#34;all\u0026#34;, srcs = glob([\u0026#34;**\u0026#34;]), visibility = [\u0026#34;//visibility:public\u0026#34;])\u0026#34;\u0026#34;\u0026#34;\r# openssl\rhttp_archive(\rname = \u0026#34;openssl\u0026#34;,\rbuild_file_content = all_content,\rstrip_prefix = \u0026#34;openssl-OpenSSL_1_1_1d\u0026#34;,\rurls = [\u0026#34;https://github.com/openssl/openssl/archive/OpenSSL_1_1_1d.tar.gz\u0026#34;]\r)\r# uv\rhttp_archive(\rname = \u0026#34;libuv\u0026#34;,\rbuild_file_content = all_content,\rstrip_prefix = \u0026#34;libuv-1.42.0\u0026#34;,\rurls = [\u0026#34;https://github.com/libuv/libuv/archive/refs/tags/v1.42.0.tar.gz\u0026#34;]\r) 新建一个文件，为thirdy_party/openssl/BUILD\n# See https://github.com/bazelbuild/rules_foreign_cc\rload(\u0026#34;@rules_foreign_cc//foreign_cc:defs.bzl\u0026#34;, \u0026#34;configure_make\u0026#34;)\rconfig_setting(\rname = \u0026#34;darwin_build\u0026#34;,\rvalues = {\u0026#34;cpu\u0026#34;: \u0026#34;darwin\u0026#34;},\r)\r# See https://wiki.openssl.org/index.php/Compilation_and_Installation\r# See https://github.com/bazelbuild/rules_foreign_cc/issues/338\r#可以通过指定out_lib_dir选项指定编译出来的lib放在哪里，aka The path to where the compiled library binaries will be written to following a successful build\r#对于使用configure-make形式的代码编译的方式，\rconfigure_make(\rname = \u0026#34;openssl\u0026#34;,\r#实际上调用configure的命令，默认是调用configure，这里可以找到openssl里面调用的是config\rconfigure_command = \u0026#34;config\u0026#34;,\r#Any options to be put on the \u0026#39;configure\u0026#39; command line.\rconfigure_options =\rselect({\r\u0026#34;:darwin_build\u0026#34;: [\r\u0026#34;shared\u0026#34;,\r\u0026#34;ARFLAGS=r\u0026#34;,\r\u0026#34;enable-ec_nistp_64_gcc_128\u0026#34;,\r\u0026#34;no-ssl2\u0026#34;, \u0026#34;no-ssl3\u0026#34;, \u0026#34;no-comp\u0026#34;\r],\r\u0026#34;//conditions:default\u0026#34;: [\r]}),\r#defines = [\u0026#34;NDEBUG\u0026#34;], Don\u0026#39;t know how to use -D; NDEBUG seems to be the default anyway\r#指定OPENSSL编译lib的源代码文件，aka Where the library source code is for openssl\rlib_source = \u0026#34;@openssl//:all\u0026#34;, visibility = [\u0026#34;//visibility:public\u0026#34;],\r#Environment variables to be set for the \u0026#39;configure\u0026#39; invocation.\rconfigure_env_vars =\rselect({\r\u0026#34;:darwin_build\u0026#34;: {\r\u0026#34;OSX_DEPLOYMENT_TARGET\u0026#34;: \u0026#34;10.14\u0026#34;,\r\u0026#34;AR\u0026#34;: \u0026#34;\u0026#34;,\r},\r\u0026#34;//conditions:default\u0026#34;: {}}),\r#用来指定共享出来的动态库、动态文件是什么，可以使用static_libraries属性来共享动态库\rout_shared_libs =\rselect({\r\u0026#34;:darwin_build\u0026#34;: [\r\u0026#34;libssl.dylib\u0026#34;,\r\u0026#34;libcrypto.dylib\u0026#34;,\r],\r\u0026#34;//conditions:default\u0026#34;: [\r\u0026#34;libssl.so\u0026#34;,\r\u0026#34;libcrypto.so\u0026#34;,\r],\r})\r) 接着新建一个文件为third_party/libuv/BUILD文件\n# See https://github.com/bazelbuild/rules_foreign_cc\rload(\u0026#34;@rules_foreign_cc//foreign_cc:defs.bzl\u0026#34;, \u0026#34;cmake\u0026#34;)\rcmake(\rname = \u0026#34;libuv\u0026#34;,\rlib_source = \u0026#34;@libuv//:all\u0026#34;,\r#out_static_libs = [\u0026#34;libuv.a\u0026#34;],\rout_static_libs = [\u0026#34;libuv_a.a\u0026#34;],\r#out_shared_libs = [\u0026#34;libuv.so.1.0.0\u0026#34;], libuv.so是个链接，直接编译会报错\r) 最后可以编译一下试试\nqcraft@BJ-vgdog:~/code_test/cmake2bazel$ bazelisk-linux-amd64 build //third_party/libuv:libuv\rDEBUG: Rule \u0026#39;libuv\u0026#39; indicated that a canonical reproducible form can be obtained by modifying arguments sha256 = \u0026#34;371e5419708f6aaeb8656671f89400b92a9bba6443369af1bb70bcd6e4b3c764\u0026#34;\rDEBUG: Repository libuv instantiated at:\r/home/qcraft/code_test/cmake2bazel/WORKSPACE:36:13: in \u0026lt;toplevel\u0026gt;\rRepository rule http_archive defined at:\r/home/qcraft/.cache/bazel/_bazel_qcraft/66cfb4dff202f299686aa7bc701960fa/external/bazel_tools/tools/build_defs/repo/http.bzl:336:31: in \u0026lt;toplevel\u0026gt;\rINFO: Analyzed target //third_party/libuv:libuv (1 packages loaded, 1 target configured).\rINFO: Found 1 target...\rTarget //third_party/libuv:libuv up-to-date:\rbazel-bin/third_party/libuv/libuv/include\rbazel-bin/third_party/libuv/libuv/lib/libuv_a.a\rbazel-bin/third_party/libuv/copy_libuv/libuv\rINFO: Elapsed time: 31.269s, Critical Path: 30.97s\rINFO: 2 processes: 1 internal, 1 linux-sandbox.\rINFO: Build completed successfully, 2 total actions 7 使用Bazel管理Python # 先来看看Bazel里面Python的基础规则\nPython基础规则 # py_binary \u0026amp; py_library \u0026amp; py_test # 我建议直接阅读，https://bazel.build/reference/be/python#py_binary，或者参考C++规则那一部分，过于基础，我这里打算只简单写一个py_library了\npy_library是Bazel中用于构建Python库的规则。用来将Python代码打包成一个库，供其他目标（如py_binary或其他py_library）使用。下面是关于py_library规则的一些重要信息：\npy_library(\rname = \u0026#34;my_library\u0026#34;,\rsrcs = [\u0026#34;module1.py\u0026#34;, \u0026#34;module2.py\u0026#34;],\rdeps = [\u0026#34;//path/to:another_library\u0026#34;],\r) python工具链的配置 # 首先还是先引入对rules_python的支持，在WORKSPACE里面写入下面的内容\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\rrules_python_version = \u0026#34;740825b7f74930c62f44af95c9a4c1bd428d2c53\u0026#34; # Latest @ 2021-06-23\rhttp_archive(\rname = \u0026#34;rules_python\u0026#34;,\r# Bazel will print the proper value to add here during the first build.\r# sha256 = \u0026#34;FIXME\u0026#34;,\rstrip_prefix = \u0026#34;rules_python-{}\u0026#34;.format(rules_python_version),\rurl = \u0026#34;https://github.com/bazelbuild/rules_python/archive/{}.zip\u0026#34;.format(rules_python_version),\r) 接着，使用rules_python的方式注册工具链，在WORKSPACE里面继续添加内容，如下。这里要注意python对象的执行，用的是这里注册的python环境和对应的python解释器，但是这些对象还是会使用默认的系统级别的python环境和解释器去“初始化”\nload(\u0026#34;@rules_python//python:repositories.bzl\u0026#34;, \u0026#34;python_register_toolchains\u0026#34;)\rpython_register_toolchains(\rname = \u0026#34;python3_9\u0026#34;,\r# Available versions are listed in @rules_python//python:versions.bzl.\r# We recommend using the same version your team is already standardized on.\rpython_version = \u0026#34;3.9\u0026#34;,\r)\rload(\u0026#34;@python3_9//:defs.bzl\u0026#34;, \u0026#34;interpreter\u0026#34;)\rload(\u0026#34;@rules_python//python:pip.bzl\u0026#34;, \u0026#34;pip_parse\u0026#34;)\rpip_parse(\r...\rpython_interpreter_target = interpreter,\r...\r) 如何引入和使用外部依赖 # 上一节实际上已经写过了如何引入外部库，这次再重复写一次，不过初始化规则，就是WORKSPACE那部分不多赘述了。注意，这里的对第三方包的管理是一种集中式的管理，我个人比较推崇这种集中化的管理方式。\n集中化管理并引入外部包 # 在WORKSPACE里面写入如下的内容\nload(\u0026#34;@rules_python//python:pip.bzl\u0026#34;, \u0026#34;pip_parse\u0026#34;)\r# Create a central repo that knows about the dependencies needed from\r# requirements_lock.txt.\rpip_parse(\rname = \u0026#34;my_deps\u0026#34;,\rrequirements_lock = \u0026#34;//path/to:requirements_lock.txt\u0026#34;,\r)\r# Load the starlark macro which will define your dependencies.\rload(\u0026#34;@my_deps//:requirements.bzl\u0026#34;, \u0026#34;install_deps\u0026#34;)\r# Call it to define repos for your requirements.\rinstall_deps() requirements_lock.txt内部只需要写入依赖的python包即可，这里我们写入jira作为对应第三方包就行了\n# requirements.txt for Python3 packages\rjira 使用外部包 # 参考下面的代码，简单来说就是直接引入requirement并找到对应的依赖即可。外部包就可以直接使用了\nload(\u0026#34;@my_deps//:requirements.bzl\u0026#34;, \u0026#34;requirement\u0026#34;)\rpy_library(\rname = \u0026#34;mylib\u0026#34;,\rsrcs = [\u0026#34;mylib.py\u0026#34;],\rdeps = [\r\u0026#34;:myotherlib\u0026#34;,\rrequirement(\u0026#34;some_pip_dep\u0026#34;),\rrequirement(\u0026#34;another_pip_dep\u0026#34;),\r]\r) 实践：使用Bazel管理Python # 下面的内容，解决了两个问题\n如何编写python binary对象？ 如何引入python的外部依赖库 前提 # 前提就是引入对rules_python的使用，用bzlmod或者WORKSPACE的方式加载rules_python，简单来说就是写入下面的内容\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\rrules_python_version = \u0026#34;740825b7f74930c62f44af95c9a4c1bd428d2c53\u0026#34; # Latest @ 2021-06-23\rhttp_archive(\rname = \u0026#34;rules_python\u0026#34;,\r# Bazel will print the proper value to add here during the first build.\r# sha256 = \u0026#34;FIXME\u0026#34;,\rstrip_prefix = \u0026#34;rules_python-{}\u0026#34;.format(rules_python_version),\rurl = \u0026#34;https://github.com/bazelbuild/rules_python/archive/{}.zip\u0026#34;.format(rules_python_version),\r) 如何编写python binary对象 # 使用rules_python相关规则，即可方便的编写对应的binary和library\n首先我们看一下对应的BUILD文件和py文件\nload(\u0026#34;@my_deps//:requirements.bzl\u0026#34;, \u0026#34;requirement\u0026#34;)\rload(\u0026#34;@rules_python//python:defs.bzl\u0026#34;, \u0026#34;py_binary\u0026#34;)\rpy_binary(\rname = \u0026#34;validate_jira_issue\u0026#34;,\rsrcs = [\u0026#34;validate_jira_issue.py\u0026#34;],\rdeps = [\rrequirement(\u0026#34;jira\u0026#34;),\r],\r) validate_jira_issue.py如下，我省略了部分的代码，可以看到这就是一个jira issue的校验代码，除了调用系统提供的基础库之外，还引用了jira的python库。那么问题就来了，怎么安装jira的库呢？使用requirement即可，它会在WORKSPACE初始化阶段自动引入外部依赖（注意，这可能不是最佳实践）\n#!/usr/bin/python3\rimport argparse\rimport logging\rimport os\rimport re\rimport sys\rimport traceback\rimport requests\rfrom jira import JIRA, JIRAError\r...\r_JIRA_SERVER_ADDR = \u0026#34;https://daddy.jira.issues.net\u0026#34;\r_JIRA_USER = \u0026#34;i am your daddy\u0026#34;\rdef jira_issue_link_check(jira_issue_text):\rtry:\rjira_pass = \u0026#34;who is your daddy?\u0026#34;\rjira_server = JIRA(server=_JIRA_SERVER_ADDR, basic_auth=(_JIRA_USER, jira_pass))\rexcept Exception as e:\rlogging.error(\r\u0026#34;Exception occurred when trying to connect to jira server, check connection?\u0026#34;\r)\rlogging.error(traceback.format_exc())\rreturn False\relse:\rlogging.info(\u0026#34;Connection to jira \u0026amp; kms server success, Congratulations\u0026#34;)\rfor issue in issues:\rlogging.info(f\u0026#34;Get one jira issue: {issue}\u0026#34;)\rtry:\rjira_issue = jira_server.issue(issue.upper())\rexcept JIRAError as e:\rlogging.error(\rf\u0026#34;Does the {issue} really exists? Exception {e.status_code}:{e.text} met \u0026#34;\r)\rreturn False\relse:\rlogging.info(f\u0026#34;Find JIRA issue \u0026#39;{issue}\u0026#39;\u0026#34;)\rreturn True\r... 如何引入python的外部依赖库 # 接下来看下requirement部分怎么实现，在WORKSPACE里面写入如下的内容\nload(\u0026#34;@rules_python//python:pip.bzl\u0026#34;, \u0026#34;pip_parse\u0026#34;)\r# Create a central repo that knows about the dependencies needed from\r# requirements_lock.txt.\rpip_parse(\rname = \u0026#34;my_deps\u0026#34;,\rrequirements_lock = \u0026#34;//path/to:requirements_lock.txt\u0026#34;,\r)\r# Load the starlark macro which will define your dependencies.\rload(\u0026#34;@my_deps//:requirements.bzl\u0026#34;, \u0026#34;install_deps\u0026#34;)\r# Call it to define repos for your requirements.\rinstall_deps() requirements_lock.txt内部只需要写入依赖的python包即可，这里我们写入jira就行了\n# requirements.txt for Python3 packages\rjira 最后直接bazel build对应的target即可了\n8 使用Bazel管理Go # Golang规则简介 # GO的工具链有三个层面， the SDK, the toolchain, 和 the context.，一般来说，用户只需要关注SDK层面的事情，比方说外部依赖什么的参考下面的部分\nGO SDK # SDK说白了就是GO的标准库，工具链的源代码还有一些预编译的库之类的东西。这部分一般是用go_download_sdk来显示地选择一个版本，有一些通用的命令\ngo_download_sdk：为特定操作系统和架构下载特定版本 Go 的工具链。 go_host_sdk：使用运行 Bazel 的系统上安装的工具链。工具链的位置通过GOROOT或 运行来 指定go env GOROOT。 如果想引用1.15.5的GO版本，那么可以在WORKSPACE里面添加下面内容\n# WORKSPACE\rload(\u0026#34;@io_bazel_rules_go//go:deps.bzl\u0026#34;, \u0026#34;go_rules_dependencies\u0026#34;, \u0026#34;go_register_toolchains\u0026#34;)\rgo_rules_dependencies()\rgo_register_toolchains(version = \u0026#34;1.15.5\u0026#34;) 如果想用机器安装的GO版本，那么改下为如下的内容\n# WORKSPACE\rload(\u0026#34;@io_bazel_rules_go//go:deps.bzl\u0026#34;, \u0026#34;go_rules_dependencies\u0026#34;, \u0026#34;go_register_toolchains\u0026#34;)\rgo_rules_dependencies()\rgo_register_toolchains(version = \u0026#34;host\u0026#34;) Toolchain # SDK 特定于主机平台（例如linux_amd64）和 Go 版本，而Tollchain就是解决这个问题，一般来说，运行Bazel构建时，Bazel会根据指定的执行平台和目标平台（分别用\u0026ndash;host_platform和\u0026ndash;platforms选项指定）自动选择已注册的工具链。这样，就无需手动配置工具链，Bazel会自动根据平台的特性和需求选择合适的工具链，以确保构建的正确性和可靠性。\n举个例子，很多时候我编译都是直接调用\nbazel build -c opt --platforms=@io_bazel_rules_go//go/toolchain:linux_amd64 //save_money:money Context # 就是指引用具体的规则，不过这个用户一般不关心，如果要自定义规则才需要使用相关的东西，参考https://github.com/bazelbuild/rules_go/blob/master/go/toolchains.rst#go-context\n引入外部依赖 # 说起来很简单，首先在WORKSPACE里面添加对gazelle的使用，接着直接使用go_repository即可，\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\r# Download the Go rules.\rhttp_archive(\rname = \u0026#34;io_bazel_rules_go\u0026#34;,\rsha256 = \u0026#34;51dc53293afe317d2696d4d6433a4c33feedb7748a9e352072e2ec3c0dafd2c6\u0026#34;,\rurls = [\r\u0026#34;https://mirror.bazel.build/github.com/bazelbuild/rules_go/releases/download/v0.40.1/rules_go-v0.40.1.zip\u0026#34;,\r\u0026#34;https://github.com/bazelbuild/rules_go/releases/download/v0.40.1/rules_go-v0.40.1.zip\u0026#34;,\r],\r)\r# Download Gazelle.\rhttp_archive(\rname = \u0026#34;bazel_gazelle\u0026#34;,\rsha256 = \u0026#34;727f3e4edd96ea20c29e8c2ca9e8d2af724d8c7778e7923a854b2c80952bc405\u0026#34;,\rurls = [\r\u0026#34;https://mirror.bazel.build/github.com/bazelbuild/bazel-gazelle/releases/download/v0.30.0/bazel-gazelle-v0.30.0.tar.gz\u0026#34;,\r\u0026#34;https://github.com/bazelbuild/bazel-gazelle/releases/download/v0.30.0/bazel-gazelle-v0.30.0.tar.gz\u0026#34;,\r],\r)\r# Load macros and repository rules.\rload(\u0026#34;@io_bazel_rules_go//go:deps.bzl\u0026#34;, \u0026#34;go_register_toolchains\u0026#34;, \u0026#34;go_rules_dependencies\u0026#34;)\rload(\u0026#34;@bazel_gazelle//:deps.bzl\u0026#34;, \u0026#34;gazelle_dependencies\u0026#34;, \u0026#34;go_repository\u0026#34;)\r# Declare Go direct dependencies.\rgo_repository(\rname = \u0026#34;org_golang_x_net\u0026#34;,\rimportpath = \u0026#34;golang.org/x/net\u0026#34;,\rsum = \u0026#34;h1:zK/HqS5bZxDptfPJNq8v7vJfXtkU7r9TLIoSr1bXaP4=\u0026#34;,\rversion = \u0026#34;v0.0.0-20200813134508-3edf25e44fcc\u0026#34;,\r)\r# Declare indirect dependencies and register toolchains.\rgo_rules_dependencies()\rgo_register_toolchains(version = \u0026#34;1.20.5\u0026#34;)\rgazelle_dependencies() 如果希望从原始的go.mod里面导入依赖，用下面的语句就可以直接添加到依赖了\nbazel run //:gazelle update-repos repo-uri 如果只想添加Kafka 的 segmentio 的 go client 包，只需要在项目根目录下执行命令：\nbazel run //:gazelle update-repos github.com/segmentio/kafka-g Gazelle 便会自动增加一条依赖到 WORKSPACE 文件：\ngo_repository(\rname = \u0026#34;com_github_segmentio_kafka_go\u0026#34;,\rimportpath = \u0026#34;github.com/segmentio/kafka-go\u0026#34;,\rsum = \u0026#34;h1:Mv9AcnCgU14/cU6Vd0wuRdG1FBO0HzXQLnjBduDLy70=\u0026#34;,\rversion = \u0026#34;v0.3.4\u0026#34;,\r) 对于Infra同学而言，都写到WORKSPACE中可能会导致WORKSPACE贼大，那么统一组织这些依赖就比较方便：\n先创建一个文件，比方说叫做bazel/go_deps.bzl，这个实际上定义了一个go_dependencies的规则，同时定义了大量的第三方依赖包\nload(\u0026#34;@bazel_gazelle//:deps.bzl\u0026#34;, \u0026#34;go_repository\u0026#34;)\rdef grouped_go_dependencies():\rgo_repository(\rname = \u0026#34;com_github_golang_glog\u0026#34;,\rbuild_file_proto_mode = \u0026#34;disable_global\u0026#34;,\rimportpath = \u0026#34;github.com/golang/glog\u0026#34;,\rsum = \u0026#34;h1:nfP3RFugxnNRyKgeWd4oI1nYvXpxrx8ck8ZrcizshdQ=\u0026#34;,\rversion = \u0026#34;v1.0.0\u0026#34;,\r) 在WORKSPACE里面写入下面的内容，实际上就是展开了grouped_go_dependencies规则，也就是把各种go_repository写在了Workspace里面，当然本质还是没变\nload(\u0026#34;@bazel_gazelle//:deps.bzl\u0026#34;, \u0026#34;gazelle_dependencies\u0026#34;)\rload(\u0026#34;//bazel:go_deps.bzl\u0026#34;, \u0026#34;grouped_go_dependencies\u0026#34;)\rgrouped_go_dependencies() 实践：Bazel管理Golang # 两个部分，第一个部分适用于从头开始写基于Bazel的Go代码，第二个适用于从GO原生的go build切换到Bazel的情况。\n使用原生的方式编写GO Target # 首先要引入对rules_go的支持，在WORKSPACE文件当中写入下面的内容，使用 git_repository 替代 http_archive 也可以，不过http_archive提供了sha256，方便缓存\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\rhttp_archive(\rname = \u0026#34;io_bazel_rules_go\u0026#34;,\rsha256 = \u0026#34;51dc53293afe317d2696d4d6433a4c33feedb7748a9e352072e2ec3c0dafd2c6\u0026#34;,\rurls = [\r\u0026#34;https://mirror.bazel.build/github.com/bazelbuild/rules_go/releases/download/v0.40.1/rules_go-v0.40.1.zip\u0026#34;,\r\u0026#34;https://github.com/bazelbuild/rules_go/releases/download/v0.40.1/rules_go-v0.40.1.zip\u0026#34;,\r],\r)\rload(\u0026#34;@io_bazel_rules_go//go:deps.bzl\u0026#34;, \u0026#34;go_register_toolchains\u0026#34;, \u0026#34;go_rules_dependencies\u0026#34;)\rgo_rules_dependencies()\rgo_register_toolchains(version = \u0026#34;1.20.5\u0026#34;) 接下来，新建一个BUILD文件，并开发对应的go代码，最后bazel build 即可\nload(\u0026#34;@io_bazel_rules_go//go:def.bzl\u0026#34;, \u0026#34;go_binary\u0026#34;)\rgo_binary(\rname = \u0026#34;hello\u0026#34;,\rsrcs = [\u0026#34;hello.go\u0026#34;],\r) 迁移原始GO代码到Bazel # 从GO迁移到Bazel自然可以直接手写对应的BUILD文件，比较麻烦，推荐使用gazelle来解决这个问题\n在WORKSPACE里面添加gazelle\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\rhttp_archive(\rname = \u0026#34;io_bazel_rules_go\u0026#34;,\rsha256 = \u0026#34;51dc53293afe317d2696d4d6433a4c33feedb7748a9e352072e2ec3c0dafd2c6\u0026#34;,\rurls = [\r\u0026#34;https://mirror.bazel.build/github.com/bazelbuild/rules_go/releases/download/v0.40.1/rules_go-v0.40.1.zip\u0026#34;,\r\u0026#34;https://github.com/bazelbuild/rules_go/releases/download/v0.40.1/rules_go-v0.40.1.zip\u0026#34;,\r],\r)\rhttp_archive(\rname = \u0026#34;bazel_gazelle\u0026#34;,\rsha256 = \u0026#34;727f3e4edd96ea20c29e8c2ca9e8d2af724d8c7778e7923a854b2c80952bc405\u0026#34;,\rurls = [\r\u0026#34;https://mirror.bazel.build/github.com/bazelbuild/bazel-gazelle/releases/download/v0.30.0/bazel-gazelle-v0.30.0.tar.gz\u0026#34;,\r\u0026#34;https://github.com/bazelbuild/bazel-gazelle/releases/download/v0.30.0/bazel-gazelle-v0.30.0.tar.gz\u0026#34;,\r],\r)\rload(\u0026#34;@io_bazel_rules_go//go:deps.bzl\u0026#34;, \u0026#34;go_register_toolchains\u0026#34;, \u0026#34;go_rules_dependencies\u0026#34;)\rload(\u0026#34;@bazel_gazelle//:deps.bzl\u0026#34;, \u0026#34;gazelle_dependencies\u0026#34;)\rgo_rules_dependencies()\rgo_register_toolchains(version = \u0026#34;1.20.5\u0026#34;)\rgazelle_dependencies() 接着，在代码的根目录添加一个BUILD.bazel，把prefix后面的那个字符串，就是那个什么github.comxxx啥的东西，替换为原始项目的import path，也就是 go.mod 里面的部分\nload(\u0026#34;@bazel_gazelle//:def.bzl\u0026#34;, \u0026#34;gazelle\u0026#34;)\r# gazelle:prefix github.com/example/project\rgazelle(name = \u0026#34;gazelle\u0026#34;) 接着执行，就会生成具体的BUILD文件。\nbazel run //:gazelle 9 使用Bazel管理Shell # 作为胶水语言，有的时候还确实需要bazel去缓存一些执行的结果，比方说我希望bazel执行一些操作，然后输出结果，那肯定得拿shell粘起来。\n下面的内容是一个sh_test对象，bazel还支持sh_binary，同样的道理。\n直接看BUILD文件怎么写的，声明了一个run_compare对象，核心是run_sompare.sh脚本，依赖了shflags功能，shflags（https://github.com/kward/shflags）实际上是个类似gflags的shell版本实现\npackage(default_visibility = [\u0026#34;//visibility:public\u0026#34;])\rsh_library(\rname = \u0026#34;sh_flags\u0026#34;,\rdata = [\u0026#34;shflags\u0026#34;],\r)\rsh_test(\rname = \u0026#34;run_compare\u0026#34;,\rsize = \u0026#34;medium\u0026#34;,\rsrcs = [\u0026#34;run_compare.sh\u0026#34;],\rdata = [\r\u0026#34;//save_money/compare:jandan\u0026#34;,\r],\rtags = [\u0026#34;manual\u0026#34;],\r# Notes: deps should only be sh_library,\r# other depends such as cc_binary and data should include in data field\rdeps = [\r\u0026#34;:sh_flags\u0026#34;,\r],\r) 这里可能需要注意下data属性，data属性提供了shell内部要直接调用的bazel target，这个和脚本是强关联的，脚本里面调用了什么对象，都需要加到这里，可以看到下面的脚本就是直接调用了save_money/compare/jandan。\n而shflags是所谓shell source的对象，放到了deps里面，这个是用户写shell需要注意的情况\nTOP_DIR=\u0026#34;$(cd \u0026#34;$(dirname \u0026#34;${BASH_SOURCE[0]}\u0026#34;)/..\u0026#34; \u0026amp;\u0026amp; pwd -P)\u0026#34;\rsource \u0026#34;${TOP_DIR}/shflags\u0026#34;\rDEFINE_boolean \u0026#39;chinese\u0026#39; \u0026#34;${FLAGS_FALSE}\u0026#34; \u0026#39;If true, use save chinese yuan.\u0026#39;\rDEFINE_boolean \u0026#39;US\u0026#39; \u0026#34;${FLAGS_TRUE}\u0026#34; \u0026#39;If true, save us dollar.\u0026#39;\r# Parse the command-line.\rFLAGS \u0026#34;$@\u0026#34; || exit 1\reval set -- \u0026#34;${FLAGS_ARGV}\u0026#34;\rset -e\recho \u0026#34;Envoking save money mode\u0026#34;\rsave_money/compare/jandan ${FLAGS_chinese} ${FLAGS_US} 最后直接调用bazel run就可以执行具体的shell target了。\n10 引入第三方库 # 首先依然推荐阅读官方文档https://bazel.build/external/overview，伴随着Bazel 6.0的发布，目前有两种方法来引入第三方库，一种是传统的写到Workspace的方法，另一种是Bzlmod的方法。注意，永远都是推荐新的方式即Bzlmod的方式来import第三方库。\n传统方法 # 传统方法讲究化劲，接，化，发！。。。不好意思，走错片场了。。。。\n实现方法 # 理解传统方式需要首先明白以下几个概念\n代码库：包含WORKSPACE带有或文件的目录WORKSPACE.bazel，包含 Bazel 构建中使用的源文件的一些列文件的组织，称为代码库。代码库不是只针对下面的主仓库，第三方库也是代码库。 主仓库： 这个不用多说了，真正的执行Bazel 命令的代码库。 WorkSpace:工作区间，也是所有 Bazel 命令共享的环境。 代码库规则：（第三方）代码库库定义的模式，告诉 Bazel 如何获取代码库。例如，它可以是“从某个 URL 下载 zip 存档并解压它”，或者“获取某个 Maven 工件并使其可用作目标 java_import”，或者只是“符号链接本地目录”。每个存储库都是 通过使用适当数量的参数调用存储库规则来**定义的。**到目前为止，最常见的存储库规则是 http_archive，它从 URL 下载存档并提取它，以及 local_repository，它符号链接已经是 Bazel 存储库的本地目录。 简单来讲，传统方式可以认为就是http_archive，官方给的例子如下，引入foo作为外部依赖。\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\rhttp_archive(\rname = \u0026#34;foo\u0026#34;,\rurls = [\u0026#34;https://example.com/foo.zip\u0026#34;],\rsha256 = \u0026#34;c9526390a7cd420fdcec2988b4f3626fe9c5b51e2959f685e8f4d170d1a9bd96\u0026#34;,\r) 举个简单例子，在WORKSPACE文件内写入下面的内容，之后在对应依赖grpc的BUILD文件里面写入相应的依赖项即可使用该grpc外部依赖，比方说glog的引入也是同样的道理。其中strip_prefix用来去除解压的文件夹前缀。\nversion = \u0026#34;1.xx.x\u0026#34;\rhttp_archive(\rname = \u0026#34;com_github_grpc_grpc\u0026#34;,\rstrip_prefix = \u0026#34;grpc-{}\u0026#34;.format(version),\rsha256 = \u0026#34;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#34;,\rurls = [\r\u0026#34;https://xxxxxxxxxxxxxxxxx/grpc-{}.tar.gz\u0026#34;.format(version),\r\u0026#34;https://xxxxxxxxxxxxxxxxxxx{}.tar.gz\u0026#34;.format(version),\r],\rpatch_args = [\u0026#34;-p1\u0026#34;],\rpatches = [\rclean_dep(\u0026#34;//third_party/grpc:p01xxxxxxxxxxxxx.patch\u0026#34;),\rclean_dep(\u0026#34;//third_party/grpc:p02xxxxxxxxxxxxx.patch\u0026#34;),\rclean_dep(\u0026#34;//third_party/grpc:p03xxxxxxxxxxxxx.patch\u0026#34;),\r],\r) 真正使用依赖的时候如下图所示\ncc_binary(\rname = \u0026#34;grpc_test_main\u0026#34;,\rtestonly = True,\rsrcs = [\r\u0026#34;grpc_test_main.cc\u0026#34;,\r],\rdeps = [\r\u0026#34;//xxxxx/proto:grpc_test_main\u0026#34;,\r\u0026#34;@com_github_google_glog//:glog\u0026#34;,\r\u0026#34;@com_github_grpc_grpc//:grpc++\u0026#34;,\r],\r) 缺陷 # 传统方式有几种不足\nBazel的WORKSPACE级别的外部依赖只能是一个依赖链，不存在灵活的选择。 为了绕开这一点，bazel要求用户自己实现宏来选择外部依赖，宏不能灵活load .bzl文件，因此需要用户多次宣式指定依赖，而显示依赖实际上是缺乏版本信息的，简单来说，http_archive是没有（显式）版本信息的。 bzlmod方法 # WORKSPACE文件这么写\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;)\rhttp_archive(\rname = \u0026#34;com_github_google_glog\u0026#34;,\rsha256 = \u0026#34;eede71f28371bf39aa69b45de23b329d37214016e2055269b3b5e7cfd40b59f5\u0026#34;,\rstrip_prefix = \u0026#34;glog-0.5.0\u0026#34;,\rurls = [\u0026#34;https://github.com/google/glog/archive/refs/tags/v0.5.0.tar.gz\u0026#34;],\r)\r# We have to define gflags as well because it\u0026#39;s a dependency of glog.\rhttp_archive(\rname = \u0026#34;com_github_gflags_gflags\u0026#34;,\rsha256 = \u0026#34;34af2f15cf7367513b352bdcd2493ab14ce43692d2dcd9dfc499492966c64dcf\u0026#34;,\rstrip_prefix = \u0026#34;gflags-2.2.2\u0026#34;,\rurls = [\u0026#34;https://github.com/gflags/gflags/archive/refs/tags/v2.2.2.tar.gz\u0026#34;],\r) 在附加一个MODULE.bazel文件\n# 1. The metadata of glog is fetched from the BCR, including its dependencies (gflags).\r# 2. The `repo_name` attribute allows users to reference this dependency via the `com_github_google_glog` repo name.\rbazel_dep(name = \u0026#34;glog\u0026#34;, version = \u0026#34;0.5.0\u0026#34;, repo_name = \u0026#34;com_github_google_glog\u0026#34;) 编译的时候，添加属性\u0026ndash;enable_bzelmod即可，并在对应的BUILD文件添加依赖\nbuild --enable_bzlmod 原理分析 # Bazel的bzlmod使用类似GO的Minimal Version Selection (MVS) 算法，即MVS 假设所有依赖满足前向兼容性，因此挑选第一个满足所有兼容性要求的版本。对这个图里面的例子，会选择1.1的D版本。如果有1.2的D版本，也会用1.1的版本。\nA 1.0\r/ \\\rB 1.0 C 1.1\r| |\rD 1.0 D 1.1 11 Bazel代码管理最佳实践 # 好了，下面给一下曾经用bazel管理代码库的时候的最佳实践\n下面的内容是一些提供给Infra或者普通用户的建议，这些规则可以使得CI或者研发的平时工作轻松很多。\n开放用户自定配置 # 有的时候Infra会提供一套通用的配置给研发使用，但是不同研发的本地环境不同，需要一些个性化且不被track到代码库的配置，可以在.bazelrc里面加上\ntry-import %workspace%/user.bazelrc 从而方便用户可以自己制定user.bazelrc里面的内容，最常见的使用情况就是并发的action数量控制，我们遇到过的是并发数量太高，用户电脑卡死了。。。\n尽量使用源码编译 # 对于C或C++软件，一个经常遇到的问题就是引用了不该用的库，或者是版本错误，或者是符号重名。这种情况下，推荐尽量用源码来管理第三方库，从而避免使用预定义的库可能带来的编译flag不一致的问题。这几天就遇到一个问题，有一个库内部打包了一个外部libcurl，(srcs=\u0026ldquo;libcurl.so\u0026rdquo;)然后打出来的包同时包含了系统的libcurl和这个libcurl，然后程序只要一启动就crash。\n一部分人，那我不得所有依赖都得自己用源码管理吗？的确如此，毕竟只要用prebuild库，就始终有兼容性风险。\n整个源码库可构建 # 一般情况下整个源代码仓库可以直接调用bazel build //... 和 bazel test //...，对于CI的同学这种方式会简化管理难度。\n尽量明确依赖而不是混杂依赖 # 我们实践中遇到一个大坑是，一些用户会把不该汇总到一起的东西放到一起，它会用glob写出来一个如下语句，并最终把这个大包裹汇聚给外面。\nglob([\u0026#34;**/**\u0026#34;]) 这个BUILD文件所在目录包含模型，音频，xml文件，有很多的TEST只用音频，反而还打包一堆模型，从而导致多了很多不必要的依赖和拷贝操作。\nBUILD文件不要跨级 # 一般情况下BUILD文件应该只管理当前目录的文件，不应该管理下级目录，如果真的需要管理下级目录，需要考虑文件的位置分布是否合理，是不是可以去掉没用的文件层级\n常用选项 # 控制action并发数量build \u0026ndash;jobs=xx 控制是否强行重跑某个test时，指定\u0026ndash;nocache_test_results，即不利用缓存。排查flaky的问题很有用。cache_test_results本来是用来判断是否缓存test结果的 只做远端编译，不下载文件\u0026ndash;remote_download_minimal 有时候做bazel test，希望看到test的完整输出，\u0026ndash;test_output=\u0026lt;summary, errors, all or streamed\u0026gt;指定为streamed即可。不过这个会强制rerun test 有时候做query或者build，希望遇到错误不停止，加上--[no\\]keep_going [-k] default: \u0026ldquo;false\u0026rdquo; 在CI的环境，很多时候可以反向依赖查找出来改动影响到哪些target，之后针对这些target做编译。可是有个问题，这些target在明确指定的情况下，可能是不兼容的目标平台target。可以加上\u0026ndash;skip_incompatible_explicit_targets来显示忽略，从而降低CI的工作量 中级 # 好了，下面我们来到了中级篇，看一些bazel除了构建代码之后，集成一些复杂的代码检查应该怎么做。\n12 Bazel Platform与可配置项 # 可配置选项与select # 可配置属性（通常称为select()）是 Bazel 的一项功能，允许用户在命令行切换构建规则属性的值。\n# myapp/BUILD\rcc_binary(\rname = \u0026#34;mybinary\u0026#34;,\rsrcs = [\u0026#34;main.cc\u0026#34;],\rdeps = select({\r\u0026#34;:arm_build\u0026#34;: [\u0026#34;:arm_lib\u0026#34;],\r\u0026#34;:x86_debug_build\u0026#34;: [\u0026#34;:x86_dev_lib\u0026#34;],\r\u0026#34;//conditions:default\u0026#34;: [\u0026#34;:generic_lib\u0026#34;],\r}),\r)\rconfig_setting(\rname = \u0026#34;arm_build\u0026#34;,\rvalues = {\u0026#34;cpu\u0026#34;: \u0026#34;arm\u0026#34;},\r)\rconfig_setting(\rname = \u0026#34;x86_debug_build\u0026#34;,\rvalues = {\r\u0026#34;cpu\u0026#34;: \u0026#34;x86\u0026#34;,\r\u0026#34;compilation_mode\u0026#34;: \u0026#34;dbg\u0026#34;,\r},\r) 接下来可以看下，对应的配置选项会怎么触发怎样编译依赖的选择。\n命令 依赖最终选择 bazel build //myapp:mybinary --cpu=arm [\u0026quot;:arm_lib\u0026quot;] bazel build //myapp:mybinary -c dbg --cpu=x86 [\u0026quot;:x86_dev_lib\u0026quot;] bazel build //myapp:mybinary --cpu=ppc [\u0026quot;:generic_lib\u0026quot;] bazel build //myapp:mybinary -c dbg --cpu=ppc [\u0026quot;:generic_lib\u0026quot;] select()用用来根据情况选择不同的配置，简单来说就是选择 config_setting 中的细节。注意select是具有传递性的，如果top level启用了某种配置，这个配置会传递到下层的依赖当中。\nselect可以组合，但是不能递归\nsh_binary(\rname = \u0026#34;my_target\u0026#34;,\rsrcs = [\u0026#34;always_include.sh\u0026#34;] +\rselect({\r\u0026#34;:armeabi_mode\u0026#34;: [\u0026#34;armeabi_src.sh\u0026#34;],\r\u0026#34;:x86_mode\u0026#34;: [\u0026#34;x86_src.sh\u0026#34;],\r}) +\rselect({\r\u0026#34;:opt_mode\u0026#34;: [\u0026#34;opt_extras.sh\u0026#34;],\r\u0026#34;:dbg_mode\u0026#34;: [\u0026#34;dbg_extras.sh\u0026#34;],\r}),\r) select的细节语法 # select支持多种写法\nselects.with_or语法，一种多种情况使用相同配置的简单写法\nsh_binary(\rname = \u0026#34;my_target\u0026#34;,\rsrcs = [\u0026#34;always_include.sh\u0026#34;],\rdeps = selects.with_or({\r(\u0026#34;:config1\u0026#34;, \u0026#34;:config2\u0026#34;, \u0026#34;:config3\u0026#34;): [\u0026#34;:standard_lib\u0026#34;],\r\u0026#34;:config4\u0026#34;: [\u0026#34;:special_lib\u0026#34;],\r}),\r) selects.config_setting_group，同样是多种匹配任何一种的情况\nconfig_setting(\rname = \u0026#34;config1\u0026#34;,\rvalues = {\u0026#34;cpu\u0026#34;: \u0026#34;arm\u0026#34;},\r)\rconfig_setting(\rname = \u0026#34;config2\u0026#34;,\rvalues = {\u0026#34;compilation_mode\u0026#34;: \u0026#34;dbg\u0026#34;},\r)\rselects.config_setting_group(\rname = \u0026#34;config1_or_2\u0026#34;,\rmatch_any = [\u0026#34;:config1\u0026#34;, \u0026#34;:config2\u0026#34;],\r)\rsh_binary(\rname = \u0026#34;my_target\u0026#34;,\rsrcs = [\u0026#34;always_include.sh\u0026#34;],\rdeps = select({\r\u0026#34;:config1_or_2\u0026#34;: [\u0026#34;:standard_lib\u0026#34;],\r\u0026#34;//conditions:default\u0026#34;: [\u0026#34;:other_lib\u0026#34;],\r}),\r) AND chaining，用来同时匹配多种的情况\nconfig_setting(\rname = \u0026#34;config1\u0026#34;,\rvalues = {\u0026#34;cpu\u0026#34;: \u0026#34;arm\u0026#34;},\r)\rconfig_setting(\rname = \u0026#34;config2\u0026#34;,\rvalues = {\u0026#34;compilation_mode\u0026#34;: \u0026#34;dbg\u0026#34;},\r)\rselects.config_setting_group(\rname = \u0026#34;config1_and_2\u0026#34;,\rmatch_all = [\u0026#34;:config1\u0026#34;, \u0026#34;:config2\u0026#34;],\r)\rsh_binary(\rname = \u0026#34;my_target\u0026#34;,\rsrcs = [\u0026#34;always_include.sh\u0026#34;],\rdeps = select({\r\u0026#34;:config1_and_2\u0026#34;: [\u0026#34;:standard_lib\u0026#34;],\r\u0026#34;//conditions:default\u0026#34;: [\u0026#34;:other_lib\u0026#34;],\r}),\r) # Platforms # platform是用来方便地组合和索引多配置的方法，简单来说可以认为多种属性构成了平台（反过来，多平台构成了属性）。简单来说可以认为platform是下面的组合\nconfig_setting 用来提供可选择的配置。\nconstraint_setting 用来表示一种配置属性，可以认为这个就是枚举类型\nconstraint_value 用来支持multi-platform behavior，这个可以认为是一种枚举类型的值\n# myapp/BUILD\rsh_binary(\rname = \u0026#34;my_rocks\u0026#34;,\rsrcs = select({\r\u0026#34;:basalt\u0026#34;: [\u0026#34;pyroxene.sh\u0026#34;],\r\u0026#34;:marble\u0026#34;: [\u0026#34;calcite.sh\u0026#34;],\r\u0026#34;//conditions:default\u0026#34;: [\u0026#34;feldspar.sh\u0026#34;],\r}),\r)\rconfig_setting(\rname = \u0026#34;basalt\u0026#34;,\rconstraint_values = [\r\u0026#34;:black\u0026#34;,\r\u0026#34;:igneous\u0026#34;,\r],\r)\rconfig_setting(\rname = \u0026#34;marble\u0026#34;,\rconstraint_values = [\r\u0026#34;:white\u0026#34;,\r\u0026#34;:metamorphic\u0026#34;,\r],\r)\r# constraint_setting acts as an enum type, and constraint_value as an enum value.\rconstraint_setting(name = \u0026#34;color\u0026#34;)\rconstraint_value(name = \u0026#34;black\u0026#34;, constraint_setting = \u0026#34;color\u0026#34;)\rconstraint_value(name = \u0026#34;white\u0026#34;, constraint_setting = \u0026#34;color\u0026#34;)\rconstraint_setting(name = \u0026#34;texture\u0026#34;)\rconstraint_value(name = \u0026#34;smooth\u0026#34;, constraint_setting = \u0026#34;texture\u0026#34;)\rconstraint_setting(name = \u0026#34;type\u0026#34;)\rconstraint_value(name = \u0026#34;igneous\u0026#34;, constraint_setting = \u0026#34;type\u0026#34;)\rconstraint_value(name = \u0026#34;metamorphic\u0026#34;, constraint_setting = \u0026#34;type\u0026#34;)\rplatform(\rname = \u0026#34;basalt_platform\u0026#34;,\rconstraint_values = [\r\u0026#34;:black\u0026#34;,\r\u0026#34;:igneous\u0026#34;,\r],\r)\rplatform(\rname = \u0026#34;marble_platform\u0026#34;,\rconstraint_values = [\r\u0026#34;:white\u0026#34;,\r\u0026#34;:smooth\u0026#34;,\r\u0026#34;:metamorphic\u0026#34;,\r],\r) 下面的命令，即编译“大理石”平台\nbazel build //my_app:my_rocks --platforms=//myapp:marble_platform 就等同于下面的配置\nbazel build //my_app:my_rocks --define color=white --define texture=smooth --define type=metamorphic Bazel的Platforms # 上面介绍了基本的语法，现在看看这东西组合出来做什么，下面的概念在Toolchain部分才有用，如果不想理解也可以先不看。\nBazel可以在各种不同的硬件、操作系统和系统配置上构建和测试代码，使用多种不同版本的链接器和编译器等构建工具。为了管理这种复杂性，Bazel引入了constraint（约束）和平台的概念。约束是是指构建或者生产环境可能不同的地方，例如CPU架构（Darwin，XXX）、是否存在GPU或系统安装的编译器版本。平台是这些约束的集合，表示某个环境中可用的特定资源。\nBazel将平台区分为三种：\nHost（主机） - 运行Bazel的平台，比方说我现在做编译，我在本地起了一个bazel，bazel cli启动了一个java进程，这个启动java进程的机器或者说当前的系统，就是Host Execution（执行） - 构建工具在其中执行构建操作以生成中间和最终输出的平台，书接上文，java进程分析好了DAG（有向无环图），拆解为多个Action，如果后台启用了Buildfarm远程执行服务，这些Action就会被分配到这些Buildfarm真正的机器上执行，这些真正执行构建的机器，就是Execution **Target(**目标) - 最终输出所在的平台，并在其中执行。继续举例，我比方说在X86编译出来了一个软件，这个软件在ARM平台执行，那么最终执行的平台就是Target平台 关于平台，Bazel支持以下构建场景：\n单平台构建（默认）- 主机、执行和目标平台相同。例如，在运行在Intel x64 CPU上的Ubuntu上构建Linux可执行文件。 交叉编译构建 - 主机和执行平台相同，但目标平台不同。例如，在运行在MacBook Pro上的macOS上构建iOS应用程序。 多平台构建 - 主机、执行和目标平台都不同。 对于一部分monorepo而言，内部混杂了诸如X86（X86内部可能还按照CPU架构拆分的更细），ARM64的平台，这些代码库构建的时候都是指定了某种具体的平台，然后对某种pattern的内部package做构建。如果命令行里匹配的模式命中了某个被认为不兼容的目标，目标会自动将被跳过。例如，以下两个调用会跳过目标模式扩展中发现的任何不兼容目标。\n$ bazel build --platforms=//:myplatform //... $ bazel build --platforms=//:myplatform //:all test_suite如果test_suite在命令行上用 指定 ， 则类似地会跳过a 中不兼容的测试--expand_test_suites。换句话说，test_suite命令行上的目标的行为类似于:all和 ...。使用--noexpand_test_suites会阻止扩展并导致 test_suite具有不兼容测试的目标也不兼容。\n在命令行上显式指定不兼容的目标会导致错误消息和构建失败。\n$ bazel build --platforms=//:myplatform //:target_incompatible_with_myplatform\r...\rERROR: Target //:target_incompatible_with_myplatform is incompatible and cannot be built, but was explicitly requested.\r...\rFAILED: Build did NOT complete successfully 如果启用--skip_incompatible_explicit_targets，不兼容的显式目标将被静默跳过 ，这就给提供了一种对CI很方便的bazel构建用法，我可以先bazel query反向依赖查出来修改的东西涉及到的文件，然后再全部编译，并且加上--skip_incompatible_explicit_targets flag，这样子，编译错误就不会被平台不兼容的错误所掩盖。\n不过这个是bazel 7.0.0才支持。\n如果想指定配置来检查改动设计哪些目标，可以用bazel cquery\n13 Bazel Query和Aquery # 14 Bazel集成Clang-Tidy # Clang-Tidy是基于Clang的C++ Lint工具，用于检查C++代码中的常见编码错误，执行代码静态分析等，和Bazel的继承使用了bazel的aspect机制实现，建议直接阅读https://github.com/erenon/bazel_clang_tidy\n为啥需要clang-tidy呢？原因很简单，针对语言层面的安全检查是SAST实践的核心。因此怎么在Bazel上集成clang-tidy就变成一种通用的手段，本质是使用Bazel提供的Aspect。\n这种方式的好处有三个\n可以针对任意的C++对象执行clang-tidy 因为用的是bazel的aspect，所以实际上并没有做真正的构建。直接调用clang-tidy对per文件做分析 Bazel会缓存clang-tidy 的结果，如果文件没变化，那么clang-tidy不会重新运行。 使用方法 # 在WORKSPACE里面添加代码\n# //:WORKSPACE\rload(\r\u0026#34;@bazel_tools//tools/build_defs/repo:git.bzl\u0026#34;,\r\u0026#34;git_repository\u0026#34;,\r)\rgit_repository(\rname = \u0026#34;bazel_clang_tidy\u0026#34;,\rcommit = \u0026#34;69aa13e6d7cf102df70921c66be15d4592251e56\u0026#34;,\rremote = \u0026#34;https://github.com/erenon/bazel_clang_tidy.git\u0026#34;,\r) 具体调用可以直接显式使用aspect调用，或者修改.bazelrc，贴到了最下面\nbazel build //... \\\r--aspects @bazel_clang_tidy//clang_tidy:clang_tidy.bzl%clang_tidy_aspect \\\r--output_groups=report 修改bazelrc如下，然后直接调用tidy配置即可\n```ini\rbuild:tidy --aspects //bazel/clang_tidy:clang_tidy.bzl%clang_tidy_aspect\rbuild:tidy --build_tag_filters=-no-tidy\rbuild:tidy --output_groups=report\r``` bazel build --config=tidy //... 接下来就会针对build的对象启动clang-tidy的检查。\n我们都非常清楚，clang-tidy是一个复杂检查，其中有很多种的checker可以开启，如果需要配置clang-tidy的config，可以添加一个新的配置文件，调用的时候使用第二条命令。\n# //:BUILD\rfilegroup(\rname = \u0026#34;clang_tidy_config\u0026#34;,\rsrcs = [\u0026#34;.clang-tidy\u0026#34;],\rvisibility = [\u0026#34;//visibility:public\u0026#34;],\r) bazel build //... \\\r--aspects @bazel_clang_tidy//clang_tidy:clang_tidy.bzl%clang_tidy_aspect \\\r--output_groups=report \\\r--@bazel_clang_tidy//:clang_tidy_config=//:clang_tidy_config 15 Bazel集成Lint # 16 Bazel生成Compile Database # 很多第三方SAST检查工具，比方说CODECHECKER，都需要生成compile database来获取具体的编译行为，从而从语义的角度检查代码上下文是否符合一些通用的安全开发准则。因此了解如何在bazel体系生成compile database就很有必要性。\n# 以https://github.com/grailbio/bazel-compilation-database为例\n添加如下内容在WORKSPACE里面\nhttp_archive(\rname = \u0026#34;com_grail_bazel_compdb\u0026#34;,\rstrip_prefix = \u0026#34;bazel-compilation-database-0.5.2\u0026#34;,\rurls = [\u0026#34;https://github.com/grailbio/bazel-compilation-database/archive/0.5.2.tar.gz\u0026#34;],\r)\rload(\u0026#34;@com_grail_bazel_compdb//:deps.bzl\u0026#34;, \u0026#34;bazel_compdb_deps\u0026#34;)\rbazel_compdb_deps() 针对想生成compile database的target，写入下面的代码，target可以直接写到targets里面\n## Replace workspace_name and dir_path as per your setup.\rload(\u0026#34;@com_grail_bazel_compdb//:defs.bzl\u0026#34;, \u0026#34;compilation_database\u0026#34;)\rload(\u0026#34;@com_grail_bazel_output_base_util//:defs.bzl\u0026#34;, \u0026#34;OUTPUT_BASE\u0026#34;)\rcompilation_database(\rname = \u0026#34;example_compdb\u0026#34;,\rtargets = [\r\u0026#34;//a_cc_binary_label\u0026#34;,\r\u0026#34;//a_cc_library_label\u0026#34;,\r],\r# OUTPUT_BASE is a dynamic value that will vary for each user workspace.\r# If you would like your build outputs to be the same across users, then\r# skip supplying this value, and substitute the default constant value\r# \u0026#34;__OUTPUT_BASE__\u0026#34; through an external tool like `sed` or `jq` (see\r# below shell commands for usage).\routput_base = OUTPUT_BASE,\r) 在命令行运行下面的命令，就可以拿到对应target的compile database了\n# Command to generate the compilation database file.\rbazel build //path/to/pkg/dir:example_compdb\r# Location of the compilation database file.\routfile=\u0026#34;$(bazel info bazel-bin)/path/to/pkg/dir/compile_commands.json\u0026#34;\r# [Optional] Command to replace the marker for output_base in the file if you\r# did not use the dynamic value in the example above.\routput_base=$(bazel info output_base)\rsed -i.bak \u0026#34;s@__OUTPUT_BASE__@${output_base}@\u0026#34; \u0026#34;${outfile}\u0026#34;\r# The compilation database is now ready to use at this location.\recho \u0026#34;Compilation Database: ${outfile}\u0026#34; 这里的方法是固定针对的target，我个人更推荐这种用法，因为我觉得对文件夹做分析会疏于管理。如果针对文件夹级别，看下面的脚本\nINSTALL_DIR=\u0026#34;/usr/local/bin\u0026#34;\rVERSION=\u0026#34;0.5.2\u0026#34;\r# Download and symlink.\r(\rcd \u0026#34;${INSTALL_DIR}\u0026#34; \\\r\u0026amp;\u0026amp; curl -L \u0026#34;https://github.com/grailbio/bazel-compilation-database/archive/${VERSION}.tar.gz\u0026#34; | tar -xz \\\r\u0026amp;\u0026amp; ln -f -s \u0026#34;${INSTALL_DIR}/bazel-compilation-database-${VERSION}/generate.py\u0026#34; bazel-compdb\r)\rbazel-compdb # This will generate compile_commands.json in your workspace root.\r# To pass additional flags to bazel, pass the flags as arguments after --\rbazel-compdb -- [additional flags for bazel]\r# You can tweak some behavior with flags:\r# 1. To use the source dir instead of bazel-execroot for directory in which clang commands are run.\rbazel-compdb -s\rbazel-compdb -s -- [additional flags for bazel]\r# 2. To consider only targets given by a specific query pattern, say `//cc/...`. Also see below section for another way.\rbazel-compdb -q //cc/...\rbazel-compdb -q //cc/... -- [additional flags for bazel] 17 Bazel管理Docker # 使用Docker编译镜像方便快捷，但是使用Docker打包出来的定向并不是确定的，换言之两个内部打包的binary一样的Docker镜像，其sha256是不同的，因此使用Bazel管理Docker镜像能带来的好处就是镜像确定化，即用来检查某些文件是不是发生了变化。\ncontainer_import # 为什么第一个写container_import? 在集成Bazel管理Docker机制到CI体系中的时候，发现Bazel直接用内置的Docker下载机制将镜像下载过程当中时，会非常慢（原因就不多分析拉），因此采用了Docker镜像直接导入，之后将之Import到Bazel内部的方法。\n步骤很简单，\n在Node机器上下载外部Base镜像，一般情况下，CI机器内部都已经缓存了镜像 使用docker save命令，将Base镜像存储到本地，打开压缩包里面的config.json文件 参考下面的代码，首先将config.json文件配置为filegroup 使用container_import命令，标记image_digest和config.json文件导入即可，其中tag加上no-cache和no-remote用来标记不需要缓存到远端，避免占用过多空间和内存。base镜像直接缓存到本地 如下所示，Bazel就可以读取到导入的镜像了\n```python\rload(\u0026#34;@io_bazel_rules_docker//cc:image.bzl\u0026#34;, \u0026#34;cc_image\u0026#34;)\rload(\u0026#34;@io_bazel_rules_docker//container:container.bzl\u0026#34;, \u0026#34;container_bundle\u0026#34;, \u0026#34;container_import\u0026#34;)\rpackage(default_visibility = [\u0026#34;//visibility:public\u0026#34;])\rfilegroup(\rname = \u0026#34;base_image_config_json\u0026#34;,\rsrcs = [\r\u0026#34;base_image_config.json\u0026#34;,\r],\rvisibility = [\u0026#34;//visibility:public\u0026#34;],\r)\rcontainer_import(\rname = \u0026#34;base_image\u0026#34;,\rbase_image_digest = \u0026#34;sha256:xxxxxxxxxxxxxxxxxxxxxx2e457cd116a429257d8f3615e51a55c56b3705539568d58c\u0026#34;,\rbase_image_registry = \u0026#34;registry.xxxxxx.com\u0026#34;,\rbase_image_repository = \u0026#34;global/xxxxxx\u0026#34;,\rconfig = \u0026#34;:base_image_config_json\u0026#34;,\rlayers = [],\rtags = [\r\u0026#34;no-cache\u0026#34;,\r\u0026#34;no-remote\u0026#34;,\r],\r)\r``` 接下来，只需要运行docker pull，这个镜像只要在本地就可以直接load进bazel了。\n编译deterministic的镜像 # 编译确定性的镜像就比较简单了，这里我以cc_image为例子，编译镜像并自定义命名Docker镜像\n代码如下，这里面复用了上一节的base_image的target.如下面的代码和流程\ncc_image的base指定为Docker Base Image，这里就是上一节导入的base_image。binary指定为要编译出来的C++ Target container_bundle用来解决镜像命名的问题，这里的REAL_IMAGE就是真正的命名对象。两个规则都加no-remote来避免cache ```python\rload(\u0026#34;@io_bazel_rules_docker//cc:image.bzl\u0026#34;, \u0026#34;cc_image\u0026#34;)\rload(\u0026#34;@io_bazel_rules_docker//container:container.bzl\u0026#34;, \u0026#34;container_bundle\u0026#34;, \u0026#34;container_import\u0026#34;)\rpackage(default_visibility = [\u0026#34;//visibility:public\u0026#34;])\rcc_image(\rname = \u0026#34;image\u0026#34;,\rbase = \u0026#34;:base_image\u0026#34;,\rbinary = \u0026#34;//offboard/xxx:abc_target\u0026#34;,\rtags = [\r\u0026#34;no-remote\u0026#34;,\r],\r)\rcontainer_bundle(\rname = \u0026#34;taged_image\u0026#34;,\rimages = {\r\u0026#34;$(REAL_IMAGE)\u0026#34;: \u0026#34;:image\u0026#34;,\r},\rtags = [\r\u0026#34;no-remote\u0026#34;,\r],\r)\r``` 那么如何将镜像编译出来呢？运行如下命令即可编译出来名字为hxndg:image的镜像\n```shellscript\rbazel run --define REAL_IMAGE=hxndg:image xxxx/xxx/xxx:taged_image -- --norun\r``` 高级篇 # 18 原理解释 # 概念解释 # 针对Bazel，Action和CAS是平时常见的两个概念。这次重新解释下对应的概念。\nAction # 在Build，Test时运行的命令，包含很多方面：比方说，对编译器的调用，执行某个test。注意Action内部包括命令行参数、环境变量和依赖的输入/输出文件产物或者其它的Action等元数据。举一个简单的例子，给出下面的一个Bazel aquery（action query）的结果。可以看到其包含了编译出来的产物，中间文件，环境变量，命令等多方面信息。Bazel的远程执行分发的可以理解为就是Action的简单包装。\nAction的多种信息，比方说Command，Inputs，Outputs都会被Hash。但是只有Command，Inputs会被当做Hashed Key存储到Action Cache里，Outputs会被当成Cache Key。这里注意，有一个非常Tricky的点，及Action Cache并没有真正的Cache Action，它Cache的是Action的FingerPrint，利用FingerPrint能够方便快捷地找到对应Action和产物\n在这种情况下，我们就可以引出Action graph的概念了，存储于内存中的包含Action调用关系和产物的有向图，在analysis phase 产生，在真正的执行阶段使用，即execution phase使用。而Action graph实际上就是个Merkle-Tree，相关概念用户可以自己搜索下\nCopy\n[example@example-dev-example:/example(master) ] $ bazel aquery //expxxx/xxx/xxxxx_\rINFO: Invocation ID: ea675cf9-4014-42b4-ac53-dc134710a7ea\rINFO: Analyzed target //experimental/xxx/xxx/xxxxx_ (1 packages loaded, 2 targets configured).\rINFO: Found 1 target...\rBazelCppSemantics_build_arch_k8-fastbuild for //experimental/xxxxxxs/xxx/xxxx:xxxxx\rMnemonic: Middleman\rTarget: //experimental/xxxxxxs/xxx/xxx/xxxxx_\rConfiguration: k8-fastbuild\rExecution platform: @local_config_platform//:host\rActionKey: 709e80c88487a2411e1ee4dfb9f22a861492d20c4765150c0c794abd70f8147c\rInputs: [bazel-out/k8-fastbuild/internal/_middlemen/@com_Ugoogle_Ugoogletest_S_S_Cgtest-BazelCppSemantics_build_arch_k8-fastbuild, bazel-out/k8-fastbuild/internal/_middlemen/@com_Ugoogle_Ugoogletest_S_S_Cgtest_Umain-BazelCppSemantics_build_arch_k8-fastbuild]\rOutputs: [bazel-out/k8-fastbuild/internal/_middlemen/_S_Sexperimental_Sxxxx_Sxxxx_Ssimd_Cxxxx_Uxxxx-BazelCppSemantics_build_arch_k8-fastbuild]\raction \u0026#39;Compiling experimental/xxxxxxs/xxx/xxx/xxxxx.cc\u0026#39;\rMnemonic: CppCompile\rTarget: //experimental/xxxxxxs//xxx/xxx/xxxxx_test\rConfiguration: k8-fastbuild\rExecution platform: @local_config_platform//:host\rActionKey: bc54c74489c4827e0560d03bea1096265f8c92eb0d9ac316eacc55031d0cd65f\rInputs: [bazel-out/k8-fastbuild/internal/_middlemen/_S_Sexperimental_Sxxxx_Sxxxx_Ssimd_Cxxxx_Uxxxx-BazelCppSemantics_build_arch_k8-fastbuild, xxxxx/xxx/xxxx/xxxx/fma_test.cc, external/bazel_tools/tools/cpp/grep-includes.sh, external/llvm_repo/llvm/bin/clang, external/llvm_repo/llvm/bin/clang++, external/llvm_repo/llvm/bin/clang-cpp, external/llvm_repo/llvm/include/c++/v1/__algorithm/adjacent_find.h, external/llvm_repo/llvm/include/c++/v1/__algorithm/all_of.h, ...\rexternal/local_cuda/cuda/nvvm/libnvvm-samples/simple/simple-gpu64.ll, external/local_cuda/cuda/nvvm/libnvvm-samples/simple/simple.c]\rOutputs: [bazel-out/k8-fastbuild/bin/xxxxx/xxx/xxxx/xxxx/_objs/fma_test/fma_test.pic.d, bazel-out/k8-fastbuild/bin/xxxxx/xxx/xxxx/xxxx/_objs/fma_test/fma_test.pic.o]\rEnvironment: [DOCKER_REPO_CACHE=/example_cache/docker, GOCACHE=/example_cache/go/cache, GOMODCACHE=/example_cache/go/module, GO_REPOSITORY_USE_HOST_CACHE=1, OMP_NUM_THREADS=1, PATH=/bin:/usr/bin:/usr/local/bin]\rCommand Line: (exec external/llvm_toolchain/bin/cc_wrapper.sh \\\r\u0026#39;--target=x86_64-unknown-linux-gnu\u0026#39; \\\r-U_FORTIFY_SOURCE \\\r-fstack-protector \\\r-fno-omit-frame-pointer \\\r-fcolor-diagnostics \\\r-Wall \\\r-Wthread-safety \\\r-Wself-assign \\\r-mavx2 \\\r-mfma \\\r\u0026#39;-std=c++17\u0026#39; \\\r\u0026#39;-stdlib=libstdc++\u0026#39; \\\r-MD \\\r-MF \\\rbazel-out/k8-fastbuild/bin/xxxxx/xxx/xxxx/xxxx/_objs/fma_test/fma_test.pic.d \\\r\u0026#39;-frandom-seed=bazel-out/k8-fastbuild/bin/xxxxx/xxx/xxxx/xxxx/_objs/fma_test/fma_test.pic.o\u0026#39; \\\r-fPIC \\\r-iquote. \\\r-iquotebazel-out/k8-fastbuild/bin \\\r-iquoteexternal/com_google_googletest \\\r-iquotebazel-out/k8-fastbuild/bin/external/com_google_googletest \\\r-iquoteexternal/bazel_tools \\\r-iquotebazel-out/k8-fastbuild/bin/external/bazel_tools \\\r-isystem \\\rexternal/com_google_googletest/googlemock \\\r-isystem \\\rbazel-out/k8-fastbuild/bin/external/com_google_googletest/googlemock \\\r-isystem \\\rexternal/com_google_googletest/googlemock/include \\\r-isystem \\\rbazel-out/k8-fastbuild/bin/external/com_google_googletest/googlemock/include \\\r-isystem \\\rexternal/com_google_googletest/googletest \\\r-isystem \\\rbazel-out/k8-fastbuild/bin/external/com_google_googletest/googletest \\\r-isystem \\\rexternal/com_google_googletest/googletest/include \\\r-isystem \\\rbazel-out/k8-fastbuild/bin/external/com_google_googletest/googletest/include \\\r-UQ_CPU_ONLY \\\r-DS2_USE_GFLAGS \\\r-DS2_USE_GLOG \\\r-DDCHECK_ALWAYS_ON \\\r\u0026#39;-std=c++17\u0026#39; \\\r-Wdeprecated-declarations \\\r\u0026#39;-Werror=reorder\u0026#39; \\\r-Wno-unknown-warning-option \\\r-Wno-unused-local-typedef \\\r-Wdelete-non-abstract-non-virtual-dtor \\\r-Wenum-compare \\\r-Wextra-tokens \\\r-Wignored-qualifiers \\\r-Winconsistent-missing-override \\\r-Wlogical-op-parentheses \\\r-Wmacro-redefined \\\r-Wpessimizing-move \\\r-Wrange-loop-construct \\\r-Wreturn-stack-address \\\r-Wreturn-type \\\r-Wself-assign-overloaded \\\r-Wswitch \\\r-Wthread-safety-analysis \\\r-Wunused-but-set-variable \\\r-Wunused-function \\\r-Wunused-lambda-capture \\\r-Wunused-parameter \\\r-Wunused-private-field \\\r-Wunused-result \\\r-Wunused-variable \\\r\u0026#39;-ffp-contract=off\u0026#39; \\\r-Wno-deprecated-builtins \\\r-Wno-deprecated-declarations \\\r-Wextra \\\r-Wno-sign-compare \\\r-Werror \\\r\u0026#39;-Wno-error=unused-parameter\u0026#39; \\\r\u0026#39;-Wno-error=unused-but-set-variable\u0026#39; \\\r-fno-access-control \\\r-no-canonical-prefixes \\\r-Wno-builtin-macro-redefined \\\r\u0026#39;-D__DATE__=\u0026#34;redacted\u0026#34;\u0026#39; \\\r\u0026#39;-D__TIMESTAMP__=\u0026#34;redacted\u0026#34;\u0026#39; \\\r\u0026#39;-D__TIME__=\u0026#34;redacted\u0026#34;\u0026#39; \\\r\u0026#39;-fdebug-prefix-map=external/llvm_repo/llvm/=__bazel_toolchain_llvm_repo__/\u0026#39; \\\r-c \\\rxxxxx/xxx/xxxx/xxxx/fma_test.cc \\\r-o \\\rbazel-out/k8-fastbuild/bin/xxxxx/xxx/xxxx/xxxx/_objs/fma_test/fma_test.pic.o)\r# Configuration: 8b90087b699d1ce6fd2f950930f3d839cf137c3e40ca61e38ebd7a75ed2a64eb\r# Execution platform: @local_config_platform//:host # 19 Bazel自定义规则 # 20 Bazel工具链配置和使用 # 21 性能诊断 # 默认profile文件 # 对于一个黑盒的增量编译系统，做性能诊断是比较困难的，不过Bazel内置了Profile功能，每执行完一次编译行为，就会在输出根目录生成一个command.profile.gz文件，即路径为下面的文件\n$(bazel info output_base)/command.profile.gz 这个文件的分析，建议打开chrome://tracing/，然后load对应的profile文件进行分析。\n# 如何阅读profile文件 # 要看剖析结果，请在Chrome浏览器标签中打开chrome://tracing，点击“Load”并选择对应的profile文件\n按1进入“选择”模式。单击特定的方框以查看事件的详细信息，说白了就是看具体的时间消耗，比方说wall time，cpu time啥的 按2进入“平移”模式。然后拖动鼠标来移动视图 按3进入“缩放”模式。然后拖动鼠标进行缩放。用w/s键进行放大和缩小 按4进入“定时”模式，可以测量两个事件之间的时间间隔 阅读Profile文件的关键指标 # bazel analyze-profile是bazel提供的子命令，不过这个我个人感觉不如自己写jq分析json的profile文件或者直接看时间消耗更方便。。。\n怎么看profile文件 # 一般阅读profile文件都是追求时间的效率，针对具体的bazel一个action，有意思的点击该action之后会显示相应的信息。有以下集中类型的时间消耗\nWall time 是实际经过的现实世界时间. 一般推荐使用JSON trace profile 来分析性能消耗 CPU time是CPU执行用户代码所花费的时间 很多时候具体问题处在了用户代码还是bazel本身的问题很难说，这种情况下一般加上 System time是CPU在内核中花费的时间. 主要与Bazel从文件系统读取文件时的I/O相关，这个实际上也一般不出问题 如果怀疑时间可能和系统负载相关，可以加上 --experimental_collect_load_average_in_profiler flag，这个flag是bazel 6.0引入，对应的profile文件里面会有对应系统负载的信息，如下图\n显示网络的使用情况 # 启用远端执行的情况下，网络带宽会影响编译的效率（因为需要上传下载文件和输入）\n添加 --experimental_collect_system_network_usage 可以在profile文件里面看到网络使用情况。\n启用BEP（构建事件协议）中的NetworkMetrics.SystemNetworkStats proto可以收集网络使用情况（需要启用\u0026ndash;experimental_collect_system_network_usage参数）进行监控，不过我还没实践过监控EBP的情况\n常见的profile问题点 # 分析阶段（runAnalysisPhase）比预期慢，尤其是增量构建的情况。这可能是规则实现不佳的迹象，例如将depsets展开的规则实现。包加载可能变慢是因为存在过多的目标、复杂的宏或递归的全局匹配。也有可能是文件下载过慢（比方说不用url，走bazel本身的下载），nas性能不够啥的，下一节写了这个情况 个别的慢速动作，特别是那些位于关键路径上的动作。可以尝试将大型动作拆分为多个较小的动作，或减少（传递）依赖项的数量以加快速度。比方说写了一个规则，单线程的跑test，这种常见于自己写的sh_test 瓶颈问题，这个一般是分配任务不均匀导致。优化这个问题可能需要修改规则实现或Bazel本身，我倒是基本没遇到过。 阅读profile做文件诊断的例子 # 看下面一个曾经遇到的例子，发现Bazel编译耗时很长，然后编译行为并不多，也就编译了几十个action就花了50mins，排查是analysis stage外部依赖花了很多时间下载，然而这些外部依赖都缓存在了对应的nas里面，并配置到编译CI环境的distdir，针对性排查网络和nas性能，发现是nas性能打满了，导致analysis stage过慢，最终更换高性能nas，并独占解决该问题\n# 22 性能优化 # Bazel的性能优化一般集中在以下几个方面：\n远程执行或远程缓存：共享action cache或文件，提供命中率 远程执行，默认情况下，编译和测试都在本地机器执行. 远程执行运行用户将编译和测试分布到不同的多台机器上执行. 远程缓存，remote cache：一般是相同Project的开发者，或者一个CI体系的研发系统用来共享编译产物，只要产物是确定性且可复用的，那么就能提高效率。参考https://github.com/buchgr/bazel-remote/ 减少外部依赖下载所使用的时间 简单来说就是distdir和第三方repo的cache 减少java对内存的消耗 我们一点一点说\nRemote Execution # 远程执行，说白了就是把应该在本地做的事情放到了云端做，换言之“分布式编译（构建）”，随着bazel7.0的到来，构建支持异步式构建，因此远程执行会带来巨大的性能提升。\nbazel的远程执行有一套remote execution api，只要兼容就可以，因此有多种远程执行的服务可以选择。\n非商业化服务 Buildbarn Buildfarm BuildGrid Scoot 商业化服务 EngFlow Remote Execution - Remote execution and remote caching service. Can be self-hosted or hosted. BuildBuddy - Remote build execution, caching, and results UI. Flare - Providing a cache + CDN for Bazel artifacts and Apple-focused remote builds in addition to build \u0026amp; test analytics. 这其中bazel-buildfarm 是bazel官方出的RBE方案官方文档，目前实际上已经处于可用状态，而且有一个很关键的一点，buildfarm支持worker节点扩缩容，因此我重点介绍这个软件。\n关于其架构可以参考下面的链接，来获取一些基本的了解： https://github.com/bazelbuild/bazel-buildfarm/issues/351\nBuildfarm配置 # 直接介绍下当前可用的BuildFarm配置是怎么做的，采用了10台BuildFarm Server维护集群的可用，24台固定的CPU Buildfarm Worker节点参与编译工作，6台GPU Buildfarm Worker参与GPU Test。除上述机器之外，还有自动扩缩容的机器参与到CPU Buildfarm Worker的工作当中。针对Buildfarm 2.3.1的版本，采用配置如下即可。\nServer配置 # backplane用来指定通信的媒介，拆分为两个不同的queues，用来方便任务的分发，比方说CPU任务包括编译和TEST，GPU任务则只包含TEST任务，可以看到GPU队列必须要满足相关的properties才会被正确的depatched。\nCPU队列允许不匹配的规则，其中min-cores和max-cores都为*，就能保证没命中GPU类型任务都会命中到CPU队列当中\nServer的类型为shard，这个是目前唯一支持的类型了\nbackplane:\rredisUri: \u0026#34;redis://xxxxxxxxxxxxxxxxxxxxxxxx:6379\u0026#34;\rqueues:\r- name: \u0026#34;gpu\u0026#34;\rallowUnmatched: false\rproperties:\r- name: \u0026#34;gpu\u0026#34;\rvalue: \u0026#34;1\u0026#34;\r- name: \u0026#34;cpu\u0026#34;\rallowUnmatched: true\rproperties:\r- name: \u0026#34;min-cores\u0026#34;\rvalue: \u0026#34;*\u0026#34;\r- name: \u0026#34;max-cores\u0026#34;\rvalue: \u0026#34;*\u0026#34;\rdigestFunction: SHA256\rmaxEntrySizeBytes: 123456\rserver:\rname: \u0026#34;shard\u0026#34;\rrecordBesEvents: true CPU Worker # CPU Worker的配置和Server端非常类似，其中executeStageWidth标记可同时并发的任务数量，inputFetchStageWidth则标记可以并发获取Input的数量。我们使用FILESYSTEM来标记该CPU节点既执行缓存操作，又有执行能力。realInputDirectories用来标记external，如果不写这个配置可能造成外部文件hard link过多的问题，\nbackplane:\rredisUri: \u0026#34;redis://xxxxxxxxxxxxxxxxxxxxxxxx:6379\u0026#34;\rqueues:\r- name: \u0026#34;cpu\u0026#34;\rallowUnmatched: true\rproperties:\r- name: \u0026#34;min-cores\u0026#34;\rvalue: \u0026#34;*\u0026#34;\r- name: \u0026#34;max-cores\u0026#34;\rvalue: \u0026#34;*\u0026#34;\rdigestFunction: SHA256\rmaxEntrySizeBytes: 123456 worker:\rport: 8982\rpublicName: \u0026#34;localhost:8982\u0026#34;\rexecuteStageWidth: 80\rinputFetchStageWidth: 8\rrealInputDirectories:\r- \u0026#34;external\u0026#34;\rstorages:\r- type: FILESYSTEM\rmaxSizeBytes: 123124124124123123 GPU Worker # 可以看到GPU Worker的配置和CPU Worker类似，但是属性那一部分并不一致，借此来保证任务的正常调度。\nbackplane:\rredisUri: \u0026#34;redis://xxxxxxxxxxxxxxxxxxxxxxxx:6379\u0026#34;\rqueues:\r- name: \u0026#34;gpu\u0026#34;\rallowUnmatched: false\rproperties:\r- name: \u0026#34;gpu\u0026#34;\rvalue: \u0026#34;1\u0026#34;\rdigestFunction: SHA256\rmaxEntrySizeBytes: 12345678 worker:\rport: 8982\rpublicName: \u0026#34;localhost:8982\u0026#34;\rexecuteStageWidth: 8\rinputFetchStageWidth: 8\rrealInputDirectories:\r- \u0026#34;external\u0026#34;\rstorages:\r- type: FILESYSTEM\rmaxSizeBytes: 123123123123123\rdequeueMatchSettings:\racceptEverything: true\rallowUnmatched: false\rproperties:\r- name: \u0026#34;gpu\u0026#34;\rvalue: \u0026#34;1\u0026#34; 终端用户集成 # 将export的端口暴露为相应的grpc服务，然后直接在用户的BAZEL配置文件里面写下如下地址即可，其中GPU TEST的Build文件里面需要添加对应poperties类型，来保证这个test被正确地调度到对应的Worker\n```python\rexec_properties = {\u0026#34;gpu\u0026#34;: \u0026#34;1\u0026#34;},\r``` ```shellscript\rbuild --remote_executor=服务地址\rbuild --remote_cache=\rbuild --remote_timeout=5m\u0026#34;\rbuild --jobs=30 #控制并发数量\r``` Buildfarm生产用排雷 # Buildfarm的使用实际上是有部分问题的，如果想把Buildfarm投入生产，建议注意下面几点\ngrpc的负载均衡 # 和nginx的负载均衡不一样，grpc破坏了标准的连接级负载均衡，Kubernetes 提供的负载均衡本身是基于连接级别的负载均衡。这是因为 gRPC 构建于 HTTP/2 之上，而 HTTP/2 被设计为具有单个长期 TCP 连接，所有请求都在该连接上进行多路复用，这意味着多个请求可以在任何时间点在同一连接上处于活动状态。因此如果希望对buildfarm的服务做负载均衡，最好启用kubernetes的ingress机制\nBuildfarm的Liveness检查 # Buildfarm从1.15到2.3.1目前已经很稳定了，但是在机器压力过大或者inode不够用的情况下还是会出现问题，这些问题的统一表现是buildfarm的worker，java创建大量线程，因此可以根据该特征写一个livenessprobe检查\nCopy\n```yaml\rlivenessProbe:\rexec:\rcommand:\r- /bin/bash\r- -c\r- |-\rjava_thread_count=$(ps huH p $(ps -C java -o pid=) | grep java | wc -l);\rif [ \u0026#34;$java_thread_count\u0026#34; -gt \u0026#34;1000\u0026#34; ]; then\rexit 1\rfi\rfailureThreshold: 12\rinitialDelaySeconds: 300\rperiodSeconds: 10\rsuccessThreshold: 1\rtimeoutSeconds: 3\r``` Remote Cache # Remote Cache的使用，相比Buildfarm就简单很多了，推荐直接参考https://github.com/buchgr/bazel-remote/。\n说白了，在本地就是运行\n# Dockerhub example:\r$ docker pull buchgr/bazel-remote-cache\r$ docker run -u 1000:1000 -v /path/to/cache/dir:/data \\\r-p 9090:8080 -p 9092:9092 buchgr/bazel-remote-cache \\\r--max_size 5 在本地启动了对应的remote cache之后，在bazelrc文件当中写入下面的内容即可使用\ncommon --remote_cache=xxx地址 优化内存 # 一般优化都是对时间效率的优化，不过另外一些时候希望优化对内存的使用。常见的方式就是指定启动flag \u0026ndash;host_jvm_args设置最大堆大小，例如\u0026ndash;host_jvm_args=-Xmx2g。\n如果BUILD消耗内存，bazel可能抛出OutOfMemoryError（OOM）异常，不过我目前基本没遇到这个问题，针对一个7w个action的编译库，我配置的启动选项如下，，没啥问题。\nbazel --host_jvm_args=-Xmx4g build -c opt 有一些选项可以用来控制内存中的graph是否保存，副作用是这次编译完了，下回没办法复用这次的编译结果。\n\u0026ndash;discard_analysis_cache将减少执行过程（而非分析过程）中使用的内存。下次构建将不需要重新加载依赖和包，但需要重新进行分析和执行（尽管磁盘上的操作缓存已经存在） \u0026ndash;notrack_incremental_state将不会存储任何Bazel的内部依赖图中的边，简单来说，依赖关系没啦！因此增量构建无法使用了 \u0026ndash;nokeep_state_after_build将在构建完成后丢弃所有数据，以便增量构建必须从头开始构建（除了磁盘上的操作缓存） 我目前用的是\nbazel --host_jvm_args=-Xmx4g build -c opt xxxxxx --notrack_incremental_state --nokeep_state_after_build --discard_analysis_cache 这里可能有一点要注意，不一定是bazel造成的内存消耗过多，对于kubernetes环境，buffer/cache也是一个可能造成内存消耗过多的点，这部分在POD当中也会被当做是内存消耗，尽管不是JAVA导致的（毕竟编译要访问大量文件）。\n23 Bazel集成Code Coverage # 结尾 # 唉，尴尬\n","date":"2024 年 5 月 10 日","externalUrl":null,"permalink":"/posts/2024-06-02-bazel%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E4%B8%AD%E7%BA%A7/","section":"Posts","summary":"","title":"2024-06-02-bazel从入门到中级","type":"posts"},{"content":"","date":"2024 年 5 月 10 日","externalUrl":null,"permalink":"/tags/bazel/","section":"Tags","summary":"","title":"Bazel","type":"tags"},{"content":"","date":"2024 年 5 月 10 日","externalUrl":null,"permalink":"/tags/ci/","section":"Tags","summary":"","title":"Ci","type":"tags"},{"content":"","date":"2024 年 5 月 10 日","externalUrl":null,"permalink":"/tags/debug/","section":"Tags","summary":"","title":"Debug","type":"tags"},{"content":"","date":"2024 年 5 月 10 日","externalUrl":null,"permalink":"/tags/fun/","section":"Tags","summary":"","title":"Fun","type":"tags"},{"content":" 工程师修养 # 0 灵魂型工程师修养 # 技术是为了灵魂服务的，术服务于道，在当前我认为有两点需要工程师具备\n云原生技术层面素养 安全服务（价值观）技术层面素养 什么才是灵魂型工程师呢，我摘抄自瑞典马工的公众号消息\n决策层需要提出有说服力的价值主张。 产品团队需要管理企业客户需求。 行销团队需要明确企业客户的画像。 销售队伍需要和企业客户真实对话的能力。 研发团队需要提升软件工程素质。 所有团队在 IT 安全上要表现出专业度。 需要若干有说服力的的企业客户成功案例。 1 加解密相关经验 # 关于加密技巧相关\n涉及到AEAD块加密相关，默认推荐使用**AES128_GCM**来加密给大部分的数据使用。 涉及到流式AEAD家解密，默认推荐使用**AES128_GCM_HKDF_1MB**来加密数据。目前，流式AEAD的实现实际上就是小的块AEAD，(基于45b7561b39d6490116b150c44b3a4502c79e72c1分析) CBC模式因为IV会受到bitwise attack的影响，应当尽量不要使用！任何情况下，参与加密的内容如果可以被bitwise attack且明确区分是padding还是加解密异常的，都应该直接失败 CHACHA20-POLY1350的相关安全行分析\n流式加密一般速度比较快，CHACHA20就是流密码。安全分析见下面的pdf， https://www.cryptrec.go.jp/exreport/cryptrec-ex-2601-2016.pdf Ciphersuite的文档看\nhttps://ciphersuite.info/rfc/?page=1 实现代码相关\n因为openssl本身的实现可能出现代码泄露的问题，所以，一般推荐直接使用google的tink作为加解密的基本组件参与到运算当中，实现起来会比较简单。\n结尾 # 唉，尴尬\n","date":"2023 年 8 月 21 日","externalUrl":null,"permalink":"/posts/2023-08-21-%E5%AE%89%E5%85%A8%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%BF%AE%E5%85%BB/","section":"Posts","summary":"","title":"2023-08-21-工程师修养","type":"posts"},{"content":" 数据库基础知识 # POSTGRESQL基础部分 # 1.1 SQL语法 # SQL是一种声明式语言，和命令式编程语言不通，声明式编程语言是描述用户需要做什么，需要得到什么结果，而不是像命名式编程语言给出过程怎么做，过程是什么。类比join，就能反映出来，join实际上是将不同的行拼凑为了新的结果，并最终执行检索操作。\nSQL分为三种分类\nDQL DML 插入 更新 DDL 建表 drop表 2.1 psql工具 # psql是postgresql默认的交互工具\n常用的指令（需要先登录进psql，走交互模式）\n\\l，用于查看有哪些数据库 \\c，后面跟数据库名称，用于连接到具体的数据库 \\d [pattern]+ ，用于描述匹配pattern（表，视图，索引，序列）的信息。如果不追加pattern，会列出数据库当中所有的表。这个命令可以加正则描述符。此外可以用\\d+来显示更详细的信息 \\h，用于查询具体的命令，比方说\\h create user 3.1 数据类型 # 布尔类型，一字节存储空间\npostgresql的bool实际上是三种类型，true、false、null。null表示未知 数值类型\nsamllint，两字节； int，四字节； bigint，八字节；相比于int类型，bigint慢很多 精确类型小数，numeric(别名decimal，用时一般加上一个（），里面指名精度)；一般 非精确类型浮点小数，real，double precision。如果要求精确地表示计算，应该使用numeric；如果做重要的计算，包括对无穷，下溢做计算，那么应该评估要不要用这种类型；另外两个此类型数字做比较的结果是不一定的 八字节货币，money 字符类型：postgresql的字符串支持多种函数，比方说二进制编解码为base64，使用md5对字符串进行操作\nvarcher(n)，变长，存储空间为4+实际的长度。最大的长度为1GB。实际上存储可能是一个指针，指向真正字符串的地址。 char（n)，定长，如果长度不足那么char会自动地用空格补足长度 char(n)，text。varchar最长可以1GB 二进制类型：\nbytea：二进制串可以用来存储不可见字符，即可以存储图片这种类型；交互需要使用转义字符 位串： 日期类型：\n空间 最小值 最大值 分辨率 Timestamp(p) 8字节 4713BC 5874897AD 1m s/14位 Timestamp(p) 8字节 日期+时间，带时区 4713BC 5874897AD 1m s/14位 Interval(p) 12字节 -178000000年 178000000年 1m s/14位 Date 4字节 日期 4713bc 5874897AD 1天 Time(p) 8字节 仅一天，不带时区 00:00:00 24:00:00 1m s/14位 Time(p) 12字节 一天，带时区 00:00:00+1459 24:00:00-1459 1m s/14位 时间类型有一些问题需要注意，输入的格式可能不是默认的，有时候输入的明明以为是月份的位置，最终可能变成日，因此建议指定输入的格式。另外请注意，输入时区的时候不要用简写，比方说CST就是好几种不同的时区，比方说Cuba ST，或者Chain ST啥的。\n另外一点需要注意，对于同一个事务而言，获取时间的函数都会返回一个相同的值\n数组类型\n枚举类型\npostgresql的枚举类型，需要先创建，使用create type来创建 postgresql的枚举类型的大小顺序是按照创建时候的顺序确定的 xml类型：postgresql支持xml类型，xml类型的数据如果用字符串存储，那么需要用户保证正确性。相反，如果让postgresql启用xml支持，它就可以省事的做校验了\njson/jsonb类型\njsonb以二进制形式存储，因此会被转换为postgresql内部的数据类型，可能损失精度/增加精度。jsonb可以创建索引，而json不能创建索引，这是两者的区别 postgresql支持对json操作的多种函数，比方说提取key，提取value，返回指定key的value（返回值为text） 3.1 postgresql逻辑结构管理 # postgresql的组织结构可以分为如下三种：\n数据库 表，索引：postgresql称为Relation，其他数据库称为Table 数据行：在postgresql称为Tuple，其他称为Rows 3.1.1 数据库基本操作 # 数据库基本操作：\n创建数据库 修改数据库：事务块里面可以删除数据库 删除数据库：注意，事务块里面不能删除数据库 3.1.2 模式基本操作 # postgresql里面有个模式的概念，模式（schema）是数据库里面的一个概念，理解为命名空间或目录，不同的模式下可以有相同名称的表，函数等对象而不会产生冲突。这里面模式大部分情况需要用户执行授权\n在postgresql里面一个数据库包含一个或者多个模式，模式又包含表，函数。postgresql不允许同事访问不同数据库的对象，模式则没有限制。从这个特性来说，postgresql的模式和mysql的database概念是对应的。oracle数据库里面，一个用户对应一个schema。总之模式存在的主要原因：\n允许多个用户使用同一个数据库而用户不会相互干扰 把数据库对象放在不同模式组织成逻辑组，方便数据库对象管理 第三方应用可以放在不同的模式中，这样就不会和其他对象冲突 如何创建模式呢？\ncreate schema schemaname [authorization username] schema_element 可能的问题点，因为postgresql不能垮数据库访问，因此如果做移植操作，那么mysql中的三个数据库，在postgresql里面最好是对应三个模式\n3.1.3 表 # 创建表的命令如下，如果希望加一下特定的检查，那么这个检查也可以用类似constraint的方式加在末尾,default用于表示默认值\n# 单个列作为主键 create table table_name (col_name col_type primary key...) # 多个列作为联合主键 create table table_name (col_name_1 col_type_1 [default xxx], col_name_2 col_type_2 [default xxx], col_name_3 col_type_3, col_name_4 col_type_4, col_name_5 col_type_5... CONSTRAINT common_constraint key(col_name_x, col_name_y, ...)) 可以将其它表作为模板来创建，语法如下\n这里的继承只会有属性，不会有约束，如果希望有约束可以用下面的指令\n下面介绍TOAST的概念\n临时表，postgresql支持两种临时表\n会话级的临时表：会话结束的时候，表才会消失，数据会一直保存在会话的生命周期里。因此不同的session的临时表实际上是不一样的 事务级的临时表：事务结束，就会丢失 语法如下\ncreate temporary table unlogged表\n约束\n检查约束 非空约束 唯一约束 主键 外键约束：用于约束本表中的一个或多个字段的树枝必须出现在另一个表的一个或多个字段里面。也被称为两个相关表之间的参照完整性约束 修改表，alter table\n表继承：注意事项有点多，需要多注意\n表继承用于实现分区表，流程如下\n约束排除\n3.1.4 触发器 # 触发器可以帮用户实现很多自由自在的功能，比方说记录执行日志\n创建触发器的语法为，一般就是先创建一个执行函数，此函数的返回值为触发器类型；然后创建对应的触发器，用下面的语法\nCREATE [ CONSTRAINT ] TRIGGER name { BEFORE | AFTER | INSTEAD OF } { event [ OR ... ] } ON table_name [ FROM referenced_table_name ] { NOT DEFERRABLE | [ DEFERRABLE ] { INITIALLY IMMEDIATE | INITIALLY DEFERRED } } [ FOR [ EACH ] { ROW | STATEMENT } ] [ WHEN ( condition ) ] EXECUTE PROCEDURE function_name ( arguments ) where event can be one of: INSERT UPDATE [ OF column_name [, ... ] ] DELETE TRUNCATE 语句级触发器和行级触发器，触发器可以在语法或者行的层次执行，语句级别只执行一次，而行层次会多次执行；语义级别的触发器即使影响的行很多，也只会执行一次。\nBefore触发器和After触发器\nbefore和after可以针对行和语句，其中语句的before最先，语句的after最后 对于行级触发器，before和instead of如果返回null，就啥也不做。对于insert和update，如果返回非null的行，那么就会执行在新的行里面里面的内容，after的返回值会被忽略 如果有多个触发器，如果是before/instead of的触发器，每个返回的行（可能已经被修改）会成为下一个触发器的输入 触发器里面的变量 NEW OLD TG_NAME TG_WHEN TG_LEVEL 事件触发器\nDDL_COMMAND_START DDL_COMMAND_END SQL_DROP 3.1.5 表空间 # 表空间实际上就是指定表的存储目录，创建数据库的时候就可以指定默认的空间。不过更改表空间的语义是有副作用的，这个需要注意\n3.1.6 视图和索引 # 视图是查询语句定义的虚拟表，可以用来组合多种数据。不过需要知道视图实际上是可读的，可以通过触发器把对视图的操作转换为对表的操作\n索引用来快速查找表记录，常见的索引类型如下\nB-tree：最常用的索引 Hash：针对等值查询 GiST：一种特定的架构，可以在架构上实现很多的不同的索引策略 3.1.7 用户和权限管理 # 权限管理可以说是最简单的控制的方法了，可以方便的控制是否可以操作数据库。\n创建用户和角色的语法如下：\n-- 创建用户 CREATE USER name [[ WITH ] option [...]] -- 创建角色 CREATE ROLE name [[ WITH ] option [...]] 备注：在PG中，用户与角色是没有区别的，角色默认没有login权限，无法登陆，如果授予login之后，也可以像用户一样登陆。\noption常用选项如下：\nSUPERUSER | NOSUPERUSER：创建出来的用户是否为超级用户 CREATEDB | NOCREATEDB：创建出来的用户是否有create database的权限 CREATEROLE | NOCREATEROLE：创建出来的用户是否有创建其它角色的权限 CREATEUSER | NOCREATEUSER：创建出来的用户是否有创建其它用户的权限 INHERIT | NOINHERIT：确定角色是否继承其它角色的权限 LOGIN | NOLOGIN：创建出来的角色是否有登录权限 CONNECTION LIMIT n：创建出来的角色并发连接数限制数量，默认值是“-1”,表示没有限制 VALID UNTIL \u0026rsquo;timestamp\u0026rsquo;：密码失效时间 用户的权限分两类，一类是在创建用户时就指定的权限，有：\n超级用户的权限 创建数据库的权限 是否允许login的权限 更多见\\help create role 这些权限是创建用户时指定的，后面可以使用alter role来修改。\n另一类是有GRANT和REVOKE命令来管理的，有：\n在数据库中创建schema的权限 在指定的数据库中创建临时表的权限 连接某个数据库的权限 在某个数据库中创建数据库对象的权限，如表、视图、函数等 在一些表中做SELECT 、INSERT、UPDATE、DELETE等操作的权限 在一张表的列上做 SELECT 、UPDATE、DELETE等操作的权限 对序列进行查询(执行序列的currval函数)、使用(执行序列的currval和nextval函数)、更新的权限 在表上创建触发器的权限 把表、索引创建到指定表空间的权限 总之postgresql中的权限是按照以下几个层次进行管理的：\n1.首先管理赋予用户的特殊权限，如超级用户的权限，创建数据库的权限、创建用户的权限、login权限等\n2.然后是在数据库中创建schema的权限\n3.接着是在schema中创建数据库对象(如表、索引)的权限\n4.之后是对表进行操作(insert、update、delete、select)的权限\n5.最后是操作(update、delete、select)表中某些字段的权限\n3.1.8 事务和锁 # 3.1.9 执行计划 # 什么是执行计划？数据库的执行计划通俗点说就是，数据库服务器在执行sql语句的时候，会准备几套方案，最后选择消耗资源最小的那个方案。在postgresql可以估算出来具体执行的代价\n语法如下，其中analyze会让语句真正地执行一次\nEXPLAIN [ ( option [, ...] ) ] statement EXPLAIN [ ANALYZE ] [ VERBOSE ] statement 这里 option可以是： ANALYZE [ boolean ] VERBOSE [ boolean ] COSTS [ boolean ] BUFFERS [ boolean ] TIMING [ boolean ] FORMAT { TEXT | XML | JSON | YAML } 可以通过执行计划看到postgresql内部的部分优化\n3.1.10 postgresql技术内幕 # 先解释几个名词\nxmin xmax cmin cmax 这些有什么用呢？\n新插入一行：新插入行的xmin为当前事务ID，xmax为0 修改一行，实际上是插入新的一行，元数据行的xmin不变，xmax改为当前事务ID，新的数据行上面的xmin改为当前的事务ID，xmax为0 删除一行的时候，把被删除的行上面的xmax填写为当前事务ID 因此，xmin实际上是插入数据行的事务ID，xmax用来标记删除数据行的事务ID（这里面还藏了一个事务ID递增这么一点），postgresql的mvcc就是这么实现的\n相比较mysql和oracle数据库的旧版本数据存储在原先的数据块里面，postgresql的好处是\n事务回滚可以立即完成 数据可以进行多更新，不必像oracle和innodb那样需要保证回滚段不会被用完 缺点是\n旧版本数据需要清理 旧版本的数据会导致查询慢 3.1.11 物理存储结构 # 结尾 # 唉，尴尬\n","date":"2023 年 8 月 21 日","externalUrl":null,"permalink":"/posts/2023-12-21-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","section":"Posts","summary":"","title":"2023-12-21-数据库基础知识","type":"posts"},{"content":"","date":"2023 年 8 月 21 日","externalUrl":null,"permalink":"/tags/postgresql/","section":"Tags","summary":"","title":"Postgresql","type":"tags"},{"content":"","date":"2023 年 8 月 21 日","externalUrl":null,"permalink":"/tags/%E6%9E%B6%E6%9E%84/","section":"Tags","summary":"","title":"架构","type":"tags"},{"content":" 开发个人检查清单 # 下面的内容我实际上是抄的代码大全2检查清单的内容，因为没看到哪里有所有的检查清单的内容。所以利用OCR+AI来拿出来所有的文字，除此之外，补上了部分我自己的检查内容，斜体是我自己的内容。\n1 需求 # 具体的功能需求\n是否指定了系统的所有输入，包括其来源、精度、值的范围和出现频率？\n是否指定了系统的所有输出，包括其目标、精度、值的范围、出现频率和格式?\n是否为Web 页面和报表等指定了所有输出格式？\n是否指定了所有外部硬件和软件接口?\n是否指定了所有外部通信接口，包括握手、错误检查和通信切议?\n是否指定了用户想要执行的所有任务?\n是否指定了每个任务中使用的数据和每个任务产生的数据。要给出产生的数据量一个预估值。\n特定的非功能性(质量)需求\n从用户的角度来看，是否为所有必要的操作指定了预期的响应时间？ 尽量避免任何跨公网，以及本地的文件拷贝 是否指定了其他时间考虑因素，比如处理时间、数据传输速率和系统吞吐量 是否指定了安全级别? 是否指定了可靠性，包括软件故障的后果、需要在故障中得到保护的重要信息以及错误测和恢复策略？ 是否指定了最小机器内存和空闲磁盘空间? 是否指定了系统的可维护性，包括适应特定功能的更改、操作环境的更改以及与其他软件接口的更改的能力？ 是否包括了成功和失败的定义? 需求质量\n需求是用用户的语言编写的么？用户这么认为么？ 每个需求都避免了与其他需求的冲突么 是否详细说明了竞争属性之间的可接受的这种，例如健壮性和正确性的折中 是否避免了在需求中规定设计 需求在详细程度上是一致的么，是否有需求需要更详细的说明？是否有需求不需要那么详细的说明 需求是否足够清晰，以至于可以移交给一个独立的团队进行构建，且不会产生误解？开发人员这么认为么？ 每个条款都与待解决的问题及其解决方案相关么？能从每个条款上溯到在问题域中对应的根源么 每个需求都是可测试的么？是否有可能通过独立测试来确定每个需求都被满足了 是否说明了需求的所有可能变更以及每种变更的可能性 需求合理性考察，很多需求实际上是非常不清楚或者不合理地，简单补充一个点。如果要检查一个文件是否正常合理，那么文件应该在它生成的过程当中就测试。而不是滞后 需要考虑需求的优先级，需要区分出来哪些是必须完成的，哪些是可能完成的。很多情况下不重要的就后推，只考虑重要的需求。简单来说也是需求的完整性 需求的完整性\n对于在开发中无法获得的信息，是否详细描述了信息不完整的区域 需求的完备程度是否可以达到这种高度：如果产品满足了所有需求，就说明它是可以接受的 对全部需求都感到满意么？是否已经去掉了那些不可能实现的需求，那些只是为了安抚客户和老板的东西 2 架构 # 针对各架构主题 顶目的整体组织是否清晰，包括良好的架构概述及其理由 主要构件是否定义良好，包括它们的职贡范围以及它们与其他构件的接口 在需求中列出的所有功能都被合理覆盖了吗？ 最关键的类是否有描述和论证？ 数据设计是否有描述和论证？ 是否说明了数据库的组织和内容？ 是否确定了所有关键业务规则及其对系统的影响? 是否描述了用户界面设计的策略？ 用户界面是模块化的，因此它的更改不会影响程序的其余部分吗? 是否描述井论证了处理IO的策略？ 是否估算了稀缺资源(如线程、数据库连接、句糖和网络带宽等)的使用量，是否描述并论证了资源管理的策略? 是否描述了架构的安全需求\u0026quot; 架构是否为每个类、每个子系统或每个功能域提出时间和空间预算? 架构是否描述了如何实现可伸缩性? 架构是否关注了互操作性? 是否描述了国际化和本地化的策略？ 是否提供了一套一致性的错误处理策略 是否提供了容错的方法（如果需要的话) 是否证实了系统各部分的技术可行性，要求系统各个部分能认识到技术难点是比较困难的 是否详细描述了过度工程的方法？ 是否包舍了必要的购买还是构律的决策? 架构是否播述了如何加工被复用的代码，使之待合其他架构目际; 架构的设计是否能够适应极有可能出现的变更？ 架构的总体质量 架构是否解决了全部需求？ 有没有哪个部分是过度架构或欠架构?是否明确提出了这方面的具体目标 整个架构是否在概念上协调一致?这个问题是可以大大拓展的，架构不是只针对代码，对所有的都可以 顶层设计是否独立于用于实现它的机器和语言 是否提供了所有主要决策的动机? 作为一个将要实现系统的程序员，你是否对架构感到满意” 3 前期准备 # 你是否已经确定了你正在从事的软件项目的类型，并适当调整了你的方法 需求是否有充分明确的定义，并且足够稳定，可以开始构建(详见需求检查） 架构是否有充分明确的定义，以便开始构建(详见架构检查清单) 你的特定顶目所特有的其他风随是否得到了解决，从而使构建不会被暴露在不必要的风险中？ 4 重要的构建实践 # 编码 是否定义了有多少设计工作要预先完成，以及多少工作再编码的同时完成 是否为名称、注释和代码格式等制定了编码约定? 是否定义了架构所隐含的特定编码实践?例如，如何处理错误条件: 如何处理安全性？类接口使用什么约定？对重用代码应用什么标准?在编码时对性能要考虑到什么程度？ 是否已经确定了自己在科技浪潮中所处的阶段，井调整了自己的方法来？如果有此要,是否已经确定了如何深入语言来编程,而不是受限于只会用语言来绵程 团队工作 是否定义了集成工序，即是否定义了程序员在将代码登入主干之前必须经过的特定步骤? 简单来说就是对应的test和集成测试需要提前完成 程序员是结对编程还是独立编程，还是采用两者的组合? 5 软件构建中的设计 # 设计实践 是否已做过迭代，从多个结果中选择了最佳的一种，而不是简单地选择首次尝试的结果? 分布式的时代需要考虑性能，可靠性，数据量，是否可管理等多方面 尝试过以多种方式分解系统以确定哪种最好吗? 同时采用了自上而下和自下而上的方法来解决设计回题吗? 针对系统中有风险或者不熟悉的部分进行过原型设计，写数量最小的抛弃型代码来回答特定回题吗 自己的设计方案被其他人评审过吗？无论正式与否 一直在推动设计，直至实现细节昭然若揭吗 使用某种适当的技术(例如Wiki、电子邮件、挂图、数码照片、UML、CRC卡片或者代码中内嵌的注释)来记录设计了吗？ 设计目标 设计是否充分解决了在整体架构层面确定并决定推迟实现的问题？ 设计是否分层的？ 对于将程序分解为子系统、包和类的方式是否感到满意 对于将类分解为子程序的方式是否感到满意？ 类的设计是否使它们之间的交互最小化？ 类和子系统的设计是否方便你在其他系统中重用 程序是否容易维护？程序的维护不是单纯地开发，针对出了问题快速定位原因及时暴露错误码也是是否容易维护的判断标准之一。程序内部采用快速失败是一个比较好的策略，如果出错了还继续执行可能造成无法理解的后果 设计是否精简？它的所有部分都是绝对必要的吗？ 设计是否使用了标准技术来避免奇特的、难以理解的元素？ 总的来说，这个设计是否有助于将偶然和本质的复杂性降至最低？ 6 类的质量 # 抽象数据类型\n是否将程序中的类视为抽象数据类型，是否从这个角度评估了他们的接口？ 抽象\n类是否有一个中心目的 类的命名是否恰当？其名字是否表达了其中心目的？ 类的接口是否呈现了一致的抽象？ 类的接口是否让人一眼就知道应该如何使用这个类？ 类的接口是否足够抽象，使开发者无需考虑它的服务具体是如何实现的能将类看作是一个黑盒吗？ 类的服务是否足够完整，使其他类无需摆弄其内部数据？ 是否已经从类中移除了无关信息？ 是否考虑过将类进一步分解为组件类？是否已经尽可能地进行了分解？ 修改类时是否保持了其接口的完整性？ 封装\n是否最小化了类成员的可访问性？ 类是否避免了公开其成员数据？ 在编程语言允许的范围内，类是否尽可能地隐藏了具体实现细节？ 类的设计是否避免了对其用户（包括其派生类）做出假设？这是一个很有趣的点，如果企鹅能够继承鸟，那么用户一般会假设鸟会飞，但是很明显企鹅不会飞。所以实际上如果真正实现的话，建议是拆解部分非通用的属性不在基类 类是否不依赖于其他类？是否松耦合？ 继承\n继承是否只用来建立\u0026quot;is-a\u0026quot;关系？即派生类是否遵循了里氏替换原则（lsp）而非仅仅为了重用代码？ 类的文档是否描述了其继承策略？ 派生类是否免除了\u0026quot;覆盖不可覆盖的函数\u0026quot;的限制？ 是否足够清晰地指定了派生类如何重载、扩展和覆盖基类的行为，并将待继承的的通用接口数据放在了继承树上层？ 继承树是否很浅？ 是否将基类中的所有成员都定义为私有或受保护的？ 与实现相关的其它问题\n类的数据成员是否只有七个或更少？ 是否将类中直接调用其他类的子程序的数量减到最少了？ 类是否只在绝对必要时才与其他类协作？ 是否所有数据成员都在构造函数中进行了初始化？ 是否经过论证，类被设计为深拷贝而不是浅拷贝来使用？ 语言特定问题，针对您所使用的编程语言，是否研究过语言特定的和与类相关的问题？ 7 高质量的子程序 # 主要问题\n是否有充分的理由来创建该子程序？ 创建子程序的理由应该是不同功能的拆分，和代码复用 在该子程序中，哪些部分更适合抽取出来作为独立的子过程或函数？ 关于该子程序的命名，是否使用了清晰的、强有力的动词加上对其操作对象的描述作为过程的名称，或者使用了对返回值的描述作为函数的名称？ 该子程序的名称是否准确地描述了它所做的一切事情？ 是否为一些常用操作建立了命名规范？ 该子程序是否具有高内聚性，即只做一件事，并且做得很好？ 该子程序是否具有松散的耦合性？该子程序与其他子程序的关联是否简单、专用、可见和灵活？ 该子程序的长度是否是由它的功能和逻辑自然决定的，而不是由人为制定的编码标准决定的？这个可能有点反直觉，很多情况下会有规定程序不能太长 参数传递问题\n该子程序的参数列表作为一个整体是否呈现了一致的接口抽象？ 该子程序的参数是否按合理顺序进行排列，与其他类似子程序的参数顺序一致？ 是否对接口假设进行了文档记录？ 该子程序的参数数量是否少于或等于7个？ 在该子程序中是否使用了每个输入参数？ 在该子程序中是否使用了每个输出参数？ 是否避免将输入参数作为工作变量使用？这里面有个问题，有的时候我们就是要把这个做工作变量，不过理论上应该是最小量的更新，获取之类的 如果该子程序是一个函数，在所有可能的情况下是否都返回了一个有意义的值？ 8 防御式编程 # 一般事宜\n子程序否可以保护自己免受输入参数的破坏？ 是否使用断言来声明假设，包括前置条件和后置条件？ 断言是否只用于声明永远不应该发生的情况？ 是否在架构或高层级设计中指定了一组特定的错误处理技术？尽管有点反直觉，目前部分C++代码规范是反对使用异常的，很多函数有对应的不抛异常版本 是否在架构或高层级设计中规定了错误处理应该偏向于健壮性还是正确性？健壮性会带来时间和试错的成本，正确性的最简单选择就是快速失败 是否建立了防护屏障来防止可能造成破坏的错误，并减少与错误处理有关的代码数量？比方说一个json解析失败不应该导致整个服务器崩溃。这也是为什么微服务会兴起的原因 代码中是否使用了辅助调试代码？ 如果要启用和停用辅助调试代码，是否不需要大动干戈？ 防御式编程引入的代码的数量是否合适，既不太多也不太少？ 在开发阶段是否使用攻击式编程技术使错误很难被忽视？这个是指混沌工程主动显示错误是吧？ 异常\n在项目中是否定义了一种标准化的异常处理方法？ 是否考虑过异常之外的其他替代方案？ 错误是否已尽可能在局部处理，而不是作为异常向外抛出？ 代码中是否避免在构造函数和析构函数中抛出异常？ 是否所有的异常都与抛出它们的子程序处于同一抽象层次上？ 每个异常是否包含了关于异常发生的所有背景信息？ 代码中是否没有使用空的catch块？或者，如果使用空的catch块，是否很合适？ 安全事宜\n检查错误输入数据的代码是否也检查了缓冲区溢出、SQL注入、HTML注入、整数溢出和其他恶意输入？ 是否检查了所有错误返回码？ 是否捕获了所有的异常？ 出错消息中是否避免了出现有助于攻击者攻入系统的信息？心脏滴血漏洞实际上还不能说是出错信息，而是泄漏了过多信息 9 伪代码编程过程 # 确认已满足所有先决条件了吗？ 定义好要解决的问题了吗？ 概要设计足够清晰，能为类及其每个子程序起一个好的名字吗？ 考虑过应该如何测试类及其每个子程序吗？ 主要是从可靠的接口和可读性好的实现，还是从满足资源和速度预算的效率考虑？一般是初期考虑可读性，后期专人负责优化和设计 在标准库或其他代码库中找过可用的子程序或组件了吗？ 在参考书中查找过有用的算法了吗？ 采用详细的伪代码去设计了每一个子程序吗？ 已经在心头检查过伪代码吗？这些伪代码容易理解吗？ 关注过那些可能会让自己重返设计的警告信息了吗？例如，关于全局变量的使用以及一些似乎更适合放在另一个类或子程序中的操作等？ 将伪代码准确转换成实际代码了吗？ 以递归方式运用编程过程，并根据需要将一些子程序拆分成更小的子程序了吗？ 在做出假设时对它们进行说明了吗？ 删除多余注释了吗？ 是否从几次迭代中选择了效果最好的，而不是在第一次迭代之后就停止尝试？ 是否完全理解了自己写的代码？它们是否容易理解？ 10 数据使用中的常规注意事项 # 初始化变量\n是否一个子程序都检查输入参数的合法性吗？ 每个子程序是否检查输入参数的有效性？ 代码是否在首次使用变量的地方声明变量？ 如果可能的话，代码是否在声明变量时对其进行初始化？ 如果不能同时声明和初始化变量，代码是否在靠近首次使用的地方初始化变量？ 是否正确初始化了计数器和累加器？如有必要，是否在每次使用时都重新初始化？ 在重复执行的代码中，变量的重新初始化是否正确？ 代码编译时，编译器是否发出警告？启用了所有可用的警告吗？ 如果所用的语言允许隐式声明，是否为由此引发的问题做好了补偿措施？ 使用数据的其他事项\n所有变量都有最小的作用域吗？ 对变量的引用都尽可能集中在一起吗？对同一变量的两次相邻引用以及变量的整个生命周期，是否都这样做了？ 控制结构是否与数据类型相对应？ 是否使用了所有已声明的变量？这种可以用编译器的设定来解决 变量都是在适当时同绑定的吗？也就是说，是否有意在后期绑定所带来的灵活性与增加的复杂度之间做出了平衡？ 每个变量是否都有且只有一个用途？ 每个变量的名称都很明确且没有隐含含义吗？ 11 变量命名 # 命名的常规注意事项\n名称是否完整且准确地描述了变量所代表的内容？举一个简单的例子，配置kubernetes comfigmap的对象，不应该叫做kubeconfig 名称是指现实世界的问题，而不是编程语言解决方案吗？ 名称是否长到没有必要去猜测它的含义？ 如果有计算值限定符，是否把它放在了命名的末尾？ 名称是否使用了Count或Index而不是Num？ 特定类型数据的命名\n循环索引的命名是否有意义（如循环超过一两行或是嵌套的，则不应是i、j或k）？ 所有“临时”变量是否被重新命名为更有意义的名字？ 当布尔变量的值为真时，变量名能准确表达其含义吗？ 枚举类型的名称是否包含一个表示其类别的前缀或后缀，比如用于Color Red、Color Green、Color Blue等？ 具名常量是以其所代表的抽象实体而不是所指代的数字来命名的吗？ 命名规范\n规范是否对局部数据、类数据和全局数据进行了区分？ 规范是否对类型名、只名常量、枚举类型和变量进行了区分？ 在不强制命名只读输入参数的情况下，是否明确标识了子程序中的只读参数？ 规范是否能够兼容于语言的标准规范？ 名称的格式是否便于阅读？ 短名称\n代码是否使用了长的名称（除非有必要用短的名称）？ 代码是否避免了使用只节省一个字符的缩写？ 所有单词的缩写是否一致？ 名称是否可读？ 是否避免了可能误读或发生错误的名称？ 短的名称是否记录在了缩写对照表中？ 常见的命名问题: 是否避免了使用\u0026hellip;\n\u0026hellip;是否避免了使用误导性的名称？ \u0026hellip;是否避免了使用含义相似的名称？ \u0026hellip;是否只有一两个字符不同的名称？ \u0026hellip;是否避免了使用发音相似的名称？ \u0026hellip;是否避免了使用包含数字的名称？ \u0026hellip;是否避免了故意拼错名称为了更短？ \u0026hellip;是否避免了英语中经常拼错的名称？ \u0026hellip;是否避免了与标准库子程序名或预定义变量名冲突的名称？ \u0026hellip;是否避免了过于随意的名称？ \u0026hellip;是否避免了包含容易混淆字符的名称？ 12 基本数据类型 # 一般的数字\n代码是否避免了魔法数字？ 代码是否考虑了除零错误？ 类型转换是否明显？ 是否按照期望进行计算？ 代码是否避免了混合类型的比较？ 程序编译时是否没有警告？ 整型\n使用整数除法的表达式是否按预期工作？ 整数表达式是否避免了整数溢出问题？ 浮点型\n代码是否避免对大小差别很大的数字进行加减运算？ 代码是否系统地防止了舍入错误？ 代码是否避免了对浮点数做等价比较？ 字符和字符串\n代码是否避免了魔法字符和魔法字符串？ 使用字符串时是否避免了差一错误？ C语言的代码是否区别对待了字符串指针和字符数组？ C语言的代码是否在适当的时候使用字符数组而不是指针？ 枚举类型\n程序是否使用枚举类型而非具名敞亮来提高可读性，可靠性和可修改性 使用枚举类型的判断是否能检测出无效值？ 枚举类型的第一个元素是否保留为“无效值”？ 具名常量\n程序是否将具名常量而非魔法数字用于数据声明和循环控制？ 具名常量的使用是否一致，是否避免在某些地方使用具名常量而在其他地方使用字面量？ 数组\n所有的数组索引是否都在数组的边界范围内？ 数组引用是否避免了差一错误？ 多维数组的所有索引顺序是否正确？ 在嵌套循环中，是否使用正确的变量作为数组索引，以避免循环索引混淆？ 创建类型\n程序是否为每一种可能变化的数据使用不同的类型？ 类型名称是否以类型所代表的现实世界实体为导向，而不是以编程语言类型为导向？ 类型名是否具有足够的描述性，可以帮助解释数据声明？ 是否避免了重新定义预定义类型？ 是否考虑过创建一个新的类而不是简单地重新定义一个类型？ 13 不常见数据类型的注意事项 # 结构体\n是否适当使用了结构体而不是单纯的变量来组织和保持相关的数据？ 是否考虑过使用类来替代结构体？ 全局数据\n除非绝对有必要，否则所有变量都应该具有局部作用域或类作用域。 变量命名规范是否区分了局部数据、类数据和全局数据？ 是否为所有全局变量提供了文档说明？ 代码中是否没有伪全局数据（pseudoglobal data），即不要包含将杂乱的数据传递给每个子程序的数据的巨大对象 是否使用了访问器子程序替代全局数据？ 访问器子程序和数据是否组织在类中？ 访问器子程序是否提供了一个在底层数据类型实现之上的抽象层？ 所有相关的访问器子程序是否处于同一抽象层？ 指针\n指针操作是否隔离在子程序中？ 指针引用是否有效？或者指针是否有可能成为野指针？ 在使用指针之前是否检查了其有效性？ 在使用指针引用的变量之前是否检查了其有效性？ 指针释放后是否被设置为空？ 为了提高可读性，代码是否使用了所有必需的指针变量？ 链表中的指针是否按照正确的顺序进行释放？ 程序是否分配了一块紧急备用内存，以便在内存耗尽时可以优雅地退出？ 是否在没有其他方法可用的情况下才使用指针？ 14 组织直线型代码 # 代码能明确语句之间的依赖关系吗？ 子程序的名称能明确表达依赖关系吗？ 子程序的参数能明确表达依赖关系吗？ 是否使用注释描述了不够明确的依赖关系？ 是否使用内部处理变量来验证关键代码中的顺序依赖关系？ 代码能够自上而下流畅地阅读吗？ 相关语句是否进行了分组？ 是否将相对独立的语句组转化为独立的子程序？ 15 使用条件语句 # if-then语句\n代码中的正常路径清晰吗？ if-then基于相等性测试的正确分支了吗？ else子句是否使用并添加了注释？ else子句用得正确吗？ 是否正确使用了if和else子句？它们有没有被用反了？ 正常情况是跟在if后面而非else后面吗？ if-then-else-if链\n复杂测试封装到布尔函数调用中了吗？ 最先测试的是最常见的情况吗？ 是否覆盖了所有情况？ if-then-else-if链是最佳实现方式吗？是否比case语句更好？ case语句\n所有case都按有意义的方式排列吗？ 每个case的动作都简单吗？必要时是否调用了其他子程序？ case语句判断的是一个真实变量，而非只为滥用case语句而虚构的变量吗？ default子句用得正当吗？ default子句是用来检测和报告出乎预料的情况吗？ 在C语言、C++语言或Java语言中，每个case的结尾处都有break吗？ 16 循环 # 循环的选择和创建\n是否在合适的时候采用while循环取代其他循环了吗？ 循环是由内向外创建的吗？ 进入循环\n是否从顶部进入循环？ 初始化代码是否直接放在循环前面了吗？ 如果是无限循环或事件循环，其结构是否清晰，而不是采用类似于\u0026quot;while True\u0026quot;这样简单的代码？ 如果循环属于C/C++或者Java的for循环，循环控制代码是否都放在循环头部了吗？ 循环内部\n是否使用括号或其等价形式来封闭循环体以免修改不当而出错？ 循环体里面有内容吗？它是非空的吗？ 内务处理代码是否集中存放在循环开始或者循环结束的位置了吗？ 循环是否就像定义良好的子程序那样只执行一种功能？ 循环是否短到足以让人一目了然？ 循环的嵌套层数控制在三层以内吗？ 长循环的内容是否转移到相应的子程序中了吗？ 如果循环很长，是不是特别清晰？ 循环索引\nFor循环体内的代码有没有随意改动循环索引值？ 是否专门用变量保存重要的循环索引值，而不是在循环体外部使用循环索引？ 循环索引是否是整数类型或者枚举类型，而不是浮点类型？ 循环索引的名称有意义吗？ 循环是否避免了索引串扰问题？ 退出循环\n循环是否在所有情况下可以终止 循环内是否使用安全计数器 循环的终止条件是否显而易见 17 不常见控制结构 # return\n每个子程序是否都只在必要的时候才使用return？ return 是否增强了可读性？ 递归\n递归子程序是否包含用于终止递归的代码？ 子程序是否使用安全计数器保证自己终止？ 递归是否只限于一个子程序（没有循环递归）？ 子程序递归深度是否在栈的大小限制范围内？ 递归是实现子程序最好的方式吗？比简单的迭代好？ goto\ngoto 是否只是用作最后的紧急手段，还是为了增强代码的可读性和可维护性？ 如果为了效率而使用goto，是否对效率的提升进行了度量和注释？ 每个子程序的goto 是否只限于使用一个标签？ 所有的goto 是否都是向前的而不是向后的？ 所有的goto 标签都用到了吗？ 18 表驱动法 # 是否考虑过将表驱动法作为复杂逻辑的替代方案？\n是否考虑过将表驱动法作为复杂继承结构的替代方案？\n是否考虑过将表数据存储在程序外部，并在运行期间读取，以实现在不修改代码的前提下进行修改？\n如果无法采用直接的数组索引来访问表（例如像age例子那样），是否考虑提取键的计算功能为一个单独的子程序，而不是在代码中复制这些计算？\n19 控制结构 # 大部分都是语言层面的错误\n20 质量保证计划 # 是否已经确定了对项目至关重要的具体质量特性？ 是否让其他人员了解项目的质量目标？ 是否区分了外部和内部质量特征？ 是否考虑了某些特性之间相互制约或促进的具体方式？最简单的考虑就是CAP了 是否要求针对不同错误类型使用不同的错误检测技术？ 质量保证计划中是否有步骤来保证软件在开发各阶段的质量？ 是否以某种方式度量质量，以便能够判断质量是在改进还是降低？ 管理层是否理解质量保证在前期会消耗额外成本，但目的是在项目后期降低成本？ 21 有效的结对编程 # 是否有编码规范，以便结对编程人员能够专注于编程，而不是编程风格的纠缠 结对双方是否都积极参与? 是否避免了对所有内容进行结对编程，而足选择真正能够受益于结对编程的任务? 是否定期对人员和工作任务进行轮换? 两人在速度和个性方面是否匹配良好? 是否有组长担任联络人来负责与项目外部管理层和其他人员沟通? 22 有效的审查 # 是否有清单可以使审查人的注意力集中于过去有问题的领域？ 是否将审查侧重于找出缺陷，而不是去修正它们？ 是否考虑过为审查人分配特定的视角或场景，以帮助他们在做准备工作时加强专注？ 审查人在审查会议前是否有充足的时间进行准备，并且每个人都做好了准备？ 每个参与者是否都扮演了明确的角色：主持人、审查人和记录员等？ 会议是否以高效的速度进行？ 会议时间是否限制在两小时以内？ 所有审查参与者是否都接受过有针对性的审查培训，以及主持人是否接受过专门的主持技能培训？ 每次审查时是否收集有关错误类型的数据，以便为组织量身定制未来的改进清单？ 是否收集了有关准备速度和审查速度的数据，以便优化未来的准备和审查工作？ 每次审查是否分配了行动项，由主持人亲自跟进或者安排一次重新审查进行跟进？ 管理层是否理解自己不应该参加审查会议？ 是否有跟进计划以确保问题已经得到正确修复？ 23 测试用例 # 是否用手头所有的测试用例保证了每个部分有足够的测试覆盖吗？包括函数覆盖率，runtime覆盖率和需求满足情况 类和子函数的设计中每个元素都有各自所对应的测试用例吗？ 每行代码至少用一个测试用例进行了测试吗？ 是否考虑了计算测试每行代码所需的最小测试用例数量来进行验证？ 是否用至少一个测试用例对每条“已定义-已使用”的数据流路径进行了测试？ 是否检查了代码中不太可能正确的数据流模式，例如\u0026quot;已定义-已定义\u0026quot;和\u0026quot;已定义-未撤销\u0026quot;？ 在编写测试用例时是否参考了一个常见错误的列表来检测过去经常出现的错误？ 是否测试了所有的简单边界条件：最大值、最小值和差一边界？ 是否测试了所有的复合边界条件，即多个输入数据的组合可能导致计算得出的变量过小或过大？ 测试用例是否检查了错误的数据类型，例如，薪资管理程序中将员工数量设为负数？ 是否测试了有代表性的、普遍性的取值？ 是否测试了最小正常配置？ 是否测试了最大正常配置？ 是否对旧数据进行了兼容性测试？是否针对旧的硬件、旧版本的操作系统以及与旧版本的其他软件的接口进行了测试？ 该测试用例是否易于进行手工查看？ 24 调试要点 # 发现缺陷的技术 使用所有可用的数据来创建假设 精炼产生错误的测试用例 在单元测试套件中运行代码 使用可用的工具 使用不同的方法重现错误 生成更多的数据以产生更多的假设 利用负面测试的结果 头脑风暴找出可能的假设 在桌子旁边放一个记事本，把要尝试的事情都列出来 缩小可疑的代码区域 以前有缺陷的类和子程序值得怀疑 检查最近修改的代码 扩大可疑的代码区域 逐步集成 检查常见的缺陷 向某人讲述发现的问题 把问题放一放，先休息一下 为快而糙的调试设置最大时间 整理一个暴力技术的清单，并且使用它们 语法错误的技术 不要相信编译器消息中的行号 不要相信编译器消息 不要相信编译器的第二条消息 分而治之 使用语法制导编辑器发现错误的注释和引号 修复缺陷的技术 在复现前先理解问题 理解程序，而不仅仅是问题 确认缺陷诊断结论 放松 保存原始代码 修复问题，而不是症状 仅在有充分理由的情况下修改代码 一次只做一处修改 检查修复的程序 添加一个暴露缺陷的单元测试 寻找类似的缺陷 常用的调试方法 你是否将调试作为了解程序、错误、代码质量和解决问题方法的机会？ 你是否避免了试错、迷信的调试方法？ 你是否假设错误是你犯错导致的？ 你是否使用科学的方法来复现间歇性错误？ 你是否使用科学的方法来发现缺陷？ 你不是每都使用相同的方法，而是使用几种不同的技术来发现缺陷吗？ 你是否验证了修复的正确性？ 你是否使用了编译器告警消息 25 重构的理由 # 代码发生重复 子程序太长 循环太长或嵌套太深 类的内聚力很差 类的接口不能提供一致的抽象层级 参数表有太多参数 在类中进行的修改各自独立 需要平行修改多个类 需要平行修改继承层级结构 需要平行修改 case 语句 一起使用的相关数据项没有被组织成类 一个子程序使用了另一个类(而非它自己的类)更多的特性 无脑使用基本数据类型 类的作用不大 子程序间传递流浪数据 一个中间对象没有做任何事情 一个类与另一个类过于亲密 某个子程序的名字太差劲 公共数据成员 一个子类只使用了其父类的一小部分功能 用注释解释难以理解的代码 全局变量的使用 程序包舍的代码似乎有一天会被需要 26 重构总结 # 数据级重构 用具名常量替换神秘数字。 用更清晰或更有信息量的名字重命名变量 使表达式内联。 用子程序替代表达式 引入中间变量。 将一个多用途的变量转换为多个单用途的变量， 局部用途的就用局部变量，而不要用参数 将数据基元转换为类 将一组类型代码转换为类或枚举， 将一组类型代码转换为带有子类的类， 将数组改为对象、 封装集合 用数据类替代传统记录 语句级重构 分解布尔表达式. 将复杂布尔表达式移入一个命名良好的布尔函数。 合并条件语句不同部分的重复片段 使用 break 或 return 替代循环控制变量 知道答案后立即返回，而不是在嵌套 if-then-else 语句中赋一个返回值。 用多态替代条件语句(尤其是重复的 case 语句)。 创建和使用空对象，而不是测试空值 子程序级重构 提取子程序 内联子程序的代码、将长的子程序转快为短动词短语 用简单算法代替复杂算法。 增加参数、 删除参数 将查询操作与修改操作分开 通过参数化合并类似的子程序 分解行为依赖于传入参数的子程序 传递整个对象而不是特定的字段。 传递特定的字段而不是整个对象。 封装向下转型 (downcasting)。 类实现重构 将值对象修改为引用对象 将引用对象修改为值对象 用数据初始化替代虚函数、 改变成员函数或数据的位置. 将特化代码提取到一个子类中 将相似代码合并到超类中， 类接口重构 移动方法到一个提供者。 将一个类转换为两个。 抽取类。 委托 去掉中间人。 用委托代替继承。 用继承代替委托。 引入外来的子程序 引入扩展类。 封装公开变量 系统级重构 为无法控制的数据创建一个明确的引用源 将单向累关联为双向类关联 提供工厂方法而不是简单构造函数 用异常代替错误代码或者相反 27 安全重构 # 每次改动都是一个语言改动策略的一部分吗? 重构前是否保存了最初的代码？ 是否保持每次重构的幅度都很小？ 是否一次只进行一个重构？ 是否列出了在重构过程中打算采取的步骤？ 是否做了一个停车场，以便记住重构中途产生的想法？ 每次重构后都重新测试了吗？ 若改动很复杂，或者会影响关键任务，是否进行了代码审查？ 是否考虑过特定重构的风险等级并相应地调整了你的方法？ 这个修改是否改善而非降低了程序的内部质量？ 是否避免了用重构作为编码和修复的幌子，或者作为不重写坏代码的借口? 28 代码调优策略 # 程序整体性能\n考虑通过变更程序需求来提升性能了吗？ 考虑通过修改程序设计来提升性能了吗？ 考虑通过修改类的设计来提升性能了吗？ 考虑通过避免程序与操作系统的交互来提升性能了吗？ 考虑通过避免IO操作创建来提升性能了吗？ 考虑用编译型语言替代解释型语言来提升性能了吗？ 考虑启用编译器优化选项来提升性能了吗？ 考虑通过切换到不同的硬件设备来提升性能了吗？ 代码调优是不是万不得已的最后选择？ 代码调优方法\n在开始代码调优之前，程序是完全正确的吗？ 在代码调优之前，度量过性能瓶颈了吗？ 度量过每一次代码调优的效果了吗？ 如果代码调优并没有带来预期的性能提升，是否已撤销所有的改动？ 是否尝试过针对每一个性能瓶颈进行多次修改以提升性能？ 是否对性能瓶颈进行过优化？性能优化通常需要多次迭代才能通过代码调优达到预期的性能提升。 性能只是整体软件质量的一个方面，而且通常并不是最重要的。精心调优的代码只是整体性能的一个方面，而且往往不是最关键的。相比于代码的效率，程序的架构设计、组件之间的协作关系以及算法的选择和优化等都有更大的影响。构建性能优秀的代码只是整体性能优化的一小部分：除非系统自身的瓶颈得到解决，否则优化的效果会很有限。 需要关注的是整体系统的细节设计以及各个模块之间的协调与规划，这些对于整体性能的提升具有重大的影响。 确定瓶颈的定位是实现性能优化的关键。百足城出能真正提供高性能的指引方向的重要手段。 在开始编码时，为性能工作做好准备是编写易于理解和修改的清晰的代码的关键。 除非系统自身的瓶颈，否则知道是哪些代码在占据时间或者系统的复杂度吗？ 29 代码调优技术 # 同时改进速度和规模 用查询表替代复杂逻辑。 合并循环 用整数而不是浮点变量 编译时初始化数据。 使用正确类型的常量。 预计算出结果。 消除公共子表达式 将关键子程序转化为低级语言 只改进速度 知道结果后，便停止测试: 按频率对 case 语句和 if-then-else 链中的测试进行排序， 比较相似逻辑结构的性能 使用惰性求值。 将循环中的条件判断提到外面 展开循环。 最小化循环内部的工作 在搜索循环中使用哨兵值 最忙的循环放到嵌套循环的内层 降低内层循环的运算强度 多维数组改为一维。 最小化数组引用。 为数据类型增加辅助索引。 缓存频繁使用的值， 利用代数恒等式。 降低逻辑和数学表达式的运算强度 小心系统子程序。 重写子程序以内联 30 配置管理 # 概要 软件配置管理计划是设计用来帮助程序员将开销尽量减小的吗? 软件配置管理 (SCM) 避免了对项目的过度控制吗? 变更请求是进行了分阶段，当作一个整体处理的吗？无论采用非正式的方法(例如创建一份传统的变更清单)还是更系统化的方法(例如设立变更控制委员会)。 系统化地评估了提交的每一项变更请求对于成本、进度和质量的影响了吗? 将重大的变更视为需求分析不够完善的一个警示了吗? 工具 采用版本控制软件来帮助配置管理了吗？ 采用版本控制软件减少团队工作中的协作问题了吗? 备份 定期备份所有项目资料了吗？ 定期将项目备份数据转移到异地存储了吗？ 所有资料(包括源代码、文档、图片和重要的笔记)都备份了吗？ 测试过备份与还原过程吗？ 31 集成 # 集成策略 是否为集成子系统、类和程序确定了最优顺序? 继承顺序是否和构建顺序相互协作，保证在正确的时间每个类都将会为集成就绪？ 准备就绪？ 这种集成策略是否能让缺陷的诊断变得容易? 这种集成策略是否能让脚手架代码数量降到最低？ 这种集成策略是否比其他方法更好？ 组件之间的接口是否已经被详细定义了吗?虽然定义接口并不属于集成的任务，但是验证它们是否已经被良好定义是集成的任务) 每日构建和冒烟测试 顶目是否频繁地构建(理想的情况是每天构建)以支持增量式集成? 是否随着每个构建都执行了冒烟测试以确定每个构建是运行正常的? 构建和冒烟测试实现了自动化吗? 开发人员频繁提交代码是否频繁，即两次代码提交之间不会超过一天或两天? 冒烟测试是否随时与最新的代码保持一致，随着代码的更新而演变? 构建失败是偶发事件吗? 即使在承受压力的情况下是否坚持构建和执行冒烟测试验证软件? 32 编程工具 # 是否有一个高效的 IDE? IDE 是否集成了源代码控制工具(构建、测试和调试工具)及其他有用的功能? 是否有自动化常用重构操作的工具？ 是否使用版本控制工具来管理源代码、文档、需求、设计、项目计划和其他项目工件？ 如果在做一个超大型项目，是否有使用数据字典或者包含每个类的权威说明的中央知识库？ 是否考虑过使用代码库而不是编写定制代码？哪里有可用的代码库？ 是否在使用交互式调试器？ 是否使用 make 或其他依赖关系控制软件来高效可靠地构建程序？ 测试环境是否包含自动化测试框架、自动化测试生成器、覆盖率监控、系统扰动器、差异对比工具和缺陷跟踪软件? 是否有构建任何定制的工具以支持特定的项目需求，特别是自动化重复执行的任务的工具？ 总的来说，目前的环境是否有足够的支持工具？ 33 布局 # 通用 是否正确地凸现了代码逻辑结构的首要任务？ 这种代码格式是否可以在使用中保持前后一致？ 这种代码格式是否能产生易于维护的代码？ 这种代码格式是否能提高代码的可读性？ 控制结构 在代码中是否使用开始-结束或者 {} 避免了双重缩进？ 连续的多个程序块是否用空行进行了分隔？ 是否调整了复杂表达式的格式以保证可读性？ 所有的单条语句块是否格式一致？ case 语句的布局方式是否与其他控制结构保持一致？ goto 语句的格式是否使其在视觉上更明显？ 单条语句 是否使用空白来改善逻辑表达式、数组引用和子程序参数的可读性？ 是否确保不完整的语句在行断开的地方有明显的语法错误？ 换行时是否采用了标准的缩进量？ 一行最多只包含一条语句？ 编写每条语句时是否确保不包含副作用？ 一行最多只包含一条数据声明？ 注释 注释是否与其对应的代码缩进量相同？ 注释的布局风格是否易于维护？ 子程序 是否使用空行来分隔子程序中的不同部分，如类、文件和程序？ 对于大多数类和文件，是否存在一一对应的关系？ 类，文件和程序 如果一个文件包含多个类，是否已经清楚地将每个类中的所有子程序分隔开？ 文件中的子程序是否以空行明显地进行了分隔？ 作为更强大的组织原则的妥协代替方法，是否按字母顺序排列了所有子程序？ 34 自文档代码 # 类\n类的接口是否体现了某种一致的抽象？ 类是否取好了名称，名称能否准确描述其核心意图？ 类的接口是否让你一目了然地知道如何使用这个类？ 类的接口抽象是否足以让你无需考虑其实现方式？可以当成黑盒对待吗？ 子程序\n是否每个子程序的名称都能准确描述它们的功能？ 是否每个子程序都只执行一个明确定义的任务？ 相比这些子程序被放入各自的子程序之前和之后，它们有受益吗？ 每个子程序的接口是否清晰明确？ 数据名称\n类型名称是否足以协助记录数据声明？ 变量是否命名良好？ 变量是否只用于其命名所示的用途？ 循环计数器是否使用了比 i、j、k 更具信息量的名称命名？ 是否使用了精心命名的枚举类型，而非临时标识布尔变量？ 是否使用了具名常量而非魔法数字或魔法字符串？ 是否能区分类型名称、枚举名称、物理尺寸、具名敞亮、局部变量、类变量和全局部变量？ 数据组织\n额外变量是否根据需要用于澄清？ 变量的引用是否彼此接近？ 数据类型是否简单达到最低复杂度？ 复杂数据是否是通过抽象访问子程序（抽象数据类型）来访问 控制\n代码中的常规路径是否清晰？ 相关语句是否组合在一起？ 相对独立的语句组是否打包成各自的子程序？ 常见路径是放在 if 语句的后面还是 else 语句的后面？ 控制结构是否足够简单，达到最低复杂度？ 是否每个循环和定义良好的子程序一样，执行一个且只执行一个功能？ 嵌套有否做到最少？ 是否使用新增的布尔变量、布尔函数和决策表来简化布尔表达式？ 布局\n程序的布局是否能表现其逻辑结构？ 设计\n代码是否明确直接且没有自作聪明？ 是否尽可能隐藏了实现细节？ 写程序时，是否尽可能多地使用问题域的术语，而非计算机科学或程序语言结构的术语？ 35 好的注释 # 通用 别人拿到你的代码马上就能看懂吗？ 注释是在解释代码意图或者总结代码做了什么，还是在复述代码？ 是否采用伪代码编程法来减少注释的耗时？ 对于重要的代码，是进行重写还是注释？ 注释是最新的吗？ 注释是否清晰、准确？ 所用注释风格是否有利于修改注释？ 语句和段落 是否避免在代码中使用行尾注释？ 注释着重解释原因还是解释具体操作步骤？ 注释是否有利于代码阅读者做好准备？ 是否每条注释都有其用处？是否已删除或改进了多余的、无关紧要或过于随意的注释？ 是否注释了代码的非常规之处？ 是否避免使用缩略语？ 主次注释的区别是否明显？ 是否注释了用于处理某个缺陷或未公开特性的代码？ 数据声明 是否已注释数据声明的数值单位？ 是否已注释数值数据的取值范围？ 是否已注释编码用途？ 是否已注释输入数据的限制？ 是否已注释位标志？ 是否已在声明处注释各全局变量？ 魔数是否已经替换为具名变量或者常量，而不是加注释 控制结构 是否对所有控制语句都进行了注释？ 冗长或者复杂的控制结构，是否在代码结尾处进行了注释？或者竭力进行简化，而不再需要注释？ 子程序 是否已注释各子程序的意图？ 是否通过注释介绍了子程序的其他相关情况（如输入输出数据、接口假设、限制、纠错、全局效果和算法出处等）？ 文件、类和程序 程序是否有一段简短的文档，就像书籍范本中介绍的那样，可以提供对程序组织方式的概览？ 是否已说明各文件的意图？ 结尾 # 唉，尴尬\n","date":"2023 年 6 月 11 日","externalUrl":null,"permalink":"/posts/2023-06-11-%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E5%85%BB/","section":"Posts","summary":"","title":"2023-06-11-程序员修养","type":"posts"},{"content":" devsecops实践 # 1 SAST实践 # 1.1.1 SAST PARTS # 目前问题总结\n目前CI的Clang-Tidy Check开启的Checker不充足，需要扫描代码库检查存在哪些代码问题，从而判断开启哪些Checker。 Clang-Tidy Check只针对用户编辑的文件进行扫描，用户不编辑的文件无法发现问题。 使用场景：\n每天定时触发一次对onboard \u0026amp; offboard下以gpu模式编译的cc_library，cc_binary对象的SAST扫描，检查结果上传至coverage.qcraftai.com/sast下，经由TPM同学进行分诊，并创建Issue到具体协同者。\n从用户角度来看，最终只会看到一个codecheck_report文件，包含各个代码文件（可能）存在的问题，报告末尾汇总各种Checker的错误报告数量，和对应文件的错误数量，参考\nFound no defects in parse_pos_to_traj.cc [HIGH] /home/qcrafter/.cache/bazel/_bazel_qcrafter/4207c8486d34138987115c0107ecb5f8/execroot/com_qcraft/onboard/planner/assist/lcc_map_builder.cc:148:7: 2nd function call argument is an uninitialized value [core.CallAndMessage] mapping::LanePathData(lane_path.start_fraction(), end_fraction, ^ Found 1 defect(s) in lcc_map_builder.cc ----==== Severity Statistics ====---- ---------------------------- Severity | Number of reports ---------------------------- HIGH | 882 MEDIUM | 13814 LOW | 1973 STYLE | 20 ---------------------------- ----=================---- ----==== Checker Statistics ====---- --------------------------------------------------------------------------------------- Checker name | Severity | Number of reports --------------------------------------------------------------------------------------- core.CallAndMessage | HIGH | 136 security.FloatLoopCounter | MEDIUM | 214 cppcoreguidelines-special-member-functions | LOW | 1264 ... ----==== File Statistics ====---- ------------------------------------------------------------------------- File name | Number of reports ------------------------------------------------------------------------- lcc_map_builder.cc | 2 ground_line.cc | 12 目前开启的Checker包括\n--------------------------------------------------------------------- Checker name | Severity | --------------------------------------------------------------------- core.CallAndMessage | HIGH | security.FloatLoopCounter | MEDIUM | cppcoreguidelines-special-member-functions | LOW | clang-diagnostic-sign-compare | MEDIUM | clang-diagnostic-unused-parameter | MEDIUM | bugprone-sizeof-container | HIGH | bugprone-undefined-memory-manipulation | MEDIUM | optin.cplusplus.UninitializedObject | MEDIUM | cert-dcl58-cpp | HIGH | clang-diagnostic-deprecated-copy-with-user-provided-copy | MEDIUM | performance-noexcept-move-constructor | MEDIUM | clang-diagnostic-deprecated-declarations | MEDIUM | readability-suspicious-call-argument | LOW | performance-move-const-arg | MEDIUM | misc-definitions-in-headers | MEDIUM | optin.cplusplus.VirtualCall | MEDIUM | deadcode.DeadStores | LOW | bugprone-forwarding-reference-overload | LOW | core.NullDereference | HIGH | bugprone-use-after-move | HIGH | misc-unconventional-assign-operator | MEDIUM | clang-diagnostic-missing-field-initializers | MEDIUM | google-global-names-in-headers | STYLE | performance-no-automatic-move | LOW | cert-dcl59-cpp | MEDIUM | google-build-namespaces | MEDIUM | bugprone-integer-division | MEDIUM | core.UndefinedBinaryOperatorResult | HIGH | bugprone-unused-return-value | MEDIUM | misc-redundant-expression | MEDIUM | bugprone-unhandled-exception-at-new | MEDIUM | core.uninitialized.Assign | HIGH | bugprone-misplaced-widening-cast | HIGH | bugprone-virtual-near-miss | MEDIUM | core.NonNullParamChecker | HIGH | bugprone-incorrect-roundings | HIGH | misc-misplaced-const | LOW | unix.Malloc | MEDIUM | cplusplus.NewDeleteLeaks | HIGH | bugprone-suspicious-missing-comma | HIGH | bugprone-lambda-function-name | LOW | core.uninitialized.UndefReturn | HIGH | optin.portability.UnixAPI | MEDIUM | bugprone-signed-char-misuse | MEDIUM | core.DivideZero | HIGH | core.StackAddressEscape | HIGH | bugprone-swapped-arguments | HIGH | bugprone-forward-declaration-namespace | LOW | cert-err09-cpp | HIGH | unix.API | MEDIUM | bugprone-not-null-terminated-result | MEDIUM | cplusplus.NewDelete | HIGH | bugprone-fold-init-type | HIGH | bugprone-sizeof-expression | HIGH | cplusplus.Move | HIGH | bugprone-inaccurate-erase | HIGH | bugprone-string-constructor | HIGH | clang-diagnostic-unused-result | MEDIUM | clang-diagnostic-#pragma-messages | MEDIUM | bugprone-signal-handler | MEDIUM | bugprone-too-small-loop-variable | MEDIUM | misc-uniqueptr-reset-release | MEDIUM | --------------------------------------------------------------------- 发现问题：\n内存泄露，空指针调用，move后调用\n附加SAST软件分析\nSAST的软件有很多，比方说sonarqube，codechecker.针对C++我使用的是codechecker\nsonarqube codechecker codechecker流程，如何安装？直接使用pip3 install codechecker即可，最终工程治理组将codechecker装进了docker里面，就不需要指定目录了，直接可以调用CodeChecker\nCodeChecker log runs the given build command and records the executed compilation steps. These steps are written to an output file (Compilation Database) in a JSON format。这个实践起来并不是一个好的方法，因为本身在本地做编译就比较荒谬。实际上使用https://github.com/grailbio/bazel-compilation-database/可以方便的生成compile database，不需要再用codechecker本身的注入式log\n#这种做法不推荐 /home/qcraft/.local/bin/CodeChecker log -o ./sim_server_compile_commands.json -b \u0026#34;bazel --batch \\ build \\ --spawn_strategy=local \\ --strategy=Genrule=local \\ --copt=-DLEVELDB_PLATFORM_POSIX \\ --action_env=LD_PRELOAD=\\$LD_PRELOAD \\ --action_env=LD_LIBRARY_PATH=\\$LD_LIBRARY_PATH \\ --action_env=CC_LOGGER_GCC_LIKE=\\$CC_LOGGER_GCC_LIKE \\ --action_env=CC_LOGGER_FILE=\\$CC_LOGGER_FILE \\ //offboard/dashboard:sim_server\u0026#34; #这种做法推荐 ( cd \u0026#34;${INSTALL_DIR}\u0026#34; \\ \u0026amp;\u0026amp; curl -L \u0026#34;https://github.com/grailbio/bazel-compilation-database/archive/${VERSION}.tar.gz\u0026#34; | tar -xz \\ \u0026amp;\u0026amp; ln -f -s \u0026#34;${INSTALL_DIR}/bazel-compilation-database-${VERSION}/generate.py\u0026#34; bazel-compdb ) # This will generate compile_commands.json in your workspace root. # ./bazel-compdb # Only generate some folder ./bazel-compdb -q //offboard/simulation/simulator/... CodeChecker analyze uses the previously created JSON Compilation Database to perform an analysis on the project, outputting analysis results in a machine-readable (plist) format。这里的skip file能帮忙过滤掉proto文件，只分析我们感兴趣的文件\n#skip file -*/proto/* +*/offboard/* +*/onboard/* -* /home/qcraft/.local/bin/CodeChecker analyze ./sim_server_compile_commands.json -o codechecker_report 1.1.2 如何避免误报 # 以CodeChecker为例，说一下怎么避免误报\n终极方法，忽略或者屏蔽，analyzor支持skip文件级别。即\n直接在文件层面skip掉这些报错的文件，这种粒度比较大，可能会有导致其它问题被隐蔽，参考https://codechecker.readthedocs.io/en/latest/analyzer/user_guide/#skip 使用codechecker支持的注释或者comment内容来避免false positive误报，参考https://codechecker.readthedocs.io/en/latest/analyzer/user_guide/#source-code-comments 在web interface能够配置，某些是false positive的。不过这个是网络层面，还没做 代码层面避免，语言层面的保障应该是高于逻辑层面的。也就是说如果用户说逻辑层面能保证这种行为，这个就不能算作是false positive\n使用const等手段，来避免编译器认为出现对应的问题\n使用好理解的代码比方说，下面的情况保证了在宏__clang_analyzer__生效的情况下，static analysis会正确地找到对应的代码，从而不会出现错误的理解。这个宏的作用实际上并不止这些还\nFor example the following code:\nunsigned f(unsigned x) { return (x \u0026gt;\u0026gt; 1) \u0026amp; 1; } Could be rewritten as:\n#ifndef __clang_analyzer__ unsigned f(unsigned x) { return (x \u0026gt;\u0026gt; 1) \u0026amp; 1; } #else unsigned f(unsigned x) { return (x / 2) % 2; } #endif 防御式编程，这个和语言就强相关了，简单的例子\nClang-Tidy has lots of useful syntax based checks. Some of these checks find bug-prone code snippets. When these snippets are intentional, usually there is a natural way to make the intent more explicit. Unfortunately, it is hard to give a general guideline, because the details are different for each check. The documentation of the check might contain hints how to express intention more clearly. Let us look at an example:\ndouble f(int i) { return 32 / (2 + i); // Warning, integer division, loss of precision. } It can be rewritten to as the following to suppress the warning:\ndouble f(int i) { return (int)(32 / (2 + i)); // No warning, the intention is explicit. } The second version makes it clear even though the return value is a floating point value the loss of precision during integer division is intentional. Adding a comment why this is intentional would make this even clearer. Such edits makes the code easier to understand for fellow developers.\n逻辑层面，确实不可执行到的路径\n对函数/部分代码添加正确的annotations，比方说C++ 11 的noreturn，https://en.cppreference.com/w/cpp/language/attributes\nanalyzor支持assert检查，编译debug对象的时候这些assert能够有效的避免出现相应的flase positive报错，编译器会检查到assert必然满足了某些条件，从而不会出现对应的问题。参考https://clang-analyzer.llvm.org/annotations.html#custom_assertions\n也是用assert代码来保证一定不会出错，认为走入了错误的path会导致报错\nint f(MyEnum Val) { int x = 0; switch (Val) { case MyEnumA: x = 1; break; case MyEnumB: x = 5; break; } return 5/x; // Division by zero when Val == MyEnumC. } It can be rewritten to as the following to suppress the warning:\nint f(MyEnum Val) { int x = 0; switch (Val) { case MyEnumA: x = 1; break; case MyEnumB: x = 5; break; default: assert(false); break; } return 5/x; // No warning. } Other macros or builtins expressing unreachable code may be used. Note that the rewritten code is also safer, since debug builds now check for more precondition violations.\nIn case of C++11 or later, another option is to use Immediately-Invoked Function Expression (IIFE) to avoid assigning a meaningless value.\nint f(MyEnum Val) { const int x = [\u0026amp;] { // Note the lambda. switch (Val) { case MyEnumA: return 1; case MyEnumB: return 5; default: assert(false); return 0; } } (); return 5/x; // No warning. } 2 代码审计 # 2.1 SQL部分 # 针对SQL的代码审计一般发生在有对数据库提交的部分，这里针对最常用的GORM做审计：GORM对结构体、map结构的value在框架底层都进行了预编译，所以使用此类方式进行CRUD操作时是十分安全的，初次之外存在如下问题\nGORM对map的value进行了预编译，但却没对key进行预编译，因此如果是key是可以用户指定的，那么就可能存在注入点。我们的代码没有这个问题 GORM对表结构的查询使用了预编译，最常见的例子是用？表示数据，比方说db.Where(\u0026quot;name = ?\u0026quot;, name)，但是如果没使用默认的预编译比方说如果是db.Where(\u0026quot;name = '\u0026quot; + name + \u0026quot;'\u0026quot;)这种，那么就会有注入风险。 raw sql执行，db.Raw(sql)，只要用户能控制sql的内容就存在注入。发现了这个问题 exec sql执行，和上面的raw sql执行一样， db.order，采用预编译执行SQL语句传入的参数不能作为SQL语句的一部分，那么OrderBy所代表的的列名、或者是后面跟随的ASC/DESC也无法进行预编译处理。 2.2 XSS审计 # 结尾 # 唉，尴尬\n","date":"2023 年 3 月 28 日","externalUrl":null,"permalink":"/posts/2023-03-28-devsecops%E5%AE%9E%E8%B7%B5/","section":"Posts","summary":"","title":"2023-03-28-devsecops实践","type":"posts"},{"content":" 架构之路 # 经历\n华耀面临的难题是非常具体的技术问题，面向协议，语言层面。需要对tls，密码学基础知识，计算机体系结构比较熟悉。一个难题的例子是移植ZX5580CPU遇到的汇编无符号证书除法稳定出错的问题，表现形式为证书生成失败，难度在于从私钥/公钥计算，证书签发中等一系列流程怎么精确找到出错的地点，毕竟出错的地方是一个特定条件才会触发的div汇编除法错误。\n华耀的遇到的最难的事情还是底层问题排查，包括定位一个CPU层面的汇编指令的错误\n技术实现 标记用户可用的行为，规定哪些行为是安全的，哪些行为是不安全的，并且将各种行为记录日志。这种行为是不能过于破坏安全特性的。 从实现者的角度，保证安全准则/逻辑没有漏洞，不会泄露客户的敏感信息。实际上我们自己规定了一些准则，按照这些准则执行开发。 从产品的角度，来提供一个完整系统，保证端到端加密，它的逻辑/设计理念必须是连续的。（比方说我们对0-RTT的争吵） 针对单独产品，怎么实现稳定性和可靠性的考虑 硬件方面 磁盘RAID，双路电源。 软件层面 针对错误的输入，比方说一些奇特的mbuf数据包（网络数据包）会对数据的格式做校验（我们系统出过几次coredump）。此外会限制ICMP PING RESPONSE的数量为200/s 针对失控程序占用一些CPU资源，内存，磁盘，网络空间和网络的问题，我们的进程在每个核上每隔一段时间就回去喂狗，软的watchdog。如果一定时间watchdog没有喂到，就会出发NMI，从而系统PANIC进而重启。 针对系统依赖的服务变慢，实际上不单纯是依赖的服务，对ATCP而言，还包括后面的服务。我们会有一个其他的进程定期去检查后面服务的状态，如果采用最短有效，那么就回去访问当前最高可用的机器。除此之外还有特定的健康检查进程去更新后台RS的状态，如果后台RS无效，那么我们会直接拒绝让rs的连接走这个服务，提供可靠性。 会有一个守护进程去检查进程的活跃状态，如果某个工作进程挂掉了，那么会被守护进程拉起来。 针对异常问题，我们统一了错误码，整体都是RST报文里面的WIN字段 针对安全1，无论是客户端证书还是后面的rs（尤其是双向，）复用的时候我们会比较客户端TICKET IDENTITY LIFETIME和我们的TICKET IDENTITY LIFETIME的差别，如果过大我们就拒绝复用（复用不需要证书），让它走完整握手。 针对安全2，TLS1.3下，我们拒绝0-RTT的时候会检查收到的错误的0-RTT报文数量，太多的话就直接拒绝连接。 针对安全3，对于证书链的校验执行最严格的审查，任何证书链必须里面的一环必须可验证/有效/，而且不能是全局的ROOT CA（为了可靠，我们和MOZILLA ROOT CA开源的保持一致），必须是针对per vhost导入的CA，从而执行最严格校验。 针对安全4，OCSP/CRL证书的校验，正常情况下如果OCSP服务器连接不上，没办法验证证书有效无效的时候都是允许证书通过验证的。我们采用了最严格校验，如果没连上直接拒绝。 美团面对的问题一部分集中在语言层面，另一部分集中在是内部C/C++基础组件混乱情况下的工程适配。比方说不同组GCC版本不同，有4.8或者5.6，高版本用我们低版本编出来的包稳定crash，因为一些数据结构变了，所以数据结构的锁位置变了，但是代码还是老的地方改变触发异常\n职业规划实现：实现功能的时候，能够筛选产品，评估缺陷和不足（针对特定技术）。也就是说一方面提出技术的评估，另一方面提出结果的评估。这个是对业界的理解。 轻舟面对的问题就从具体语言层面，变为结构设计，组件的划分，还有一些是分布式系统性通用问题。难题是复杂环境下问题排查和功能取舍，举个功能取舍简单的例子，仿真测试是轻舟CI最后一环，它使用cpfscache对象存储自动热更新，但更新线程有限，遇到大量数据要更新，那么读需要等待写，然后大量的读又会拖崩cpfs（因为每个节点是无法感知到对整个系统的线程超量引用，超时就新建不断重试），无法挂载。功能取舍就是舍弃掉对全部数据热更新，只维护热点数据，更新采用定期手动更新的方式。另一个比方说 轻舟从微型公司到小中型还有很多问题，比方说快速重试，编译服务用户限流\n轻舟最难的问题实际上是当一个系统规模庞大到将处理复杂问题的能力内置其中（从高并发到匪夷所思的业务场景都被内嵌），程序员需要的不再是具体的一两个深入的能力点，而是如何排查定位复杂系统的问题，以及做问题排查，做设计时如何做决策。\n这个感慨实际上有点类似https://www.v2ex.com/t/1055455\n除了上面的CPFSCACHE这个，还有一个类似的例子就是轻舟仿真从aws迁移到阿里云，出现了一系列的故障，怎么利用手头的工具认识系统，怎么去定位具体的问题点。\n技术实现 分布式的快速失败，快速重试具体实践，限流，功能取舍 职业规划实现 针对一个研发的体系，（实际上是抄的）能够制定一套安全的开发准则，够制定一套安全的设计准则，能够制定一套安全的审计准则 给出足够简单并且有效（逻辑可推理）的解决方案。比方说安全，在有KMS的参与下做授权，直接就是授权关键密钥 理想\n攻击检测样本怎么搭建？请求包含哪些信息？ 0 架构的基本思路 # 做事做人的原则\n拥抱现实，应对现实 真相（或者更精确地说，对现实的准确理解）是任何良好结果的根本依据，要做到头脑极度开放、极度透明，不要担心其他人的看法，使之成为你的障碍 观察自然，学习现实规律，不要固守你对事物“应该”是什么样的看法，这将使你无法了解真实的情况，一个东西要“好”，就必须符合现实的规律，并促进整体的进化，这能带来最大的回报。 在你不擅长的领域请教擅长的其他人，依赖“全部证据”，这是一个你无论如何都应该培养的出色技能，这将帮助你建立起安全护栏，避免自己做错事。 做到头脑极度开放，谨记，你是在寻找最好的答案，而不是你自己能得出的最好答案。 一个系统有要素，关联和功能三个东西构成。因此，系统具备层次性，自组织和适应性（弹性），因此要努力培养系统的弹性 做事的方法和原则\n原则，要清楚，单一因素直接引起后果是程序员的线性，或者说理性思维。系统往往是复杂系统，多方面糅合。除了从上向下的方式去追求通用原则，从下往上排查实际，具体的流程才是认清楚系统多样性的最好方法。在非线性的世界，不要用线性的思维模式\n原则：系统分为三个要素，要素，联系和功能。我们平时重点应该是关注联系，因为是联系提供了系统的三个特征（适应性，层次性，自组织）里面的适应性。所以关注系统不应该看存量，而应该看适应性\n方法：用四步流程实现你的人生愿望：\n有明确的目标，排列优先顺序，不要混淆目标和欲望 找出问题，要精准地找到问题所在，不要把问题的某个原因误认为问题本身；区分大问题和小问题；诊断问题，找到问题的根源；先把问题是什么弄明白，再决定怎么做；区分直接原因和根本原因 通过快速试错以适应现实是无价的，拥有灵活性并自我归责，那么几乎没有什么能阻止你成功 建立清晰的衡量标准来确保你在严格执行方案，很多时候如果不能建立衡量标准，那么可能就不应该定做什么的目标 关键是要做一个清晰的“产品定义‘，即要做什么出来 学习如何有效决策，要认识到\n影响好决策的最大威胁是有害的情绪 决策是一个两步流程（先了解后决定） a. 综合分析眼前的形势你能做的最重要的决定之一是决定问谁。 b．不要听到什么信什么。 c．所有东西都是放在眼前看更大。 d．不要夸大新东西的好处。 e.不要过度分析细节 f.不要过于着急做决定 始终记住改善事物的速度和水平，以及两者的关系 谨记“80/20法则”，并明白关键性的“20%”是什么。 不必过于精确，不要做完美主义者，对于决策的后果而言，如果收益比付出要大，那么这个事情就是可以做的 高效地综合考虑各个层次a．用“基线以上”和“基线以下”来确定谈话位于哪一层。b．谨记，决策需要在合理的层次做出，但也应在各层次之间保持一致。 不要把可能性当作概率 从上往下学习 这里有一个批判性思维 问“五个为什么”， 谁从中获益？ 有什么背景 为什么这是个问题？是否存在一个基础模型，这个模型这么工作？ 什么时候可以从哪里工作起来，不要停留在一阶思维，要进行二阶思维：当它结束后还会发生什么？ 如何找到机会\n如何找到机会\n首先你得知道什么是好的 然后思考为什么目前好的东西为啥还没普及 另外一个方面，寻找附加价值。比方说充电桩\n因为充电速度太慢，所以不能直接从充电翻桌率盈利 但是可以从补贴上面拿到赚的钱 降维打击\n多样性对抗\n如何找到研究的idea？\n下面的内容为：《How to Look for Ideas in Computer Science Research》\n阅读其它的论文或者关键点，学习如何理解识别research idea的形成模式：\n填表法： 拓展： 目前企业的根本实际上并不是做善事，或者出发时是善良的，但是附加是邪恶的。对企业而言，付费的才是真正的客户，如果你是免费用户，那么“从实际”的角度来说，你是产品。\n通用工具库：\n分治思想\n分库分表 读写分离 冷热分离 系统的八大陷阱\n政策阻力：治标不治本。这种问题往往是因为不同参与者有不同的目标，将系统存量往 解决办法，重新制定更大的总体目标，让参与者突破各自的有限理性，追求共同目标 系统的12大变革方式\n基础知识：网络分布式八宗罪\n程序员主要涉及到两个价值观：行为(behavior）和结构(structor)，一半需求要的是行为，而我们关注的是结构，实际上我们应该讲机制和实现相分离，我们需要的是机制，而不是具体的实现\n更精确地说让高层策略与实现细节脱钩，使其策略部分完全不需要关心底层细节，当然也不会对这些细节有任何形式的依赖\n转变观念，将问题从“是或否”的二元属性，转变为可以按照不同强度分开讨论的多元属性，在确保代价的情况下获得一定的收益。总之从具体的操作上面的变成问题，上升为一个全局权衡的架构问题。\n通用手段：先将满足不同需求的代码分组（即 SRP），然后再来调整这些分组之间的依赖关系（即 DIP）\n进步的手段：\n每年学习一门新的语言\n每月阅读一本技术书\n每月阅读一本非技术书\n与时俱进\n0.5 Clean-Architecture-zh学习 # 2 两个价值观 # 程序员主要涉及到两个价值观：行为(behavior）和结构(structor)，一般需求要的是行为，而程序员需要关注结构。只关注行为不关注结构会最终导致失序\n行为：行为是其最直观的价值维度。程序员的工作就是让机器按照某种指定方式运转，给系统的使用者创造或者提高利润。简单来说就是需求 结构（架构）：当需求方改变需求的时候，随之所需的软件变更必须可以简单而方便地实现。变更实施的难度应该和变更的范畴（scope）成等比关系，而与变更的具体形状（shape）无关。因此程序员需要关心结构（ The difficulty in making such a change should be proportional only to the scope of the change, and not to the shape of the change.） 行为和结构哪个重要呢？按照艾森豪威尔的紧急/重要矩阵\nI have two kinds of problems, the urgent and the important. The urgent are not important, and the important are never urgent.\n一般来说，事情可以为分为四种\n重要且紧急 重要不紧急 不重要但紧急 不重要且不紧急 软件的系统架构——那些重要的事情——占据了该列表的前两位，而系统行为——那些紧急的事情——只占据了第一和第三位。功能从来都是不重要但是紧急，但是业务部门原本就是没有能力评估系统架构的重要程度的，这本来就应该是研发人员自己的工作职责！所以，平衡系统架构的重要性与功能的紧急程度这件事，是软件研发人员自己的职责。\n3 编程范式 # 结构化编程 面向对象编程：很多OO编程语言声称面向对象就是封装，继承和多态，然后封装本质是无需了解本质，比方说.h泄露了内部信息。目前并不符合，而多态才是关心的重点，因此什么是OO？业界在这个问题上存在着很多不同的说法和意见。然而对一个软件架构师来说，其含义应该是非常明确的：面向对象编程就是以对象为手段来对源代码中的依赖关系进行控制的能力，这种能力让软件架构师可以构建出某种插件式架构，让高层策略性组件与底层实现性组件相分离，底层组件可必编译成插件，实现独立于高层组件的开发和部署。 函数式编程： 4 设计准则 # SOLID准则：我自己加一个准则\nSRP：A module should be responsible to one, and only one, actor。应当只服务于一种角色？举个例子：\n某个工资管理程序中的 Employee 类有三个函数 calculatePay()、reportHours() 和 save()；calculatePay() 函数是由财务部门制定的，他们负责向 CFO 汇报。；reportHours() 函数是由人力资源部门制定并使用的，他们负责向 COO 汇报。；save() 函数是由 DBA 制定的，他们负责向 CTO 汇报。；这三个函数被放在同一个源代码文件，即同一个 Employee 类中，程序员这样 做实际上就等于使三类行为者的行为耦合在了一起，这有可能会导致 CFO 团队的命令影响到 C 00 团队所依赖的功能。这就违背了SRP原则，因为任何改动可能带来给其他团队的副作用 解决方法非常简单，直接拆分为角色为三种不同的类型，而不是对基类Employee 在组件层面，我们可以将其称为共同闭包原则（Common Closure Principle)，在软件架构层面，它则是用于奠定架构边界的变更轴心（Axis of Change）。 OCP准则：A software artifact should be open for extension but closed for modification.该怎么做呢？\n先将满足不同需求的代码分组（即 SRP），然后再来调整这些分组之间的依赖关系（即 DIP）。 接下来，我们就该修改其源代码之间的依赖关系了。这样做的目的是保证其中一个操作被修改之后不会影响到另外一个操作。同时，我们所构建的新的组织形式应该保证该程序后续在行为上的扩展都无须修改现有代码。换句话说保证所有组件之间的关系都是单向依赖的 让我们再来复述一下这里的设计原则：如果 A 组件不想被 B 组件上发生的修改所影响，那么就应该让 B 组件依赖于 A 组件。 总之：OCP 是我们进行系统架构设计的主导原则，其主要目标是让系统易于扩展，同时限制其每次被修改所影响的范围。实现方式是通过将系统划分为一系列组件，并且将这些组件间的依赖关系按层次结构进行组织，使得高阶组件不会因低阶组件被修改而受到影响。 LSP准则：What is wanted here is something like the following substitution property: If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T.1\n举一个反例来表示这个，正方形如果是长方形的子类，那么就会出现违背这种设定的情况，比方说下面的代码就会出现问题\nRectangle r = … r.setW(5); r.setH(2); assert(r.area() == 10); LSP准则不单纯适用于继承，它是一种更广泛的、指导接口与其实现方式的设计原则。\nLSP 可以且应该被应用于软件架构层面，因为一旦违背了可替换也该系统架构就不得不为此增添大量复杂的应对机制。\n我怎么感觉LSP有点像是一个pot，got一样的东西，函数蹦床；简单来说就是保证接口是实现无关，直接通用的\nISP准则：在一般情况下，任何层次的软件设计如果依赖于不需要的东西，都会是有害的。从源代码层次来说，这样的依赖关系会导致不必要的重新编译和重新部署，对更高层次的软件架构设计来说，问题也是类似的。\n这个我觉得可以类比cpfs，它提供了缓存，更新缓存的功能，功能过于复杂。任何层次的软件设计如果依赖了它并不需要的东西，就会带来意料之外的麻烦。 DIP准则：\n应在代码中多使用抽象接口，尽量避免使用那些多变的具体实现类。这条守则适用于所有编程语言，无论静态类型语言还是动态类型语言。同时，对象的创建过程也应该受到严格限制，对此，我们通常会选择用抽象工厂（abstract factory）这个设计模式。 不要在具体实现类上创建衍生类。上一条守则虽然也隐含了这层意思，但它还是值得被单独拿出来做一次详细声明。在静态类型的编程语言中，继承关系是所有一切源代码依赖关系中最强的、最难被修改的，所以我们对继承的使用应该格外小心。即使是在稍微便于修改的动态类型语言中，这条守则也应该被认真考虑。 不要覆盖（override）包含具体实现的函数。调用包含具体实现的函数通常 就意味着引入了源代码级别的依赖。即使覆盖了这些函数，我们也无法消除这其中的依赖——这些函数继承了那些依赖关系。在这里，控制依赖关系的唯一办法，就是创建一个抽象函数，然后再为该函数提供多种具体实现。 应避免在代码中写入与任何具体实现相关的名字，或者是其他容易变动的事物的名字。这基本上是 DIP 原则的另外一个表达方式。 redundancy准则：\n任务组件应该在支持的情况下能够存储一些方便检索的冗余信息，尤其是管理功能 一部分具体的通用设计准则\n系统的关键数据（这里我推荐使用DDD的实体的概念）要有元信息管理，举个简单的例子，对于仿真平台而言，仿真场景是关键数据，这部分关键数据是需要提供元信息管理的 不同功能的组件或者文件的存储和检索，不应该放在一个地方，否则会造成管理问题 系统的输入和输出，包括生成的报告，存储的流程文件，都需要有相应的元信息管理。或者至少能够方便的检索和管理 5 设计方法 # 常见的设计方法有DDD（领域驱动设计）和ADD（属性驱动设计）。初次之外，针对复杂系统，可以采用状态/事件驱动设计\n5.1 DDD # 领域驱动设计抽象名词一大堆，专家不说人话，说白了DDD是业务架构——根据业务需求设计业务模块及其关系，将业务架构映射到系统架构上，在响应业务变化调整业务架构时，也随之变化系统架构。建议直接阅读https://tech.meituan.com/2017/12/22/ddd-in-practice.html，作为一个直观的参考\n简单总结流程如下。\n领域驱动设计的一般化流程如下\n根据需求划分出初步的领域和限界上下文，以及上下文之间的关系； 划分领域和限界上下文指的是在特定的前提下，组织各种概念。为什么不用模块等概念，因为这是个业务架构，早于实现架构或者系统架构 考虑产品所讲的通用语言，；我们将紧耦合的各自圈在一起，观察他们内在的联系，从而形成对应的界限上下文。形成之后，我们可以尝试用语言来描述下界限上下文的职责，看它是否清晰、准确、简洁和完整（划分出来的限界上下文满足自治的架构单元具备4个要素，即最小完备、自我履行、稳定空间和独立进化）。简言之，限界上下文应该从需求出发，按领域划分。 总结来说： 怎样识别限界啥下文？从中提取一些术语称之为概念对象，寻找对象之间的联系；或者从需求里提取一些动词，观察动词和对象之间的关系。四个步骤来拆分很验证限界上下文的合理性 步骤1业务维度拆分 使用语义相关性意味着存在相同或相似的领域概念，对应于业务服务描述的名词，如果不同的业务服务操作了相同或相似的对象，即可认为它们存在语义相关性。 使用功能相关性体现为领域行为的相关性，但它并非设计意义上领域行为之间的功能依赖，而是指业务服务是否服务于同一个业务目标。 步骤2验证拆分合理 正交：保证每个限界上下文对外提供的业务能力不能出现雷同，这就需要保证为完成该业务能力需要的领域知识不能出现交叉 单一抽象原则：保证一个方法中的所有操作都在同一个抽象层次，违背了单一抽象层次原则的限界上下文会导致概念层次的混乱。一个高抽象层次的概念由于内涵更小，使得它的外延更大，就有可能包含低抽象层次的概念，使得位于不同抽象层次的限界上下文存在概念上的包含关系，这实际上也违背了正交原则。例如，在一个集装箱多式联运系统中，商务上下文与合同上下文就不在一个抽象层次上 奥卡姆剃刀原则：如果对识别出来的限界上下文的准确性依然心存疑虑，比较务实的做法是保证限界上下文具备一定的粗粒度。 步骤3管理维度 步骤4技术维度考校 进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象； 实体，实体必然有下面三个东西 身份标识：身份标识（identity，简称为ID）是实体对象的必要标志，实体的身份标识就好像每个公民的身份号码，除了帮助我们识别实体的同一性，身份标识的主要目的还是管理实体的生命周期 属性：实体的属性用来说明主体的静态特征，并持有数据与状态。通常，我们会依据粒度的粗细将属性分为原子属性与组合属性 领域行为：实体拥有领域行为，可以更好地说明其作为主体的动态特征 值对象，可以理解为 对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根；只能由实体、值对象、领域服务和领域事件表示模型 聚合实际上就是类的聚合（引入了实现）,控制类的关系具体做法 去除不必要的关系：一部分依赖的关系是可以去除的，比方说配送单需要订单的信息，但是实际上配送单真正依赖的是包裹存单，而不是配送单。因此原本的依赖是去除的。 降低耦合的强度: 一种策略是引入泛化提取通用特征，形成更弱的依赖或关联关系，如Car对汽车的泛化使得Driver可以驾驶各种汽车 另一种是降低耦合的细度，比方说订单Order与订单项OrderItem，依赖orderitem，而不是order 避免双向耦合: 为聚合根设计仓储，并思考实体或值对象的创建方式； 在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构。 以DDD为方法，我划分CI试试\n5.2 ADD # 属性驱动设计\n1 远程服务 # 1.1 RPC的可靠性问题 # 远程服务也就是RPC，早先的目的实际上是为了让计算机能够与本地方法一样调用远程方法。当时使用socket接口，透明的socket给程序员带来了通信无成本的假象，因此在当时Andrew Tanenbaum发表论文对RPC发起质疑：将本地调用和RPC远程调用当做同样的调用来处理，犯了方向性的错误，将系统间调用透明化，反而会增加程序员工作的复杂度。 简单来说就是使用网络进行分布式运算的八宗罪：\n网络是可靠的 延迟是不存在的 带宽是无限的 网络是安全的 拓扑结构是一成不变的 总会有一个管理员 不必考虑传输成本 网络是同质化的 最终RPC被定性为：RPC应该是一种高层次的或者说语言层次的特征，而不是像IPC那样子低层次或者系统层次的特征。\n1.2 RPC要解决的问题 # 在对RPC的本质有了清醒的认识之后，20世纪80年代中后期，RPC的主要问题被思考出来即\n如何表示数据：这里的数据包括传递给方法的参数和方法执行之后的返回值，举个简单的例子grpc的protobuf，轻量级rpc支持的json序列化 如何传递数据：如何通过网络，在两个网络的endpoint之间相互操作。两个服务交互并不只扔个序列化数据流就完事，比方说异常，超时，安全，认证，授权，事务都得处理。在计算机科学里面有个名词叫做Wire Protocol，比方说java RMI的远程消息交换，JRMP 如何表示方法：不同的语言怎么表示一个函数或者方法呢？怎么跨语言定位函数和方法，比方说统一序号啥的。 1.3 REST # 提到RPC，不得不提到REST了，REST本质可以理解为对资源的CRUD，实际上去看kubernetes的实现就会发现它实际上就是定义各种资源，然后对资源执行CRUD。如果用RPC的方式考虑问题就是典型的对着函数（方法）编程，而使用REST一般抽象程度比较高。\n为了方便理解REST，我们先看看REST的基础概念\n资源： 表征 状态 转移 统一接口 超文本驱动 自描述信息 REST的编程思想\nCS架构：客户端和服务端分离，提高用户界面的可移植性 无状态**（核心原则）**：每个请求都是独立的、自成一个个体，与前后请求无关。如此好处有很多，包含可靠（容易从错误中复原）、高效能与可扩充性（可以将请求交给不同伺服器处理），而元件可以被修改、更动而不会影响到系统整体的运作。 可缓存：希望能够缓存一些关键数据，减少多次请求，提高性能 分层：这里的分层指的是客户端不需要清楚是不是直接连接到了服务器，中间服务器提供的请求也可用 在发出请求的Client 与送出回应的Server 之间可以有好几个Server 中间人（称作Connectors，下面介绍），彼此独立并且不会影响到Request 与Response。 统一接口**（核心原则）**：将操作细节抽象出来，降低耦合并提高独立性。这里指的是将软件系统设计的重点放在抽象系统有哪些资源，而不是服务有哪些行为上。这个原则可以类比计算机中对文件管理的操作来理解，管理文件可能会设计删除，修改，移动等操作，这些操作时可数的，且对所有文件是固定统一的。 按需代码：这个原则是可选的，简单来说就是指可执行的程序可以从服务端发送到客户端。 最后我们来看看REST的模型评测，也就是RMM，直接参考https://martinfowler.com/articles/richardsonMaturityModel.html的医生的例子\n0级：完全不rest：接口的功能非常单一，就是申请和返回。得开发多个接口 1级：引入了统一资源的概念：开始考虑资源的概念，将请求都包含资源的实体 2级：引入统一接口：依赖各种http的状态码来统一的表示是否可以成功的表达接口的状态 3级：超媒体控制：完全不依赖任何已知的信息，整个服务自举，比方说输入查询指令之后，返回的接口包含如何了解医生信息，如何预约等接口 REST的不足：\n只适合做CRUD：因为是面向资源，所以只适合做CRUD，面向过程，面向对象的逻辑更复杂。当然也不是不能用REST表示方法，只不过就得加上一些行为的表示 REST没有事务的概念 REST没有传输可靠性的支持，毕竟本来就不是做这个事情的 REST缺乏对资源做部分和批量处理的能力， 2 事务处理 # 事务分为多种\n本地事务：本地事务是指仅操作单一事务资源的、不需要全局事务管理器进行协调的事务。ACID里面的AIC要拆开实现\nAtomic + Durability\n实现上 常用“Commit Logging”（提交日志），拆分每一步不原子的操作为一系列的日志并记录。 细节记录修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式——即仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中。在日志记录全部都安全落盘，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化。 commit log的问题是，因此有ARIES 理论。为了能够在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。优化磁盘 I/O 性能。方法：增加了另一种被称为 Undo Log 的日志类型，当变动数据写入磁盘前，必须先记录 Undo Log，注明修改了哪个位置的数据、从什么值改成什么值，等等。以便在事务回滚或者崩溃恢复时根据 Undo Log 对提前写入的数据变动进行擦除。 隔离性Isolation\n写锁：也叫做排他锁，如果数据有加写锁，就只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据，也不能施加读锁。这里要注意：这个是不能写入数据，不能施加读锁 读锁：也叫做共享锁，多个事务可以对同一个数据添加多个读锁，数据被加上读锁后就不能再被加上写锁，所以其他事务不能对该数据进行写入，但仍然可以读取。对于持有读锁的事务，如果该数据只有它自己一个事务加了读锁，允许直接将其升级为写锁，然后写入数据。 范围锁：对于某个范围直接加排他锁，在这个范围内的数据不能被写入。 隔离性级别\nANSI/ISO SQL-92中定义的最高等级的隔离级别便是可串行化（Serializable）。 可串行化的下一个隔离级别是可重复读（Repeatable Read），可重复读对事务所涉及的数据加读锁和写锁，且一直持有至事务结束，但不再加范围锁。可重复读比可串行化弱化的地方在于幻读问题（Phantom Reads），它是指在事务执行过程中，两个完全相同的范围查询得到了不同的结果集。 可重复读的下一个隔离级别是读已提交（Read Committed），读已提交对事务涉及的数据加的写锁会一直持续到事务结束，但加的读锁在查询操作完成后就马上会释放。读已提交比可重复读弱化的地方在于不可重复读问题（Non-Repeatable Reads），它是指在事务执行过程中，对同一行数据的两次查询得到了不同的结果。 读已提交的下一个级别是读未提交（Read Uncommitted），读未提交对事务涉及的数据只加写锁，会一直持续到事务结束，但完全不加读锁。读未提交比读已提交弱化的地方在于脏读问题（Dirty Reads），它是指在事务执行过程中，一个事务读取到了另一个事务未提交的数据。 全局事务\n全局事务被限定为一种适用于单个（也没说必须单个）服务使用多个数据源场景的事务解决方案。 方法： 2PC 准备阶段：又叫作投票阶段，在这一阶段，协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared。这里所说的准备操作跟人类语言中通常理解的准备并不相同，对于数据库来说，准备操作是在重做日志中记录全部事务提交操作所要做的内容，它与本地事务中真正提交的区别只是暂不写入最后一条 Commit Record 而已，这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。 提交阶段：又叫作执行阶段，协调者如果在上一阶段收到所有事务参与者回复的 Prepared 消息，则先自己在本地持久化事务状态为 Commit，在此操作完成后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；否则，任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，协调者将自己的事务状态持久化为 Abort 之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作。对于数据库来说，这个阶段的提交操作应是很轻量的，仅仅是持久化一条 Commit Record 而已，通常能够快速完成，只有收到 Abort 指令时，才需要根据回滚日志清理已提交的数据，这可能是相对重负载的操作。 3 流量治理（分级与分流） # 为什么我要郑重其事地写这条？因为我发现任何系统（这个只要是基础服务或者是稍微大一点的分布式系统/单点系统）的分级分流是必然要考虑的！buildfarm服务的机器一直在增加，但是性能依然跟不上用户的脚步，因此我们需要在前面加流量控制，容错处理啥的.\n我们目前针对错误采用的就是重试策略，这一次我要采用的流量控制。\n3.1 服务容错 # Martin Fowler 与 James Lewis 提出的“微服务的九个核心特征”是构建微服务系统的指导性原则，但不是技术规范，并没有严格的约束力。在实际构建系统时候，其中多数特征可能会有或多或少的妥协，譬如分散治理、数据去中心化、轻量级通信机制、演进式设计，等等。但也有一些特征是无法做出妥协的，其中的典型就是今天我们讨论的主题：容错性设计。\n3.1.1 容错策略 # 要落实容错性设计这条原则，除了思想观念上转变过来，正视程序必然是会出错的，对它进行有计划的防御之外，还必须了解一些常用的容错策略和容错设计模式。常见的容错策略有以下几种：\n故障转移（Failover）：关键路径上的服务，均会部署有多个副本。如果调用的服务器出现故障，不会立即返回失败结果，而是自动切换到其他服务副本，尝试其他副本能否返回成功调用的结果，从而保证了整体的高可用性。 快速失败（Failfast）：部分业务场景是不允许做故障转移的，故障转移策略能够实施的前提是要求服务具备幂等性，对于非幂等的服务，重复调用就可能产生脏数据，应直接返回失败。 安全失败（Failsafe）：即使旁路逻辑调用实际失败了，也当作正确来返回，自动记录一条服务调用出错的日志备查即可，这种策略被称为安全失败。典型的有审计、日志、调试信息，等等 沉默失败（Failsilent）：如果大量的请求造成服务失败，认为服务不可用，直接隔离错误的服务提供者，不再分配请求流量，将错误隔离开来，避免对系统其他部分产生影响，此即为沉默失败策略。 故障恢复（Failback）：故障恢复一般不单独存在，而是作为其他容错策略的补充措施，系统通常默认会采用快速失败加上故障恢复的策略组合：失败之后，返回失败+由系统自动开始异步重试调用。 上面五种以“Fail”开头的策略是针对调用失败时如何进行弥补的，以下这两种策略则是在调用之前就开始考虑如何获得最大的成功概率。\n并行调用（Forking）：“双重保险”或者“多重保险”的处理思路，它是指一开始就同时向多个服务副本发起调用，只要有其中任何一个返回成功，那调用便宣告成功。 广播调用（Broadcast）：广播调用与并行调用是相对应的，都是同时发起多个调用，但并行调用是任何一个调用结果返回成功便宣告成功，广播调用则是要求所有的请求全部都成功。 比较下表：\n容错策略 优点 缺点 应用场景 故障转移 系统自动处理，调用者对失败的信息不可见 增加调用时间，额外的资源开销 调用幂等服务 对调用时间不敏感的场景 快速失败 调用者有对失败的处理完全控制权 不依赖服务的幂等性 调用者必须正确处理失败逻辑，如果一味只是对外抛异常，容易引起雪崩 调用非幂等的服务 超时阈值较低的场景 安全失败 不影响主路逻辑 只适用于旁路调用 调用链中的旁路服务 沉默失败 控制错误不影响全局 出错的地方将在一段时间内不可用 频繁超时的服务 故障恢复 调用失败后自动重试，也不影响主路逻辑 重试任务可能产生堆积，重试仍然可能失败 调用链中的旁路服务 对实时性要求不高的主路逻辑也可以使用 并行调用 尽可能在最短时间内获得最高的成功率 额外消耗机器资源，大部分调用可能都是无用功 资源充足且对失败容忍度低的场景 广播调用 支持同时对批量的服务提供者发起调用 资源消耗大，失败概率高 只适用于批量操作的场景 3.1.2 容错设计模式 # 为了实现各种各样的容错策略，开发人员总结出了一些被实践证明是有效的服务容错设计模式，譬如微服务中常见的断路器模式、舱壁隔离模式，重试模式，等等\n断路器模式：本质是一种快速失败策略的实现方式 通过代理（断路器对象）来一对一地（一个远程服务对应一个断路器对象）接管服务调用者的远程请求。断路器会持续监控并统计服务返回的成功、失败、超时、拒绝等各种结果，当出现故障（失败、超时、拒绝）的次数达到断路器的阈值时 舱壁隔离模式 实现方式 线程池方法：为每个服务单独设立线程池，这些线程池默认不预置活动线程，只用来控制单个服务的最大连接数。 信号量机制（Semaphore）。控制一个服务并发调用的最大次数，可以只为每个远程服务维护一个线程安全的计数器即可。服务开始调用时计数器加 1，服务返回结果后计数器减 1，一旦计数器超过设置的阈值就立即开始限流，在回落到阈值范围之前都不再允许请求了。 细节：以上介绍的是从微观的、服务调用的角度应用的舱壁隔离设计模式，舱壁隔离模式还可以在更高层、更宏观的场景中使用，不是按调用线程，而是按功能、按子系统、按用户类型等条件来隔离资源都是可以的。一般来说，我们会选择将服务层面的隔离实现在服务调用端或者边车代理上，将系统层面的隔离实现在 DNS 或者网关处。 重试模式 有可能自己恢复（Resilient，称为自愈，也叫做回弹性）的临时性失灵，网络抖动、服务的临时过载（典型的如返回了 503 Bad Gateway 错误）这些都属于瞬时故障。这些可以用重试 使用条件： 仅在主路逻辑的关键服务上进行同步的重试，不是关键的服务，尤其不该进行同步重试。 仅对由瞬时故障导致的失败进行重试。尽管一个故障是否属于可自愈的瞬时故障并不容易精确判定，比方说没权限就不该重试 仅对具备幂等性的服务进行重试。具体服务如何实现并无强制约束力，但我们自己建设系统时，遵循业界惯例本身就是一种良好的习惯。 重试必须有明确的终止条件，常用的终止条件有两种： 超时终止：并不限于重试，所有调用远程服务都应该要有超时机制避免无限期的等待。 次数终止：重试必须要有一定限度，不能无限制地做下去，通常最多就只重试 2 至 5 次。 3.1.3 流量控制 # 需要妥善解决以下三个问题：\n依据什么限流？：要不要控制流量，要控制哪些流量，控制力度要有多大，等等这些操作都没法在系统设计阶段静态地给出确定的结论，必须根据系统此前一段时间的运行状况，甚至未来一段时间的预测情况来动态决定。\n主流系统大多倾向使用 HPS 作为首选的限流指标，它是相对容易观察统计的，而且能够在一定程度上反应系统当前以及接下来一段时间的压力。 方法： 每秒事务数（Transactions per Second，TPS）：TPS 是衡量信息系统吞吐量的最终标准。“事务”可以理解为一个逻辑上具备原子性的业务操作。比方说taobao买东西，真个买完了就是一个t 每秒请求数（Hits per Second，HPS）：HPS 是指每秒从客户端发向服务端的请求数（请将 Hits 理解为 Requests 而不是 Clicks，国内某些翻译把它理解为“每秒点击数”多少有点望文生义的嫌疑）。 每秒查询数（Queries per Second，QPS）：QPS 是指一台服务器能够响应的查询次数。如果只有一台服务器来应答请求， 具体如何限流？：解决系统具体是如何做到允许一部分请求能够通行，而另外一部分流量实行受控制的失败降级，这必须了解掌握常用的服务限流算法和设计模式。\n流量计数器：设置一个计算器，根据当前时刻的流量计数结果是否超过阈值来决定是否限流。譬如前面场景应用题中，我们计算得出了该系统能承受的最大持续流量是 80 TPS。但是\n每一秒的统计流量都没有超过 80 TPS，也不能说明系统没有遇到过大于 80 TPS 的流量压力 即使连续若干秒的统计流量都超过了 80 TPS，也不能说明流量压力就一定超过了系统的承受能力。 滑动时间窗\n漏桶：以请求对象作为元素的先入先出队列（FIFO Queue），队列长度就相当于漏桶的大小，当队列已满时便拒绝新的请求进入。漏桶实现起来很容易，困难在于如何确定漏桶的两个参数：桶的大小和水的流出速率。\n令牌桶：系统在 X 秒内最大请求次数不超过 Y，那就每间隔 X/Y 时间就往桶中放一个令牌，当有请求进来时，首先要从桶中取得一个准入的令牌，然后才能进入系统处理。任何时候，一旦请求进入桶中却发现没有令牌可取了\n分布式限流：单机限流很好办，指标都是存储在服务的内存当中，而分布式限流的目的就是要让各个服务节点的协同限流，无论是将限流功能封装为专门的远程服务\n实现\n请求进入集群时，首先在 API 网关处领取到一定数额的“货币”，将用户 A 的额度表示为 QuanityA。由于任何一个服务在响应请求时都需要消耗集群一定量的处理资源，所以访问每个服务时都要求消耗一定量的“货币”，假设服务 X 要消耗的额度表示为 CostX，那当用户 A 访问了 N 个服务以后，他剩余的额度 LimitN即表示为：\nLimitN = QuanityA - ∑NCostX\n此时，我们可以把剩余额度 LimitN作为内部限流的指标，规定在任何时候，只要一旦剩余额度 LimitN小于等于 0 时，就不再允许访问其他服务了。此时必须先发生一次网络请求，重新向令牌桶申请一次额度\n客户端限流，如果能控制客户端的限流方式那么直接控制客户端的并发\n超额流量如何处理？：超额流量可以有不同的处理策略，也许会直接返回失败（如 429 Too Many Requests），或者被迫使它们进入降级逻辑，这种被称为否决式限流。也可能让请求排队等待，暂时阻塞一段时间后继续处理，这种被称为阻塞式限流。\n架构安全 # 我们重点关注5个点\n认证 授权 凭证 保密 传输 验证 2 K8S学习笔记 # 2.1 基本概念 # kubernetes的概念可以拆分为多种\n资源类 某种资源的对象，比方说节点，pod，服务，存储卷。资源对象一般包含一些通用属性比方说版本，类别，标签，名称注解。资源对象的名称，标签，注解是资源对象的元数据 与资源对象相关的事物和动作，比方说标签，注解，命名空间，部署，HPA，PVC 集群类 表示一个由master和node组成的kubernetes集群 master是集群的控制节点，运行着关键进程 kube-apiserver，提供http restful api接口的主要服务 kube-controller-manager，资源对象的控制中心 kube-echeduler，负责资源调度的进程， node，集群里面除了master之外的所有服务器 kubelet进程 kube-proxy进程 容器runtime，比方说docker 多租户隔离：命名空间。 命名空间属于kubernetes的集群范畴的资源对象，不同命名空间的资源对象从逻辑上相互隔离。系统相关的资源对象比方说网络组建，dns组件，监控类组件都放在kube-system里面。 应用类 service类 pod类 高级扩缩容功能HPA 高级扩缩容VPA 存储类 2.2 核心组件运行原理 # 核心组件交互实际上可以拆分为api server，controller，scheduler等组件交互流程，实际上可以理解为对etcd的简单crud。注意，这里主要用到的list watch机制\nkube api server原理解析 kubeapi的listwatch接口 kubeapi server分为四层 API 访问控制层 api server的网络隔离 + scheduler原理： controler的原理 kubeproxy机制，三代发展 一代 二代 三代 2.3 节点调度相关 # 2.4 安全机制 # 2.5 kubernetes运维管理 # 2.6 kubernetes开发 # 3 云工程师 # 从单体架构迁移到云原生架构，需要考虑的方面很多，虽然云原生是一种文化理念，但是参考下面写的十二因素应用程序和云原生变革理念，就能知道从单体到云原生绝对不是迁移几个接口就完了的\n云原生是什么？是一种理念，如果可以建议直接阅读https://tanzu.vmware.com/content/ebooks/migrating-to-cloud-native-application-architectures，或者看看https://lib.jimmysong.io/migrating-to-cloud-native-application-architectures/ 的翻译\n云原生程序的架构特性\n从传统的单体到云原生架构，需要文化，组织和技术的变革。云原生涉及的应用架构包括如下的方面：\n十二因素应用程序：云原生应用架构模式的集合，这些模式可以用来说明什么才是云原生\n代码库\n依赖：使用可以声明的标准依赖，比方说maven，等。不该有部署环境里面隐式的依赖\n配置：配置或其他随发布环境（如部署、staging、生产）而变更的部分应当作为操作系统级的环境变量注入。\n后端服务：后端服务，例如数据库、消息代理应视为附加资源，并在所有环境中同等看待。\n编译、发布、运行：构建一个可部署的 app 组件并将它与配置绑定，根据这个组件 / 配置的组合来启动一个或者多个进程，这两个阶段是严格分离的。\n进程：该 app 执行一个或者多个无状态进程（例如 master/work），它们之间不需要共享任何东西。任何需要的状态都置于后端服务（例如 cache、对象存储等）。\n端口绑定：该应用程序是独立的，并通过端口绑定（包括 HTTP）导出任何 / 所有服务。\n并发：并发通常通过水平扩展应用程序进程来实现（尽管如果需要的话进程也可以通过内部管理的线程多路复用来实现）。\n可任意处置性：通过快速迅速启动和优雅的终止进程，可以最大程度上的实现鲁棒性。这些方面允许快速弹性缩放、部署更改和从崩溃中恢复。\n开发 / 生产平等：通过保持开发、staging 和生产环境尽可能的相同来实现持续交付和部署。\n日志：不管理日志文件，将日志视为事件流，允许执行环境通过集中式服务收集、聚合、索引和分析事件。\n管理进程行政或管理类任务（如数据库迁移），应该在与 app 长期运行的相同的环境中一次性完成。\n微服务：独立部署的服务，每个服务只做一件事情\n自助服务的敏捷基础设施：快速，可重复和一致地提供应用环境和后台服务的平台，这里面有两点要注意：服务化和基础设施IAC\n基于 API 的协作：发布和版本化的 API，允许在云原生应用架构中的服务之间进行交互\n这样子，只要不破坏现有的承诺，那么团队可以做快速的部署 抗压性：根据压力变强的系统\n安全：\n云原生理念带来变革\n文化变革 云原生意味着将过去曾经的“信息孤岛”，比方说DBA相关的领域构建成共享的工具集、词汇表和沟通结构，以服务于专注于单一目标的文化：快速、安全得交付价值。然后创建激励结构，强制和奖励领导组织朝着这一目标迈进的行为。做产品而不是做项目 从间断开发到敏捷开发：每次迭代（实际上是次每个源代码提交！）都被证明可以以自动化的方式部署。我们构建部署流水线，可自动执行每次测试，如果该测试失败，将会阻止生产部署。 从集中治理到分散自治：团队个体的分散自治和自主性是通过最小化、轻量级的结构进行平衡的，这些结构在可独立开发和部署的服务之间使用集成模式（例如，他们更喜欢 HTTP REST JSON API 而不是不同风格的 RPC）来实现。这些结构通常会在底层解决交叉问题，如容错。激励团队自己设法解决这些问题，然后自发组织与其他团队一起建立共同的模式和框架。随着整个组织中的最优解决方案出现，该解决方案的所有权通常被转移到云框架 / 工具团队，这可能嵌入到平台运营团队中也可能不会。当组织正在围绕对架构共识进行改革时，云框架 / 工具团队通常也将开创解决方案。 组织变革：康威定律和逆康威定律 寻求迁移到将业务能力分离的微服务等云原生架构的公司经常采用 Thoughtworks 称之为的“逆康威定律”。他们没有建立一个与其组织结构图相匹配的架构，而是决定了他们想要的架构，并重组组织以匹配该架构。 技术变革：技术变革实际上是说现代架构的变化，采用云提供的独特能力设计新的架构， 分解数据： 将有界上下文与每个服务模式的数据库结合，每个微服务封装、管理和保护自己的领域模型和持久存储。在每个服务模式的数据库中，只允许一个应用程序服务访问逻辑数据存储，逻辑数据存储可能是以多租户集群中的单个 schema 或专用物理数据库中存在。 到容器化 容器调度相关，这个不用多解释了 迁移指南：\n如何迁移到新的架构呢？ 首先，新功能用微服务构建 使用DDD经典的 表现层表现层的目的是为了简化与单体应用接口集成的过程。单体应用设计之初很可能没有考虑这个集成，因此我们引入了表现层来解决这个问题。它没有改变单体应用的模型，这很重要，注意不要将转换和集成问题耦合到一起。 适配器我们用适配器来定义 service，用来提供我们需要的新功能。它知道如何获取系统请求并使用协议将请求发送给单体应用的表层。 转换器转换器的职责是在单体应用与新的微服务之间进行请求和响应的领域模型转换。 因此，技术上我们需要使用分布式系统 版本化和分布式配置 服务注册发现 路由和负载均衡 容错 API网关/边缘服务 结尾 # 唉，尴尬\n","date":"2023 年 3 月 28 日","externalUrl":null,"permalink":"/posts/2023-03-31-%E6%9E%B6%E6%9E%84%E4%B9%8B%E8%B7%AF/","section":"Posts","summary":"","title":"2023-03-31-架构之路","type":"posts"},{"content":"","date":"2023 年 3 月 28 日","externalUrl":null,"permalink":"/tags/devops/","section":"Tags","summary":"","title":"Devops","type":"tags"},{"content":"","date":"2023 年 3 月 28 日","externalUrl":null,"permalink":"/tags/security/","section":"Tags","summary":"","title":"Security","type":"tags"},{"content":" folly学习笔记 # 1 ThreadLocal 部分 # 参考的代码commit at 77e08c29d9f3b60b55dd74c1ceede35a8297e586，第一个就看ThreadLocal，是因为这几天解BUG涉及到这块，所以就先写了\n1.1 ThreadLocal的结构 # 参考folly自己对于threadlocal的描述，可以发现实际上针对每种Tag类型，只会占用一个pthreadke。参考实现能发现，folly内部实际上是一个per thread存储一个指针，这个指针指向一个ThreadEntry::elements数组\nSimilar speed as using pthread_getspecific directly, but only consumes a single pthread_key_t per Tag template param.\nWe keep a __thread array of pointers to objects (ThreadEntry::elements) where each array has an index for each unique instance of the ThreadLocalPtr object. Each ThreadLocalPtr object has a unique id that is an index into these arrays so we can fetch the correct object from thread local storage very efficiently.\nIn order to prevent unbounded growth of the id space and thus huge ThreadEntry::elements arrays, for example due to continuous creation and destruction of ThreadLocalPtr objects, we keep track of all active instances by linking them together into a list. When an instance is destroyed we remove it from the chain and insert the id into freeIds_ for reuse. These operations require a global mutex, but only happen at construction and destruction time. accessAllThreads also acquires this global mutex.\nWe use a single global pthread_key_t per Tag to manage object destruction and memory cleanup upon thread exit because there is a finite number of pthread_key_t\u0026rsquo;s available per machine.\n这个描述不够清楚，我再用自己的话简单描述一下，\ntemplate \u0026lt;class T, class Tag = void, class AccessMode = void\u0026gt; ThreadLocal，是ThreadLocalPtr的简单包裹，没有太多需要担心的东西\ntemplate \u0026lt;class T, class Tag = void, class AccessMode = void\u0026gt; ThreadLocalPtr，ThreadLocalPtr如果初始化的时候没有特别的初始化Tag，那么实际上都是从StaticMeta里面拿到具体的element的，简单陈述就是从static thread_local ThreadEntry* threadEntryTL的数组找到element然后拿出来\ntypedef threadlocal_detail::StaticMeta\u0026lt;Tag, AccessMode\u0026gt; StaticMeta，全局单例的静态元数据，里面放了一个pthread_key，用来在新线程找来的时候找到对应的thread_entry。默认的tag是void，意味着即使你存储着一堆不同类型T的对象，只要tag一致，它们都会放在一个thread_entry指向的element数组里面。\nstruct folly::threadlocal_detail::ThreadEntry，每个线程存储着自己的Per-thread entry，进程里面有几个StaticMeta，那么线程就会存储几个ThreadEntry。每次拿取threadentry都是从ThreadLocalPtr里面的get进去，然后就开始perthread的操作了\n用一张图来表示，就是ThreadLocalPtr统一入口，如果已经分配了Per-thread entry和元素，那就直接返回并分配，没分配的话就走第一次分配的流程，也就是下面1.2节的ThreadLocal第一次执行操作时的流程\n这个描述还没看明白的话，可以对着下面的操作流程看下\n1.2 ThreadLocal第一次执行操作时的流程 # 简单来说，当一个线程第一次调用folly::ThreadLocal的时候，实际上走的基本都是slow函数，调用关系伪代码如下\nolly::ThreadLocalPtr\u0026lt;T, Tag, AccessMode\u0026gt;::get() { olly::threadlocal_detail::StaticMeta\u0026lt;Tag, AccessMode\u0026gt;::get { if (tls entry capacity \u0026lt;= id) { StaticMeta\u0026lt;...\u0026gt;::getSlowReserveAndCache { tls entry = StaticMeta\u0026lt;Tag, AccessMode\u0026gt;::getThreadEntrySlow { tls entry = pthread_getspecific(meta.pthreadKey_) if （tls entry not set) alloc and pthread_setspecific return tls entry } if (tls entry capacity \u0026lt;= id) alloc and return tls entry } } threadEntry-\u0026gt;elements[id] } } 流程图还是不够精细，让我们直接来看源码，从最外层开始，走一遍一个线程第一次调用threadlocal类型的流程。\nThreadLocal 是ThreadLocalPtr的简单包裹，可以参考下面的代码，就是做个一个构造函数初始化一下，实际上每次get的时候都是拿取的tlp_，即自己的ThreadLocalPtr指针\ntemplate \u0026lt;class T, class Tag, class AccessMode\u0026gt; class ThreadLocalPtr; template \u0026lt;class T, class Tag = void, class AccessMode = void\u0026gt; class ThreadLocal { public: ... FOLLY_ERASE T* get() const { auto const ptr = tlp_.get(); return FOLLY_LIKELY(!!ptr) ? ptr : makeTlp(); } ... T* operator-\u0026gt;() const { return get(); } T\u0026amp; operator*() const { return *get(); } ... mutable ThreadLocalPtr\u0026lt;T, Tag, AccessMode\u0026gt; tlp_; std::function\u0026lt;T*()\u0026gt; constructor_; }; 那么ThreadLocalPtr的结果是什么，看下面实际上就包裹了一个StaticMeta::EntryID的对象，那么怎么做到的per线程？关注get函数StaticMeta::get(\u0026amp;id_);\ntemplate \u0026lt;class T, class Tag = void, class AccessMode = void\u0026gt; class ThreadLocalPtr { private: typedef threadlocal_detail::StaticMeta\u0026lt;Tag, AccessMode\u0026gt; StaticMeta; ... public: constexpr ThreadLocalPtr() : id_() {} T* get() const { threadlocal_detail::ElementWrapper\u0026amp; w = StaticMeta::get(\u0026amp;id_); return static_cast\u0026lt;T*\u0026gt;(w.ptr); } ... mutable typename StaticMeta::EntryID id_; }; 函数StaticMeta::get可以看到，有一个简单的判断，根据是否使用kUseThreadLocal，来拿取threadEntryTL，这是一个真正的static thread_local类型对象，每个线程都有独一的一份，注意，这里开始了第一次分化。如果当前的capacity小于ID，那就需要走getSlowReserveAndCache分配出来容量。有人问为什么需要id_很简单，当你编译ThreadLocalPtr的模板参数没有指定Tag时，就用的都是一套StaticMeta\u0026lt;void,void\u0026gt;::get，也就是说你存储不同类别的（T类别）的对象，最后都会被塞到一个StaticMeta\u0026lt;void,void\u0026gt;::get，拿的都是一套threadEntryNonTL，既然如此就得给这个threadEntryNonTL所保存的element数组多分配点空间和元素。\n如果你指定了独特的Tag，那么就不用多分配elements了，第一次分配了拿了就行。\n我们模拟的是一个新线程走这一块，那么我们可以认为threadEntryTL第一次就是个空指针，就会再往getSlowReserveAndCache里面走，如果是第二次到来且已经给新的id分配过空间了，那么可以直接就拿初始化过的threadEntryTL对应的element返回了\nFOLLY_EXPORT FOLLY_ALWAYS_INLINE static ElementWrapper\u0026amp; get(EntryID* ent) { // Eliminate as many branches and as much extra code as possible in the // cached fast path, leaving only one branch here and one indirection below. uint32_t id = ent-\u0026gt;getOrInvalid(); static thread_local ThreadEntry* threadEntryTL{}; ThreadEntry* threadEntryNonTL{}; auto\u0026amp; threadEntry = kUseThreadLocal ? threadEntryTL : threadEntryNonTL; static thread_local size_t capacityTL{}; size_t capacityNonTL{}; auto\u0026amp; capacity = kUseThreadLocal ? capacityTL : capacityNonTL; if (FOLLY_UNLIKELY(capacity \u0026lt;= id)) { getSlowReserveAndCache(ent, id, threadEntry, capacity); } return threadEntry-\u0026gt;elements[id]; } 顺着getSlowReserveAndCache查看调用过程，可以看到当前线程ThreadEntry thread local static指针被instance的threadEntry_函数赋值，这个地方threadEntry = inst.threadEntry_()这里拿到了当前数组的threadEntry，实际上的函数是getThreadEntrySlow。Here comes the fun part，是怎么拿到perthread的threadentry呢？\n首先还是找到instance，然后拿到该static StaticMeta\u0026lt;Tag, AccessMode\u0026gt;保存的pthread_key，毕竟是第一次走到这里，当前线程调用pthread_getspecific发现，呀，我这个线程还没有绑定这个key的独有空间。ok，那么我可得申请一个。\n先调用getThreadEntryList拿到StaticMeta的Theandentrylist，然后再构造一个static thread local类型entry，然后取地址挂到StaticMeta的链上。挂完了在把自己的tid和tid_os挂上，最终调用pthread_setspecific绑定该thread_entry，下这样子下次如果再进入getThreadEntrySlow就不需要再申请新的threadentry了，毕竟太慢了。\ngetThreadEntrySlow跑完了，实际上就可以分配element了，这时候就又回到了getSlowReserveAndCache里面，过程就比较直接了，inst里面reserve足够多的ent，然后拿一下id，返回即可，我们看看对应的reserve函数\nFOLLY_NOINLINE static void getSlowReserveAndCache( EntryID* ent, uint32_t\u0026amp; id, ThreadEntry*\u0026amp; threadEntry, size_t\u0026amp; capacity) { auto\u0026amp; inst = instance(); threadEntry = inst.threadEntry_(); if (UNLIKELY(threadEntry-\u0026gt;getElementsCapacity() \u0026lt;= id)) { inst.reserve(ent); id = ent-\u0026gt;getOrInvalid(); } capacity = threadEntry-\u0026gt;getElementsCapacity(); assert(capacity \u0026gt; id); } FOLLY_EXPORT FOLLY_NOINLINE static ThreadEntry* getThreadEntrySlow() { auto\u0026amp; meta = instance(); auto key = meta.pthreadKey_; ThreadEntry* threadEntry = static_cast\u0026lt;ThreadEntry*\u0026gt;(pthread_getspecific(key)); if (!threadEntry) { ThreadEntryList* threadEntryList = StaticMeta::getThreadEntryList(); if (kUseThreadLocal) { static thread_local ThreadEntry threadEntrySingleton; threadEntry = \u0026amp;threadEntrySingleton; } else { threadEntry = new ThreadEntry(); } // if the ThreadEntry already exists // but pthread_getspecific returns NULL // do not add the same entry twice to the list // since this would create a loop in the list if (!threadEntry-\u0026gt;list) { threadEntry-\u0026gt;list = threadEntryList; threadEntry-\u0026gt;listNext = threadEntryList-\u0026gt;head; threadEntryList-\u0026gt;head = threadEntry; } threadEntry-\u0026gt;tid() = std::this_thread::get_id(); threadEntry-\u0026gt;tid_os = folly::getOSThreadID(); // if we\u0026#39;re adding a thread entry // we need to increment the list count // even if the entry is reused threadEntryList-\u0026gt;count++; threadEntry-\u0026gt;meta = \u0026amp;meta; int ret = pthread_setspecific(key, threadEntry); checkPosixError(ret, \u0026#34;pthread_setspecific failed\u0026#34;); } return threadEntry; } reserve过程实际上是从新分配element数组的个数，可以认为是扩充以后把原本的element数组的内容再原样拷贝回去，所以得加锁。这里的reallocate过程实际上是有倍数的，其会根据情况在两个增长因子计算出来的数字做分配，简单说就是要么分配(idval + 5) * kSmallGrowthFactor，要么分配(idval + 5) * kBigGrowthFactor，+5是为了避免过慢增长。\nvoid StaticMetaBase::reserve(EntryID* id) { auto\u0026amp; meta = *this; ThreadEntry* threadEntry = (*threadEntry_)(); size_t prevCapacity = threadEntry-\u0026gt;getElementsCapacity(); uint32_t idval = id-\u0026gt;getOrAllocate(meta); if (prevCapacity \u0026gt; idval) { return; } size_t newCapacity; ElementWrapper* reallocated = reallocate(threadEntry, idval, newCapacity); // Success, update the entry { std::lock_guard\u0026lt;std::mutex\u0026gt; g(meta.lock_); if (reallocated) { /* * Note: we need to hold the meta lock when copying data out of * the old vector, because some other thread might be * destructing a ThreadLocal and writing to the elements vector * of this thread. */ if (prevCapacity != 0) { memcpy( reallocated, threadEntry-\u0026gt;elements, sizeof(*reallocated) * prevCapacity); } std::swap(reallocated, threadEntry-\u0026gt;elements); } for (size_t i = prevCapacity; i \u0026lt; newCapacity; i++) { threadEntry-\u0026gt;elements[i].node.initZero(threadEntry, i); } threadEntry-\u0026gt;setElementsCapacity(newCapacity); } free(reallocated); } 好了，threadlocalPtr部分就这个样子了\n1.3 Threadlocalptr的一些问题 # 一些问题，\n如果在执行getSlowReserveAndCache，上下文切换了，当前线程被丢到另外的cpu上执行怎么办？没啥问题，它是threadlocal，不是cpulocal，所以上下文都还是传递过去了。 为什么还需要pthread_key放在staticmeta里面，直接从静态函数进去走static pthread local，换句话说用c17以后的_thread不行吗？我理解是两点，但是感觉这解释也不太对劲 pthread_key这个东西，每个Meta只有一个，就能够大大节省_thread成员创建时候对内存的浪费 在主线程退出时，能针对性的去做清理，释放掉对应的tls 结尾 # 唉，尴尬\n","date":"2023 年 3 月 25 日","externalUrl":null,"permalink":"/posts/2023-03-25-folly%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"","title":"2023-03-25-folly学习笔记","type":"posts"},{"content":" 去tm的八股文 # 打不过就加入。。。\n1 C/C++部分 # const的作用\n修饰变量，说明变量不可被更改； 修饰指针要么是指向常量的指针const char* p，这个就是一个变量，它指向的是const char*即常量，要么是自身是常量的指针（常量指针）char* const p，这里的const修饰p； 修饰引用，指向常量的引用（reference to const），用于形参类型，即避免了拷贝，又避免了函数对值的修改； 修饰成员函数，说明该成员函数内部不能修改成员变量，写法为 int operator[](int idx) const Static的作用\n修饰普通变量，修改变量的存储区域和生命周期，使变量存储在静态区。且该变量不能在这个文件外面直接进行访问\n这里面有一个区别就是C++里面详细区分了local static storage和global static storage\n如果是函数内部的Static类型变量，在函数内部使用 static 关键字声明局部变量。这样，该变量的值会在函数调用之间保留，但只能在函数内部访问。这个变量实际上也是存储在静态区静态数据区（static data segment）\n修饰普通函数，使得外部文件不能直接使用该函数（这种文件范围的static可见性限制在C++里面通过嵌套一个匿名namespace废弃掉，但是这个feature估计短期还不会去掉）。\n修饰成员变量，修饰成员变量使所有的对象只保存一个该变量，而且不需要生成对象就可以访问该成员。\n修饰成员函数，使得不需要生成对象就可以访问该函数，但是在 static 函数内不能访问非静态成员。换言之就是类的static函数，别人可以直接使用。这个是C++新提供的\n单例模式（因为提到了static，所以直接给出单例模式），可以参考https://www.drdobbs.com/cpp/c-and-the-perils-of-double-checked-locki/184405726\n有问题的实现\n懒汉式：问题在于多个线程同时操作会有一致性+内存泄露的问题\nclass Singleton{\rprivate:\rSingleton(){}\rSingleton(Singleton\u0026amp;)=delete;\rSingleton\u0026amp; operator=(const Singleton\u0026amp;)=delete;\rstatic Singleton* m_instance_ptr;\rpublic:\r~Singleton(){}\rstatic Singleton* get_instance(){\rif(m_instance_ptr==nullptr){\rm_instance_ptr = new Singleton;\r}\rreturn m_instance_ptr;\r}\rvoid use() const { std::cout \u0026lt;\u0026lt; \u0026#34;in use\u0026#34; \u0026lt;\u0026lt; std::endl; }\r}; DCL（双检锁）懒汉式，这个实际上也有问题m_instance_ptr的判断实际上也可能受到一致性的问题\nclass Singleton{\rpublic:\rtypedef std::shared_ptr\u0026lt;Singleton\u0026gt; Ptr;\r~Singleton(){}\rSingleton(Singleton\u0026amp;)=delete;\rSingleton\u0026amp; operator=(const Singleton\u0026amp;)=delete;\rstatic Ptr get_instance(){\r// \u0026#34;double checked lock\u0026#34;\rif(m_instance_ptr==nullptr){\rstd::lock_guard\u0026lt;std::mutex\u0026gt; lk(m_mutex);\rif(m_instance_ptr == nullptr){\rm_instance_ptr = std::shared_ptr\u0026lt;Singleton\u0026gt;(new Singleton);\r}\r}\rreturn m_instance_ptr;\r}\rprivate:\rSingleton(){\rstd::cout\u0026lt;\u0026lt;\u0026#34;constructor called!\u0026#34;\u0026lt;\u0026lt;std::endl;\r}\rstatic Ptr m_instance_ptr;\rstatic std::mutex m_mutex;\r}; 饿汉式\n没问题的实现，使用了C++11保证的局部静态变量线程一致性。这里的Singleton的实例的生命周期从声明到程序结束，一直都存在，所以也是懒汉式，毕竟也是用到了才有\n懒汉式+CRTP（使用CRTP来保证肯定有方法）\ntemplate \u0026lt;typename T\u0026gt; class SingletonCRTP { public: static T\u0026amp; GetInstance() { static T instance; return instance; } // why must be protected? Derived Singleton will call implicited protected: SingletonCRTP() = default; ~SingletonCRTP() = default; // 禁止拷贝构造和赋值操作 SingletonCRTP(const SingletonCRTP\u0026amp;) = delete; SingletonCRTP\u0026amp; operator=(const SingletonCRTP\u0026amp;) = delete; }; class MySingleton : public SingletonCRTP\u0026lt;MySingleton\u0026gt; { public: void PrintMessage() { std::cout \u0026lt;\u0026lt; \u0026#34;This is a message from MySingleton.\u0026#34; \u0026lt;\u0026lt; std::endl; } }; 关于上面的CRTP，有一个有趣的地方，我写过一个task_pool的代码，内部使用范型进行代码管理，发现一个尴尬的问题，这里内存分配太大，然后程序崩了。。。把kDefaultSize改小就可以了。。。说实话，这个我是真没想到。。。\n#include \u0026lt;concepts\u0026gt; #include \u0026lt;type_traits\u0026gt; constexpr size_t kDefaultSize = 1024*1024*1024; template\u0026lt;typename T\u0026gt; concept HasXXXType = requires { typename T::xxx; }; template \u0026lt;typename T, size_t N = kDefaultSize\u0026gt; class Pool : public SingletonCRTP\u0026lt;Pool\u0026lt;T\u0026gt;\u0026gt; { friend class SingletonCRTP\u0026lt;Pool\u0026lt;T\u0026gt;\u0026gt;; public: Pool() : mpmc_(kDefaultSize) { std::cout \u0026lt;\u0026lt; \u0026#34; mpmc create with \u0026#34; \u0026lt;\u0026lt; kDefaultSize \u0026lt;\u0026lt; std::endl; } void Push(T::xxx\u0026amp; task) requires HasXXXType\u0026lt;T\u0026gt; { return mpmc_.push(task); } void Pop(T::xxx\u0026amp; task) requires HasXXXType\u0026lt;T\u0026gt; { return mpmc_.pop(task); } bool TryPush(T::xxx task) requires HasXXXType\u0026lt;T\u0026gt; { return mpmc_.try_push(task); } bool TryPop(T::xxx task) requires HasXXXType\u0026lt;T\u0026gt; { return mpmc_.try_pop(task); } private: // 这里就可以随便写了，比方说使用rigtorp的mpmc来存储对应T的某个类型 }; inline的作用\n内联函数展开，直接执行函数体，避免参数压栈，针栈开辟回收啥的，但会做安全检查或自动类型转换（同普通函数 只是建议编译器展开，具体是否展开不一定，编译器一般不内联包含循环、递归、switch 等复杂操作的内联函数； 在类声明中定义的函数，除了虚函数的其他函数都会自动隐式地当成内联函数。 问题1:虚函数可以是内连函数吗？虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。毕竟runtime鬼知道是谁 volatile的作用\nvolatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素（操作系统、硬件、其它线程等）更改。所以使用 volatile 告诉编译器不应对这样的对象进行优化。 volatile 关键字声明的变量，每次访问时都必须从内存中取出值 我基本不用这个，多线程下这个volatile没同步，没有内存屏障，甚至执行顺序都不保证。实际上C++11之后就基本都是什么内存序的东西，对这个也不吭声了，哈哈哈哈。这个除非是直接硬件底层编程，比方说嵌入式啥的有承诺才用 #program pack(n)的作用\n设定结构体、联合以及类成员变量以 n 字节方式对齐。#program经常用来关闭特定类型的warn消息，也用来pack struct。一般来说，如果要设定的结构体是个精确控制的内存map结构，换言之要求多少多少字节的位置是成员变量的位置才需要这个东西\n一般你以多少字节对齐？64位GCC一般是8字节对齐\n补充对齐的基础知识：\n结构体第一个成员的偏移量（offset）为0，以后每个成员相对于结构体首地址的 offset 都是该成员大小与实际的对齐值\t中较小那个的整数倍，如有需要编译器会在成员之间加上填充字节。 结构体的总大小为 实际的对齐值 的整数倍，如有需要编译器会在最末一个成员之后加上填充字节。 关于对齐值：\n基本类型的对齐值就是其sizeof值 结构体的对齐值是其成员的最大对齐值 编译器可以设置一个对齐值，但是类型的实际对齐值是该类型的对齐值与设定的对齐值取最小值得来。 结构体的成员为数组的时候，计算对齐值是根据数据元素的长度，而不是数组的整体大小 c++构造相关\nexplict关键字\nexplicit 修饰构造函数时，可以防止隐式转换和复制初始化 explicit 修饰转换函数时，可以防止隐式转换，但 按语境转换 除外 成员初始化列表\n好处为初始化列表不需要定义默认构造函数，直接就会调用对应的构造函数\n使用方法为\n有些场合必须用初始化列表\n常量成员：常量成员只能初始化，不能赋值，所以必须放在初始化列表里 引用类型：引用类型必须在定义时初始化，切不能重新赋值 没有默认构造函数的类型：使用初始化列表不需要默认构造函数构造 如何定义一个只能在堆上生成对象的类：\n方法1(比较糟糕的方法）：将析构函数设置为私有，原因：C++ 是静态绑定语言，编译器管理栈上对象的生命周期，编译器在为类对象分配栈空间时，会先检查类的析构函数的访问性。若析构函数不可访问，则不能在栈上创建对象。初次之外，还需要 禁用拷贝构造: 防止通过拷贝构造函数在栈上创建对象的副本。 禁用赋值操作符: 防止通过赋值操作符将一个堆对象赋值给栈对象。 方法2：将构造函数全都定义为Protected/Privated类型，即禁用栈分配。然后创建一个Static函数，代表静态工厂方法: 提供一个静态的 Create() 方法，该方法在堆上分配内存并返回一个 std::unique_ptr，指向新创建的对象。 如何定义一个只能在栈上生成对象的类：\n将 new 和 delete 重载为私有，原因：在堆上生成对象，使用 new 关键词操作，其过程分为两阶段：第一阶段，使用 new 在堆上寻找可用内存，分配给对象；第二阶段，调用构造函数生成对象。将 new 操作设置为私有，那么第一阶段就无法完成，就不能够在堆上生成对象。 多态 \u0026amp; 虚函数\n如何实现的？ 虚函数指针：在含有虚函数类的对象中，指向虚函数表，在运行时确定。 虚函数表：在程序只读数据段（.rodata section，见：目标文件存储结构），存放虚函数指针，如果派生类实现了基类的某个虚函数，则在虚表中覆盖原本基类的那个虚函数指针，在编译时根据类的声明创建。 构造函数能是虚函数吗？奇怪的问题，因为构造的时候都是直接确定要哪个类型的对象，难道还能不确定是啥构造吗？另外In a constructor, the virtual call mechanism is disabled because overriding from derived classes hasn’t yet happened. Objects are constructed from the base up, “base before derived”. 构造函数里面调用虚函数靠谱吗？不靠谱Calling virtual functions from a constructor or destructor is dangerous and should be avoided whenever possible. All C++ implementations should call the version of the function defined at the level of the hierarchy in the current constructor and no further. 虚函数可以是inline的吗？虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。因为inline是编译的时候确定，而虚函数表现为多态性时（运行期）确定，因此不可以内联。 析构函数能是虚函数吗？析构函数可以是虚函数，另外基类的析构函数一般建议声明为虚函数，否则析构的时候（如果是删除一个基类指针，这个指针指向一个子类对象）那么会造成内存泄漏，因为不定义虚函数，不会调用子类的析构函数。简单说为了解决基类的指针指向派生类对象，并用基类的指针删除派生类对象。 Decltype\ndecltype 关键字用于检查实体的声明类型或表达式的类型及值分类，说的似乎不是人话，简单说就是decltype is useful when declaring types that are difficult or impossible to declare using standard notation, like lambda-related types or types C++引用\n左值引用，常规引用表示对象的身份\n右值引用，必须绑定到右值（一个临时对象、将要销毁的对象）的引用。实现转移语义（Move Sementics）和精确传递（Perfect Forwarding）\n它可以消除两个对象交互时不必要的对象拷贝； 能够更简洁明确地定义泛型函数。 C++左值 \u0026amp; 右值\n真正的理解，看https://en.cppreference.com/w/cpp/language/value_category， 左值和右值实际上定义看这里\n前置定义：\na glvalue (“generalized” lvalue) is an expression whose evaluation determines the identity of an object or function; 这里实际上将对象和函数都视为了一类成员\na prvalue (“pure” rvalue) is an expression whose evaluation\ncomputes the value of an operand of a built-in operator (such prvalue has no result object), or\ninitializes an object (such prvalue is said to have a result object).\nThe result object may be a variable, an object created by new-expression, a temporary created by temporary materialization, or a member thereof. Note that non-void discarded expressions have a result object (the materialized temporary). Also, every class and array prvalue has a result object except when it is the operand of decltype;\nan xvalue (an “eXpiring” value) is a glvalue that denotes an object whose resources can be reused; 根本定义\nan lvalue is a glvalue that is not an xvalue; an rvalue is a prvalue or an xvalue; 概念上理解左值右值过于离谱，简单说就是\n右值就是纯右值+消亡值 左值就是上述的其他 这里又引出来几个新的问题\nfoo(T a)\nPass-by-Value\n传值会导致拷贝构造，这种情况下无论传递的是左值还是右值，都会导致出现一次\n对于右值，移动构造的语意优先级更高，所以对于右值而言通常优先调用移动构造函数。但是如果移动构造函数被=delete，就会调用拷贝构造函数 foo(T \u0026amp;a)\nPass-by-Reference 调用的时候，只有传递左值才能正确调用，操作也是在左值上操作 foo(T \u0026amp;\u0026amp;a)\nPass-by-Rvalue-Reference C11相关的东西\n智能指针\nshared_ptr\nClass shared_ptr 实现共享式拥有（shared ownership）概念。多个智能指针指向相同对象，该对象和其相关资源会在 “最后一个 reference 被销毁” 时被释放。为了在结构较复杂的情景中执行上述工作，标准库提供 weak_ptr、bad_weak_ptr 和 enable_shared_from_this 等辅助类。\n线程安全：计数器是原子的，但是包裹的对象不一定是\n内存安全：\n可能存在的内存泄漏的点，参考https://stackoverflow.com/questions/38298008/possible-memory-leaks-with-smart-pointers\nshared_ptr环引用，最简单的情况是两个智能指针互指，稍微复杂一些就是， a shared_ptr to A, which directly or indirectly holds a shared_ptr back to A, A\u0026rsquo;s use count will be 2.。英文是circular references like this，解决方式是把一个换成weak_ptr，one object should hold a weak_ptr to the other, not a shared_ptr. 另一种内存泄露的点，在于shared_ptr可能在将new出来的对象真正转换为shared_ptr的时候，因为其他流程崩溃而造成内存泄露。比方说下面的代码，可能在第二步操作就抛异常退出了。不过C++17开始保证函数执行顺序了，所以理论上这个情况也避免了 processThing(std::shared_ptr\u0026lt;MyThing\u0026gt;(new MyThing()), get_num_samples()); // 1 第一步操作 new MyThing() // 2 第二步操作，在这里crash了 get_num_samples() // 3 第三步操作 std::shared_ptr\u0026lt;MyThing\u0026gt;() std::enable_shared_from_this 在 C++ 中的作用是：让一个类的成员函数能够安全地返回一个指向该类对象的 shared_ptr，从而避免潜在的内存问题。\n问题背景：\n假设你有一个类 Example，你想在其成员函数 get_shared_this() 中返回一个指向自身的 shared_ptr，这个方法有个严重的问题是当外部有两个独立的 shared_ptr 分别管理 this 对象时，会出现 double-free 问题。因为这两个 shared_ptr 的引用计数是独立的，当它们都析构时，会重复释放 this 对象。 class Example {\rpublic:\rstd::shared_ptr\u0026lt;Example\u0026gt; get_shared_this() {\rreturn std::shared_ptr\u0026lt;Example\u0026gt;(this); // 潜在的危险！\r}\rprivate:\r// ...\r}; 解决办法\n继承: 让 Example 类继承自 std::enable_shared_from_this\u0026lt;Example\u0026gt;。\nweak_ptr: enable_shared_from_this 内部维护一个 weak_ptr 指向 this 对象。\nshared_from_this(): 提供 shared_from_this() 成员函数，它通过内部的 weak_ptr 安全地构造 shared_ptr。\nunique_ptr\nClass unique_ptr 实现独占式拥有（exclusive ownership）或严格拥有（strict ownership）概念，保证同一时间内只有一个智能指针可以指向该对象。你可以移交拥有权。它对于避免内存泄漏（resource leak）——如 new 后忘记 delete ——特别有用。 weak_ptr\nweak_ptr 允许你共享但不拥有某对象，一旦最末一个拥有该对象的智能指针失去了所有权，任何 weak_ptr 都会自动成空（empty）。因此，在 default 和 copy 构造函数之外，weak_ptr 只提供 “接受一个 shared_ptr” 的构造函数。 auto_ptr（被 C++11 弃用）\n类型转换\nstatic_cast：1 用于非多态类型的转换 2 不执行运行时类型检查（转换安全性不如 dynamic_cast） dynamic_cast：1 用于多态类型的转换 2 执行行运行时类型检查 const_cast: 用于删除 const、volatile 和 __unaligned 特性（如将 const int 类型转换为 int 类型 ） 运行时类型信息(RTTI)\ntypeid，typeid 运算符允许在运行时确定对象的类型；type_id 返回一个 type_info 对象的引用 typeinfo，type_info 类描述编译器在程序中生成的类型信息。 此类的对象可以有效存储指向类型的名称的指针。 多态\n静态多态，函数重载\n动态多态，运行绑定\n原子操作怎么实现\nin pre-C++ 11 times, had to be performed using (for example) interlocked functions with MSVC or atomic bultins in case of GCC.\nA regular int has atomic loads and stores. Whats the point of wrapping it with atomic\u0026lt;\u0026gt;?our statement is only true for architectures that provide such guarantee of atomicity for stores and/or loads. There are architectures that do not do this. Also, it is usually required that operations must be performed on word-/dword-aligned address to be atomic\nUser level locks involve utilizing the atomic instructions of processor to atomically update a memory space. The atomic instructions involve utilizing a lock prefix on the instruction and having the destination operand assigned to a memory address. The following instructions can run atomically with a lock prefix on current Intel processors: ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG. [\u0026hellip;] On most instructions a lock prefix must be explicitly used except for the xchg instruction where the lock prefix is implied if the instruction involves a memory address\nIn the days of Intel 486 processors, the lock prefix used to assert a lock on the bus along with a large hit in performance. Starting with the Intel Pentium Pro architecture, the bus lock is transformed into a cache lock. A lock will still be asserted on the bus in the most modern architectures if the lock resides in uncacheable memory or if the lock extends beyond a cache line boundary splitting cache lines. Both of these scenarios are unlikely, so most lock prefixes will be transformed into a cache lock which is much less expensive.\nThis means the CPU delays responding to MESI requests to invalidate or share the cache line, keeping exclusive access so no other CPU can look at it. MESI cache coherency always requires exclusive ownership of a cache line before a core can modify it so this is cheap if we already owned the line\n2 操作系统部分 # 死锁的条件\n进程和线程\n进程是资源分配的独立单位，线程是资源调度的独立单位\n进程的内存布局\n高地址\r+------------------+\r| 栈 | \u0026lt;- ebp (高地址),\r+------------------+ //栈存放参数,局部变量。通常也就几MB大小\r| | \u0026lt;- esp\r| |\r+------------------+\r| 堆 | \u0026lt;- 堆顶 //\r| |\r| |\r+------------------+\r| 共享库区域 |\r+------------------+\r| |\r| 数据段(.bss) |\r| |\r+------------------+\r| 数据段(.data) |\r+------------------+\r| 代码段 |\r+------------------+\r| 命令行参数/环境变量 |\r+------------------+\r低地址 详细描述\n栈：由操作系统自动分配释放，存放函数的参数值、局部变量等的值，用于维护函数调用的上下文 栈的大小一般是有限制的，用来避免占用过多内存资源，linux默认应该是8192 kb 堆：一般由程序员分配释放，若程序员不释放，程序结束时可能由操作系统回收，用来容纳应用程序动态分配的内存区域 堆的大小是否有限制？理论上，堆的大小可以非常大，甚至可以达到 GB 级别 共享库：存储程序运行时动态加载的共享库代码和数据。 数据端：存储程序中已初始化的全局变量和静态变量。 根据数据类型的不同，数据段进一步划分为： 初始化数据段（.data）：存储已经初始化的非零全局变量和静态变量。 未初始化数据段（.bss）：存储未初始化或者初始化为零的全局变量和静态变量。 代码端：存储程序的可执行代码，也就是机器指令。 进程之间私有和共享的资源\n线程之间共享和私有的资源\n私有： 栈(Stack): 每个线程拥有独立的栈空间，用于存储函数调用信息、局部变量以及函数参数等。这意味着不同线程的局部变量互不干扰，即使变量名相同，也位于不同的内存地址。 寄存器: 线程在执行过程中需要使用CPU寄存器存储临时数据。每个线程拥有独立的寄存器组，确保线程切换时数据得以保存。 线程本地存储(TLS, Thread Local Storage): 这是专门为线程私有数据设计的机制。通过TLS，可以创建全局变量，但每个线程访问的是该变量的私有副本。 共享： 堆(Heap): 堆内存是所有线程共享的区域，用于动态分配内存。这意味着任何线程都可以访问和修改堆上的数据，因此需要特别注意数据同步和互斥访问。 全局变量: 位于全局作用域的变量是所有线程共享的。对全局变量的读写操作需要进行同步控制，否则可能导致数据竞争和程序错误。 静态变量: 静态变量的生命周期贯穿整个程序运行，所有线程都可以访问。与全局变量类似，对静态变量的操作也需要进行同步控制。 文件、数据库等外部资源: 多个线程可能同时访问同一个文件、数据库连接等外部资源。为了避免数据混乱，需要协调线程对这些资源的访问。 ELF相关：\n对应于 程序通信的手段\n无名管道( pipe )； 高级管道(popen)； 有名管道 (named pipe)； 消息队列( message queue )； 信号量( semophore )； 共享内存( shared memory )； 套接字( socket )。 线程通信的手段\n大端序和小端序，x86 linux是小端\nLittle-Endian就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。\nBig-Endian就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。\n举一个例子，比如数字0x12 34 56 78在内存中的表示形式为：\n1)大端模式：\n低地址 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt; 高地址 0x12 | 0x34 | 0x56 | 0x78\n2)小端模式：\n低地址 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt; 高地址 0x78 | 0x56 | 0x34 | 0x12\n页面置换算法\nfifo lru opt 内核部分\n上下文切换 3 网络部分 # 基础，协议分层五层\n应用层， 传输层，端到端的报文传递，TCP，UDP 网络层，负责数据包从源到宿的传递，IP，ICMP，ARP 数据链路 物理层 从浏览器输入网址，到网页返回发生的过程\nTCP\n该协议的特点：面向连接；只能端到端；全双工；可靠交互；面向字节流\n怎么保证可靠性\n确认和重传机制：\n序列号和确认号： TCP 使用序列号对每个字节进行编号，接收方使用确认号来告知发送方已成功接收的数据。 超时重传： 发送方在发送数据包后会启动一个计时器，如果在计时器超时前没有收到接收方的确认，则会重新发送该数据包。 累积确认： 接收方不必为每个收到的数据包都发送确认，可以累积确认多个数据包，提高效率。 流量控制：\n滑动窗口机制： 接收方通过通告窗口大小来限制发送方发送数据的速率，避免发送方发送数据过快导致接收方缓冲区溢出。\n拥塞控制： 当网络出现拥塞时，TCP 会自动降低发送速率，避免加剧网络拥塞。\n慢启动 (Slow Start)\n初始阶段： 连接建立之初，发送方维护一个拥塞窗口 (cwnd)，初始值很小，通常为 1 个报文段大小 (MSS)。 指数增长： 每收到一个 ACK 确认，拥塞窗口大小就翻倍，实现发送速率的指数增长，快速探测网络容量。 慢启动门限 (ssthresh)： 当拥塞窗口大小达到慢启动门限值时，慢启动阶段结束，进入拥塞避免阶段。 2. 拥塞避免 (Congestion Avoidance)\n线性增长： 拥塞窗口超过慢启动门限后，每收到一个 ACK，拥塞窗口大小只增加 1 个 MSS，实现发送速率的线性增长，避免网络拥塞。 3. 快速重传 (Fast Retransmit)\n重复 ACK： 当接收方发现数据包丢失时，会发送重复的 ACK，提示发送方进行重传。 快速重传： 发送方如果连续收到 3 个重复 ACK，则认为数据包丢失，立即进行重传，无需等待超时计时器。 4. 快速恢复 (Fast Recovery)\n拥塞窗口减半： 快速重传发生后，将慢启动门限设置为当前拥塞窗口大小的一半。 拥塞窗口调整： 将拥塞窗口设置为慢启动门限值 + 3 个 MSS，开始执行拥塞避免算法。 校验和：\nTCP 报文段首部包含校验和字段，用于校验数据在传输过程中是否出现错误。 连接管理：\n三次握手： 在传输数据前，TCP 使用三次握手建立可靠的连接，确保双方都准备好进行数据传输。 四次挥手： 数据传输结束后，TCP 使用四次挥手断开连接，确保数据传输完整。 三次握手\n为什么需要三次握手：因为信道不可靠，而 TCP 想在不可靠信道上建立可靠地传输，那么三次通信是理论上的最小值。（而 UDP 则不需建立可靠传输，因此 UDP 不需要三次握手。）简单来说就是攀岩，山上扽扽绳子，山下扽扽绳子\n四次挥手\nTCP 为什么要进行四次挥手？ / 为什么 TCP 建立连接需要三次，而释放连接则需要四次？因为 TCP 是全双工模式，客户端请求关闭连接后，客户端向服务端的连接关闭（一二次挥手），服务端继续传输之前没传完的数据给客户端（数据传输），服务端向客户端的连接关闭（三四次挥手）。所以 TCP 释放连接时服务器的 ACK 和 FIN 是分开发送的（中间隔着数据传输），而 TCP 建立连接时服务器的 ACK 和 SYN 是一起发送的（第二次握手），所以 TCP 建立连接需要三次，而释放连接则需要四次。\n为什么 TCP 连接时可以 ACK 和 SYN 一起发送，而释放时则 ACK 和 FIN 分开发送呢？（ACK 和 FIN 分开是指第二次和第三次挥手）因为客户端请求释放时，服务器可能还有数据需要传输给客户端，因此服务端要先响应客户端 FIN 请求（服务端发送 ACK），然后数据传输，传输完成后，服务端再提出 FIN 请求（服务端发送 FIN）；而连接时则没有中间的数据传输，因此连接时可以 ACK 和 SYN 一起发送。\n为什么客户端释放最后需要 TIME-WAIT 等待 2MSL 呢？为了保证客户端发送的最后一个 ACK 报文能够到达服务端。若未成功到达，则服务端超时重传 FIN+ACK 报文段，客户端再重传 ACK，并重新计时；另外防止已失效的连接请求报文段出现在本连接中。TIME-WAIT 持续 2MSL 可使本连接持续的时间内所产生的所有报文段都从网络中消失，这样可使下次连接中不会出现旧的连接报文段。\n如果有大量timewait，说明我们关闭了大量的连接，\n如果有大量closewait，close_wait的大量出现说明我们作为服务端（关闭的被动方，客户端发起的关闭连接），用户层程序没有把连接关闭，因此占用了大量的closewait和端口。对于服务端而言，这种往往是因为负载均衡器发起了关闭，但是负载均衡器后面的服务没有执行关闭。\n为什么服务一般建议调整timewait和closewait，虽然端口数量和tcp连接数量没直接关系，毕竟tcp四元组嘛。但是每个进程能打开的文件描述符是有限制的，所以一般会建议调整timewait。不过也可以调整打开的文件描述符数量\nIP报文最大报文和TCP报文最大报文什么区别，如果TCP报文长度大于IP报文呢\nUDP\nTCP和UDP的区别\nTCP 面向连接，UDP 是无连接的； TCP 提供可靠的服务，也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付 TCP 的逻辑通信信道是全双工的可靠信道；UDP 则是不可靠信道 每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信 UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等） DNS协议\nHTTP错误码\n200 400 403 404 500 503 网络编程\n4 编程题 # 使用C++实现简单的智能指针\nuniqure_ptr template \u0026lt;typename T\u0026gt;\rclass UniquePtr {\rT* ptr;\rpublic:\r// 这里为什么要加上explicit？隐式转换可能会导致副作用，因此禁止\r// // 假设 SomeClass 是已经定义的类\r// SomeClass* raw_ptr = new SomeClass();\r// UniquePtr\u0026lt;SomeClass\u0026gt; ptr1 = raw_ptr; // 隐式转换\r// // void fn(UniquePtr\u0026lt;SomeClass\u0026gt; p) { /* ... */ };\r// SomeClass* raw_ptr = new SomeClass();\r// fn(raw_ptr); // raw_ptr 会被隐式转换为 UniquePtr\r// 因此将接受原始指针、手动管理资源的智能指针的构造函数声明为 explicit\rexplicit UniquePtr(T* p = nullptr) : ptr(p) {}\r~UniquePtr() {\rdelete ptr;\r}\rUniquePtr(UniquePtr \u0026amp;\u0026amp;up) : ptr(up.ptr) {\rup.ptr = nullptr;\r}\rUniquePtr \u0026amp;operator=(UniquePtr \u0026amp;\u0026amp;up) {\rif (this != \u0026amp;up) {\rdelete ptr;\rptr = up.ptr;\rup.ptr = nullptr;\r}\rreturn *this;\r}\rT \u0026amp;operator* () const { return *ptr; }\rT *operator-\u0026gt; () const { return ptr; }\r// disable copy UniquePtr(const UniquePtr\u0026amp;) = delete;\rUniquePtr\u0026amp; operator=(const UniquePtr\u0026amp;) = delete;\r}; shared_ptr #include \u0026lt;atomic\u0026gt;\rtemplate\u0026lt;typename T\u0026gt;\rclass SharedPtr {\rprivate:\rT* ptr_;\rstd::atomic\u0026lt;int\u0026gt;* count_;\rpublic:\rSharedPtr(T* ptr = nullptr): ptr_(ptr) {\rif (ptr != nullptr) {\rcount_= new std::atomic\u0026lt;int\u0026gt;(1);\r}\r}\r~SharedPtr() {\rif(ptr_ != nullptr \u0026amp;\u0026amp; --*count==0) {\rdelete ptr_;\rptr_ = nullptr;\rdelete count_;\rcount_ = nullptr;\r}\r}\r// 拷贝构造函数不需要考虑是不是给自己赋值的情况\rSharedPtr(const SharedPtr\u0026amp; rhs) {\rcount_= rhs.count_;\rptr_ = rhs.ptr_;\rif (count_ != nullptr) {\r++(*count_);\r}\r}\rSharedPtr\u0026amp; operator=(const SharedPtr\u0026amp; rhs) {\rif (this != \u0026amp;rhs) {\rif (ptr_ !=nullptr \u0026amp;\u0026amp; --(*count_) == 0) {\rdelete ptr_;\rptr_ == nullptr;\rdelete count_;\rcount_ = nullptr;\r}\rptr_ = rhs.ptr_;\rcount_ = rhs.count_;\rif (count_ != nullptr) {\r++(*count_);\r}\r}\rreturn *this;\r}\rT\u0026amp; operator*() {\rreturn *ptr;\r}\rT* operator-\u0026gt;(){\rreturn ptr;\r}\r}\r// 支持自定义删除器的shared_ptr\rtemplate \u0026lt;typename T\u0026gt;\rclass MySharedPtr {\rpublic:\r// 构造函数\rMySharedPtr(T* ptr = nullptr, void (*deleter)(T*) = nullptr) : ptr_(ptr), deleter_(deleter), count_(ptr ? new std::atomic\u0026lt;int\u0026gt;(1) : nullptr) {}\r// 拷贝构造函数\rMySharedPtr(const MySharedPtr\u0026amp; other) : ptr_(other.ptr_), deleter_(other.deleter_), count_(other.count_) {\rif (count_) {\r(*count_)++;\r}\r}\r// 赋值运算符\rMySharedPtr\u0026amp; operator=(const MySharedPtr\u0026amp; other) {\rif (this != \u0026amp;other) {\r// 减少当前对象的引用计数\rif (count_ \u0026amp;\u0026amp; --(*count_) == 0) {\rif (deleter_) {\rdeleter_(ptr_);\r} else {\rdelete ptr_;\r}\rdelete count_;\r}\r// 复制新对象的指针和引用计数\rptr_ = other.ptr_;\rdeleter_ = other.deleter_;\rcount_ = other.count_;\rif (count_) {\r(*count_)++;\r}\r}\rreturn *this;\r}\r// 析构函数\r~MySharedPtr() {\rif (count_ \u0026amp;\u0026amp; --(*count_) == 0) {\rif (deleter_) {\rdeleter_(ptr_);\r} else {\rdelete ptr_;\r}\rdelete count_;\r}\r}\r// 解引用运算符\rT\u0026amp; operator*() const { return *ptr_; }\rT* operator-\u0026gt;() const { return ptr_; }\r// 获取原始指针\rT* get() const { return ptr_; }\r// 获取引用计数\rint use_count() const { return count_ ? count_-\u0026gt;load() : 0; }\rprivate:\rT* ptr_; // 指向管理对象的指针\rvoid (*deleter_)(T*); // 自定义删除器\rstd::atomic\u0026lt;int\u0026gt;* count_; // 引用计数\r}; 实现shared_ptr和weak_ptr，并且实现enable_shared_from_this\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;atomic\u0026gt; // 引入 \u0026lt;atomic\u0026gt; 头文件 // 前向声明避免循环依赖 template \u0026lt;typename T\u0026gt; class SharedPtr; template \u0026lt;typename T\u0026gt; class WeakPtr; template \u0026lt;typename T\u0026gt; class ControlBlock { public: T* ptr; std::atomic\u0026lt;std::size_t\u0026gt; strong_count; std::atomic\u0026lt;std::size_t\u0026gt; weak_count; ControlBlock(T* p) : ptr(p), strong_count(1), weak_count(0) {} ~ControlBlock() { delete ptr; } }; template \u0026lt;typename T\u0026gt; class enable_shared_from_this { public: SharedPtr\u0026lt;T\u0026gt; shared_from_this() { return weak_this.lock(); } private: WeakPtr\u0026lt;T\u0026gt; weak_this; friend class SharedPtr\u0026lt;T\u0026gt;; }; template \u0026lt;typename T\u0026gt; class WeakPtr; template \u0026lt;typename T\u0026gt; class SharedPtr { public: SharedPtr() : control_block(nullptr) {} explicit SharedPtr(T* ptr) : control_block(new ControlBlock\u0026lt;T\u0026gt;(ptr)) { if (auto esf = dynamic_cast\u0026lt;enable_shared_from_this\u0026lt;T\u0026gt;*\u0026gt;(ptr)) { esf-\u0026gt;weak_this = *this; } } SharedPtr(const SharedPtr\u0026amp; other) : control_block(other.control_block) { if (control_block) { ++control_block-\u0026gt;strong_count; } } SharedPtr(const WeakPtr\u0026lt;T\u0026gt;\u0026amp; weak_ptr); ~SharedPtr() { release(); } T* operator-\u0026gt;() const { return control_block-\u0026gt;ptr; } T\u0026amp; operator*() const { return *(control_block-\u0026gt;ptr); } SharedPtr\u0026amp; operator=(const SharedPtr\u0026amp; other) { if (this != \u0026amp;other) { release(); control_block = other.control_block; if (control_block) { ++control_block-\u0026gt;strong_count; } } return *this; } std::size_t use_count() const { return control_block ? control_block-\u0026gt;strong_count.load() : 0; } private: void release() { if (control_block) { if (--control_block-\u0026gt;strong_count == 0) { delete control_block-\u0026gt;ptr; // 仅删除对象 control_block-\u0026gt;ptr = nullptr; // 避免悬挂指针 // 如果所有的 weak_ptr 也都不存在了，才删除控制块 if (control_block-\u0026gt;weak_count == 0) { delete control_block; } } } } ControlBlock\u0026lt;T\u0026gt;* control_block; friend class WeakPtr\u0026lt;T\u0026gt;; }; template \u0026lt;typename T\u0026gt; class WeakPtr { public: WeakPtr() : control_block(nullptr) {} WeakPtr(const SharedPtr\u0026lt;T\u0026gt;\u0026amp; shared_ptr) : control_block(shared_ptr.control_block) { if (control_block) { ++control_block-\u0026gt;weak_count; } } WeakPtr(const WeakPtr\u0026amp; other) : control_block(other.control_block) { if (control_block) { ++control_block-\u0026gt;weak_count; } } ~WeakPtr() { release(); } SharedPtr\u0026lt;T\u0026gt; lock() const { if (control_block \u0026amp;\u0026amp; control_block-\u0026gt;strong_count \u0026gt; 0) { return SharedPtr\u0026lt;T\u0026gt;(*this); } return SharedPtr\u0026lt;T\u0026gt;(); } WeakPtr\u0026amp; operator=(const WeakPtr\u0026amp; other) { if (this != \u0026amp;other) { release(); control_block = other.control_block; if (control_block) { ++control_block-\u0026gt;weak_count; } } return *this; } private: void release() { if (control_block) { if (--control_block-\u0026gt;weak_count == 0 \u0026amp;\u0026amp; control_block-\u0026gt;strong_count == 0) { delete control_block; } } } ControlBlock\u0026lt;T\u0026gt;* control_block; friend class SharedPtr\u0026lt;T\u0026gt;; }; template \u0026lt;typename T\u0026gt; SharedPtr\u0026lt;T\u0026gt;::SharedPtr(const WeakPtr\u0026lt;T\u0026gt;\u0026amp; weak_ptr) : control_block(weak_ptr.control_block) { if (control_block \u0026amp;\u0026amp; control_block-\u0026gt;strong_count \u0026gt; 0) { ++control_block-\u0026gt;strong_count; } else { control_block = nullptr; } } class Test : public enable_shared_from_this\u0026lt;Test\u0026gt; { public: void show() { std::cout \u0026lt;\u0026lt; \u0026#34;Test::show() called\u0026#34; \u0026lt;\u0026lt; std::endl; } }; int main() { SharedPtr\u0026lt;Test\u0026gt; sp1(new Test()); std::cout \u0026lt;\u0026lt; \u0026#34;sp1 use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; // 1 SharedPtr\u0026lt;Test\u0026gt; sp2 = sp1-\u0026gt;shared_from_this(); std::cout \u0026lt;\u0026lt; \u0026#34;sp1 use count after shared_from_this: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; // 2 sp1-\u0026gt;show(); sp2-\u0026gt;show(); return 0; } 在C++11实现信号量\n//C++11 信号量 #include \u0026lt;mutex\u0026gt; #include \u0026lt;condition_variable\u0026gt; class Semaphore { public: Semaphore(int count_ = 0) : count(count_) {} void Signal() { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mtx); ++count; cv.notify_one(); } void Wait() { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mtx); while(count \u0026lt;= 0) { cv.wait(lock); } --count; } private: std::mutex mtx; std::condition_variable cv; int count; }; 给你一个类：\npublic class Foo {\rpublic void first() { print(\u0026#34;first\u0026#34;); }\rpublic void second() { print(\u0026#34;second\u0026#34;); }\rpublic void third() { print(\u0026#34;third\u0026#34;); }\r} 三个不同的线程 A、B、C 将会共用一个 Foo 实例。\n线程 A 将会调用 first() 方法 线程 B 将会调用 second() 方法 线程 C 将会调用 third() 方法 请设计修改程序，以确保 second() 方法在 first() 方法之后被执行，third() 方法在 second() 方法之后被执行。这个题目也可以看为“三个线程，交替打印x,y,z请问如何实现”的简单版本\n// 两种解法，一种是利用条件变量，另一种利用信号量 // 解法1 利用条件变量的做法,这里的打印是循环打印 class Foo { private: std::mutex mtx; std::condition_variable cv; int k = 0; public: Foo() { } void first(function\u0026lt;void()\u0026gt; printFirst) { while(true) { std::unique_lock\u0026lt;mutex\u0026gt; lock(mtx); cv.wait(lock, [this](){return k == 0;}); printFirst(); k = 1; cv.notify_all(); } } void second(function\u0026lt;void()\u0026gt; printSecond) { while(true) { std::unique_lock\u0026lt;mutex\u0026gt; lock(mtx); cv.wait(lock, [this](){return k == 1;}); printSecond(); k = 2 ; cv.notify_all(); } } void third(function\u0026lt;void()\u0026gt; printThird) { while(true) { std::unique_lock\u0026lt;mutex\u0026gt; lock(mtx); cv.wait(lock, [this](){return k == 2;}); printThird(); k = 0 ; cv.notify_all(); } // printThird() outputs \u0026#34;third\u0026#34;. Do not change or remove this line. } }; //这里cv wait的后面的条件可以参考 template\u0026lt;typename _Predicate\u0026gt; void wait(unique_lock\u0026lt;mutex\u0026gt;\u0026amp; __lock, _Predicate __p) { while (!__p()) wait(__lock); } //解法2 信号量 class Foo { private: sem_t sem_1, sem_2; public: Foo() { sem_init(\u0026amp;sem_1, 0, 0), sem_init(\u0026amp;sem_2, 0, 0); } void first(function\u0026lt;void()\u0026gt; printFirst) { printFirst(); sem_post(\u0026amp;sem_1); } void second(function\u0026lt;void()\u0026gt; printSecond) { sem_wait(\u0026amp;sem_1); printSecond(); sem_post(\u0026amp;sem_2); } void third(function\u0026lt;void()\u0026gt; printThird) { sem_wait(\u0026amp;sem_2); printThird(); } }; Dining Philosophers Problem: 吃饭的哲学家问题是一个经典的并发问题和同步问题，介绍在五个哲学家坐在一张圆桌前，每两位哲学家之间放有一只餐叉。哲学家的生活形式固定，即「思考」和「进餐」的两种形式交替出现。\n// 解法1：最简单或者说最愚蠢的解法，每次只让一个哲学家吃到饭 // 解法2: 限定同时吃饭的哲学家，让四个哲学家吃饭，那么根据抽屉原理，必然会有一个哲学家吃到饭 // 解法3: 奇偶侧拿不同的叉子 // 解法4: 限制哲学家必须同时拿起左右两个筷子 // 解法5: 引入服务员的概念，让服务员来确定哪个哲学家可以吃饭，但是这引入了第三方 // 解法1对应的方法，非常简单 #include \u0026lt;mutex\u0026gt; #include \u0026lt;array\u0026gt; #include \u0026lt;thread\u0026gt; class DiningPhilosophers { private: bool terminate = false; std::thread philosophers[kNumPhilosophers]; std::mutex m; public: static const int kNumPhilosophers = 5; static const int kNumForks = kNumPhilosophers; ... void Eat(int philosopher) { std::unique_lock\u0026lt;std::mutex\u0026gt; lk(m); puts((\u0026#34;Philosopher \u0026#34; + std::to_string(philosopher) + \u0026#34; starts eating.\u0026#34;).c_str()); std::this_thread::sleep_for(std::chrono::milliseconds(500)); puts((\u0026#34;Philosopher \u0026#34; + std::to_string(philosopher) + \u0026#34; ends eating.\u0026#34;).c_str()); } }; // 解法2，限定哲学家吃饭的数量 class DiningPhilosophers { private: bool terminate = false; std::mutext lock[kNumForks] //上面题目的信号量，初始化的时候需要初始化count为4 Semaphore m; public: static const int kNumPhilosophers = 5; static const int kNumForks = kNumPhilosophers; ... void Eat(int philosopher) { std::unique_lock\u0026lt;std::mutex\u0026gt; lk(m); int left_fork = philosopher; int right_fork = (philosopher+1)%5; m.Wait(); lock[left_fork].lock(); lock[right_fork].lock(); puts((\u0026#34;Philosopher \u0026#34; + std::to_string(philosopher) + \u0026#34; starts eating.\u0026#34;).c_str()); std::this_thread::sleep_for(std::chrono::milliseconds(500)); puts((\u0026#34;Philosopher \u0026#34; + std::to_string(philosopher) + \u0026#34; ends eating.\u0026#34;).c_str()); lock[right_fork].lock(); lock[left_fork].lock(); m.Signal() } }; Producer-Consumer Problem: 制造者消费者问题是一个设置在共享固定大小缓冤断言的同步问题。理想情况于两个流程，一个消费者和一个生产者在同一时间里应用一堆存有项目的缓存。\nReaders-Writers Problem: 读者写者问题是一个并发问题，这个问题考察了当并发进程试图访问同一共享资源时，基于读者优先和写者优先的策略的限制。\nSleeping Barber Problem: 睡眠理发师问题是一个经典的进程同步问题。该问题假设有一个理发师、一个理发椅和一些椅子供等待的顾客。如果没有客户，那么理发师就在理发椅上睡觉。当顾客到来时，他们需要唤醒理发师进行理发。如果所有椅子都被占用，那么进来的顾客就会离开。\nCigarette Smokers Problem: 烟瘾者问题是一个同步问题。假设有三个烟瘾者，每个人都有无尽的某种烟草配料（纸，烟草，火柴）。然后有一个代理人，他随机把两个配料放在桌上。正好的烟草配料 ont able的烟瘾者能做一支烟，然后要求代理人放下下一组配料。\n给你一个类：\nclass FooBar {\rpublic void foo() {\rfor (int i = 0; i \u0026lt; n; i++) {\rprint(\u0026#34;foo\u0026#34;);\r}\r}\rpublic void bar() {\rfor (int i = 0; i \u0026lt; n; i++) {\rprint(\u0026#34;bar\u0026#34;);\r}\r}\r} 两个不同的线程将会共用一个 FooBar 实例：\n线程 A 将会调用 foo() 方法，而 线程 B 将会调用 bar() 方法 请设计修改程序，以确保 \u0026quot;foobar\u0026quot; 被输出 n 次。\n5 面试题目收集 # 为什么Linux要区分用户态和Kernel态 上下文切换的时候发生了什么事情？ 一次系统调用会发生几次上下文切换 进程的内存结构是什么样子的 +字节面试题目\n介绍\ndns的过程\ntcp和udp的区别\ntcp三次握手和四次挥手的过程\n进程和线程的区别\nC里面栈和堆的区别\n结尾 # 唉，尴尬\n","date":"2023 年 3 月 25 日","externalUrl":null,"permalink":"/posts/2023-03-25-%E5%8E%BBtm%E7%9A%84%E5%85%AB%E8%82%A1%E6%96%87/","section":"Posts","summary":"","title":"2023-03-25-去tm的八股文","type":"posts"},{"content":"","date":"2023 年 3 月 25 日","externalUrl":null,"permalink":"/tags/perf/","section":"Tags","summary":"","title":"Perf","type":"tags"},{"content":" reverse4fun # Reverse Part # 1 license checker 0x03 # crackme的下载路径在这里：https://crackmes.one/crackme/62072dd633c5d46c8bcbfd9b，本身的代码非常直接，所以可以直接看disass出来的代码\n(gdb) disass Dump of assembler code for function main: 0x0000555555555179 \u0026lt;+0\u0026gt;: push %rbp #标准开局，保存堆栈环境 0x000055555555517a \u0026lt;+1\u0026gt;: mov %rsp,%rbp 0x000055555555517d \u0026lt;+4\u0026gt;: sub $0x30,%rsp #非常标准的对应main函数的两个参数int main(int argc, char** argv),这个是argc 0x0000555555555181 \u0026lt;+8\u0026gt;: mov %edi,-0x24(%rbp) 0x0000555555555184 \u0026lt;+11\u0026gt;: mov %rsi,-0x30(%rbp) #对应argv 0x0000555555555188 \u0026lt;+15\u0026gt;: mov %fs:0x28,%rax 0x0000555555555191 \u0026lt;+24\u0026gt;: mov %rax,-0x8(%rbp) 0x0000555555555195 \u0026lt;+28\u0026gt;: xor %eax,%eax # #比较有没有参数，换言之有没有输入参数，如果有输入参数跳转到下面箭头指的地方 0x0000555555555197 \u0026lt;+30\u0026gt;: cmpl $0x2,-0x24(%rbp) ------- 0x000055555555519b \u0026lt;+34\u0026gt;: je 0x5555555551c5 \u0026lt;main+76\u0026gt; | # 没输入参数的话直接开始调用printf函数打印下面的格式 | 0x000055555555519d \u0026lt;+36\u0026gt;: mov -0x30(%rbp),%rax | 0x00005555555551a1 \u0026lt;+40\u0026gt;: mov (%rax),%rax | 0x00005555555551a4 \u0026lt;+43\u0026gt;: mov %rax,%rsi | # 格式的字符对应\u0026#34;Usage : %s \u0026lt;license pass code here [numbers only]\u0026gt;\\n\u0026#34; | 0x00005555555551a7 \u0026lt;+46\u0026gt;: lea 0xe5a(%rip),%rax # 0x555555556008 | 0x00005555555551ae \u0026lt;+53\u0026gt;: mov %rax,%rdi | 0x00005555555551b1 \u0026lt;+56\u0026gt;: mov $0x0,%eax | 0x00005555555551b6 \u0026lt;+61\u0026gt;: callq 0x555555555050 \u0026lt;printf@plt\u0026gt; | 0x00005555555551bb \u0026lt;+66\u0026gt;: mov $0x0,%edi | 0x00005555555551c0 \u0026lt;+71\u0026gt;: callq 0x555555555070 \u0026lt;exit@plt\u0026gt; | #下面的两个地址存储着两个参数 | # 清空两个数值，这里存储着一个计算出来的和 ------\u0026gt; 0x00005555555551c5 \u0026lt;+76\u0026gt;: movl $0x0,-0x10(%rbp) #这个地址存储的是处理过的字符串的字符的个数 0x00005555555551cc \u0026lt;+83\u0026gt;: movl $0x0,-0xc(%rbp) -- 0x00005555555551d3 \u0026lt;+90\u0026gt;: jmp 0x555555555201 \u0026lt;main+136\u0026gt; --------\u0026gt; 0x00005555555551d5 \u0026lt;+92\u0026gt;: mov -0x30(%rbp),%rax #还是拿到输入的数字的位置 | | 0x00005555555551d9 \u0026lt;+96\u0026gt;: add $0x8,%rax | | 0x00005555555551dd \u0026lt;+100\u0026gt;: mov (%rax),%rdx | | 0x00005555555551e0 \u0026lt;+103\u0026gt;: mov -0xc(%rbp),%eax # 这个存储着处理过的字符串字符的个数，第一次是0 | | 0x00005555555551e3 \u0026lt;+106\u0026gt;: cltq | | 0x00005555555551e5 \u0026lt;+108\u0026gt;: add %rdx,%rax #找到当前处理的字符 | | #取rax，实际上就是输入的数字所在的字符串的1byte，拓展到eax里 | | 0x00005555555551e8 \u0026lt;+111\u0026gt;: movzbl (%rax),%eax | | 0x00005555555551eb \u0026lt;+114\u0026gt;: mov %al,-0x11(%rbp) #丢到栈里面,可以看到是刚才-0x10(%rbp)的低一位 | | 0x00005555555551ee \u0026lt;+117\u0026gt;: lea -0x11(%rbp),%rax | | 0x00005555555551f2 \u0026lt;+121\u0026gt;: mov %rax,%rdi | | #转换为整数，整个过程是一个循环，就是在不断地将每一位转换为数字，然后加到-0x10(%rbp)上 | | 0x00005555555551f5 \u0026lt;+124\u0026gt;: callq 0x555555555060 \u0026lt;atoi@plt\u0026gt; | | #eax存储着从字符转换为数字的结果（返回值）,存储到求和到刚才舒适的存储和的位置 | | 0x00005555555551fa \u0026lt;+129\u0026gt;: add %eax,-0x10(%rbp) | | #addl加了一个1，实际上就是诸位比较，还是继续运行， | | 0x00005555555551fd \u0026lt;+132\u0026gt;: addl $0x1,-0xc(%rbp) | | #argv的起始地址， | ---\u0026gt;0x0000555555555201 \u0026lt;+136\u0026gt;: mov -0x30(%rbp),%rax | # 偏移8字节，实际上目的是找到第二个元素,也就是我们输入参数所对应字符串的地址 | 0x0000555555555205 \u0026lt;+140\u0026gt;: add $0x8,%rax | # 将元素的值赋值给rax，就是输入的数字的所在字符串的地址， | 0x0000555555555209 \u0026lt;+144\u0026gt;: mov (%rax),%rax | 0x000055555555520c \u0026lt;+147\u0026gt;: mov %rax,%rdi | # 对字符串调用strlen判断长度 | 0x000055555555520f \u0026lt;+150\u0026gt;: callq 0x555555555040 \u0026lt;strlen@plt\u0026gt; | # 返回的字符串长度放在了eax里面，和已经操作的字符串的字符个数比较一下，看看是不是处理完了 | 0x0000555555555214 \u0026lt;+155\u0026gt;: cmp %eax,-0xc(%rbp) --- 0x0000555555555217 \u0026lt;+158\u0026gt;: jl 0x5555555551d5 \u0026lt;main+92\u0026gt; #比较输入的参数字符串每一个转换为数字后加起来以后是不是0x32，所以构造一个字符串各位求和是0x32的即可 0x0000555555555219 \u0026lt;+160\u0026gt;: cmpl $0x32,-0x10(%rbp) 0x000055555555521d \u0026lt;+164\u0026gt;: jne 0x555555555238 \u0026lt;main+191\u0026gt; 0x000055555555521f \u0026lt;+166\u0026gt;: lea 0xe1a(%rip),%rax # 0x555555556040 0x0000555555555226 \u0026lt;+173\u0026gt;: mov %rax,%rdi 0x0000555555555229 \u0026lt;+176\u0026gt;: callq 0x555555555030 \u0026lt;puts@plt\u0026gt; 0x000055555555522e \u0026lt;+181\u0026gt;: mov $0x0,%edi 0x0000555555555233 \u0026lt;+186\u0026gt;: callq 0x555555555070 \u0026lt;exit@plt\u0026gt; 0x0000555555555238 \u0026lt;+191\u0026gt;: lea 0xe25(%rip),%rax # 0x555555556064 0x000055555555523f \u0026lt;+198\u0026gt;: mov %rax,%rdi 0x0000555555555242 \u0026lt;+201\u0026gt;: callq 0x555555555030 \u0026lt;puts@plt\u0026gt; 0x0000555555555247 \u0026lt;+206\u0026gt;: mov $0x0,%edi 0x000055555555524c \u0026lt;+211\u0026gt;: callq 0x555555555070 \u0026lt;exit@plt\u0026gt; 2 trycrackme # trycrackme的下载地址为https://crackmes.one/crackme/61c8deff33c5d413767ca0ea，直接从汇编就能看出来到底在做什么\nDump of assembler code for function main: # 标准开局，保存堆栈 0x00005555555551af \u0026lt;+0\u0026gt;: push %rbp 0x00005555555551b0 \u0026lt;+1\u0026gt;: mov %rsp,%rbp 0x00005555555551b3 \u0026lt;+4\u0026gt;: sub $0xe0,%rsp #存储argc \u0026amp; argv，不过这里没用到 0x00005555555551ba \u0026lt;+11\u0026gt;: mov %edi,-0xd4(%rbp) 0x00005555555551c0 \u0026lt;+17\u0026gt;: mov %rsi,-0xe0(%rbp) 0x00005555555551c7 \u0026lt;+24\u0026gt;: mov %fs:0x28,%rax 0x00005555555551d0 \u0026lt;+33\u0026gt;: mov %rax,-0x8(%rbp) 0x00005555555551d4 \u0026lt;+37\u0026gt;: xor %eax,%eax # 注意这个常量，是我们比较的关键 0x00005555555551d6 \u0026lt;+39\u0026gt;: movabs $0x3534323773734034,%rax # 存储到了-0xbb(%rbp)的位置 0x00005555555551e0 \u0026lt;+49\u0026gt;: mov %rax,-0xbb(%rbp) # 给上面的常量补充了两个字节的数字，拼接到最后面,拼接完以后看一下具体的内容 # (gdb) x/16xb 140737488347509 # 0x7fffffffe175: 0x34 0x40 0x73 0x73 0x37 0x32 0x34 0x35 # 0x7fffffffe17d: 0x33 0x36 0x00 0x00 0x00 0x00 0x00 0x00 0x00005555555551e7 \u0026lt;+56\u0026gt;: movw $0x3633,-0xb3(%rbp) 0x00005555555551f0 \u0026lt;+65\u0026gt;: movb $0x0,-0xb1(%rbp) 0x00005555555551f7 \u0026lt;+72\u0026gt;: lea -0xbb(%rbp),%rax 0x00005555555551fe \u0026lt;+79\u0026gt;: mov %rax,%rdi 0x0000555555555201 \u0026lt;+82\u0026gt;: callq 0x555555555050 \u0026lt;strlen@plt\u0026gt; # 存储我们刚才拼接出来的字符串长度，明确地看出来是10 0x0000555555555206 \u0026lt;+87\u0026gt;: mov %eax,-0xc0(%rbp) 0x000055555555520c \u0026lt;+93\u0026gt;: mov $0x0,%eax # 调用banner打印一些flag，没有啥用，不用管 0x0000555555555211 \u0026lt;+98\u0026gt;: callq 0x555555555199 \u0026lt;banner\u0026gt; # 准备调用printf提示用户输入数据，格式化字符串为Put the key: 0x0000555555555216 \u0026lt;+103\u0026gt;: lea 0xef9(%rip),%rax # 0x555555556116 0x000055555555521d \u0026lt;+110\u0026gt;: mov %rax,%rdi 0x0000555555555220 \u0026lt;+113\u0026gt;: mov $0x0,%eax 0x0000555555555225 \u0026lt;+118\u0026gt;: callq 0x555555555070 \u0026lt;printf@plt\u0026gt; # 记住这个-0xb0(%rbp)的地址，这个是存储scanf输入进来的地址 0x000055555555522a \u0026lt;+123\u0026gt;: lea -0xb0(%rbp),%rax 0x0000555555555231 \u0026lt;+130\u0026gt;: mov %rax,%rsi 0x0000555555555234 \u0026lt;+133\u0026gt;: lea 0xee9(%rip),%rax # 0x555555556124 0x000055555555523b \u0026lt;+140\u0026gt;: mov %rax,%rdi 0x000055555555523e \u0026lt;+143\u0026gt;: mov $0x0,%eax 0x0000555555555243 \u0026lt;+148\u0026gt;: callq 0x555555555080 \u0026lt;__isoc99_scanf@plt\u0026gt; # 初始化两个变量，分别存储上面-0xbb(%rbp)字符串处理过的字符个数 # 和要算出来作为正确的code所处理过的字符个数 0x0000555555555248 \u0026lt;+153\u0026gt;: movl $0x0,-0xc8(%rbp) 0x0000555555555252 \u0026lt;+163\u0026gt;: movl $0x0,-0xc4(%rbp) |--- 0x000055555555525c \u0026lt;+173\u0026gt;: jmp 0x5555555552ab \u0026lt;main+252\u0026gt; | # -0xc8(%rbp)是刚才那个常量字符串处理过的byte数，所以cltq下面那句就很明显了 |-----\u0026gt; 0x000055555555525e \u0026lt;+175\u0026gt;: mov -0xc8(%rbp),%eax | | 0x0000555555555264 \u0026lt;+181\u0026gt;: cltq | | # 这里的意思是把刚才-0xbb(%rbp)字符串的字符,hex形式丢到eax | | 0x0000555555555266 \u0026lt;+183\u0026gt;: movzbl -0xbb(%rbp,%rax,1),%eax | | # 先做有符号数拓展，再做无符号数拓展，不过都小于0x80，所以无所谓了 | | 0x000055555555526e \u0026lt;+191\u0026gt;: movsbl %al,%eax | | 0x0000555555555271 \u0026lt;+194\u0026gt;: movzbl %al,%eax | | 0x0000555555555274 \u0026lt;+197\u0026gt;: mov -0xc4(%rbp),%edx | | 0x000055555555527a \u0026lt;+203\u0026gt;: movslq %edx,%rdx | | # rcx存储了计算结果的首地址， -0x70(%rbp)是我们最后比较的参照物的地址 | | 0x000055555555527d \u0026lt;+206\u0026gt;: lea -0x70(%rbp),%rcx | | # 加上已经结算过的结果，实际上就是挪动指针,存储下面sprintf的结果 | | 0x0000555555555281 \u0026lt;+210\u0026gt;: add %rdx,%rcx | | 0x0000555555555284 \u0026lt;+213\u0026gt;: mov %eax,%edx | | # 这个字符是 %02x | | 0x0000555555555286 \u0026lt;+215\u0026gt;: lea 0xe9a(%rip),%rax # 0x555555556127 | | 0x000055555555528d \u0026lt;+222\u0026gt;: mov %rax,%rsi | | 0x0000555555555290 \u0026lt;+225\u0026gt;: mov %rcx,%rdi | | 0x0000555555555293 \u0026lt;+228\u0026gt;: mov $0x0,%eax | | # 这里调用sprintf的含义就非常清楚了，从hex编码转换为字符串 | | # 原先是hex 0x34，那么转换为字符串\u0026#34;34\u0026#34; | | 0x0000555555555298 \u0026lt;+233\u0026gt;: callq 0x555555555090 \u0026lt;sprintf@plt\u0026gt; | | # hex 字符串处理过一byte后挪一 | | # 而sprintf处理的结果是2byte（两个char字符） | | 0x000055555555529d \u0026lt;+238\u0026gt;: addl $0x1,-0xc8(%rbp) | | 0x00005555555552a4 \u0026lt;+245\u0026gt;: addl $0x2,-0xc4(%rbp) | | #开始处理，先找到第一个字符，看看和上面的字符串长度10的大小，判断有没有处理完 | ---\u0026gt; 0x00005555555552ab \u0026lt;+252\u0026gt;: mov -0xc8(%rbp),%eax | 0x00005555555552b1 \u0026lt;+258\u0026gt;: cmp -0xc0(%rbp),%eax |------ 0x00005555555552b7 \u0026lt;+264\u0026gt;: jl 0x55555555525e \u0026lt;main+175\u0026gt; 0x00005555555552b9 \u0026lt;+266\u0026gt;: lea -0x70(%rbp),%rax 0x00005555555552bd \u0026lt;+270\u0026gt;: mov %rax,%rdi 0x00005555555552c0 \u0026lt;+273\u0026gt;: callq 0x555555555050 \u0026lt;strlen@plt\u0026gt; 0x00005555555552c5 \u0026lt;+278\u0026gt;: mov %rax,%rdx # 算出来的正确的code 0x00005555555552c8 \u0026lt;+281\u0026gt;: lea -0x70(%rbp),%rcx # 输入的code 0x00005555555552cc \u0026lt;+285\u0026gt;: lea -0xb0(%rbp),%rax 0x00005555555552d3 \u0026lt;+292\u0026gt;: mov %rcx,%rsi 0x00005555555552d6 \u0026lt;+295\u0026gt;: mov %rax,%rdi # 比较 0x00005555555552d9 \u0026lt;+298\u0026gt;: callq 0x555555555030 \u0026lt;strncmp@plt\u0026gt; 0x00005555555552de \u0026lt;+303\u0026gt;: test %eax,%eax |----0x00005555555552e0 \u0026lt;+305\u0026gt;: je 0x5555555552fd \u0026lt;main+334\u0026gt; | 0x00005555555552e2 \u0026lt;+307\u0026gt;: lea 0xe43(%rip),%rax # 0x55555555612c | 0x00005555555552e9 \u0026lt;+314\u0026gt;: mov %rax,%rdi | 0x00005555555552ec \u0026lt;+317\u0026gt;: mov $0x0,%eax | 0x00005555555552f1 \u0026lt;+322\u0026gt;: callq 0x555555555070 \u0026lt;printf@plt\u0026gt; | 0x00005555555552f6 \u0026lt;+327\u0026gt;: mov $0xffffffff,%eax | 0x00005555555552fb \u0026lt;+332\u0026gt;: jmp 0x555555555316 \u0026lt;main+359\u0026gt; | # 这里就是正确的结果，所以我们只需要输入一个字符串和上面常量字符串从hex到字符串转换的结果即可 |---\u0026gt;0x00005555555552fd \u0026lt;+334\u0026gt;: lea 0xe3b(%rip),%rax # 0x55555555613f 0x0000555555555304 \u0026lt;+341\u0026gt;: mov %rax,%rdi 0x0000555555555307 \u0026lt;+344\u0026gt;: mov $0x0,%eax 0x000055555555530c \u0026lt;+349\u0026gt;: callq 0x555555555070 \u0026lt;printf@plt\u0026gt; 0x0000555555555311 \u0026lt;+354\u0026gt;: mov $0x0,%eax 0x0000555555555316 \u0026lt;+359\u0026gt;: mov -0x8(%rbp),%rdx 0x000055555555531a \u0026lt;+363\u0026gt;: sub %fs:0x28,%rdx 0x0000555555555323 \u0026lt;+372\u0026gt;: je 0x55555555532a \u0026lt;main+379\u0026gt; 0x0000555555555325 \u0026lt;+374\u0026gt;: callq 0x555555555060 \u0026lt;__stack_chk_fail@plt\u0026gt; 0x000055555555532a \u0026lt;+379\u0026gt;: leaveq 0x000055555555532b \u0026lt;+380\u0026gt;: retq End of assembler dump. 3 fr0zien 的crackme # 0x0000555555555165 \u0026lt;+0\u0026gt;: push %rbp 0x0000555555555166 \u0026lt;+1\u0026gt;: mov %rsp,%rbp 0x0000555555555169 \u0026lt;+4\u0026gt;: sub $0xa0,%rsp # argc 0x0000555555555170 \u0026lt;+11\u0026gt;: mov %edi,-0x94(%rbp) # argv, 可以通过argv找到具体的参数 0x0000555555555176 \u0026lt;+17\u0026gt;: mov %rsi,-0xa0(%rbp) #stack gard 0x000055555555517d \u0026lt;+24\u0026gt;: mov %fs:0x28,%rax 0x0000555555555186 \u0026lt;+33\u0026gt;: mov %rax,-0x8(%rbp) 0x000055555555518a \u0026lt;+37\u0026gt;: xor %eax,%eax # 检查参数是不是两个 0x000055555555518c \u0026lt;+39\u0026gt;: cmpl $0x1,-0x94(%rbp) 0x0000555555555193 \u0026lt;+46\u0026gt;: jne 0x5555555551ab \u0026lt;main+70\u0026gt; # 如果没有输入参数，那么直接输出提示的字符：Usage: ./crackme FLAG 0x0000555555555195 \u0026lt;+48\u0026gt;: lea 0xe68(%rip),%rdi # 0x555555556004 0x000055555555519c \u0026lt;+55\u0026gt;: callq 0x555555555030 \u0026lt;puts@plt\u0026gt; 0x00005555555551a1 \u0026lt;+60\u0026gt;: mov $0x1,%eax 0x00005555555551a6 \u0026lt;+65\u0026gt;: jmpq 0x555555555355 \u0026lt;main+496\u0026gt; # 比较参数是不是0x15的长度, 下面的语句明显是先找到参数，调用strlen检查字符串的长度 0x00005555555551ab \u0026lt;+70\u0026gt;: mov -0xa0(%rbp),%rax 0x00005555555551b2 \u0026lt;+77\u0026gt;: add $0x8,%rax 0x00005555555551b6 \u0026lt;+81\u0026gt;: mov (%rax),%rax 0x00005555555551b9 \u0026lt;+84\u0026gt;: mov %rax,%rdi 0x00005555555551bc \u0026lt;+87\u0026gt;: callq 0x555555555040 \u0026lt;strlen@plt\u0026gt; # 比较参数是不是0x15的长度, 0x15才会往下走，否则报错 0x00005555555551c1 \u0026lt;+92\u0026gt;: cmp $0x15,%rax 0x00005555555551c5 \u0026lt;+96\u0026gt;: je 0x5555555551dd \u0026lt;main+120\u0026gt; 0x00005555555551c7 \u0026lt;+98\u0026gt;: lea 0xe4c(%rip),%rdi # 0x55555555601a 0x00005555555551ce \u0026lt;+105\u0026gt;: callq 0x555555555030 \u0026lt;puts@plt\u0026gt; 0x00005555555551d3 \u0026lt;+110\u0026gt;: mov $0x1,%eax 0x00005555555551d8 \u0026lt;+115\u0026gt;: jmpq 0x555555555355 \u0026lt;main+496\u0026gt; # 该字符串为sup3r_s3cr3t_k3y_1337 0x00005555555551dd \u0026lt;+120\u0026gt;: lea 0xe41(%rip),%rax # 0x555555556025 0x00005555555551e4 \u0026lt;+127\u0026gt;: mov %rax,-0x88(%rbp) # 注意这个地址-0x90(%rbp)从0开始循环 0x00005555555551eb \u0026lt;+134\u0026gt;: movl $0x0,-0x90(%rbp) |--0x00005555555551f5 \u0026lt;+144\u0026gt;: jmp 0x555555555225 \u0026lt;main+192\u0026gt; ----|-\u0026gt; 0x00005555555551f7 \u0026lt;+146\u0026gt;: mov -0x90(%rbp),%eax \u0026lt;------------ | | 0x00005555555551fd \u0026lt;+152\u0026gt;: movslq %eax,%rdx | | 0x0000555555555200 \u0026lt;+155\u0026gt;: mov -0x88(%rbp),%rax | | 0x0000555555555207 \u0026lt;+162\u0026gt;: add %rdx,%rax | | 0x000055555555520a \u0026lt;+165\u0026gt;: movzbl (%rax),%eax | | # 刚才上面的字符串对应的ascii每个减去0x22，再存入代码中 | | 0x000055555555520d \u0026lt;+168\u0026gt;: sub $0x22,%eax | | 0x0000555555555210 \u0026lt;+171\u0026gt;: mov %eax,%edx | | 0x0000555555555212 \u0026lt;+173\u0026gt;: mov -0x90(%rbp),%eax | | 0x0000555555555218 \u0026lt;+179\u0026gt;: cltq | | 0x000055555555521a \u0026lt;+181\u0026gt;: mov %dl,-0x20(%rbp,%rax,1) | | 0x000055555555521e \u0026lt;+185\u0026gt;: addl $0x1,-0x90(%rbp) | | # 这里比较是不是到了0x14的长度，就是上面字符串的长度处理完了没 | |-\u0026gt;0x0000555555555225 \u0026lt;+192\u0026gt;: cmpl $0x14,-0x90(%rbp) |---- 0x000055555555522c \u0026lt;+199\u0026gt;: jle 0x5555555551f7 \u0026lt;main+146\u0026gt; -- # 这里开始存储另一个ascii码，这里注意是movl，间隔为4,下面会看到具体的比较，记住这些常量，一会会用到 0x000055555555522e \u0026lt;+201\u0026gt;: movl $0x37,-0x80(%rbp) 0x0000555555555235 \u0026lt;+208\u0026gt;: movl $0x3f,-0x7c(%rbp) 0x000055555555523c \u0026lt;+215\u0026gt;: movl $0x2f,-0x78(%rbp) 0x0000555555555243 \u0026lt;+222\u0026gt;: movl $0x76,-0x74(%rbp) 0x000055555555524a \u0026lt;+229\u0026gt;: movl $0x2b,-0x70(%rbp) 0x0000555555555251 \u0026lt;+236\u0026gt;: movl $0x62,-0x6c(%rbp) 0x0000555555555258 \u0026lt;+243\u0026gt;: movl $0x28,-0x68(%rbp) 0x000055555555525f \u0026lt;+250\u0026gt;: movl $0x21,-0x64(%rbp) 0x0000555555555266 \u0026lt;+257\u0026gt;: movl $0x34,-0x60(%rbp) 0x000055555555526d \u0026lt;+264\u0026gt;: movl $0xf,-0x5c(%rbp) 0x0000555555555274 \u0026lt;+271\u0026gt;: movl $0x77,-0x58(%rbp) 0x000055555555527b \u0026lt;+278\u0026gt;: movl $0x62,-0x54(%rbp) 0x0000555555555282 \u0026lt;+285\u0026gt;: movl $0x48,-0x50(%rbp) 0x0000555555555289 \u0026lt;+292\u0026gt;: movl $0x27,-0x4c(%rbp) 0x0000555555555290 \u0026lt;+299\u0026gt;: movl $0x75,-0x48(%rbp) 0x0000555555555297 \u0026lt;+306\u0026gt;: movl $0x8,-0x44(%rbp) 0x000055555555529e \u0026lt;+313\u0026gt;: movl $0x56,-0x40(%rbp) 0x00005555555552a5 \u0026lt;+320\u0026gt;: movl $0x6a,-0x3c(%rbp) 0x00005555555552ac \u0026lt;+327\u0026gt;: movl $0x68,-0x38(%rbp) 0x00005555555552b3 \u0026lt;+334\u0026gt;: movl $0x4e,-0x34(%rbp) 0x00005555555552ba \u0026lt;+341\u0026gt;: movl $0x68,-0x30(%rbp) # 这里在此保存了一个0，-0x8c(%rbp)，计数用 0x00005555555552c1 \u0026lt;+348\u0026gt;: movl $0x0,-0x8c(%rbp) | --0x00005555555552cb \u0026lt;+358\u0026gt;: jmp 0x555555555325 \u0026lt;main+448\u0026gt; | # 还是先找到输入的参数对应的字符串 ---|--\u0026gt;0x00005555555552cd \u0026lt;+360\u0026gt;: mov -0xa0(%rbp),%rax | | 0x00005555555552d4 \u0026lt;+367\u0026gt;: add $0x8,%rax | | 0x00005555555552d8 \u0026lt;+371\u0026gt;: mov (%rax),%rdx | | # 我们是一个char一个char比较，所以得加上刚才的计数,存储到eax | | 0x00005555555552db \u0026lt;+374\u0026gt;: mov -0x8c(%rbp),%eax | | 0x00005555555552e1 \u0026lt;+380\u0026gt;: cltq | | 0x00005555555552e3 \u0026lt;+382\u0026gt;: add %rdx,%rax | | # 拿到具体对应的char，存储到edx里面 | | 0x00005555555552e6 \u0026lt;+385\u0026gt;: movzbl (%rax),%edx | | 0x00005555555552e9 \u0026lt;+388\u0026gt;: mov -0x8c(%rbp),%eax | | 0x00005555555552ef \u0026lt;+394\u0026gt;: cltq | | # 在拿到刚才上面算出来的常量字符串减去0x22后面存储的结果 | | 0x00005555555552f1 \u0026lt;+396\u0026gt;: movzbl -0x20(%rbp,%rax,1),%eax | | # 两者求异或 | | 0x00005555555552f6 \u0026lt;+401\u0026gt;: xor %edx,%eax | | 0x00005555555552f8 \u0026lt;+403\u0026gt;: movsbl %al,%edx | | 0x00005555555552fb \u0026lt;+406\u0026gt;: mov -0x8c(%rbp),%eax | | 0x0000555555555301 \u0026lt;+412\u0026gt;: cltq | | # 再拿到刚才四个四个存储的常量，进行比较，如果都一致就成功，否则失败 | | 0x0000555555555303 \u0026lt;+414\u0026gt;: mov -0x80(%rbp,%rax,4),%eax | | 0x0000555555555307 \u0026lt;+418\u0026gt;: cmp %eax,%edx | | 0x0000555555555309 \u0026lt;+420\u0026gt;: je 0x55555555531e \u0026lt;main+441\u0026gt; | | 0x000055555555530b \u0026lt;+422\u0026gt;: lea 0xd08(%rip),%rdi # 0x55555555601a | | 0x0000555555555312 \u0026lt;+429\u0026gt;: callq 0x555555555030 \u0026lt;puts@plt\u0026gt; | | 0x0000555555555317 \u0026lt;+434\u0026gt;: mov $0x1,%eax | | 0x000055555555531c \u0026lt;+439\u0026gt;: jmp 0x555555555355 \u0026lt;main+496\u0026gt; | | 0x000055555555531e \u0026lt;+441\u0026gt;: addl $0x1,-0x8c(%rbp) | --\u0026gt; 0x0000555555555325 \u0026lt;+448\u0026gt;: cmpl $0x14,-0x8c(%rbp) |------0x000055555555532c \u0026lt;+455\u0026gt;: jle 0x5555555552cd \u0026lt;main+360\u0026gt; 0x000055555555532e \u0026lt;+457\u0026gt;: mov -0xa0(%rbp),%rax 0x0000555555555335 \u0026lt;+464\u0026gt;: add $0x8,%rax 0x0000555555555339 \u0026lt;+468\u0026gt;: mov (%rax),%rax 0x000055555555533c \u0026lt;+471\u0026gt;: mov %rax,%rsi 0x000055555555533f \u0026lt;+474\u0026gt;: lea 0xcf5(%rip),%rdi # 0x55555555603b 0x0000555555555346 \u0026lt;+481\u0026gt;: mov $0x0,%eax 0x000055555555534b \u0026lt;+486\u0026gt;: callq 0x555555555060 \u0026lt;printf@plt\u0026gt; 0x0000555555555350 \u0026lt;+491\u0026gt;: mov $0x0,%eax 0x0000555555555355 \u0026lt;+496\u0026gt;: mov -0x8(%rbp),%rcx 0x0000555555555359 \u0026lt;+500\u0026gt;: sub %fs:0x28,%rcx 0x0000555555555362 \u0026lt;+509\u0026gt;: je 0x555555555369 \u0026lt;main+516\u0026gt; 0x0000555555555364 \u0026lt;+511\u0026gt;: callq 0x555555555050 \u0026lt;__stack_chk_fail@plt\u0026gt; 0x0000555555555369 \u0026lt;+516\u0026gt;: leaveq 0x000055555555536a \u0026lt;+517\u0026gt;: retq rax 0x7fffffffe030 0x5555555552b4 \u0026lt;main+255\u0026gt; mov %rax,-0x40(%rbp) # 上面的地址放到-0x40(%rbp)里面去 0x5555555552bc \u0026lt;main+263\u0026gt; movq $0x1,(%rax) # 放一个64bit的数字，然后开始每个都放 3 RainerZimmerman\u0026rsquo;s Keygen # 这个题比较有意思的是它实际上是优化了除法的表示，不过总的来说还是比较简单，掌握了除法优化规则就大概能看明白了\n# main函数部分dump Dump of assembler code for function __libc_start_call_main: =\u0026gt; 0x00007f3aed342d10 \u0026lt;+0\u0026gt;:\tpush %rax 0x00007f3aed342d11 \u0026lt;+1\u0026gt;:\tpop %rax 0x00007f3aed342d12 \u0026lt;+2\u0026gt;:\tsub $0x98,%rsp 0x00007f3aed342d19 \u0026lt;+9\u0026gt;:\tmov %rdi,0x8(%rsp) 0x00007f3aed342d1e \u0026lt;+14\u0026gt;:\tlea 0x20(%rsp),%rdi 0x00007f3aed342d23 \u0026lt;+19\u0026gt;:\tmov %esi,0x14(%rsp) 0x00007f3aed342d27 \u0026lt;+23\u0026gt;:\tmov %rdx,0x18(%rsp) 0x00007f3aed342d2c \u0026lt;+28\u0026gt;:\tmov %fs:0x28,%rax 0x00007f3aed342d35 \u0026lt;+37\u0026gt;:\tmov %rax,0x88(%rsp) 0x00007f3aed342d3d \u0026lt;+45\u0026gt;:\txor %eax,%eax 0x00007f3aed342d3f \u0026lt;+47\u0026gt;:\tcall 0x7f3aed35b1e0 \u0026lt;_setjmp\u0026gt; 0x00007f3aed342d44 \u0026lt;+52\u0026gt;:\tendbr64 0x00007f3aed342d48 \u0026lt;+56\u0026gt;:\ttest %eax,%eax 0x00007f3aed342d4a \u0026lt;+58\u0026gt;:\tjne 0x7f3aed342d97 \u0026lt;__libc_start_call_main+135\u0026gt; 0x00007f3aed342d4c \u0026lt;+60\u0026gt;:\tmov %fs:0x300,%rax 0x00007f3aed342d55 \u0026lt;+69\u0026gt;:\tmov %rax,0x68(%rsp) 0x00007f3aed342d5a \u0026lt;+74\u0026gt;:\tmov %fs:0x2f8,%rax 0x00007f3aed342d63 \u0026lt;+83\u0026gt;:\tmov %rax,0x70(%rsp) 0x00007f3aed342d68 \u0026lt;+88\u0026gt;:\tlea 0x20(%rsp),%rax 0x00007f3aed342d6d \u0026lt;+93\u0026gt;:\tmov %rax,%fs:0x300 0x00007f3aed342d76 \u0026lt;+102\u0026gt;:\tmov 0x1ef23b(%rip),%rax # 0x7f3aed531fb8 0x00007f3aed342d7d \u0026lt;+109\u0026gt;:\tmov 0x14(%rsp),%edi 0x00007f3aed342d81 \u0026lt;+113\u0026gt;:\tmov 0x18(%rsp),%rsi 0x00007f3aed342d86 \u0026lt;+118\u0026gt;:\tmov (%rax),%rdx 0x00007f3aed342d89 \u0026lt;+121\u0026gt;:\tmov 0x8(%rsp),%rax 0x00007f3aed342d8e \u0026lt;+126\u0026gt;:\tcall *%rax \u0026lt;======这里就是真正计算key的部分 0x00007f3aed342d90 \u0026lt;+128\u0026gt;:\tmov %eax,%edi 0x00007f3aed342d92 \u0026lt;+130\u0026gt;:\tcall 0x7f3aed35e5f0 \u0026lt;__GI_exit\u0026gt; 0x00007f3aed342d97 \u0026lt;+135\u0026gt;:\tcall 0x7f3aed3aa670 \u0026lt;__GI___nptl_deallocate_tsd\u0026gt; 0x00007f3aed342d9c \u0026lt;+140\u0026gt;:\tlock decl 0x1ef505(%rip) # 0x7f3aed5322a8 \u0026lt;__nptl_nthreads\u0026gt; 0x00007f3aed342da3 \u0026lt;+147\u0026gt;:\tsete %al 0x00007f3aed342da6 \u0026lt;+150\u0026gt;:\ttest %al,%al 0x00007f3aed342da8 \u0026lt;+152\u0026gt;:\tjne 0x7f3aed342db8 \u0026lt;__libc_start_call_main+168\u0026gt; 0x00007f3aed342daa \u0026lt;+154\u0026gt;:\tmov $0x3c,%edx 0x00007f3aed342daf \u0026lt;+159\u0026gt;:\tnop 0x00007f3aed342db0 \u0026lt;+160\u0026gt;:\txor %edi,%edi 0x00007f3aed342db2 \u0026lt;+162\u0026gt;:\tmov %edx,%eax 0x00007f3aed342db4 \u0026lt;+164\u0026gt;:\tsyscall 0x00007f3aed342db6 \u0026lt;+166\u0026gt;:\tjmp 0x7f3aed342db0 \u0026lt;__libc_start_call_main+160\u0026gt; 0x00007f3aed342db8 \u0026lt;+168\u0026gt;:\txor %edi,%edi 0x00007f3aed342dba \u0026lt;+170\u0026gt;:\tjmp 0x7f3aed342d92 \u0026lt;__libc_start_call_main+130\u0026gt; # 从上面的0x00007f3aed342d8e \u0026lt;+126\u0026gt;:\tcall *%rax 蹦过来到这里，这里实际上是输入keygen的部分 (gdb) disass $pc,$pc+100 Dump of assembler code from 0x5571d8a48397 to 0x5571d8a483fb: =\u0026gt; 0x00005571d8a48397:\tmov %edi,-0x34(%rbp) 0x00005571d8a4839a:\tmov %rsi,-0x40(%rbp) 0x00005571d8a4839e:\tlea 0xc5f(%rip),%rax # 0x5571d8a49004 0x00005571d8a483a5:\tmov %rax,%rsi 0x00005571d8a483a8:\tlea 0x2cd1(%rip),%rax # 0x5571d8a4b080 \u0026lt;_ZSt4cout\u0026gt; 0x00005571d8a483af:\tmov %rax,%rdi 0x00005571d8a483b2:\tcall 0x5571d8a48070 \u0026lt;_ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc@plt\u0026gt; 0x00005571d8a483b7:\tlea -0x30(%rbp),%rax 0x00005571d8a483bb:\tmov %rax,%rdi 0x00005571d8a483be:\tcall 0x5571d8a480a0 \u0026lt;_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1Ev@plt\u0026gt; 0x00005571d8a483c3:\tlea -0x30(%rbp),%rax 0x00005571d8a483c7:\tmov %rax,%rsi 0x00005571d8a483ca:\tlea 0x2dcf(%rip),%rax # 0x5571d8a4b1a0 \u0026lt;_ZSt3cin\u0026gt; 0x00005571d8a483d1:\tmov %rax,%rdi 0x00005571d8a483d4:\tcall 0x5571d8a48090 \u0026lt;_ZStrsIcSt11char_traitsIcESaIcEERSt13basic_istreamIT_T0_ES7_RNSt7__cxx1112basic_stringIS4_S5_T1_EE@plt\u0026gt; 0x00005571d8a483d9:\tlea -0x30(%rbp),%rax 0x00005571d8a483dd:\tmov %rax,%rdi 0x00005571d8a483e0:\tcall 0x5571d8a48030 \u0026lt;_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE5c_strEv@plt\u0026gt; 0x00005571d8a483e5:\tmov %rax,%rdi 0x00005571d8a483e8:\tcall 0x5571d8a48255 \u0026lt;================在这里做真正的keygen的计算 0x00005571d8a483ed:\ttest %al,%al 0x00005571d8a483ef:\tje 0x5571d8a4841e 0x00005571d8a483f1:\tlea 0xc18(%rip),%rax # 0x5571d8a49010 0x00005571d8a483f8:\tmov %rax,%rsi End of assembler dump. (gdb) #从上面的0x00005571d8a483e8:\tcall 0x5571d8a48255 蹦过来 (gdb) disass $pc,$pc+400 Dump of assembler code from 0x5571d8a48255 to 0x5571d8a483e5: =\u0026gt; 0x00005571d8a48255:\tpush %rbp 0x00005571d8a48256:\tmov %rsp,%rbp 0x00005571d8a48259:\tsub $0x30,%rsp 0x00005571d8a4825d:\tmov %rdi,-0x28(%rbp) # -0x28(%rbp)地址保存的输入的原始字符串 0x00005571d8a48261:\tmov -0x28(%rbp),%rax 0x00005571d8a48265:\tmov %rax,%rdi 0x00005571d8a48268:\tcall 0x5571d8a48040 \u0026lt;strlen@plt\u0026gt; # 判断长度是不是0xd，不是就直接返回失败拉 0x00005571d8a4826d:\tmov %eax,-0x8(%rbp) 0x00005571d8a48270:\tcmpl $0xd,-0x8(%rbp) 0x00005571d8a48274:\tjne 0x5571d8a48285 0x00005571d8a48276:\tmov -0x28(%rbp),%rax 0x00005571d8a4827a:\tadd $0x3,%rax 0x00005571d8a4827e:\tmovzbl (%rax),%eax 0x00005571d8a48281:\tcmp $0x2d,%al # 比较位置3，也就是第四个字符是不是分隔符“-” 0x00005571d8a48283:\tje 0x5571d8a4828f 0x00005571d8a48285:\tmov $0x0,%eax 0x00005571d8a4828a:\tjmp 0x5571d8a4838c 0x00005571d8a4828f:\tmov -0x28(%rbp),%rax 0x00005571d8a48293:\tmov $0x3,%edx 0x00005571d8a48298:\tmov $0x0,%esi 0x00005571d8a4829d:\tmov %rax,%rdi 0x00005571d8a482a0:\tcall 0x5571d8a481ee #这个函数负责计算给定的字符串的数字的求和结果，这里edx是3，所以三位的求和 0x00005571d8a482a5:\tmov %eax,-0xc(%rbp) #记住这个地址，这个地址是一直参与运算的 0x00005571d8a482a8:\tcmpl $0xffffffff,-0xc(%rbp) 0x00005571d8a482ac:\tjne 0x5571d8a482b8 0x00005571d8a482ae:\tmov $0x0,%eax 0x00005571d8a482b3:\tjmp 0x5571d8a4838c 0x00005571d8a482b8:\tmov -0xc(%rbp),%edx # 下面的运算实际上是往-0xc(%rbp)存入 0x00005571d8a482bb:\tmovslq %edx,%rax # sum(0,2) - 3*[sum(0,2)* 0x55555556\u0026gt;\u0026gt;32-sum(0,2)\u0026gt;\u0026gt;31] 0x00005571d8a482be:\timul $0x55555556,%rax,%rax # 这个实际上就是sum(0,2) % 3 0x00005571d8a482c5:\tshr $0x20,%rax 0x00005571d8a482c9:\tmov %rax,%rcx 0x00005571d8a482cc:\tmov %edx,%eax 0x00005571d8a482ce:\tsar $0x1f,%eax 0x00005571d8a482d1:\tsub %eax,%ecx 0x00005571d8a482d3:\tmov %ecx,%eax 0x00005571d8a482d5:\tadd %eax,%eax 0x00005571d8a482d7:\tadd %ecx,%eax 0x00005571d8a482d9:\tsub %eax,%edx 0x00005571d8a482db:\tmov %edx,-0xc(%rbp) 0x00005571d8a482de:\tmovl $0x4,-0x4(%rbp) 0x00005571d8a482e5:\tjmp 0x5571d8a4837d 0x00005571d8a482ea:\tmov -0x4(%rbp),%ecx 0x00005571d8a482ed:\tmov -0x28(%rbp),%rax 0x00005571d8a482f1:\tmov $0x3,%edx 0x00005571d8a482f6:\tmov %ecx,%esi 0x00005571d8a482f8:\tmov %rax,%rdi 0x00005571d8a482fb:\tcall 0x5571d8a481ee 0x00005571d8a48300:\tmov %eax,-0x10(%rbp) # 后面三位数字的求和，每次根据conter加三位 0x00005571d8a48303:\tcmpl $0xffffffff,-0x10(%rbp) 0x00005571d8a48307:\tjne 0x5571d8a48310 0x00005571d8a48309:\tmov $0x0,%eax 0x00005571d8a4830e:\tjmp 0x5571d8a4838c 0x00005571d8a48310:\tmov -0x4(%rbp),%eax # 这个就是counter 0x00005571d8a48313:\tsub $0x4,%eax 0x00005571d8a48316:\tmovslq %eax,%rdx 0x00005571d8a48319:\timul $0x55555556,%rdx,%rdx # 从conter拿到具体要计算数字的位置，可以看到这个就直接是 0x00005571d8a48320:\tshr $0x20,%rdx # [(counter-4)* 0x55555556\u0026gt;\u0026gt;32-(counter-4)\u0026gt;\u0026gt;31]，这个是除法，除以3 0x00005571d8a48324:\tsar $0x1f,%eax 0x00005571d8a48327:\tsub %eax,%edx 0x00005571d8a48329:\tmovslq %edx,%rdx 0x00005571d8a4832c:\tmov -0x28(%rbp),%rax 0x00005571d8a48330:\tadd %rdx,%rax 0x00005571d8a48333:\tmovzbl (%rax),%eax 0x00005571d8a48336:\tmovsbl %al,%eax 0x00005571d8a48339:\tmov %eax,%edi 0x00005571d8a4833b:\tcall 0x5571d8a481c9 # 从计算出来的position，拿到对应数字的值 0x00005571d8a48340:\txor -0xc(%rbp),%eax 0x00005571d8a48343:\tmov %eax,-0x14(%rbp) # 这里注意，存储的是 0x00005571d8a48346:\tmov -0x10(%rbp),%ecx # 拿到了刚才的求和 0x00005571d8a48349:\tmovslq %ecx,%rax # 这个地方计算的值是下面，x就是counter 0x00005571d8a4834c:\timul $0x38e38e39,%rax,%rax # sum(x,x+2) - 9*[sum(x,x+2)* 38e38e39\u0026gt;\u0026gt;33-sum(x,x+2)\u0026gt;\u0026gt;31] 0x00005571d8a48353:\tshr $0x20,%rax # 实际上是sum(x,x+2) % 9 0x00005571d8a48357:\tmov %eax,%edx 0x00005571d8a48359:\tsar %edx 0x00005571d8a4835b:\tmov %ecx,%eax 0x00005571d8a4835d:\tsar $0x1f,%eax 0x00005571d8a48360:\tsub %eax,%edx 0x00005571d8a48362:\tmov %edx,%eax 0x00005571d8a48364:\tshl $0x3,%eax 0x00005571d8a48367:\tadd %edx,%eax 0x00005571d8a48369:\tsub %eax,%ecx 0x00005571d8a4836b:\tmov %ecx,%edx 0x00005571d8a4836d:\tcmp %edx,-0x14(%rbp) # 这里基本就清楚了，要求-0xc(%rbp) XOR num[(counter-4)/3] = sum(x,x+2) % 9 0x00005571d8a48370:\tje 0x5571d8a48379 0x00005571d8a48372:\tmov $0x0,%eax 0x00005571d8a48377:\tjmp 0x5571d8a4838c 0x00005571d8a48379:\taddl $0x3,-0x4(%rbp) 0x00005571d8a4837d:\tcmpl $0xc,-0x4(%rbp) 0x00005571d8a48381:\tjle 0x5571d8a482ea 0x00005571d8a48387:\tmov $0x1,%eax 0x00005571d8a4838c:\tleave 0x00005571d8a4838d:\tret 基本上走一趟就明白了，所以写个函数跑了下\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace::std; int main() { int tmp_value = 0; for (int i = 0; i \u0026lt;= 9; ++i) { for ( int j = 0; j \u0026lt;= 9; ++j) { for ( int k = 0; k \u0026lt;= 9; ++k) { bool find_456 = false; bool find_789 = false; bool find_abc = false; int tmp_sum_456 = 0; int tmp_sum_789 = 0; int tmp_sum_abc = 0; tmp_value = (i+j +k)%3; //tmp_value = (i+j+k)-(3*(i+j+k)*0x55555556\u0026gt;\u0026gt;32)+(3*(i+j+k)\u0026gt;\u0026gt;31); //std::cout \u0026lt;\u0026lt;\u0026#34; iterate tmp_value is \u0026#34; \u0026lt;\u0026lt; tmp_value \u0026lt;\u0026lt; std::endl; for ( int sum = 0 ; sum \u0026lt;=27; ++sum) { int final_ans = sum % 9; int last_tmp = tmp_value ^ i; if (final_ans == last_tmp) { find_456=true; tmp_sum_456 = sum; } last_tmp = tmp_value ^ j; if (final_ans == last_tmp) { find_789=true; tmp_sum_789 = sum; } last_tmp = tmp_value ^ k; if (final_ans == last_tmp) { find_abc=true; tmp_sum_abc = sum; } if ((find_abc == true) \u0026amp;\u0026amp; (find_456 == true) \u0026amp;\u0026amp; (find_789 == true)) { std::cout \u0026lt;\u0026lt;\u0026#34;##########\u0026#34;\u0026lt;\u0026lt;tmp_sum_456 \u0026lt;\u0026lt;\u0026#34; \u0026#34; \u0026lt;\u0026lt; tmp_sum_789\u0026lt;\u0026lt;\u0026#34; \u0026#34; \u0026lt;\u0026lt; tmp_sum_abc \u0026lt;\u0026lt;std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;!!!!!!!!!!!!!\u0026#34;\u0026lt;\u0026lt;i \u0026lt;\u0026lt;\u0026#34; \u0026#34; \u0026lt;\u0026lt; j \u0026lt;\u0026lt;\u0026#34; \u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt;std::endl; } } } } } return 0; } 最后随便输入一个000-000000000，过了。。。。\n结尾 # 唉，尴尬\n","date":"2023 年 3 月 14 日","externalUrl":null,"permalink":"/posts/2023-03-14-reverse4fun/","section":"Posts","summary":"","title":"2023-03-14-reverse4fun","type":"posts"},{"content":" 安全CVE知识库学习 # 针对加解密相关的攻击\nCVE-2019-3730（padding oracle attack vulnerability）：根本原因，cbc块加密的IV是透明的，攻击者可以对其进行bitwise manipulate，而加解密服务又没有认证。客户端送什么就给什么，所以可以perbit操纵IV，从而获得解密的结果。简单来说就是在不清楚 key 和 IV 的前提下解密任意给定的密文。\nCVE-2014-3566（poodle攻击）：\nCVE-2022-21449\n这个漏洞涉及到ecdsa的流程，在ecdsa验证签名的流程当中第一步验证要求\n验证r和s在[1,n-1]之间，如果不在，则签名无效\n但是java的实现人员没有理这个问题，这就导致攻击者直接输入（0,0)即可完成校验，所以就相当于校验形同虚设了。嘿嘿，其他的库比方说openssl，borring ssl都没有这个问题\n针对协议本身的攻击\nBEASET攻击：同样是CBC，类似padding pracle attack，session位置固定就可以一位一位猜测出来。利用的是TLS1.0的IV不加密为明文，且HTTP协议的报文为固定格式，对应的位置是特定的内容，从而直接爆破出来session 弱hash算法（CVE-2004-2761）：这个是hash算力不足导致碰撞得到的结果 CVE-2015-4458：重协商不安全导致可以直接降级到不安全的版本上 针对实现错误的攻击\nCVE-2014-0160（心脏滴血）：根本原因为：拷贝边界/信息校验没做到位，触发条件为：使用了openssl协议栈，且有其他的连接，这时候用非法连接接入可能会窃听到隐私信息 CVE-2018-15473：openssh的问题，存在的用户名校验流程和不存在的用户名校验流程的步骤可区分导致的信息泄漏 针对网络安全本身的攻击\nCVE-2021-44228（log4shell): 结尾 # 唉，尴尬\n","date":"2023 年 2 月 15 日","externalUrl":null,"permalink":"/posts/2023-02-15-%E5%AE%89%E5%85%A8cve%E7%9F%A5%E8%AF%86%E5%BA%93%E5%AD%A6%E4%B9%A0/","section":"Posts","summary":"","title":"2023-02-15-安全CVE知识库学习","type":"posts"},{"content":" 安全二进制学习 # 逆向相关 # 简单的elf注入方式 # 最简单，但是限制最多，直接硬编码hard code LD_PRELOAD修改共享库，注意LD_PRELOAD只能使用绝对路径，且不能注入静态链接的函数 实现的历程实际上是个hook过去代码的地址，然后调用load dlsym函数，获取指向共享库函数的指针，做一些检查再把流程传递回原本的流程。从而能够方便的注入（hook）代码 高级技巧 elfinject技术，注入代码节，覆盖原有的代码，并且修改entrypoint 注入代码节，但是不修改entrypoint，然后 或者手动修改entrypoint 或者劫持构造函数和析构函数，得返回具体初始化的地址的硬编码 劫持plt 劫持got 结尾 # 唉，尴尬\n","date":"2023 年 2 月 15 日","externalUrl":null,"permalink":"/posts/2023-02-15-%E5%AE%89%E5%85%A8%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AD%A6%E4%B9%A0/","section":"Posts","summary":"","title":"2023-02-15-安全二进制学习","type":"posts"},{"content":" 安全二进制学习 # 2网络攻击攻击的原理和基本防护手段 # 2.1 XSS攻击 # 本质是将恶意脚本嵌入到网页并执行的攻击，产生的主要原因是网站对用户提交的数据检查不严格。一般分为\n反射性跨站：将用户输入的数据通过URL的形式直接或未经过完善的安全过滤就在浏览器输出 存储型xSS：将用户输入保存在服务器的数据段或者文件里，网页查询数据时会展示 DOM型跨站攻击 XSS攻击IDE条件，针对不同阶段\n入库处理阶段： 网页有攻击者可控制的输入点 输入信息可以再受害者浏览器显示 数据预备功能的可执行脚本，且没有特殊字符过滤和字符串转意或者防护措施具备一定的绕过手段 出库处理阶段： 浏览器将输入解析为脚本，且具备脚本执行的能力 XSS测试及绕过部分防护的手段\n一般都是测试能否输入，然后能否显示，是否有过滤。一般都是输入下面的语句看什么效果做测试\n\u0026lt;script\u0026gt;alert(/xss/)\u0026lt;/script\u0026gt; 闭合标签测试，如果script的语句被包含在标签里比方说\u0026lt;testxtarea\u0026gt;\u0026lt;/textarea\u0026gt;标签里面，那么久尝试先闭合textarea标签 大小写混合测试，主要针对过滤script没区分大小写的匹配导致 多重嵌套，如果服务端会替换script语句，而且只替换一次，那么就需要使用这个手段换言之，语句为\u0026lt;scr\u0026lt;scritp\u0026gt;ipt\u0026gt;alert\u0026lt;/xss/\u0026gt;\u0026lt;/script\u0026gt; 宽字节注入法，宽字节主要是针对常见中文编码比方说GBK啥的，它会吃一字节字符。如果网页字符是GBK，然后因为单引号被转移，但是转移符号的编码是0x5c，在GBK的低字节里面，后面加一个高字节编码，高字节编码就会和原先的编码组合成合法字符，然后跨站就过了 Xss的防范手段\n过滤特殊字符，这种方法又被叫做xss filter 利用实体化编码，严格限制哪些语句是数据，哪些语句是代码 httponly 2.2请求伪造漏洞和防护 # 2.2.1 CSRF # CSRF本质就是攻击者伪造一个链接，这个链接会自动向当前用户的用户服务器提交攻击者伪造的业务请求\n触发条件：\n用户处于登录状态 伪造的连接和正常应用请求链接一致 后台未对用户业务开展合法性校验 \u0026lt;== 针对CSRF的防护\n添加中间环节： 添加验证过程 添加验证码 验证用户请求的合法性： 验证refer。从哪里来 验证token，token一般是攻击者无法获取的，因此即使发起了攻击也不可以拿到。但是这个有限制 token必须为一次性的 token具备较强的随机性 2.2.2.2 SSRF # 2.3 SQL注入 # 本质是对用户的输入没做充分的校验，一般有以下几种条件\n参数处理问题 对用户参数进行了错误的类型处理 对转义字符处理环节产生了遗漏或者可悲绕过 服务配置问题 不安全的数据库主力 web应用对错误的处理不同 不当的类型处理 不安全的数据库配置 SQL注入的分类\n回显注入，其思路如下 寻找注入点，检查页面是否有变化；页面是否缺少了部分内容；是否有错误回显；跳转到默认界面； 确定有注入点以后，尝试获取表的信息 盲注 防护手段\n参数类型检测及绕过：参数类型检测是否符合预期，比方说是不是数字，是不是正负数，是不是数字字符串啥的 绕过:针对具体的防护手段，比方说检查数字的时候提交0x01 参数长度检测：判断参数长度，strlen可以获取参数长度，太长就截断 危险参数绕过 黑名单过滤，将尖括号，union啥的过滤掉 2.4文件上传攻击 # 是否允许用户上传特殊文件，上传检测绕过技术\n上传检测绕过基础 JS检测及绕过，一般是检查拓展名。 绕过：禁用js或者直接修改拓展名，或者直接就该拓展名后缀 MIME类型，HTTP协议利用content-typoe表示上传内容类型， 绕过：毕竟也是客户端的东西，可以控制 服务端解析：在服务端检查上传类型和具体内容， 文件解析攻击 .htaccess攻击 apache解析漏洞攻击 IIS解析漏洞攻击 nginx解析漏洞攻击 2.5 Web木马 # 2.6 文件包含攻击 # 2.7 命令执行攻击 # 结尾 # 唉，尴尬\n","date":"2023 年 2 月 15 日","externalUrl":null,"permalink":"/posts/2023-02-15-%E5%AE%89%E5%85%A8%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/","section":"Posts","summary":"","title":"2023-02-15-安全二进制学习","type":"posts"},{"content":" 二进制分析 # 1 elf文件的结构 # elf的格式看这个：https://linuxhint.com/understanding_elf_file_format/\n如果是可执行文件，那么elf header会指明程序头表的偏移量，程序头表(Program header table) - 列举了所有有效的段(segments)和他们的属性（执行视图），每个结构都表示一个段，就是上图右边的图片，可以想象从Program Header Table伸出一条条箭头指向下面的Segment 1, Segment 2 \u0026hellip;\n一般来说，我们将ELF文件标记为以下几个类型\nET_NONE ET_REL：重定位文件，通常是还未被链接到可执行程序的一段为止独立的代码( position independent code)， ET_EXEC：可执行文件 ET_DYN：共享目标文件，一般是共享库 ET_CODE：coredump文件相关 elf文件的结构如图，一点一点说\nelf头部保存了关于比方关于幻数，架构位宽，大端序/小端序，ABI等信息。此外e_type表明是可重定位文件（Relocatable File）：ETL_REL，还是可执行文件（Executable File）：ET_EXEC，共享目标文件（Shared Object File）：ET_DYN等类型。此外还有e_phoff和e_shoff，指明程序头表和街头表的偏移量，这都是文件偏移量。还有一个e_entry表示开始执行的虚拟地址。 剩下的我建议参考这个：http://chuquan.me/2018/05/21/elf-introduce/ 使用readelf -h 查看文件头，默认的文件头结构定义如下\n#define EI_NIDENT 16 typedef struct { unsigned char e_ident[EI_NIDENT]; //magic number Elf32_Half e_type; //Ojbect file type Elf32_Half e_machine; //Architecture Elf32_Word e_version; //Object file version Elf32_Addr e_entry; //entry point Elf32_Off e_phoff; //程序头内容在文件的偏移量 Elf32_off e_shoff; //段头内容在文件的偏移量 Elf32_Word e_flags; Elf32_Half e_ehsize; //elf头部大小 Elf32_Half e_phentsize; //程序头部表格的表项大小 Elf32_Half e_phnum; //程序头的个数Program header Elf32_Half e_shentsize; //节区头部表格的表项大小 Elf32_Half e_shnum; //段头的个数Section header Elf32_Half e_shstrndx; //String段在整个段列表中的索引值，实际上是.shstrtab的头索引，用来找字符串， }Elf32_Ehdr; 1.1 Section结构 # 和段不同，节主要用于链接和调试，节头表对程序不是必须的，部分人可能会删除节头表的信息来对抗调试。\n节的数据结构比较直接\ntypedef struct { Elf32_Word sh_name; //给出节区名称。是节区头部字符串节区（Section Header String Table Section）的索引。名字是一个NULL结尾的字符串，保存在一个名为.shstrtab的字符串表（可通过Section Header索引到） Elf32_Word sh_type; //节类型。为节区的内容和语义进行分类。SHT_PROGRAMBITS包含程序指令，机器指令或者常量 Elf32_Word sh_flags; //节标志位。节区支持1位形式的标志，这些标志描述了多种属性 Elf32_Addr sh_addr; //节的虚拟地址。如果节区将出现在进程的内存映像中或可被加载，则sh_addr为该节被加载后在进程地址空间中的虚拟地址，给出节区的每一个字节应处的位置。否则，此字段为0 Elf32_Off sh_offset; //节偏移。如果该节存在于文件中，则该节表示在文件中的偏移；否则无意义，如sh_offset对于BSS节来说就是没有意义的。即此成员的取值给出节区的第一个字节与文件头之间的偏移。 Elf32_Word sh_size; //节大小。此成员给出节区的长度（字节数）。除非节区的类型是SHT_NOBITS，否则节区占用文件中的sh_size字节。 Elf32_Word sh_link; //节链接信息。此成员给出节区头部表索引链接，其解释依赖于节区类型 Elf32_Word sh_info; //节链接信息。此成员给出附加信息，其解释依赖于节区类型 Elf32_Word sh_addralign; //节地址对齐方式。某些节区带有地址对齐约束。 Elf32_Word sh_entsize; //节项大小。某些节区中包含固定大小的项目，如符号表，其包含的每个符号所在的大小都一样。 } Elf32_Shdr; 一些有趣的节\n.text: .text节是保存了程序代码指令的代码节。一段可执行程序，如果存在Phdr，则.text节就会存在于text段中。由于.text节保存了程序代码，所以节类型为SHT_PROGBITS。\n.rodata.rodata节保存了只读的数据，如一行c语言代码中的字符串。由于.rodata节是只读的，所以只能存在于一个可执行文件的只读段中。因此，只能在text段（而不是data段）中找到.rodata节。由于.rodata节是只读的，所以节类型为SHT_PROGBITS。\n.data: .data节存在于data段中，其保存了初始化的全局变量等数据。由于.data节保存了程序的变量数据，所以节类型为SHT_PROGBITS。\n.bss: .bss节存在于data段中，占用空间不超过4字节，仅表示这个节本来的空间。.bss节保存了未进行初始化的全局数据。程序加载时数据被初始化为0，在程序执行期间可以进行赋值。由于.bss节未保存实际的数据，所以节类型为SHT_NOBITS。\n.rel.name .relaname\nname根据重定位所适用的节区给定。例如.text节区的重定位节区名字将是：.rel.text或者.rela.text。重定位表保存了重定位相关的信息，这些信息描述了如何在链接或运行时，对ELF目标文件的某些部分或者进程镜像进行补充或者修改。由于重定位表保存了重定位相关的数据，所以节类型为SHT_REL。\n.hash\n.hash节也称为.gnu.hash，其保存了一个用于查找符号的散列表。\n.symtab\n.symtab节是一个ElfN_Sym的数组，保存了符号信息。节类型为SHT_SYMTAB。\n.strtab\n.strtab节保存的是符号字符串表，表中的内容会被.symtab的ElfN_Sym结构中的st_name引用。节类型为SHT_STRTAB。\n.ctors\u0026amp;.dtors ctors（构造器）节和.dtors（析构器）节分别保存了指向构造函数和析构函数的函数指针，构造函数是在main函数执行之前需要执行的代码；析构函数是在main函数之后需要执行的代码。\n我们重点关注这几个节：\n.plt:.plt节也称为过程链接表（Procedure Linkage Table），其包含了动态链接器调用从共享库导入的函数所必需的相关代码。由于.plt节保存了代码，所以节类型为SHT_PROGBITS。\n.got \u0026amp; .plt:.got节保存了全局偏移量。.got节和.plt节一起提供了对导入的共享库函数的访问入口，由动态链接器在运行时进行修改。由于.got .plt节与程序执行有关，所以节类型为SHT_PROGBITS。\n为什么需要这个节呢？ .text和.pot是不可写的，所以需要一个可写的节来存储 现代操作系统动态库虽然都load了，可是虚拟地址不同，所以还是得每个进程保存自己的got plt .dynsym：从共享库导入的外部符号，后面动态链接器链接的时候往往要看这个节来确定要链接哪些东西\n.dynstr：.dynstr保存了动态链接字符串表，表中存放了一系列字符串，这些字符串代表了符号名称，以空字符作为终止符。\n.dynamic节：在加载和创建要执行的elf二进制文件的是哦户，.dynamic节充当操作系统和动态链接库的路线图，该节包含名为ELF64_Dyn的结构体数组，或者说标签，每个标签都有个关联\n.rel.*\n符号引用和符号定义\n节的分类中我们介绍了.dynsym节和.symtab节，两者都是符号表。那么它们到底有什么区别呢？存在什么关系呢？\n符号是对某些类型的数据或代码（如全局变量或函数）的符号引用，函数名或变量名就是符号名。例如，printf()函数会在动态链接符号表.dynsym中存有一个指向该函数的符号项（以Elf_Sym数据结构表示）。在大多数共享库和动态链接可执行文件中，存在两个符号表。即.dynsym和.symtab。\n.dynsym保存了引用来自外部文件符号的全局符号。如printf库函数。.dynsym保存的符号是.symtab所保存符合的子集，.symtab中还保存了可执行文件的本地符号。如全局变量，代码中定义的本地函数等。\n既然.dynsym是.symtab的子集，那为何要同时存在两个符号表呢？\n通过readelf -S命令可以查看可执行文件的输出，一部分节标志位（sh_flags）被标记为了A（ALLOC）、WA（WRITE/ALLOC）、AX（ALLOC/EXEC）。其中，.dynsym被标记为ALLOC，而.symtab则没有标记。\nALLOC表示有该标记的节会在运行时分配并装载进入内存，而.symtab不是在运行时必需的，因此不会被装载到内存中。.dynsym保存的符号只能在运行时被解析，因此是运行时动态链接器所需的唯一符号。.dynsym对于动态链接可执行文件的执行是必需的，而.symtab只是用来进行调试和链接的\n动态链接 # 动态库没有PT_INTERP段，所以不会触发程序解释器。当共享库加载到一个进程的地址空间的时候，动态链接器会修改可执行文件的GOT。这个段位于数据段（.got.plt节)\n一般来说，动态链接的过程是\n调用动态链接的函数首先跳转到plt plt会调用jmp *got[3+x]的位置，x是函数的plt存根的数字。这个*got[3+x]实际上一开始就是plt的下一条指令 为什么是got[3+x]呢？下面是 GOT 的头3个偏移量。 GOT[0]：存放了指向可执行文件动态段的地址，动态链接器利用该地址提取动态链接相关的信息。 GOT[1]：存放 link_map 结构的地址，动态链接器利用该地址来对符号进行解析。 GOT[2]：存放了指向动态链接器_dl_runtime_resolve(),函数的地址，该函数用来解析共享库函数的实际符号地址。 之后plt会跳转到就jmp plt[0]的位置，这个地址实际上放了三条指令 pushl将got[1]压入栈内，指向link_map的地址 跳转到got[2]的地址，这俩放了动态链接_dl_runtime_resolve()函数的地址，之后动态链接器会修改got里面的地址 动态链接，调用的过程，我们看一个scanf的例子，可以看到这个时候跳转到plt实际上已经没有了延迟链接的事情，check this link:https://stackoverflow.com/questions/43048932/why-does-the-plt-exist-in-addition-to-the-got-instead-of-just-using-the-got\nqcraft@BJ-vgdog:~/code_test/ass_c++/control_flow$ readelf -r a.out Relocation section \u0026#39;.rela.dyn\u0026#39; at offset 0x4a0 contains 8 entries: Offset Info Type Sym. Value Sym. Name + Addend 000000200da8 000000000008 R_X86_64_RELATIVE 7b0 000000200db0 000000000008 R_X86_64_RELATIVE 770 000000201008 000000000008 R_X86_64_RELATIVE 201008 000000200fd8 000100000006 R_X86_64_GLOB_DAT 0000000000000000 _ITM_deregisterTMClone + 0 000000200fe0 000300000006 R_X86_64_GLOB_DAT 0000000000000000 __libc_start_main@GLIBC_2.2.5 + 0 000000200fe8 000400000006 R_X86_64_GLOB_DAT 0000000000000000 __gmon_start__ + 0 000000200ff0 000700000006 R_X86_64_GLOB_DAT 0000000000000000 _ITM_registerTMCloneTa + 0 000000200ff8 000800000006 R_X86_64_GLOB_DAT 0000000000000000 __cxa_finalize@GLIBC_2.2.5 + 0 Relocation section \u0026#39;.rela.plt\u0026#39; at offset 0x560 contains 3 entries: Offset Info Type Sym. Value Sym. Name + Addend 000000200fc0 000200000007 R_X86_64_JUMP_SLO 0000000000000000 __stack_chk_fail@GLIBC_2.4 + 0 000000200fc8 000500000007 R_X86_64_JUMP_SLO 0000000000000000 __printf_chk@GLIBC_2.3.4 + 0 000000200fd0 000600000007 R_X86_64_JUMP_SLO 0000000000000000 scanf@GLIBC_2.2.5 + 0 (gdb) disass Dump of assembler code for function scanf@plt: =\u0026gt; 0x00005555555545f0 \u0026lt;+0\u0026gt;:\tjmpq *0x2009da(%rip) # 0x555555754fd0 0x00005555555545f6 \u0026lt;+6\u0026gt;:\tpushq $0x2 0x00005555555545fb \u0026lt;+11\u0026gt;:\tjmpq 0x5555555545c0 rip 0x5555555545f0\t0x5555555545f0 \u0026lt;scanf@plt\u0026gt; (gdb) ni __scanf (format=0x555555554844 \u0026#34;%d\u0026#34;) at scanf.c:28 28\tscanf.c: No such file or directory. (gdb) disass Dump of assembler code for function __scanf: =\u0026gt; 0x00007ffff7a5d120 \u0026lt;+0\u0026gt;:\tsub $0xd8,%rsp 0x00007ffff7a5d127 \u0026lt;+7\u0026gt;:\ttest %al,%al 0x00007ffff7a5d129 \u0026lt;+9\u0026gt;:\tmov %rsi,0x28(%rsp) 0x00007ffff7a5d12e \u0026lt;+14\u0026gt;:\tmov %rdx,0x30(%rsp) 0x00007ffff7a5d133 \u0026lt;+19\u0026gt;:\tmov %rcx,0x38(%rsp) 0x00007ffff7a5d138 \u0026lt;+24\u0026gt;:\tmov %r8,0x40(%rsp) 0x00007ffff7a5d13d \u0026lt;+29\u0026gt;:\tmov %r9,0x48(%rsp) 0x00007ffff7a5d142 \u0026lt;+34\u0026gt;:\tje 0x7ffff7a5d17b \u0026lt;__scanf+91\u0026gt; 0x00007ffff7a5d144 \u0026lt;+36\u0026gt;:\tmovaps %xmm0,0x50(%rsp) 0x00007ffff7a5d149 \u0026lt;+41\u0026gt;:\tmovaps %xmm1,0x60(%rsp) 0x00007ffff7a5d14e \u0026lt;+46\u0026gt;:\tmovaps %xmm2,0x70(%rsp) 0x00007ffff7a5d153 \u0026lt;+51\u0026gt;:\tmovaps %xmm3,0x80(%rsp) 0x00007ffff7a5d15b \u0026lt;+59\u0026gt;:\tmovaps %xmm4,0x90(%rsp) 0x00007ffff7a5d163 \u0026lt;+67\u0026gt;:\tmovaps %xmm5,0xa0(%rsp) 0x00007ffff7a5d16b \u0026lt;+75\u0026gt;:\tmovaps %xmm6,0xb0(%rsp) 0x00007ffff7a5d173 \u0026lt;+83\u0026gt;:\tmovaps %xmm7,0xc0(%rsp) 0x00007ffff7a5d17b \u0026lt;+91\u0026gt;:\tmov %fs:0x28,%rax 0x00007ffff7a5d184 \u0026lt;+100\u0026gt;:\tmov %rax,0x18(%rsp) 0x00007ffff7a5d189 \u0026lt;+105\u0026gt;:\txor %eax,%eax 0x00007ffff7a5d18b \u0026lt;+107\u0026gt;:\tlea 0xe0(%rsp),%rax 0x00007ffff7a5d193 \u0026lt;+115\u0026gt;:\tmov %rdi,%rsi 0x00007ffff7a5d196 \u0026lt;+118\u0026gt;:\txor %ecx,%ecx 0x00007ffff7a5d198 \u0026lt;+120\u0026gt;:\tmov %rsp,%rdx 0x00007ffff7a5d19b \u0026lt;+123\u0026gt;:\tmov %rax,0x8(%rsp) 0x00007ffff7a5d1a0 \u0026lt;+128\u0026gt;:\tlea 0x20(%rsp),%rax 0x00007ffff7a5d1a5 \u0026lt;+133\u0026gt;:\tmovl $0x8,(%rsp) 0x00007ffff7a5d1ac \u0026lt;+140\u0026gt;:\tmovl $0x30,0x4(%rsp) 0x00007ffff7a5d1b4 \u0026lt;+148\u0026gt;:\tmov %rax,0x10(%rsp) 0x00007ffff7a5d1b9 \u0026lt;+153\u0026gt;:\tmov 0x36fdf0(%rip),%rax # 0x7ffff7dccfb0 0x00007ffff7a5d1c0 \u0026lt;+160\u0026gt;:\tmov (%rax),%rdi 0x00007ffff7a5d1c3 \u0026lt;+163\u0026gt;:\tcallq 0x7ffff7a4d320 \u0026lt;_IO_vfscanf_internal\u0026gt; 0x00007ffff7a5d1c8 \u0026lt;+168\u0026gt;:\tmov 0x18(%rsp),%rcx 0x00007ffff7a5d1cd \u0026lt;+173\u0026gt;:\txor %fs:0x28,%rcx 0x00007ffff7a5d1d6 \u0026lt;+182\u0026gt;:\tjne 0x7ffff7a5d1e0 \u0026lt;__scanf+192\u0026gt; 0x00007ffff7a5d1d8 \u0026lt;+184\u0026gt;:\tadd $0xd8,%rsp 0x00007ffff7a5d1df \u0026lt;+191\u0026gt;:\tretq 0x00007ffff7a5d1e0 \u0026lt;+192\u0026gt;:\tcallq 0x7ffff7b16b10 \u0026lt;__stack_chk_fail\u0026gt; End of assembler dump. (gdb) x/2 0x555555754fd0 0x555555754fd0:\t0xf7a5d120\t0x00007fff (gdb) 1.2 Segment结构 # ELF程序头，是程序装载的时候关心的对象。段在内核装载的是时候被解析，然后load到内存里面\n部分的Segment我们需要关注几种类别，比方说\nPT_LOAD：一般是可装载的段，一般需要动态链接的ELF可执行程序都包含两个\n存放代码的text段，权限一般为PF_X|PF_R，即执行和读 存放全局变量和动态链接信息的data段，data段的权限为PF_W|PF_R PT_DYNAMIC：动态链接可执行文件所特有的，包含动态链接器所必须的信息。动态段包含一些标记值和指针。为什么会有这个段？因为程序运行的时候不能有section header tabel引入（简单来说就是不能有节信息），所以需要一个段包含这些信息。当共享库被映射到内存后，首先处理自身（这个自身是指动态链接器自己）的重定位，然后查看可执行程序的动态段并查找DT_NEEDED参数，该参数保存了指向所需要的共享库的字符串或者路径名。连接器接着会获取到共享库的动态段，并将共享库的符号表添加到符号表链中，符号表链存储了所有映射到内存中的共享库的符号表。这个段保存有以下信息：\n运行时候需要链接的共享库列表 全局偏移表（GOT）的地址 重定位条目的信息 这里需要关注一部分的特定类型 DT_NEEDED DT_SYMTAB，对应.dynsym节 DY_HASH，对应.hash节 DT_STRTAB，对应.dynstr节 DT_PLTGOT：全局偏移表的地址 PT_NOTE：与供应商或者系统相关的附加信息\nPT_INTERP：一般存放动态链接器的位置\nPT_PHDR\n看一个具体例子\nqcraft@BJ-vgdog:~/qcraft$ readelf -l /usr/bin/vim Elf file type is DYN (Shared object file) Entry point 0x375f0 There are 9 program headers, starting at offset 64 Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align PHDR 0x0000000000000040 0x0000000000000040 0x0000000000000040 0x00000000000001f8 0x00000000000001f8 R 0x8 INTERP 0x0000000000000238 0x0000000000000238 0x0000000000000238 0x000000000000001c 0x000000000000001c R 0x1 [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2] LOAD 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000266878 0x0000000000266878 R E 0x200000 LOAD 0x00000000002676f0 0x00000000004676f0 0x00000000004676f0 0x0000000000025360 0x00000000000323c8 RW 0x200000 DYNAMIC 0x00000000002733d8 0x00000000004733d8 0x00000000004733d8 0x0000000000000270 0x0000000000000270 RW 0x8 NOTE 0x0000000000000254 0x0000000000000254 0x0000000000000254 0x0000000000000044 0x0000000000000044 R 0x4 GNU_EH_FRAME 0x0000000000229628 0x0000000000229628 0x0000000000229628 0x0000000000008adc 0x0000000000008adc R 0x4 GNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 RW 0x10 GNU_RELRO 0x00000000002676f0 0x00000000004676f0 0x00000000004676f0 0x000000000000c910 0x000000000000c910 R 0x1 Section to Segment mapping: Segment Sections... 00 01 .interp 02 .interp .note.ABI-tag .note.gnu.build-id .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rela.dyn .rela.plt .init .plt .plt.got .text .fini .rodata .eh_frame_hdr .eh_frame 03 .init_array .fini_array .data.rel.ro .dynamic .got .data .bss 04 .dynamic 05 .note.ABI-tag .note.gnu.build-id 06 .eh_frame_hdr 07 08 .init_array .fini_array .data.rel.ro .dynamic .got 动态链接\n2 PE文件的结构 # PE文件的结构如图，DOS头后面跟NT头\n","date":"2023 年 2 月 9 日","externalUrl":null,"permalink":"/posts/2023-02-09-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%88%86%E6%9E%90/","section":"Posts","summary":"","title":"二进制分析","type":"posts"},{"content":" 一个INFRA工程师的思考 # 个人的思考方面：\n感觉一个TL关注的不应该是单纯哪部分做个灾备，哪部分做个备份之类的东西，更关注的应该是software engineer的大的衡量标准。实际上TL要考虑的可能是目前有哪些东西不能动？这些部分能不能筛查出来？我们究竟是多灵活？在这个过程当中我觉得很多监控的东西要做起来\nsoftware engineer要多于单纯的code complete，其中metain的东西比较多，所以实际上代码这块我们要考虑的不单纯是研发，还要考虑matain的问题，所以我建议INFRA这部分在review的时候要加一个matain的成员，matain的成员要考虑的事情就很多了。这里代码review还需要考虑一点，该谁的代码，就要让谁review，这点需要注意，不是光改完了就完了，一定要通知到个人。\n还有一个事情，就是代码的研发者要对代码的用户直接负责，代码使用者的组织需要有个人专门管理由依赖引起的问题。当代码的研发者进行了版本升级或者相关的改动时，需要通知到用户做评估，可能有人问，我怎么直到谁用了我的代码呢？bazel管理的代码deps有直接的依赖，可以非常清楚的获知。\n当我们做决定的时候我们考虑什么？\n时间和变化 代码的影响范围，这个影响范围是个抽象的东西，我觉得不妨考虑代码的声明周期， 代码的改变承诺， Hyrum’s Law：我认为我们应当为承诺型，即C++的行为，我们承诺我们做到什么，其它的不保证，用错了是UB With a sufficient number of users of an API, it does not matter what you promise in the contract: all observable behaviors of your system will be depended on by somebody. 规模和效率 Your organization’s codebase is sustainable when you are able to change all of the things that you ought to change, safely, and can do so for the life of your codebase。换言之，我们应该将任何固定依赖或者说不可替代的东西替换为可替代物 我们应当能够类似衡量硬件资源那样子，衡量人力和具体的涉及到workflow都是不可持久的both in terms of human time involvement and the compute resources that power your development workflow. 实际上我们就是在衡量codebase 问题来了，如何衡量一个策略是不是糟糕的呢？看这个策略对单个工程师的影响，并考虑当组织扩大十倍的时候，是不是会导致消耗扩大十倍 一个兼容的rule为infrastructure teams must do the work to move their internal users to new versions themselves or do the update in place, in backward-compatible fashion. If a product experiences outages or other problems as a result of infrastructure changes, but the issue wasn’t surfaced by tests in our Continuous Integration (CI) system, it is not the fault of the infrastructure change. 实际上我们的CI应该能够检测到这种错误，换言之If you liked it, you should have put a CI test on it Trade-offs和代价 因此，我这段时间做了什么呢？从多个方面来考虑：\n对设备的管理：\n编写阿里云ack集群的机器的setup脚本，实现扩容的自动化 根据机器的上任务的运行时长，并发效率和我们任务的新建数量，计算出所需要的机器数量 针对仿真集群，编写自动cordon脚本 对内部环境的管理：\nsetup \u0026amp; 维护 buildfarm环境，从1.12 =\u0026gt; 1.15并启用nginx同时使用主备buildfarm环境应对公司内部任务量代码量的激增，目前看起来效果显著。 围绕gitlab的workflow优化：gitlab-webhook \u0026amp; margebot流程优化与拆分，margebot优化了4/5s 建立CI/CD的告警监控机制 KMS 排查各种cratical problem：\n定位仿真性能问题，并给出对应的总结和处理手段，总结4,5次。 定位内存泄漏，coredump等问题，累计两次。 排查并解决基础架构业务过慢问题，gitlab+arm机器慢，2次 唉，尴尬\n","date":"2022 年 1 月 13 日","externalUrl":null,"permalink":"/posts/2022-01-13-%E4%B8%80%E4%B8%AAinfra%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E6%80%9D%E8%80%83/","section":"Posts","summary":"","title":"一个INFRA工程师的思考","type":"posts"},{"content":"光看注释和代码不清楚怎么用，不如直接上手写。\n今天的目标就是将redis-plus-plus库（c++库）从cmake编译转换为bazel编译，redis-plus-plus依赖hiredis库，hiredis库使用源码引入，redis-plus-plus依赖的uv库我们使用外部引入。\n包含几个部分：\n如何使用bazel编译sync \u0026amp; async 的hiredis，并且查看生成的头文件。生成两个目标hiredis \u0026amp; hiredis_ssl\n如何使用rules_foreign_cc编译第三方外部依赖（非bazel项目）openssl \u0026amp; libuv，两者分别使用configure_make \u0026amp; cmake\n如何使用bazel编译生成redis++库，包括sync，async，tls版本\n附录部分贴了starlark的东西：\n1 hiredis的编译 # 1.1 hiredis 的bazel转换 # 我们首先看下目前的cmakelists.txt文件，从而确定我们要生成的BUILD.bazel包含哪些东西。下面的代码我把一些没用的属性，比方说win32才需要的什么的或者一些无关的属性删除掉了。具体的分析的东西实际上在cmakelists.tx文件里面是非常清楚的，看注释即可，就不多解释了。\n# Hiredis requires C99 SET(CMAKE_C_STANDARD 99) #C99标准，添加到copt里面即可 SET(CMAKE_POSITION_INDEPENDENT_CODE ON) #fpic标记，编译静态库时需要加上，这样子才能生成的静态库被第三方引用 SET(CMAKE_DEBUG_POSTFIX d) SET(hiredis_sources #下面的.c文件对应于bazel src文件，我们可以看到目前的代码实际上是包含sync和async的， alloc.c async.c dict.c hiredis.c net.c read.c sds.c sockcompat.c) SET(hiredis_sources ${hiredis_sources}) ... ADD_LIBRARY(hiredis SHARED ${hiredis_sources}) #要生成这两个库文件 ADD_LIBRARY(hiredis_static STATIC ${hiredis_sources}) SET_TARGET_PROPERTIES(hiredis PROPERTIES WINDOWS_EXPORT_ALL_SYMBOLS TRUE VERSION \u0026#34;${HIREDIS_SONAME}\u0026#34;) SET_TARGET_PROPERTIES(hiredis_static PROPERTIES COMPILE_PDB_NAME hiredis_static) SET_TARGET_PROPERTIES(hiredis_static PROPERTIES COMPILE_PDB_NAME_DEBUG hiredis_static${CMAKE_DEBUG_POSTFIX}) #INSTALL_INTERFACE用于给install的时候指定使用的引用文件，那么INSTALL_INTERFACE又是怎么指定的？看这个https://ravenxrz.ink/archives/e40194d1.html TARGET_INCLUDE_DIRECTORIES(hiredis PUBLIC $\u0026lt;INSTALL_INTERFACE:include\u0026gt; $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}\u0026gt;) TARGET_INCLUDE_DIRECTORIES(hiredis_static PUBLIC $\u0026lt;INSTALL_INTERFACE:include\u0026gt; $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}\u0026gt;) #CONFIGURE_FILE替换原本的普通文件的内容，给pkg用的，不需要了，所以去掉 CONFIGURE_FILE(hiredis.pc.in hiredis.pc @ONLY) ... #Cpack打包的内容，直接省略了，关系并不大 ... IF(ENABLE_SSL) IF (NOT OPENSSL_ROOT_DIR) #这个是export的openssl根目录，用来判断找openssl IF (APPLE) SET(OPENSSL_ROOT_DIR \u0026#34;/usr/local/opt/openssl\u0026#34;) ENDIF() ENDIF() FIND_PACKAGE(OpenSSL REQUIRED) #找到依赖的openssl库 SET(hiredis_ssl_sources #编译hiredis_ssl库的源文件 ssl.c) ADD_LIBRARY(hiredis_ssl SHARED ${hiredis_ssl_sources}) #设定生成的库文件 ADD_LIBRARY(hiredis_ssl_static STATIC ${hiredis_ssl_sources}) ... SET_TARGET_PROPERTIES(hiredis_ssl_static PROPERTIES COMPILE_PDB_NAME hiredis_ssl_static) SET_TARGET_PROPERTIES(hiredis_ssl_static PROPERTIES COMPILE_PDB_NAME_DEBUG hiredis_ssl_static${CMAKE_DEBUG_POSTFIX}) TARGET_INCLUDE_DIRECTORIES(hiredis_ssl PRIVATE \u0026#34;${OPENSSL_INCLUDE_DIR}\u0026#34;) #引入openssl包裹的头文件，只给自己用。不会暴露给hiredis_ssl的使用者 TARGET_INCLUDE_DIRECTORIES(hiredis_ssl_static PRIVATE \u0026#34;${OPENSSL_INCLUDE_DIR}\u0026#34;) TARGET_LINK_LIBRARIES(hiredis_ssl PRIVATE ${OPENSSL_LIBRARIES}) ... INSTALL(TARGETS hiredis_ssl hiredis_ssl_static EXPORT hiredis_ssl-targets RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR} #安装bin文件的位置 LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR} #安装动态库的位置 ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}) #安装静态库的位置 ... INSTALL(FILES hiredis_ssl.h DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/hiredis) #可以看到安装头文件的位置，将hiredis_ssl.h搞到了安装头文件hiredis里面 INSTALL(FILES ${CMAKE_CURRENT_BINARY_DIR}/hiredis_ssl.pc #提供给pkg安装用的，不用关注 DESTINATION ${CMAKE_INSTALL_LIBDIR}/pkgconfig) export(EXPORT hiredis_ssl-targets FILE \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/hiredis_ssl-targets.cmake\u0026#34; NAMESPACE hiredis::) SET(CMAKE_CONF_INSTALL_DIR share/hiredis_ssl) ... ENDIF() ... 有几点需要单独解释。\n头文件可见性控制：无论是bazel还是cmake，实际上都在追究一个头文件可见性。一些老的c/c++代码是直接把头文件和代码放到一起，然后直接include \u0026quot;foo.h\u0026quot;。cmake通过指定TARGET_INCLUDE_DIRECTORIES来确定引用哪些目录，然后调用者可以类似上面include \u0026quot;foo.h\u0026quot;调用头文件。这里面引发一个问题，直接target_link_libraries，头文件会使用库引入而直接暴露的头文件，也就是上一层库暴露的头文件，这里TARGET_INCLUDE_DIRECTORIES(hiredis PUBLIC $\u0026lt;INSTALL_INTERFACE:include\u0026gt; $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}\u0026gt;)就是公开包，打包openssl的时候就是私有包TARGET_INCLUDE_DIRECTORIES(hiredis_ssl PRIVATE \u0026quot;${OPENSSL_INCLUDE_DIR}\u0026quot;)参考链接：https://ravenxrz.ink/archives/e40194d1.html，而bazel是采用相对于workspace的相对路径来引用具体的文件。\n需要简单解释INSTALL_INTERFACE \u0026amp; BUILD_INTERFACE的意思，两者分别指定了编译/安装的时候需要执行的操作，在target_include_directories的时候，我理解就是找到引用的头文件。BUILD_INTERFACE是指编译的时候会使用这些指定的头文件。而安装的时候会指定使用INSTALL_INTERFACE的头文件，Nmmm，但是我实际上没明白的是，到了安装的时候，我应该只暴露一个单独的给外界使用的外部接口的头文件和库文件，干嘛还需要依赖依赖头文件呢？我又仔细想了下，觉得可能这个所谓的install_interface不是常见的直接找头文件和lib库的方式，可能是一种所谓的modern cmake，即找到其它的依托cmake的build，然后使用里面的引用的头文件，举一个简单的例子，下面的例子是先find_package，不行了才执行find_library命令。而find_package即为modern cmake的部分，即从找二进制文件脱离到一个包上，从而可以指定版本，组件等信息。具体可以参考《Professional-CMake》23章。\n# hiredis dependency find_package(hiredis QUIET) if(hiredis_FOUND) list(APPEND REDIS_PLUS_PLUS_HIREDIS_LIBS hiredis::hiredis) if(REDIS_PLUS_PLUS_USE_TLS) find_package(hiredis_ssl REQUIRED) list(APPEND REDIS_PLUS_PLUS_HIREDIS_LIBS hiredis::hiredis_ssl) endif() else() find_path(HIREDIS_HEADER hiredis REQUIRED) find_library(HIREDIS_LIB hiredis REQUIRED) list(APPEND REDIS_PLUS_PLUS_HIREDIS_LIBS ${HIREDIS_LIB}) if(REDIS_PLUS_PLUS_USE_TLS) find_library(HIREDIS_TLS_LIB hiredis_ssl REQUIRED) list(APPEND REDIS_PLUS_PLUS_HIREDIS_LIBS ${HIREDIS_TLS_LIB}) endif() endif() 如果对cmake还有疑问，建议直接看这个https://zhuanlan.zhihu.com/p/393316878，国内写的很详尽的内容。或者直接看官方文档https://cmake.org/cmake/help/git-stage/guide/importing-exporting/index.html#exporting-targets, 如果对modern cmake有疑问，建议看看https://zhuanlan.zhihu.com/p/76975231，这个知乎的专栏写的比较清楚了。\nxxx.pc是什么：CFLAGS： 指定头文件（.h文件）的路径，如：CFLAGS=-I/usr/include -I/path/include。同样地，安装一个包时会在安装路径下建立一个include目录，当安装过程中出现问题时，试着把以前安装的包的include目录加入到该变量中来。可以看到下面制定了具体安装的路径是默认的prefix/include/hiredis。当然因为我们不适用pkg软件了，所以实际上我们不需要关注这个。上面的代码我注释掉了\nprefix=@CMAKE_INSTALL_PREFIX@ install_libdir=@CMAKE_INSTALL_LIBDIR@ exec_prefix=${prefix} libdir=${exec_prefix}/${install_libdir} includedir=${prefix}/include pkgincludedir=${includedir}/hiredis Name: hiredis Description: Minimalistic C client library for Redis. Version: @PROJECT_VERSION@ Libs: -L${libdir} -lhiredis Cflags: -I${pkgincludedir} -D_FILE_OFFSET_BITS=64 使用编译安装的时候还遇到一个问题，即async.c文件44行引用的是个dict.c文件，解决方法有两种：将这个改成dict.h，这个dict.c加到hdrs里面作为头文件引入。最终的BUILD文件如下。在公司的时候和同事聊确认一点，不推荐修改代码。修改代码的方式很糟糕。\ncc_library( name = \u0026#34;hiredis\u0026#34;, srcs = [ \u0026#34;alloc.c\u0026#34;, \u0026#34;dict.c\u0026#34;, \u0026#34;async.c\u0026#34;, \u0026#34;hiredis.c\u0026#34;, \u0026#34;net.c\u0026#34;, \u0026#34;read.c\u0026#34;, \u0026#34;sds.c\u0026#34;, \u0026#34;sockcompat.c\u0026#34;, ], hdrs = glob([\u0026#34;*.h\u0026#34;])+glob([\u0026#34;adapters/*.h\u0026#34;])+[\u0026#34;dict.c\u0026#34;,], #dict.c的引入是因为被async.c引了，而adapters是编译async时候别的库要使用 include_prefix = \u0026#34;hiredis\u0026#34;, visibility = [\u0026#34;//visibility:public\u0026#34;], ) cc_library( name = \u0026#34;hiredis_ssl\u0026#34;, srcs = [ \u0026#34;ssl.c\u0026#34;, ], hdrs = glob([\u0026#34;*.h\u0026#34;]), deps = [ \u0026#34;//third_party/openssl:openssl\u0026#34;, #我们重点关注下这个是怎么引入的 ], include_prefix = \u0026#34;hiredis\u0026#34;, visibility = [\u0026#34;//visibility:public\u0026#34;], ) 1.1 转换时学习bazel的行为 # bazel是一个追求编译速度的软件，编译hiredis_ssl的时候，这里要注意一点，如果头文件第一次拷贝过了，以后修改hdrs不需要了，它是不会删除的，依然会保留那些不用的；如果不存在才会再次拷贝。换言之，按需拷贝。另外头文件的路径是按照hdrs里面写的相对路径组织的。\nroot@3f01551b38dd:~/code_test/cmake2bazel# ls bazel-out/k8-fastbuild/bin/third_party/hiredis/_virtual_includes/hiredis_ssl/hiredis_ssl/ alloc.h async.h async_private.h dict.h fmacros.h hiredis.h hiredis_ssl.h net.h read.h sds.h sdsalloc.h sockcompat.h win32.h 我们再看编译redis++的时候虚拟头文件是什么，我们知道hdrs是这么写的\nhdrs = glob([\u0026#34;src/sw/redis++/*.h\u0026#34;])+glob([\u0026#34;src/sw/redis++/*.hpp\u0026#34;])+glob([\u0026#34;src/sw/redis++/cxx17/*.h\u0026#34;])+glob([\u0026#34;src/sw/redis++/no_tls/*.h\u0026#34;]) 它会按照文件的布局，组织头文件和目录拷贝到对应的/文件目标名字/文件目标名字下面，但是引用的时候按照最顶级的共享目录的名字来引用。参照下面的diff，我想使用tls.h的时候，可以#include \u0026quot;third_party/redis-plus-plus/src/sw/redis++/no_tls/tls.h\u0026quot;，那么为什么也可以#include \u0026quot;no_tls/tls.h\u0026quot;呢，因为我们保持了相对路径的正确性。第一种写法是相对于cmake2bazel的WORKSPCE的路径，而第二种是直接找的索引的最根本的想对路径。\nroot@3f01551b38dd:~/code_test/cmake2bazel# ll bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_virtual_includes/redis++/redis++/src/sw/redis++/ total 136 drwxr-xr-x 4 root root 4096 Nov 20 21:45 ./ drwxr-xr-x 3 root root 4096 Nov 20 21:45 ../ lrwxrwxrwx 1 root root 89 Nov 20 21:45 async_connection.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_connection.h lrwxrwxrwx 1 root root 94 Nov 20 21:45 async_connection_pool.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_connection_pool.h lrwxrwxrwx 1 root root 86 Nov 20 21:45 async_redis++.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_redis++.h lrwxrwxrwx 1 root root 84 Nov 20 21:45 async_redis.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_redis.h lrwxrwxrwx 1 root root 92 Nov 20 21:45 async_redis_cluster.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_redis_cluster.h lrwxrwxrwx 1 root root 87 Nov 20 21:45 async_sentinel.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_sentinel.h lrwxrwxrwx 1 root root 90 Nov 20 21:45 async_shards_pool.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_shards_pool.h lrwxrwxrwx 1 root root 86 Nov 20 21:45 cmd_formatter.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/cmd_formatter.h lrwxrwxrwx 1 root root 80 Nov 20 21:45 command.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/command.h lrwxrwxrwx 1 root root 85 Nov 20 21:45 command_args.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/command_args.h lrwxrwxrwx 1 root root 88 Nov 20 21:45 command_options.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/command_options.h lrwxrwxrwx 1 root root 83 Nov 20 21:45 connection.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/connection.h lrwxrwxrwx 1 root root 88 Nov 20 21:45 connection_pool.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/connection_pool.h drwxr-xr-x 2 root root 4096 Nov 20 21:45 cxx17/ lrwxrwxrwx 1 root root 79 Nov 20 21:45 errors.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/errors.h lrwxrwxrwx 1 root root 83 Nov 20 21:45 event_loop.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/event_loop.h drwxr-xr-x 2 root root 4096 Nov 20 21:45 no_tls/ lrwxrwxrwx 1 root root 81 Nov 20 21:45 pipeline.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/pipeline.h lrwxrwxrwx 1 root root 85 Nov 20 21:45 queued_redis.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/queued_redis.h lrwxrwxrwx 1 root root 87 Nov 20 21:45 queued_redis.hpp -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/queued_redis.hpp lrwxrwxrwx 1 root root 80 Nov 20 21:45 redis++.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis++.h lrwxrwxrwx 1 root root 78 Nov 20 21:45 redis.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis.h lrwxrwxrwx 1 root root 80 Nov 20 21:45 redis.hpp -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis.hpp lrwxrwxrwx 1 root root 86 Nov 20 21:45 redis_cluster.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis_cluster.h lrwxrwxrwx 1 root root 88 Nov 20 21:45 redis_cluster.hpp -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis_cluster.hpp lrwxrwxrwx 1 root root 78 Nov 20 21:45 reply.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/reply.h lrwxrwxrwx 1 root root 81 Nov 20 21:45 sentinel.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/sentinel.h lrwxrwxrwx 1 root root 79 Nov 20 21:45 shards.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/shards.h lrwxrwxrwx 1 root root 84 Nov 20 21:45 shards_pool.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/shards_pool.h lrwxrwxrwx 1 root root 83 Nov 20 21:45 subscriber.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/subscriber.h lrwxrwxrwx 1 root root 84 Nov 20 21:45 transaction.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/transaction.h lrwxrwxrwx 1 root root 78 Nov 20 21:45 utils.h -\u0026gt; /root/code_test/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/utils.h 现在我们考虑另一个问题，引用的第三方头文件在哪里？redis++引用hiredis，具体的代码可以参考下面的diff，它引用的目录是hiredis/redis.h。为什么能够直接找到呢？因为hiredis的BUILD里面有一句include_prefix = \u0026quot;hiredis\u0026quot;，从而将头文件的相对位置补齐了，从而redis++能够从hiredis目录找到具体的hiredis.h文件。查找include_prefix的定义会发现\nThe prefix to add to the paths of the headers of this rule.\nWhen set, the headers in the hdrs attribute of this rule are accessible at is the value of this attribute prepended to their repository-relative path.\nroot@3f01551b38dd:~/code_test/cmake2bazel/third_party/redis-plus-plus# egrep -R \u0026#34;hiredis.h\u0026#34; src/sw/redis++/cmd_formatter.h:#include \u0026lt;hiredis/hiredis.h\u0026gt; src/sw/redis++/tls/tls.h:#include \u0026lt;hiredis/hiredis.h\u0026gt; src/sw/redis++/tls/tls.h:#include \u0026lt;hiredis/hiredis_ssl.h\u0026gt; src/sw/redis++/redis.cpp:#include \u0026lt;hiredis/hiredis.h\u0026gt; src/sw/redis++/redis_cluster.cpp:#include \u0026lt;hiredis/hiredis.h\u0026gt; src/sw/redis++/no_tls/tls.h:#include \u0026lt;hiredis/hiredis.h\u0026gt; src/sw/redis++/reply.h:#include \u0026lt;hiredis/hiredis.h\u0026gt; src/sw/redis++/connection.h:#include \u0026lt;hiredis/hiredis.h\u0026gt; src/sw/redis++/errors.h:#include \u0026lt;hiredis/hiredis.h\u0026gt; 编译redis++的时候，_virtual_includes下面包含的文件\n如果去掉了include_prefix我们再看具体的编译输出代码，重点看具体编译的命令。\nroot@3f01551b38dd:~/code_test/cmake2bazel# bazel build //third_party/redis-plus-plus:redis++ --sandbox_debug INFO: Analyzed target //third_party/redis-plus-plus:redis++ (1 packages loaded, 23 targets configured). INFO: Found 1 target... INFO: From Compiling third_party/hiredis/dict.c: third_party/hiredis/dict.c:277:19: warning: \u0026#39;dictNext\u0026#39; defined but not used [-Wunused-function] 277 | static dictEntry *dictNext(dictIterator *iter) { | ^~~~~~~~ third_party/hiredis/dict.c:270:13: warning: \u0026#39;dictInitIterator\u0026#39; defined but not used [-Wunused-function] 270 | static void dictInitIterator(dictIterator *iter, dict *ht) { | ^~~~~~~~~~~~~~~~ third_party/hiredis/dict.c:250:13: warning: \u0026#39;dictRelease\u0026#39; defined but not used [-Wunused-function] 250 | static void dictRelease(dict *ht) { | ^~~~~~~~~~~ third_party/hiredis/dict.c:194:12: warning: \u0026#39;dictDelete\u0026#39; defined but not used [-Wunused-function] 194 | static int dictDelete(dict *ht, const void *key) { | ^~~~~~~~~~ third_party/hiredis/dict.c:169:12: warning: \u0026#39;dictReplace\u0026#39; defined but not used [-Wunused-function] 169 | static int dictReplace(dict *ht, void *key, void *val) { | ^~~~~~~~~~~ third_party/hiredis/dict.c:74:14: warning: \u0026#39;dictCreate\u0026#39; defined but not used [-Wunused-function] 74 | static dict *dictCreate(dictType *type, void *privDataPtr) { | ^~~~~~~~~~ third_party/hiredis/dict.c:54:21: warning: \u0026#39;dictGenHashFunction\u0026#39; defined but not used [-Wunused-function] 54 | static unsigned int dictGenHashFunction(const unsigned char *buf, int len) { | ^~~~~~~~~~~~~~~~~~~ Target //third_party/redis-plus-plus:redis++ up-to-date: bazel-bin/third_party/redis-plus-plus/libredis++.a bazel-bin/third_party/redis-plus-plus/libredis++.so INFO: Elapsed time: 2.323s, Critical Path: 2.11s INFO: 24 processes: 1 internal, 23 processwrapper-sandbox. INFO: Build completed successfully, 24 total actions root@3f01551b38dd:~/code_test/cmake2bazel# vim third_party/hiredis/BUILD root@3f01551b38dd:~/code_test/cmake2bazel# bazel build //third_party/redis-plus-plus:redis++ --sandbox_debug INFO: Analyzed target //third_party/redis-plus-plus:redis++ (1 packages loaded, 23 targets configured). INFO: Found 1 target... INFO: From Compiling third_party/hiredis/dict.c: third_party/hiredis/dict.c:277:19: warning: \u0026#39;dictNext\u0026#39; defined but not used [-Wunused-function] 277 | static dictEntry *dictNext(dictIterator *iter) { | ^~~~~~~~ third_party/hiredis/dict.c:270:13: warning: \u0026#39;dictInitIterator\u0026#39; defined but not used [-Wunused-function] 270 | static void dictInitIterator(dictIterator *iter, dict *ht) { | ^~~~~~~~~~~~~~~~ third_party/hiredis/dict.c:250:13: warning: \u0026#39;dictRelease\u0026#39; defined but not used [-Wunused-function] 250 | static void dictRelease(dict *ht) { | ^~~~~~~~~~~ third_party/hiredis/dict.c:194:12: warning: \u0026#39;dictDelete\u0026#39; defined but not used [-Wunused-function] 194 | static int dictDelete(dict *ht, const void *key) { | ^~~~~~~~~~ third_party/hiredis/dict.c:169:12: warning: \u0026#39;dictReplace\u0026#39; defined but not used [-Wunused-function] 169 | static int dictReplace(dict *ht, void *key, void *val) { | ^~~~~~~~~~~ third_party/hiredis/dict.c:74:14: warning: \u0026#39;dictCreate\u0026#39; defined but not used [-Wunused-function] 74 | static dict *dictCreate(dictType *type, void *privDataPtr) { | ^~~~~~~~~~ third_party/hiredis/dict.c:54:21: warning: \u0026#39;dictGenHashFunction\u0026#39; defined but not used [-Wunused-function] 54 | static unsigned int dictGenHashFunction(const unsigned char *buf, int len) { | ^~~~~~~~~~~~~~~~~~~ ERROR: /root/code_test/cmake2bazel/third_party/redis-plus-plus/BUILD:1:11: Compiling third_party/redis-plus-plus/src/sw/redis++/command_options.cpp failed: (Exit 1): process-wrapper failed: error executing command (cd /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/sandbox/processwrapper-sandbox/52/execroot/cmake2bazel \u0026amp;\u0026amp; \\ exec env - \\ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\ PWD=/proc/self/cwd \\ TMPDIR=/tmp \\ /root/.cache/bazel/_bazel_root/install/ee8d7e4b6774884ed2cd0aece6fc9fda/process-wrapper \u0026#39;--timeout=0\u0026#39; \u0026#39;--kill_delay=15\u0026#39; /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer \u0026#39;-std=c++0x\u0026#39; -MD -MF bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command_options.pic.d \u0026#39;-frandom-seed=bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command_options.pic.o\u0026#39; -fPIC -iquote . -iquote bazel-out/k8-fastbuild/bin -Ibazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_virtual_includes/redis++ \u0026#39;-std=c++17\u0026#39; -fno-canonical-system-headers -Wno-builtin-macro-redefined \u0026#39;-D__DATE__=\u0026#34;redacted\u0026#34;\u0026#39; \u0026#39;-D__TIMESTAMP__=\u0026#34;redacted\u0026#34;\u0026#39; \u0026#39;-D__TIME__=\u0026#34;redacted\u0026#34;\u0026#39; -c third_party/redis-plus-plus/src/sw/redis++/command_options.cpp -o bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command_options.pic.o) In file included from third_party/redis-plus-plus/src/sw/redis++/command_options.cpp:18: third_party/redis-plus-plus/src/sw/redis++/errors.h:22:10: fatal error: hiredis/hiredis.h: No such file or directory 22 | #include \u0026lt;hiredis/hiredis.h\u0026gt; | ^~~~~~~~~~~~~~~~~~~ compilation terminated. Target //third_party/redis-plus-plus:redis++ failed to build Use --verbose_failures to see the command lines of failed build steps. INFO: Elapsed time: 0.284s, Critical Path: 0.13s INFO: 24 processes: 16 internal, 8 processwrapper-sandbox. FAILED: Build did NOT complete successfully 调用process-wrapper去编译代码，引用头文件的目录的选项和具体设置为-Ibazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_virtual_includes/redis++而编译的文件为-c third_party/redis-plus-plus/src/sw/redis++/command.cpp，生成的中间文件为-o bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command.pic.o。但是我们很清楚gcc不会递归查找头文件，那么头文件是怎么找到的呢？\n/root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/sandbox/processwrapper-sandbox/52/execroot/cmake2bazel\n这里就可以看到具体的执行的路径了，换言之是在这个路径下的找到third_party/redis-plus-plus/src/sw/redis++/command.cpp，而相应的头文件也是拷贝到这个文件夹下面的相对路径。而不是我们本身的WORKSPACE所在的相对路径。可以看到只包含了要编译的cpp文件，和redis++里面的头文件，那么hiredis的头文件如何引入呢？\nroot@3f01551b38dd:~/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/sandbox/processwrapper-sandbox/52/execroot/cmake2bazel# ll third_party/redis-plus-plus/src/sw/redis++/ total 140 drwxr-xr-x 4 root root 4096 Nov 21 14:05 ./ drwxr-xr-x 3 root root 4096 Nov 21 14:05 ../ lrwxrwxrwx 1 root root 146 Nov 21 14:05 async_connection.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_connection.h lrwxrwxrwx 1 root root 151 Nov 21 14:05 async_connection_pool.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_connection_pool.h lrwxrwxrwx 1 root root 143 Nov 21 14:05 async_redis++.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_redis++.h lrwxrwxrwx 1 root root 141 Nov 21 14:05 async_redis.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_redis.h lrwxrwxrwx 1 root root 149 Nov 21 14:05 async_redis_cluster.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_redis_cluster.h lrwxrwxrwx 1 root root 144 Nov 21 14:05 async_sentinel.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_sentinel.h lrwxrwxrwx 1 root root 147 Nov 21 14:05 async_shards_pool.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/async_shards_pool.h lrwxrwxrwx 1 root root 143 Nov 21 14:05 cmd_formatter.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/cmd_formatter.h lrwxrwxrwx 1 root root 137 Nov 21 14:05 command.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/command.h lrwxrwxrwx 1 root root 142 Nov 21 14:05 command_args.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/command_args.h lrwxrwxrwx 1 root root 147 Nov 21 14:05 command_options.cpp -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/command_options.cpp lrwxrwxrwx 1 root root 145 Nov 21 14:05 command_options.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/command_options.h lrwxrwxrwx 1 root root 140 Nov 21 14:05 connection.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/connection.h lrwxrwxrwx 1 root root 145 Nov 21 14:05 connection_pool.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/connection_pool.h drwxr-xr-x 2 root root 4096 Nov 21 14:05 cxx17/ lrwxrwxrwx 1 root root 136 Nov 21 14:05 errors.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/errors.h lrwxrwxrwx 1 root root 140 Nov 21 14:05 event_loop.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/event_loop.h drwxr-xr-x 2 root root 4096 Nov 21 14:05 no_tls/ lrwxrwxrwx 1 root root 138 Nov 21 14:05 pipeline.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/pipeline.h lrwxrwxrwx 1 root root 142 Nov 21 14:05 queued_redis.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/queued_redis.h lrwxrwxrwx 1 root root 144 Nov 21 14:05 queued_redis.hpp -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/queued_redis.hpp lrwxrwxrwx 1 root root 137 Nov 21 14:05 redis++.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis++.h lrwxrwxrwx 1 root root 135 Nov 21 14:05 redis.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis.h lrwxrwxrwx 1 root root 137 Nov 21 14:05 redis.hpp -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis.hpp lrwxrwxrwx 1 root root 143 Nov 21 14:05 redis_cluster.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis_cluster.h lrwxrwxrwx 1 root root 145 Nov 21 14:05 redis_cluster.hpp -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/redis_cluster.hpp lrwxrwxrwx 1 root root 135 Nov 21 14:05 reply.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/reply.h lrwxrwxrwx 1 root root 138 Nov 21 14:05 sentinel.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/sentinel.h lrwxrwxrwx 1 root root 136 Nov 21 14:05 shards.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/shards.h lrwxrwxrwx 1 root root 141 Nov 21 14:05 shards_pool.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/shards_pool.h lrwxrwxrwx 1 root root 140 Nov 21 14:05 subscriber.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/subscriber.h lrwxrwxrwx 1 root root 141 Nov 21 14:05 transaction.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/transaction.h lrwxrwxrwx 1 root root 135 Nov 21 14:05 utils.h -\u0026gt; /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/execroot/cmake2bazel/third_party/redis-plus-plus/src/sw/redis++/utils.h 所以有个问题，什么是virutal include folder。bazel使用virual includes来管理\n#如果没有加prefix，在那个目录查找hiredis.h root@3f01551b38dd:~/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/sandbox/processwrapper-sandbox/52/execroot/cmake2bazel# find ./ -name hiredis.h ./third_party/hiredis/hiredis.h #不加prefix，看看redis++的编译报错，可以看到没有直接引入hiredis.h文件。这是怎么回事呢？ root@3f01551b38dd:~/code_test/cmake2bazel# bazel build //third_party/redis-plus-plus:redis++ --sandbox_debug INFO: Analyzed target //third_party/redis-plus-plus:redis++ (1 packages loaded, 23 targets configured). INFO: Found 1 target... ERROR: /root/code_test/cmake2bazel/third_party/redis-plus-plus/BUILD:1:11: Compiling third_party/redis-plus-plus/src/sw/redis++/command_options.cpp failed: (Exit 1): process-wrapper failed: error executing command (cd /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/sandbox/processwrapper-sandbox/147/execroot/cmake2bazel \u0026amp;\u0026amp; \\ exec env - \\ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\ PWD=/proc/self/cwd \\ TMPDIR=/tmp \\ /root/.cache/bazel/_bazel_root/install/ee8d7e4b6774884ed2cd0aece6fc9fda/process-wrapper \u0026#39;--timeout=0\u0026#39; \u0026#39;--kill_delay=15\u0026#39; /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer \u0026#39;-std=c++0x\u0026#39; -MD -MF bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command_options.pic.d \u0026#39;-frandom-seed=bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command_options.pic.o\u0026#39; -fPIC -iquote . -iquote bazel-out/k8-fastbuild/bin -Ibazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_virtual_includes/redis++ \u0026#39;-std=c++17\u0026#39; -fno-canonical-system-headers -Wno-builtin-macro-redefined \u0026#39;-D__DATE__=\u0026#34;redacted\u0026#34;\u0026#39; \u0026#39;-D__TIMESTAMP__=\u0026#34;redacted\u0026#34;\u0026#39; \u0026#39;-D__TIME__=\u0026#34;redacted\u0026#34;\u0026#39; -c third_party/redis-plus-plus/src/sw/redis++/command_options.cpp -o bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command_options.pic.o) In file included from third_party/redis-plus-plus/src/sw/redis++/command_options.cpp:18: third_party/redis-plus-plus/src/sw/redis++/errors.h:22:10: fatal error: hiredis/hiredis.h: No such file or directory 22 | #include \u0026lt;hiredis/hiredis.h\u0026gt; | ^~~~~~~~~~~~~~~~~~~ compilation terminated. Target //third_party/redis-plus-plus:redis++ failed to build Use --verbose_failures to see the command lines of failed build steps. INFO: Elapsed time: 0.204s, Critical Path: 0.07s INFO: 19 processes: 17 internal, 2 processwrapper-sandbox. FAILED: Build did NOT complete successfully #如果加了prefix，查找hiredis.h root@3f01551b38dd:~/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/sandbox/processwrapper-sandbox/88/execroot/cmake2bazel# find ./ -name hiredis.h ./third_party/hiredis/hiredis.h #可以看到，这个路径是相对于WORKSPACE的路径，是一直存在的，无论编译与否都不会出错。这个也是推荐的编译目录 ./bazel-out/k8-fastbuild/bin/third_party/hiredis/_virtual_includes/hiredis/hiredis/hiredis.h #这个就是加了include_prefix之后生成的假的include folder #如果加了prefix我们在看编译redis++的命令（我加了一个未导入的文件hxndg.hcc来打断生成的文件） #可以看到引用的头文件目录多了两个，为： #bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_virtual_includes/redis++ #-Ibazel-out/k8-fastbuild/bin/third_party/hiredis/_virtual_includes/hiredis root@3f01551b38dd:~/code_test/cmake2bazel# bazel build //third_party/redis-plus-plus:redis++ --sandbox_debug INFO: Analyzed target //third_party/redis-plus-plus:redis++ (0 packages loaded, 0 targets configured). INFO: Found 1 target... ERROR: /root/code_test/cmake2bazel/third_party/redis-plus-plus/BUILD:1:11: Compiling third_party/redis-plus-plus/src/sw/redis++/command.cpp failed: (Exit 1): process-wrapper failed: error executing command (cd /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/sandbox/processwrapper-sandbox/137/execroot/cmake2bazel \u0026amp;\u0026amp; \\ exec env - \\ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\ PWD=/proc/self/cwd \\ TMPDIR=/tmp \\ /root/.cache/bazel/_bazel_root/install/ee8d7e4b6774884ed2cd0aece6fc9fda/process-wrapper \u0026#39;--timeout=0\u0026#39; \u0026#39;--kill_delay=15\u0026#39; /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer \u0026#39;-std=c++0x\u0026#39; -MD -MF bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command.pic.d \u0026#39;-frandom-seed=bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command.pic.o\u0026#39; -fPIC -iquote . -iquote bazel-out/k8-fastbuild/bin -Ibazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_virtual_includes/redis++ -Ibazel-out/k8-fastbuild/bin/third_party/hiredis/_virtual_includes/hiredis \u0026#39;-std=c++17\u0026#39; -fno-canonical-system-headers -Wno-builtin-macro-redefined \u0026#39;-D__DATE__=\u0026#34;redacted\u0026#34;\u0026#39; \u0026#39;-D__TIMESTAMP__=\u0026#34;redacted\u0026#34;\u0026#39; \u0026#39;-D__TIME__=\u0026#34;redacted\u0026#34;\u0026#39; -c third_party/redis-plus-plus/src/sw/redis++/command.cpp -o bazel-out/k8-fastbuild/bin/third_party/redis-plus-plus/_objs/redis++/command.pic.o) third_party/redis-plus-plus/src/sw/redis++/command.cpp:18:10: fatal error: hxndg.hcc: No such file or directory 18 | #include \u0026#34;hxndg.hcc\u0026#34; | ^~~~~~~~~~~ compilation terminated. Target //third_party/redis-plus-plus:redis++ failed to build Use --verbose_failures to see the command lines of failed build steps. INFO: Elapsed time: 0.223s, Critical Path: 0.12s INFO: 15 processes: 15 internal. FAILED: Build did NOT complete successfully 这里存在一个问题，在modern cmake里面我们经常希望能够控制头文件/库文件的暴露，bazel是如何控制头文件暴露的？\nFor cc_library rules, headers in hdrs comprise the public interface of the library and can be directly included both from the files in hdrs and srcs of the library itself as well as from files in hdrs and srcs of cc_* rules that list the library in their deps. Headers in srcs must only be directly included from the files in hdrs and srcs of the library itself.\ncc_library的hdrs里面的描述\nThe list of header files published by this library to be directly included by sources in dependent rules.\nThis is the strongly preferred location for declaring header files that describe the interface for the library. These headers will be made available for inclusion by sources in this rule or in dependent rules. Headers not meant to be included by a client of this library should be listed in the srcs attribute instead, even if they are included by a published header\n可见我们想直接暴露的头文件应当写到cc_library的hdrs里面，而内部使用的头文件写到src里面。\n具体存储了什么看这里：https://docs.bazel.build/versions/main/output_directories.html\n具体代码参考bazel-master\\src\\main\\java\\com\\google\\devtools\\build\\lib\\rules\\cpp\\CcCompilationHelper.java，想理解代码建议阅读CODEBASE.md文件\nbazel-out存储了中间文件，运行的环境实际上就在bazel-out里面，\n2 openssl \u0026amp; libuv的编译。 # 2.1 openssl的编译 \u0026amp; libuv # 首先，我们需要下载openssl的源码和Libuv的源代码，因此修改WORKSPACE如下\nworkspace(name = \u0026#34;cmake2bazel\u0026#34;) load(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;) # 1.0版本的rules_foreign_cc，非常老旧了，网上我就搜到一个老外博客写怎么用这个的，就是用的1.0的版本 #http_archive( # name = \u0026#34;rules_foreign_cc\u0026#34;, # sha256 = \u0026#34;c2cdcf55ffaf49366725639e45dedd449b8c3fe22b54e31625eb80ce3a240f1e\u0026#34;, # strip_prefix = \u0026#34;rules_foreign_cc-0.1.0\u0026#34;, # url = \u0026#34;https://github.com/bazelbuild/rules_foreign_cc/archive/0.1.0.zip\u0026#34;, #) # #load(\u0026#34;@rules_foreign_cc//foreign_cc:repositories.bzl\u0026#34;, \u0026#34;rules_foreign_cc_dependencies\u0026#34;) http_archive( name = \u0026#34;rules_foreign_cc\u0026#34;, strip_prefix = \u0026#34;rules_foreign_cc-4010620160e0df4d894b61496d3d3b6fc8323212\u0026#34;, sha256 = \u0026#34;07e3414cc841b1f4d16e5231eb818e5c5e03e2045827f5306a55709e5045c7fd\u0026#34;, url = \u0026#34;https://github.com/bazelbuild/rules_foreign_cc/archive/4010620160e0df4d894b61496d3d3b6fc8323212.zip\u0026#34;, ) load(\u0026#34;@rules_foreign_cc//foreign_cc:repositories.bzl\u0026#34;, \u0026#34;rules_foreign_cc_dependencies\u0026#34;) rules_foreign_cc_dependencies() all_content = \u0026#34;\u0026#34;\u0026#34;filegroup(name = \u0026#34;all\u0026#34;, srcs = glob([\u0026#34;**\u0026#34;]), visibility = [\u0026#34;//visibility:public\u0026#34;])\u0026#34;\u0026#34;\u0026#34; # openssl http_archive( name = \u0026#34;openssl\u0026#34;, build_file_content = all_content, strip_prefix = \u0026#34;openssl-OpenSSL_1_1_1d\u0026#34;, urls = [\u0026#34;https://github.com/openssl/openssl/archive/OpenSSL_1_1_1d.tar.gz\u0026#34;] ) # uv http_archive( name = \u0026#34;libuv\u0026#34;, build_file_content = all_content, strip_prefix = \u0026#34;libuv-1.42.0\u0026#34;, urls = [\u0026#34;https://github.com/libuv/libuv/archive/refs/tags/v1.42.0.tar.gz\u0026#34;] ) thirdy_party/openssl/BUILD文件直接引用第三方仓库，然后调用rules_foreign_cc的configure_make进行安装和编译，libuv也能使用configure_make的命令进行编译，他也依托auto_gen生成代码，下面的BUILD文件使用了cmake命令。\n整个的过程可以说是非常简单了，指定源码，指定编译出来的文件，然后就没有了。\n如果对rules_foreign_cc有疑问就看这个链接https://github.com/bazelbuild/rules_foreign_cc/blob/main/docs/README.md。如果想学能够看懂rules_foreign_cc的代码，得看starlark的语言教程，参考：https://github.com/bazelbuild/starlark/blob/master/spec.md\n# See https://github.com/bazelbuild/rules_foreign_cc load(\u0026#34;@rules_foreign_cc//foreign_cc:defs.bzl\u0026#34;, \u0026#34;configure_make\u0026#34;) config_setting( name = \u0026#34;darwin_build\u0026#34;, values = {\u0026#34;cpu\u0026#34;: \u0026#34;darwin\u0026#34;}, ) # See https://wiki.openssl.org/index.php/Compilation_and_Installation # See https://github.com/bazelbuild/rules_foreign_cc/issues/338 #可以通过指定out_lib_dir选项指定编译出来的lib放在哪里，aka The path to where the compiled library binaries will be written to following a successful build #对于使用configure-make形式的代码编译的方式， configure_make( name = \u0026#34;openssl\u0026#34;, #实际上调用configure的命令，默认是调用configure，这里可以找到openssl里面调用的是config configure_command = \u0026#34;config\u0026#34;, #Any options to be put on the \u0026#39;configure\u0026#39; command line. configure_options = select({ \u0026#34;:darwin_build\u0026#34;: [ \u0026#34;shared\u0026#34;, \u0026#34;ARFLAGS=r\u0026#34;, \u0026#34;enable-ec_nistp_64_gcc_128\u0026#34;, \u0026#34;no-ssl2\u0026#34;, \u0026#34;no-ssl3\u0026#34;, \u0026#34;no-comp\u0026#34; ], \u0026#34;//conditions:default\u0026#34;: [ ]}), #defines = [\u0026#34;NDEBUG\u0026#34;], Don\u0026#39;t know how to use -D; NDEBUG seems to be the default anyway #指定OPENSSL编译lib的源代码文件，aka Where the library source code is for openssl lib_source = \u0026#34;@openssl//:all\u0026#34;, visibility = [\u0026#34;//visibility:public\u0026#34;], #Environment variables to be set for the \u0026#39;configure\u0026#39; invocation. configure_env_vars = select({ \u0026#34;:darwin_build\u0026#34;: { \u0026#34;OSX_DEPLOYMENT_TARGET\u0026#34;: \u0026#34;10.14\u0026#34;, \u0026#34;AR\u0026#34;: \u0026#34;\u0026#34;, }, \u0026#34;//conditions:default\u0026#34;: {}}), #用来指定共享出来的动态库、动态文件是什么，可以使用static_libraries属性来共享动态库 out_shared_libs = select({ \u0026#34;:darwin_build\u0026#34;: [ \u0026#34;libssl.dylib\u0026#34;, \u0026#34;libcrypto.dylib\u0026#34;, ], \u0026#34;//conditions:default\u0026#34;: [ \u0026#34;libssl.so\u0026#34;, \u0026#34;libcrypto.so\u0026#34;, ], }) ) third_party/libuv/BUILD文件\n这里要注意一点，生成静态库文件的时候是文件名字为libuv_a.a，一开始我写的是libuv.a，然后报错没想明白咋回事，后来去找了libuv的编译过程看了下才发现静态库文件是libuv_a.a，如果想使用动态库，就用out_shared_libs即可。那么现在问题就来了，从rules_foreign_cc是怎么到具体的生成的头文件和静态库文件呢？\n# See https://github.com/bazelbuild/rules_foreign_cc load(\u0026#34;@rules_foreign_cc//foreign_cc:defs.bzl\u0026#34;, \u0026#34;cmake\u0026#34;) cmake( name = \u0026#34;libuv\u0026#34;, lib_source = \u0026#34;@libuv//:all\u0026#34;, #out_static_libs = [\u0026#34;libuv.a\u0026#34;], out_static_libs = [\u0026#34;libuv_a.a\u0026#34;], #out_shared_libs = [\u0026#34;libuv.so.1.0.0\u0026#34;], libuv.so是个链接，直接编译会报错 ) libuv编译时候的代码为：\nqcraft@BJ-vgdog:~/code_test/cmake2bazel$ bazelisk-linux-amd64 build //third_party/libuv:libuv DEBUG: Rule \u0026#39;libuv\u0026#39; indicated that a canonical reproducible form can be obtained by modifying arguments sha256 = \u0026#34;371e5419708f6aaeb8656671f89400b92a9bba6443369af1bb70bcd6e4b3c764\u0026#34; DEBUG: Repository libuv instantiated at: /home/qcraft/code_test/cmake2bazel/WORKSPACE:36:13: in \u0026lt;toplevel\u0026gt; Repository rule http_archive defined at: /home/qcraft/.cache/bazel/_bazel_qcraft/66cfb4dff202f299686aa7bc701960fa/external/bazel_tools/tools/build_defs/repo/http.bzl:336:31: in \u0026lt;toplevel\u0026gt; INFO: Analyzed target //third_party/libuv:libuv (1 packages loaded, 1 target configured). INFO: Found 1 target... Target //third_party/libuv:libuv up-to-date: bazel-bin/third_party/libuv/libuv/include bazel-bin/third_party/libuv/libuv/lib/libuv_a.a bazel-bin/third_party/libuv/copy_libuv/libuv INFO: Elapsed time: 31.269s, Critical Path: 30.97s INFO: 2 processes: 1 internal, 1 linux-sandbox. INFO: Build completed successfully, 2 total actions 有另外一个问题，rules_foreign_cc能否正确处理第三方的依赖，也就是引入的库还依赖别的库？我们还是用简单的试下好了，\n2.2 rules_foreign_cc的相关问题 # 目前存在两个相关rules_foreign_cc的问题：\nrules_foreign_cc能不能起到和bazel相同的功能？能不能编译生成的文件和cmake一样？简单来说就是能不能保证编译出来的文件和头文件一致呢？ rules_foreign_cc到底干了什么？我们需要看看源代码到底干了什么? 我们先关注问题1，\n再看问题2，\n2.3 bazel的学习 # 有个问题冒出来了，openssl的头文件是怎么找到的呢？我改了一下hireds/ssl.c的代码，引入了一个不存在的头文件，然后执行编译命令。看到这句话-isystem bazel-out/k8-fastbuild/bin/third_party/openssl/openssl/include，这个路径下有openssl文件夹\nroot@3f01551b38dd:~/code_test/cmake2bazel# bazel build //third_party/hiredis:hiredis_ssl INFO: Analyzed target //third_party/hiredis:hiredis_ssl (4 packages loaded, 3059 targets configured). INFO: Found 1 target... ERROR: /root/code_test/cmake2bazel/third_party/hiredis/BUILD:18:11: Compiling third_party/hiredis/ssl.c failed: (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -MD -MF ... (remaining 19 argument(s) skipped) Use --sandbox_debug to see verbose messages from the sandbox third_party/hiredis/ssl.c:48:10: fatal error: hxndg.hcc: No such file or directory 48 | #include \u0026#34;hxndg.hcc\u0026#34; | ^~~~~~~~~~~ compilation terminated. Target //third_party/hiredis:hiredis_ssl failed to build Use --verbose_failures to see the command lines of failed build steps. INFO: Elapsed time: 1.350s, Critical Path: 0.54s INFO: 14 processes: 14 internal. FAILED: Build did NOT complete successfully root@3f01551b38dd:~/code_test/cmake2bazel# bazel build //third_party/hiredis:hiredis_ssl --sandbox_debug INFO: Analyzed target //third_party/hiredis:hiredis_ssl (0 packages loaded, 0 targets configured). INFO: Found 1 target... ERROR: /root/code_test/cmake2bazel/third_party/hiredis/BUILD:18:11: Compiling third_party/hiredis/ssl.c failed: (Exit 1): process-wrapper failed: error executing command (cd /root/.cache/bazel/_bazel_root/40ee89a49d5eb376cc6e6e5356870e5a/sandbox/processwrapper-sandbox/165/execroot/cmake2bazel \u0026amp;\u0026amp; \\ exec env - \\ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\ PWD=/proc/self/cwd \\ TMPDIR=/tmp \\ /root/.cache/bazel/_bazel_root/install/ee8d7e4b6774884ed2cd0aece6fc9fda/process-wrapper \u0026#39;--timeout=0\u0026#39; \u0026#39;--kill_delay=15\u0026#39; /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -MD -MF bazel-out/k8-fastbuild/bin/third_party/hiredis/_objs/hiredis_ssl/ssl.pic.d \u0026#39;-frandom-seed=bazel-out/k8-fastbuild/bin/third_party/hiredis/_objs/hiredis_ssl/ssl.pic.o\u0026#39; -fPIC -iquote . -iquote bazel-out/k8-fastbuild/bin -Ibazel-out/k8-fastbuild/bin/third_party/hiredis/_virtual_includes/hiredis_ssl -isystem bazel-out/k8-fastbuild/bin/third_party/openssl/openssl/include -fno-canonical-system-headers -Wno-builtin-macro-redefined \u0026#39;-D__DATE__=\u0026#34;redacted\u0026#34;\u0026#39; \u0026#39;-D__TIMESTAMP__=\u0026#34;redacted\u0026#34;\u0026#39; \u0026#39;-D__TIME__=\u0026#34;redacted\u0026#34;\u0026#39; -c third_party/hiredis/ssl.c -o bazel-out/k8-fastbuild/bin/third_party/hiredis/_objs/hiredis_ssl/ssl.pic.o) third_party/hiredis/ssl.c:48:10: fatal error: hxndg.hcc: No such file or directory 48 | #include \u0026#34;hxndg.hcc\u0026#34; | ^~~~~~~~~~~ compilation terminated. Target //third_party/hiredis:hiredis_ssl failed to build Use --verbose_failures to see the command lines of failed build steps. INFO: Elapsed time: 0.232s, Critical Path: 0.06s INFO: 2 processes: 2 internal. FAILED: Build did NOT complete successfully redis++的编译 # 贴上cmakelist文件的代码\n... set(REDIS_PLUS_PLUS_DEFAULT_CXX_STANDARD 17) #设定一个变量指代代码标准为c++17 ... if(NOT WIN32) set(CMAKE_CXX_FLAGS \u0026#34;${CMAKE_CXX_FLAGS} -std=c++${REDIS_PLUS_PLUS_CXX_STANDARD}\u0026#34;) #设定代码标准为c++17 else() set(CMAKE_CXX_FLAGS \u0026#34;${CMAKE_CXX_FLAGS} /std:c++${REDIS_PLUS_PLUS_CXX_STANDARD}\u0026#34;) endif() if(REDIS_PLUS_PLUS_BUILD_ASYNC) #是否编译ASYNC代码 if(REDIS_PLUS_PLUS_BUILD_ASYNC STREQUAL \u0026#34;libuv\u0026#34;) message(STATUS \u0026#34;redis-plus-plus build async interface with libuv\u0026#34;) #如果编译async的代码，那么需要找到libuv头文件和库，我在代码中通过rules_foreign_cc解决 # libuv dependency find_path(REDIS_PLUS_PLUS_ASYNC_LIB_HEADER NAMES uv.h) find_library(REDIS_PLUS_PLUS_ASYNC_LIB uv) else() message(FATAL_ERROR \u0026#34;invalid REDIS_PLUS_PLUS_BUILD_ASYNC\u0026#34;) endif() endif() set(REDIS_PLUS_PLUS_SOURCE_DIR src/sw/redis++) set(REDIS_PLUS_PLUS_SOURCES #sync的源文件 \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/command.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/command_options.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/connection.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/connection_pool.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/crc16.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/errors.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/pipeline.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/redis.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/redis_cluster.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/reply.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/sentinel.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/shards.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/shards_pool.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/subscriber.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/transaction.cpp\u0026#34; ) if(REDIS_PLUS_PLUS_BUILD_ASYNC) #async还得加上这些源文件 list(APPEND REDIS_PLUS_PLUS_SOURCES \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/async_connection.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/async_connection_pool.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/async_redis.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/event_loop.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/async_sentinel.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/async_redis_cluster.cpp\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/async_shards_pool.cpp\u0026#34; ) if(NOT REDIS_PLUS_PLUS_ASYNC_FUTURE) set(REDIS_PLUS_PLUS_ASYNC_FUTURE \u0026#34;std\u0026#34;) #使用标准库的std::future特性，std17已经支持了. endif() if(REDIS_PLUS_PLUS_ASYNC_FUTURE STREQUAL \u0026#34;std\u0026#34;) set(REDIS_PLUS_PLUS_ASYNC_FUTURE_HEADER \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/future/std\u0026#34;) #链进来的future/std头文件 elseif(REDIS_PLUS_PLUS_ASYNC_FUTURE STREQUAL \u0026#34;boost\u0026#34;) set(REDIS_PLUS_PLUS_ASYNC_FUTURE_HEADER \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/future/boost\u0026#34;) find_package(Boost REQUIRED COMPONENTS system thread) else() message(FATAL_ERROR \u0026#34;invalid REDIS_PLUS_PLUS_ASYNC_FUTURE\u0026#34;) endif() endif() # cxx utils if(REDIS_PLUS_PLUS_CXX_STANDARD LESS 17) set(CXX_UTILS_DIR \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/cxx11\u0026#34;) else() set(CXX_UTILS_DIR \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/cxx17\u0026#34;) #链接cxx17的头文件 endif() # TLS support option(REDIS_PLUS_PLUS_USE_TLS \u0026#34;Build with TLS support\u0026#34; OFF) #默认tls是关闭的 message(STATUS \u0026#34;redis-plus-plus TLS support: ${REDIS_PLUS_PLUS_USE_TLS}\u0026#34;) if(REDIS_PLUS_PLUS_USE_TLS) set(TLS_SUB_DIR \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/tls\u0026#34;) #如果使用tls，头文件里面引用源码目录下的tls文件夹 list(APPEND REDIS_PLUS_PLUS_SOURCES \u0026#34;${TLS_SUB_DIR}/tls.cpp\u0026#34;) #如果要使用tls，那么sync \u0026amp; async都得加上tls的cpp文件 set(REDIS_PLUS_PLUS_DEPENDS \u0026#34;hiredis,hiredis_ssl\u0026#34;) #使用tls，就依赖hiredis和hiredis_ssl else() set(TLS_SUB_DIR \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/no_tls\u0026#34;) #不使用tls，头文件里面引用no_tls文件夹 set(REDIS_PLUS_PLUS_DEPENDS \u0026#34;hiredis\u0026#34;) endif() # hiredis dependency find_package(hiredis QUIET) #依赖hiredis文件 if(hiredis_FOUND) list(APPEND REDIS_PLUS_PLUS_HIREDIS_LIBS hiredis::hiredis) if(REDIS_PLUS_PLUS_USE_TLS) find_package(hiredis_ssl REQUIRED) list(APPEND REDIS_PLUS_PLUS_HIREDIS_LIBS hiredis::hiredis_ssl) endif() else() find_path(HIREDIS_HEADER hiredis) find_library(HIREDIS_LIB hiredis) list(APPEND REDIS_PLUS_PLUS_HIREDIS_LIBS ${HIREDIS_LIB}) if(REDIS_PLUS_PLUS_USE_TLS) find_library(HIREDIS_TLS_LIB hiredis_ssl) list(APPEND REDIS_PLUS_PLUS_HIREDIS_LIBS ${HIREDIS_TLS_LIB}) endif() endif() # Build static library option(REDIS_PLUS_PLUS_BUILD_STATIC \u0026#34;Build static library\u0026#34; ON) message(STATUS \u0026#34;redis-plus-plus build static library: ${REDIS_PLUS_PLUS_BUILD_STATIC}\u0026#34;) if(REDIS_PLUS_PLUS_BUILD_STATIC) set(STATIC_LIB redis++_static) add_library(${STATIC_LIB} STATIC ${REDIS_PLUS_PLUS_SOURCES}) add_library(redis++::${STATIC_LIB} ALIAS ${STATIC_LIB}) list(APPEND REDIS_PLUS_PLUS_TARGETS ${STATIC_LIB}) target_include_directories(${STATIC_LIB} PUBLIC $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/${REDIS_PLUS_PLUS_SOURCE_DIR}\u0026gt; #编译时候的头文件包含这三个目录 $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/${TLS_SUB_DIR}\u0026gt; $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/${CXX_UTILS_DIR}\u0026gt; $\u0026lt;INSTALL_INTERFACE:include\u0026gt;) if(hiredis_FOUND) target_link_libraries(${STATIC_LIB} PUBLIC ${REDIS_PLUS_PLUS_HIREDIS_LIBS}) else() target_include_directories(${STATIC_LIB} PUBLIC $\u0026lt;BUILD_INTERFACE:${HIREDIS_HEADER}\u0026gt;) endif() if(REDIS_PLUS_PLUS_BUILD_ASYNC) target_include_directories(${STATIC_LIB} PUBLIC $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/${REDIS_PLUS_PLUS_ASYNC_FUTURE_HEADER}\u0026gt;) target_include_directories(${STATIC_LIB} PUBLIC $\u0026lt;BUILD_INTERFACE:${REDIS_PLUS_PLUS_ASYNC_LIB_HEADER}\u0026gt;) if(REDIS_PLUS_PLUS_ASYNC_FUTURE STREQUAL \u0026#34;boost\u0026#34;) target_include_directories(${STATIC_LIB} SYSTEM PUBLIC $\u0026lt;BUILD_INTERFACE:${Boost_INCLUDE_DIR}\u0026gt;) endif() endif() if (WIN32) ... else() target_compile_options(${STATIC_LIB} PRIVATE \u0026#34;-Wall\u0026#34; \u0026#34;-W\u0026#34; \u0026#34;-Werror\u0026#34;) set_target_properties(${STATIC_LIB} PROPERTIES OUTPUT_NAME redis++) endif() set_target_properties(${STATIC_LIB} PROPERTIES CLEAN_DIRECT_OUTPUT 1) set_target_properties(${STATIC_LIB} PROPERTIES CXX_EXTENSIONS OFF) option(REDIS_PLUS_PLUS_BUILD_STATIC_WITH_PIC \u0026#34;Build static library with position independent code\u0026#34; ON) message(STATUS \u0026#34;redis-plus-plus build static library with position independent code: ${REDIS_PLUS_PLUS_BUILD_STATIC_WITH_PIC}\u0026#34;) if(REDIS_PLUS_PLUS_BUILD_STATIC_WITH_PIC) set_target_properties(${STATIC_LIB} PROPERTIES POSITION_INDEPENDENT_CODE ON) endif() endif() # Build shared library option(REDIS_PLUS_PLUS_BUILD_SHARED \u0026#34;Build shared library\u0026#34; ON) message(STATUS \u0026#34;redis-plus-plus build shared library: ${REDIS_PLUS_PLUS_BUILD_SHARED}\u0026#34;) if(REDIS_PLUS_PLUS_BUILD_SHARED) set(SHARED_LIB redis++) add_library(${SHARED_LIB} SHARED ${REDIS_PLUS_PLUS_SOURCES}) add_library(redis++::${SHARED_LIB} ALIAS ${SHARED_LIB}) list(APPEND REDIS_PLUS_PLUS_TARGETS ${SHARED_LIB}) target_include_directories(${SHARED_LIB} PUBLIC $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/${REDIS_PLUS_PLUS_SOURCE_DIR}\u0026gt; $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/${TLS_SUB_DIR}\u0026gt; $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/${CXX_UTILS_DIR}\u0026gt; $\u0026lt;INSTALL_INTERFACE:include\u0026gt;) if(hiredis_FOUND) target_link_libraries(${SHARED_LIB} PUBLIC ${REDIS_PLUS_PLUS_HIREDIS_LIBS}) else() target_include_directories(${SHARED_LIB} PUBLIC $\u0026lt;BUILD_INTERFACE:${HIREDIS_HEADER}\u0026gt;) target_link_libraries(${SHARED_LIB} PUBLIC ${REDIS_PLUS_PLUS_HIREDIS_LIBS}) endif() if(REDIS_PLUS_PLUS_BUILD_ASYNC) target_include_directories(${SHARED_LIB} PUBLIC $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/${REDIS_PLUS_PLUS_ASYNC_FUTURE_HEADER}\u0026gt;) target_include_directories(${SHARED_LIB} PUBLIC $\u0026lt;BUILD_INTERFACE:${REDIS_PLUS_PLUS_ASYNC_LIB_HEADER}\u0026gt;) target_link_libraries(${SHARED_LIB} PUBLIC ${REDIS_PLUS_PLUS_ASYNC_LIB}) if(REDIS_PLUS_PLUS_ASYNC_FUTURE STREQUAL \u0026#34;boost\u0026#34;) target_include_directories(${SHARED_LIB} SYSTEM PUBLIC $\u0026lt;BUILD_INTERFACE:${Boost_INCLUDE_DIR}\u0026gt;) endif() endif() if(WIN32) ... else() target_compile_options(${SHARED_LIB} PRIVATE \u0026#34;-Wall\u0026#34; \u0026#34;-W\u0026#34; \u0026#34;-Werror\u0026#34;) endif() set_target_properties(${SHARED_LIB} PROPERTIES OUTPUT_NAME redis++) set_target_properties(${SHARED_LIB} PROPERTIES CLEAN_DIRECT_OUTPUT 1) set_target_properties(${SHARED_LIB} PROPERTIES CXX_EXTENSIONS OFF) set_target_properties(${SHARED_LIB} PROPERTIES POSITION_INDEPENDENT_CODE ON) set_target_properties(${SHARED_LIB} PROPERTIES VERSION ${PROJECT_VERSION} SOVERSION ${PROJECT_VERSION_MAJOR}) endif() option(REDIS_PLUS_PLUS_BUILD_TEST \u0026#34;Build tests for redis++\u0026#34; ON) message(STATUS \u0026#34;redis-plus-plus build test: ${REDIS_PLUS_PLUS_BUILD_TEST}\u0026#34;) if(REDIS_PLUS_PLUS_BUILD_TEST) add_subdirectory(test) endif() install(TARGETS ${REDIS_PLUS_PLUS_TARGETS} EXPORT redis++-targets LIBRARY DESTINATION lib ARCHIVE DESTINATION lib RUNTIME DESTINATION bin INCLUDES DESTINATION include) set(REDIS_PLUS_PLUS_CMAKE_DESTINATION share/cmake/redis++) install(EXPORT redis++-targets FILE redis++-targets.cmake NAMESPACE redis++:: DESTINATION ${REDIS_PLUS_PLUS_CMAKE_DESTINATION}) # Install headers. set(HEADER_PATH \u0026#34;sw/redis++\u0026#34;) file(GLOB HEADERS \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/*.h*\u0026#34; \u0026#34;${TLS_SUB_DIR}/*.h\u0026#34; \u0026#34;${CXX_UTILS_DIR}/*.h\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_ASYNC_FUTURE_HEADER}/*.h\u0026#34;) if(NOT REDIS_PLUS_PLUS_BUILD_ASYNC) file(GLOB ASYNC_HEADERS \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/async_*.h\u0026#34; \u0026#34;${REDIS_PLUS_PLUS_SOURCE_DIR}/event_*.h\u0026#34;) list(REMOVE_ITEM HEADERS ${ASYNC_HEADERS}) endif() install(FILES ${HEADERS} DESTINATION ${CMAKE_INSTALL_PREFIX}/include/${HEADER_PATH}) include(CMakePackageConfigHelpers) write_basic_package_version_file(\u0026#34;${CMAKE_CURRENT_BINARY_DIR}/cmake/redis++-config-version.cmake\u0026#34; VERSION ${PROJECT_VERSION} COMPATIBILITY AnyNewerVersion) configure_package_config_file(\u0026#34;${CMAKE_CURRENT_SOURCE_DIR}/cmake/redis++-config.cmake.in\u0026#34; \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/cmake/redis++-config.cmake\u0026#34; INSTALL_DESTINATION ${REDIS_PLUS_PLUS_CMAKE_DESTINATION}) install(FILES \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/cmake/redis++-config.cmake\u0026#34; \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/cmake/redis++-config-version.cmake\u0026#34; DESTINATION ${REDIS_PLUS_PLUS_CMAKE_DESTINATION}) export(EXPORT redis++-targets FILE \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/cmake/redis++-targets.cmake\u0026#34; NAMESPACE redis++::) configure_file(\u0026#34;${CMAKE_CURRENT_SOURCE_DIR}/cmake/redis++.pc.in\u0026#34; \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/cmake/redis++.pc\u0026#34; @ONLY) install(FILES \u0026#34;${CMAKE_CURRENT_BINARY_DIR}/cmake/redis++.pc\u0026#34; DESTINATION \u0026#34;lib/pkgconfig\u0026#34;) # All the Debian-specific cpack defines. if(${CMAKE_VERSION} VERSION_GREATER 3.6) SET(CPACK_DEBIAN_PACKAGE_GENERATE_SHLIBS \u0026#34;ON\u0026#34;) endif() if(NOT DEFINED CPACK_DEBIAN_PACKAGE_DEPENDS) SET(CPACK_DEBIAN_PACKAGE_DEPENDS \u0026#34;libstdc++6, libhiredis-dev\u0026#34;) endif() SET(CPACK_DEBIAN_FILE_NAME DEB-DEFAULT) SET(CPACK_DEBIAN_PACKAGE_VERSION \u0026#34;${REDIS_PLUS_PLUS_VERSION}\u0026#34;) SET(CPACK_DEBIAN_PACKAGE_SOURCE \u0026#34;https://github.com/sewenew/redis-plus-plus\u0026#34;) message(STATUS \u0026#34;Debian package name: ${CPACK_PACKAGE_FILE_NAME}.deb\u0026#34;) # All the common cpack defines. if(NOT DEFINED CPACK_PACKAGE_NAME) SET(CPACK_PACKAGE_NAME \u0026#34;libredis++-dev\u0026#34;) endif() SET(CPACK_INSTALL_PREFIX \u0026#34;${CMAKE_INSTALL_PREFIX}\u0026#34;) SET(CPACK_PACKAGE_DESCRIPTION \u0026#34;A pure C++ client for Redis, based on hiredis.\u0026#34;) SET(CPACK_PACKAGE_CONTACT \u0026#34;anonymous\u0026#34;) SET(CPACK_GENERATOR \u0026#34;DEB\u0026#34;) INCLUDE(CPack) 最终的生成的BUILD文件\n#如果使用tls的话，把下面的src/sw/redis++/no_tls/改成src/sw/redis++/tls/，并且把对hiredis_ssl的依赖前面的#去掉，还有就是代码里面的tls.cpp前面的井号去掉 cc_library( name = \u0026#34;sync_redis++\u0026#34;, srcs = [ \u0026#34;src/sw/redis++/command.cpp\u0026#34;, \u0026#34;src/sw/redis++/command_options.cpp\u0026#34;, \u0026#34;src/sw/redis++/connection.cpp\u0026#34;, \u0026#34;src/sw/redis++/connection_pool.cpp\u0026#34;, \u0026#34;src/sw/redis++/crc16.cpp\u0026#34;, \u0026#34;src/sw/redis++/errors.cpp\u0026#34;, \u0026#34;src/sw/redis++/pipeline.cpp\u0026#34;, \u0026#34;src/sw/redis++/redis.cpp\u0026#34;, \u0026#34;src/sw/redis++/redis_cluster.cpp\u0026#34;, \u0026#34;src/sw/redis++/reply.cpp\u0026#34;, \u0026#34;src/sw/redis++/sentinel.cpp\u0026#34;, \u0026#34;src/sw/redis++/shards.cpp\u0026#34;, \u0026#34;src/sw/redis++/shards_pool.cpp\u0026#34;, \u0026#34;src/sw/redis++/subscriber.cpp\u0026#34;, \u0026#34;src/sw/redis++/transaction.cpp\u0026#34;, #\u0026#34;src/sw/redis++/tls/tls.cpp\u0026#34;， ], hdrs = glob([\u0026#34;src/sw/redis++/*.h\u0026#34;])+glob([\u0026#34;src/sw/redis++/*.hpp\u0026#34;])+glob([\u0026#34;src/sw/redis++/cxx17/*.h\u0026#34;])+glob([\u0026#34;src/sw/redis++/no_tls/*.h\u0026#34;]), deps = [ \u0026#34;//third_party/hiredis:hiredis\u0026#34;, #\u0026#34;//third_party/hiredis:hiredis_ssl\u0026#34;, ], copts = [\u0026#34;-std=c++17\u0026#34;,], visibility = [\u0026#34;//visibility:public\u0026#34;], ) cc_library( name = \u0026#34;async_redis++\u0026#34;, srcs = [ \u0026#34;src/sw/redis++/command.cpp\u0026#34;, \u0026#34;src/sw/redis++/command_options.cpp\u0026#34;, \u0026#34;src/sw/redis++/connection.cpp\u0026#34;, \u0026#34;src/sw/redis++/connection_pool.cpp\u0026#34;, \u0026#34;src/sw/redis++/crc16.cpp\u0026#34;, \u0026#34;src/sw/redis++/errors.cpp\u0026#34;, \u0026#34;src/sw/redis++/pipeline.cpp\u0026#34;, \u0026#34;src/sw/redis++/redis.cpp\u0026#34;, \u0026#34;src/sw/redis++/redis_cluster.cpp\u0026#34;, \u0026#34;src/sw/redis++/reply.cpp\u0026#34;, \u0026#34;src/sw/redis++/sentinel.cpp\u0026#34;, \u0026#34;src/sw/redis++/shards.cpp\u0026#34;, \u0026#34;src/sw/redis++/shards_pool.cpp\u0026#34;, \u0026#34;src/sw/redis++/subscriber.cpp\u0026#34;, \u0026#34;src/sw/redis++/transaction.cpp\u0026#34;, \u0026#34;src/sw/redis++/async_connection.cpp\u0026#34;, \u0026#34;src/sw/redis++/async_connection_pool.cpp\u0026#34;, \u0026#34;src/sw/redis++/async_redis.cpp\u0026#34;, \u0026#34;src/sw/redis++/event_loop.cpp\u0026#34;, \u0026#34;src/sw/redis++/async_sentinel.cpp\u0026#34;, \u0026#34;src/sw/redis++/async_redis_cluster.cpp\u0026#34;, \u0026#34;src/sw/redis++/async_shards_pool.cpp\u0026#34;, ], #如果使用tls的话，把下面的src/sw/redis++/no_tls/改成src/sw/redis++/tls/，并且把对hiredis_ssl的依赖前面的#去掉 hdrs = glob([\u0026#34;src/sw/redis++/*.h\u0026#34;])+glob([\u0026#34;src/sw/redis++/*.hpp\u0026#34;])+glob([\u0026#34;src/sw/redis++/cxx17/*.h\u0026#34;])+glob([\u0026#34;src/sw/redis++/no_tls/*.h\u0026#34;])+glob([\u0026#34;src/sw/redis++/future/std/*.h\u0026#34;]), deps = [ \u0026#34;//third_party/hiredis:hiredis\u0026#34;, #\u0026#34;//third_party/hiredis:hiredis_ssl\u0026#34;, \u0026#34;//third_party/libuv:libuv\u0026#34;, ], copts = [\u0026#34;-std=c++17\u0026#34;,], visibility = [\u0026#34;//visibility:public\u0026#34;], ) 编译async \u0026amp; sync的时候，不需要ssl的代码需要修改的patch。\nqcraft@BJ-vgdog:~/code_test/cmake2bazel/third_party/redis-plus-plus$ git diff diff --git a/src/sw/redis++/async_connection.h b/src/sw/redis++/async_connection.h index 6cccb96..5fa3f75 100644 --- a/src/sw/redis++/async_connection.h +++ b/src/sw/redis++/async_connection.h @@ -27,8 +27,8 @@ #include \u0026#34;connection.h\u0026#34; #include \u0026#34;command_args.h\u0026#34; #include \u0026#34;event_loop.h\u0026#34; -#include \u0026#34;async_utils.h\u0026#34; -#include \u0026#34;tls.h\u0026#34; +#include \u0026#34;future/std/async_utils.h\u0026#34; +#include \u0026#34;no_tls/tls.h\u0026#34; #include \u0026#34;shards.h\u0026#34; #include \u0026#34;cmd_formatter.h\u0026#34; diff --git a/src/sw/redis++/connection.h b/src/sw/redis++/connection.h index 3403755..78b9e02 100644 --- a/src/sw/redis++/connection.h +++ b/src/sw/redis++/connection.h @@ -28,7 +28,7 @@ #include \u0026#34;errors.h\u0026#34; #include \u0026#34;reply.h\u0026#34; #include \u0026#34;utils.h\u0026#34; -#include \u0026#34;tls.h\u0026#34; +#include \u0026#34;no_tls/tls.h\u0026#34; namespace sw { diff --git a/src/sw/redis++/sentinel.h b/src/sw/redis++/sentinel.h index 6f99879..f08d527 100644 --- a/src/sw/redis++/sentinel.h +++ b/src/sw/redis++/sentinel.h @@ -25,7 +25,7 @@ #include \u0026#34;connection.h\u0026#34; #include \u0026#34;shards.h\u0026#34; #include \u0026#34;reply.h\u0026#34; -#include \u0026#34;tls.h\u0026#34; +#include \u0026#34;no_tls/tls.h\u0026#34; namespace sw { diff --git a/src/sw/redis++/utils.h b/src/sw/redis++/utils.h index f77f796..1d9a624 100644 --- a/src/sw/redis++/utils.h +++ b/src/sw/redis++/utils.h @@ -20,7 +20,7 @@ #include \u0026lt;cstring\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;type_traits\u0026gt; -#include \u0026#34;cxx_utils.h\u0026#34; +#include \u0026#34;cxx17/cxx_utils.h\u0026#34; namespace sw { 编译async \u0026amp; sync的时候使用ssl的diff文件\nqcraft@BJ-vgdog:~/code_test/cmake2bazel/third_party/redis-plus-plus$ git diff diff --git a/src/sw/redis++/async_connection.h b/src/sw/redis++/async_connection.h index 6cccb96..b76b2a2 100644 --- a/src/sw/redis++/async_connection.h +++ b/src/sw/redis++/async_connection.h @@ -27,8 +27,8 @@ #include \u0026#34;connection.h\u0026#34; #include \u0026#34;command_args.h\u0026#34; #include \u0026#34;event_loop.h\u0026#34; -#include \u0026#34;async_utils.h\u0026#34; -#include \u0026#34;tls.h\u0026#34; +#include \u0026#34;future/std/async_utils.h\u0026#34; +#include \u0026#34;tls/tls.h\u0026#34; #include \u0026#34;shards.h\u0026#34; #include \u0026#34;cmd_formatter.h\u0026#34; diff --git a/src/sw/redis++/connection.h b/src/sw/redis++/connection.h index 3403755..547ddb3 100644 --- a/src/sw/redis++/connection.h +++ b/src/sw/redis++/connection.h @@ -28,7 +28,7 @@ #include \u0026#34;errors.h\u0026#34; #include \u0026#34;reply.h\u0026#34; #include \u0026#34;utils.h\u0026#34; -#include \u0026#34;tls.h\u0026#34; +#include \u0026#34;tls/tls.h\u0026#34; namespace sw { diff --git a/src/sw/redis++/sentinel.h b/src/sw/redis++/sentinel.h index 6f99879..2110573 100644 --- a/src/sw/redis++/sentinel.h +++ b/src/sw/redis++/sentinel.h @@ -25,7 +25,7 @@ #include \u0026#34;connection.h\u0026#34; #include \u0026#34;shards.h\u0026#34; #include \u0026#34;reply.h\u0026#34; -#include \u0026#34;tls.h\u0026#34; +#include \u0026#34;tls/tls.h\u0026#34; namespace sw { diff --git a/src/sw/redis++/tls/tls.cpp b/src/sw/redis++/tls/tls.cpp index 1ee4309..0d79a01 100644 --- a/src/sw/redis++/tls/tls.cpp +++ b/src/sw/redis++/tls/tls.cpp @@ -15,7 +15,7 @@ *************************************************************************/ #include \u0026#34;tls.h\u0026#34; -#include \u0026#34;errors.h\u0026#34; +#include \u0026#34;../errors.h\u0026#34; namespace sw { diff --git a/src/sw/redis++/utils.h b/src/sw/redis++/utils.h index f77f796..1d9a624 100644 --- a/src/sw/redis++/utils.h +++ b/src/sw/redis++/utils.h @@ -20,7 +20,7 @@ #include \u0026lt;cstring\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;type_traits\u0026gt; -#include \u0026#34;cxx_utils.h\u0026#34; +#include \u0026#34;cxx17/cxx_utils.h\u0026#34; namespace sw { 3.2 bazel的学习 # bazel remote cache缓存的信息action和文件，每个 action有inputs, output names, a command line, and environment variables. Required inputs and expected outputs are declared explicitly for each action.\n具体缓存的数据如下，这里注意除了缓存的生成的文件，也缓存具体的std_out和std_err信息，所以test实际上也是缓存的\naction缓存的是一个map，key为action的hash值，value为action result metadata. 一系列可以进行寻址的文件 这里面就引入了一个有趣的问题，bazel build \u0026ndash;nobuild到底干了什么?这个问题是因为我今天发现CI rebase了一个同学的代码，然后错误的把直接依赖给去了。直接依赖去了以后bazel build \u0026ndash;nobuild没检测出来代码用了头文件而deps里面没有的问题，然后发现bazel build \u0026ndash;nobuild只是构建build action，也就是只看BUILD，分析里面各种target的关系，但是不看代码里面头文件的引用的。所以没检测出来这个问题。\n那么bazel到底是怎么回事？\n3.3 bazel的有趣问题 # 3.3.1 bazel sandbox # sandbox的选择:这两天在用bazel管理一个sh_test的时候遇到了一个有趣的问题，在本地机器跑一个sh_test的时候，能够执行aws login操作(会修改/home/config.json)，而在ci executor上没办法修改/home/config.json，最后发现是因为本地用的是processwrapper-sandbox，而ci机器用的linux-sandbox，linux-sandbox的权限管理更严格。\n问题的解决就变成了两个方向的选择:\n让ci机器也用processwrapper-sandbox 让ci机器在linux-sandbox里面也能修改/home/config.json 第一个方法将ci机器和本地机器对齐，这种方法实际上包含着第二种允许改动文件，但是这种对齐是一种比较好的方法。具体手段是在加上加上一个flag:\u0026ndash;spawn_strategy=processwrapper-sandbox，这里要注意个processwrapper-sandbox是offdocument的。\n第二种方法实际上是指定可以修改的路径，但是这个就会导致ci机器和本地机器行为不同，对分析会造成恶劣的影响。使用的flag是\u0026ndash;sandbox_writable_path=xxx\n3.3.2 记录bazel的输出 # 今天有个问题，有一个脚本，编译\u0026amp;运行bazel编译出来的程序，然后定时发送信号测试程序是否退出的错误码正常。我现在想用sh_test来进行管理，这样子能够节省时间，因为如果代码没变依赖没变，那么就可以直接输出缓存的结果。但是在移植的时候有个问题，bazel运行的日志怎么输出呢？答案很简单，如下:\n2\u0026gt;\u0026amp;1 | tee original_lite_integration_test.log 3.3.3 bazel test group # 我们目前运行运行test是直接一起运行的，希望能够同时运行不同的test group。直接看了下，似乎没有test group的概念，唯一一个相关的exec group和平台相关。那么如何进行管理呢？翻文档的时候看到https://docs.bazel.build/versions/main/be/common-definitions.html 里面提到了test_suite，所以查了下，具体参考https://docs.bazel.build/versions/main/be/general.html#test_suite\n我们现在的目的是将不同的test_suite执行，其中test_suite A并行的程度为5，test_suite B并行的程度为1.那么是不是需要加上test_shardl呢?\n3.4 bazel codebase # 参考的是https://github.com/bazelbuild/bazel/blob/master/CODEBASE.md。可以把下面的看成是翻译和部分对源代码的分析\n3.4.1 cliet/server架构 # bazel实际上是client/server架构的服务，客户端为C++，启动时检查是不是有server实例\u0026ndash;检查$OUTPUT_BASE/serve下是不是有lockfile。如果启动配置/输出路径没出错，继续使用server，否则杀掉旧server，新建一个server。server端创建完成，客户端和服务端使用grpc进行通信，每次只能运行一个job。客户端的源代码在下面src/main/cpp，与服务器通信的协议在src/main/protobuf/command_server.proto。服务器的主要入口点是BlazeRuntime.main()，来自客户端的 gRPC 由GrpcServerImpl.run().调用。\n3.4.2 目录布局 # 3.4.4 执行命令流程 # 当Bazel 服务器获得控制权并获得需要执行的命令，就会发生以下事件：\nBlazeCommandDispatcher被告知新的请求。它检查命令是否需要WORKSPACE才能运行（几乎所有命令，除了与源代码没有任何关系的命令，例如版本或帮助）也会检查目前是否正在运行另一个命令。 找到需要执行的正确的命令。每个命令都必须实现接口 BlazeCommand并且必须有@Command注解（这有点反模式，如果命令需要的所有元数据都由 on 方法描述就好了BlazeCommand） 命令行参数被解析。每个命令都有不同的命令行参数，@Command注释中对此进行了描述。 创建了一个事件总线。事件总线是构建期间发生的事件的流。其中一些在构建事件协议的支持下被导出到 Bazel 之外，以便告诉世界构建是如何进行的。 待执行的command获得控制权。最有趣的命令是那些运行构建的命令：构建、测试、运行、覆盖等：此功能由BuildTool.实现 待执行的命令，所涉及到的targets被解析，诸如通配符 //pkg:all和//pkg/...也被解析。这AnalysisPhaseRunner.evaluateTargetPatterns()在 Skyframe 中实现 并具体化为 TargetPatternPhaseValue. 运行加载/分析阶段(loading/analysis phase) 以生成action图（需要为构建执行的命令的有向无环图）。 执行阶段运行。这意味着运行构建请求的顶级目标所需的每个操作。 3.4.5 命令行选项 # Bazel 调用的命令行选项在一个OptionsParsingResult对象中描述，该对象包含一个从“option classes”到\u0026quot;option\u0026quot;的映射map。“option classes”是OptionsBase的子类和相互关联的命令行选项的组合。例如：\n与编程语言（CppOptions或JavaOptions）相关的选项。这些应该是一个FragmentOptions子类，并最终被包装到一个BuildOptions对象中。 与 Bazel 执行操作的方式相关的选项 ( ExecutionOptions) 这些选项旨在用于analysis phase和（通过Java的RuleContext.getFragment() 或Starlark的ctx.fragments）。其中一些（例如，是否执行 C++ 包括扫描）在执行阶段读取，但这始终需要显式管道，因为那时 BuildConfiguration不可用。有关详细信息，请参阅“配置”部分。\n**警告：**我们喜欢假装OptionsBase实例是不可变的并以这种方式使用它们（例如，作为 的一部分SkyKeys）。情况并非如此，修改它们是一种以难以调试的微妙方式破坏 Bazel 的非常好的方法。不幸的是，使它们实际上不可变是一项巨大的努力。（FragmentOptions在其他人有机会保留对它的引用之前，在构造之后立即修改它，equals()或者hashCode()在它被调用之前修改它是可以的。）\nBazel 通过以下方式获得option class：\n有些是hardcoded到 Bazel ( CommonCommandOptions) 来自每个 Bazel 命令的 @Command 注释 From ConfiguredRuleClassProvider（这些是与各个编程语言相关的命令行选项） Starlark 规则也可以定义自己的选项（见 这里） 每个选项（不包括 Starlark 定义的选项）都是FragmentOptions具有@Option注释的子类的成员变量， 该注释指定命令行选项的名称和类型以及一些帮助文本。\n命令行选项值的 Java 类型通常很简单（字符串、整数、布尔值、标签等）。但是，我们也支持更复杂类型的选项；在这种情况下，从命令行字符串转换为数据类型的工作落到了 com.google.devtools.common.options.Converter.\n3.4.6 存储库 # “存储库”是开发人员在其上工作的源代码树；它通常代表一个项目。Bazel 的祖先 Blaze 在 一个大的整体代码库上运行，即包含任何涉及到的项目的所有源代码的大源码库(就是不能引入外部源码)。相比之下，Bazel 支持源代码跨越多个代码库的项目(可以引入外部代码)。调用 Bazel 的存储库称为“主存储库”，其他存储库称为“外部存储库”。\n存储库由其根目录中名为WORKSPACE（或WORKSPACE.bazel）的文件标记。此文件的内容包含对内部任何BUILD可见的“全局”信息，例如，可用的外部存储库集。它像普通的 Starlark 文件一样工作，这意味着可以使用load()来载入其他 Starlark 文件。这通常用于引入显式引用的存储库所需的存储库（我们称之为“deps.bzl模式”）\n外部存储库的代码通过软连接或下载方式置于 $OUTPUT_BASE/external.\n运行构建时，需要将整个源代码树拼凑在一起；这是由 SymlinkForest 完成的，它将主存储库中的每个包链接到$EXECROOT下，每个外部存储库符号链接到$EXECROOT/external或 $EXECROOT/..（当然前者使得external在主存储库中调用包是不可能的；这就是我们要从它迁移的原因）\n3.4.7 packages # 每个存储库都由package组成，用于组织文件(集合)并且指定依赖。名为BUILD或 BUILD.bazel的文件用来指定package。如果两者都存在，Bazel 更喜欢BUILD.bazel; BUILD 文件仍然被接受的原因是，Bazel 的祖先 Blaze 使用了这个文件名。\n包是相互独立的：一个包的BUILD文件的改变不会导致其他包的改变。添加或删除 BUILD 文件 _can _change 其他包，因为递归 glob 在包边界处停止，因此 BUILD 文件的存在会停止递归。\nBUILD 文件的评估称为“package loading”。它由class PackageFactory实现，通过调用 Starlark interpreter工作，并且需要了解可用规则类的集合。包加载的结果是一个Package对象。它主要是从字符串（目标名称）到目标本身的映射。\n包加载过程中的一大块内容是和globbing相关的：Bazel 不需要显式列出每个源文件，而是可以运行 glob（例如glob([\u0026quot;**/*.java\u0026quot;])）。与 shell 不同，它支持下降到子目录（但不下降到子package）的递归 glob。这需要访问文件系统，因为这可能会很慢，所以我们实施了各种技巧以使其尽可能高效地并行运行。\nGlobbing 在以下类中实现：\nLegacyGlobber，一个快速而幸福的Skyframe-unaware 不知道的 globber SkyframeHybridGlobber，一个使用 Skyframe 并恢复到旧 globber 的版本，以避免“Skyframe 重新启动”（如下所述） 在Package类本身包含一些成员，专门用于分析工作区文件并没有真正的包才有意义。这是一个设计缺陷，因为描述常规包的对象不应包含描述其他内容的字段。这些包括：\n存储库映射 注册的工具链 注册的执行平台 理想情况下，解析 WORKSPACE 文件与解析常规包之间会有更多的分离，因此Package不需要同时满足两者的需求。不幸的是，这很难做到，因为这两者交织得很深。\n标签、目标和规则 # 包由目标组成，这些目标具有以下类型：\n**文件：**作为构建的输入或输出的东西。在 Bazel 的说法中，我们称它们为人工制品（在别处讨论过）。并非所有在构建期间创建的文件都是目标；Bazel 的输出通常没有关联的标签。 **规则：**这些描述了从输入中导出其输出的步骤。它们通常与编程语言相关联（例如cc_library， java_library或py_library），但也有一些与语言无关的（例如，genrule或filegroup） **包组：**在可见性部分讨论。 目标的名称称为标签。标签的语法是@repo//pac/kage:name，其中repo是标签 所在的存储库的名称，pac/kage是它的 BUILD 文件所在的目录，是name文件相对于包目录的路径（如果标签是指源文件） . 在命令行上引用目标时，标签的某些部分可以省略：\n如果省略了存储库，则将标签视为在主存储库中。 如果省略了包部分（例如name或:name），则将标签视为当前工作目录的包中（不允许包含上级引用 (..) 的相对路径） 一种规则（例如“C++ 库”）称为“规则类”。规则类可以在 Starlark（rule()函数）或 Java（所谓的“原生规则”，type RuleClass）中实现。从长远来看，每个特定语言的规则都将在 Starlark 中实现，但一些遗留规则系列（例如 Java 或 C++）暂时仍使用 Java。\nStarlark 规则类需要在 BUILD 文件的开头使用load()语句导入，而 Java 规则类是 Bazel “天生”知道的，因为它是在ConfiguredRuleClassProvider.\n规则类包含以下信息：\n它的属性（如srcs，deps）：它们的类型，默认值，约束等 附加到每个属性的配置转换和方面（如果有） 规则的实施 规则“通常”创建的传递信息提供者 **术语说明：**在代码库中，我们经常使用“规则”来表示由规则类创建的目标。但在 Starlark 和面向用户的文档中，“Rule”应该专门用于指代规则类本身；目标只是一个“目标”。另请注意，尽管名称中RuleClass有“类”，但规则类和该类型的目标之间没有 Java 继承关系。\nbazel genrule，可以关注https://github.com/bazelbuild/examples/tree/main/rules, https://docs.bazel.build/versions/main/be/general.html#genrule Bazel 底层的评估框架称为 Skyframe。它的模型是，在构建过程中需要构建的所有内容都被组织成一个有向无环图，其边从任何数据片段指向其依赖项，即构建它需要知道的其他数据片段。\n图中的节点称为SkyValues，它们的名称称为 SkyKeys。两者都是不可变的，即只有不可变的对象应该可以从它们访问。这个不变量几乎总是成立，如果它不成立（例如，对于单个选项类BuildOptions，它是BuildConfigurationValue及其成员 SkyKey），我们非常努力地不改变它们或仅以无法从观察到的方式改变它们外部。由此可见，在 Skyframe 中计算的所有内容（例如配置的目标）也必须是不可变的。\n观察 Skyframe 图形最方便的方法是运行bazel dump --skyframe=detailed，它会转储图形，SkyValue每行一个。最好为小型构建执行此操作，因为它可能会变得非常大。\nSkyframe 位于com.google.devtools.build.skyframe包装中。类似名称的包com.google.devtools.build.lib.skyframe包含在 Skyframe 之上的 Bazel 实现。有关 Skyframe 的更多信息，请点击此处。\n生成一个新的SkyValue涉及以下步骤：\n运行相关联 SkyFunction 声明需要完成其工作的依赖项（即SkyValues）SkyFunction。这是通过调用 SkyFunction.Environment.getValue(). 如果依赖项不可用，Skyframe 会通过从getValue(). 在这种情况下，SkyFunction期望通过返回 null 将控制权交给 Skyframe，然后 Skyframe 评估尚未评估的依赖项并SkyFunction 再次调用，从而返回 (1)。 构建结果 SkyValue 这样做的结果是，如果在 (3) 中并非所有依赖项都可用，则需要完全重新启动函数，因此需要重新进行计算，这显然是低效的。SkyFunction.Environment.getState() 让我们通过让 SkyframeSkyKeyComputeState在SkyFunction.compute对相同的调用之间维护实例来直接解决这个问题 SkyKey。查看 javadoc 中的示例 SkyFunction.Environment.getState()，以及 Bazel 代码库中的实际用法。\n其他间接解决方法：\nSkyFunction在组中声明s 的依赖关系，这样如果一个函数有 10 个依赖关系，它只需要重新启动一次而不是十次。 拆分SkyFunctions 使得一个功能不需要多次重启。这具有将数据实习到可能是内部的 Skyframe 的副作用SkyFunction，从而增加了内存使用。 这些只是针对 Skyframe 限制的解决方法，这主要是由于 Java 不支持轻量级线程并且我们通常有数十万个运行中的 Skyframe 节点。\n星雀 # Starlark 是人们用来配置和扩展 Bazel 的特定领域语言。它被认为是 Python 的一个受限子集，它的类型少得多，对控制流的限制更多，最重要的是，强大的不变性保证可以实现并发读取。它不是图灵完备的，这会阻止一些（但不是所有）用户尝试在该语言中完成一般的编程任务。\nStarlark 在com.google.devtools.build.lib.syntax包中实现。它在这里也有一个独立的 Go 实现 。Bazel 中使用的 Java 实现目前是一个解释器。\nStarlark 在四种情况下使用：\n**构建语言。**这是定义新规则的地方。在此上下文中运行的 Starlark 代码只能访问 BUILD 文件本身和由它加载的 Starlark 文件的内容。 **规则定义。**这就是新规则（例如对新语言的支持）的定义方式。在此上下文中运行的 Starlark 代码可以访问其直接依赖项提供的配置和数据（稍后会详细介绍）。 **工作空间文件。**这是定义外部存储库（不在主源代码树中的代码）的地方。 **存储库规则定义。**这是定义新的外部存储库类型的地方。在此上下文中运行的 Starlark 代码可以在运行 Bazel 的机器上运行任意代码，并到达工作区之外。 BUILD 和 .bzl 文件可用的方言略有不同，因为它们表达不同的东西。此处提供了差异列表 。\n有关 Starlark 的更多信息，请 点击此处。\n加载/分析阶段 # 加载/分析阶段是 Bazel 确定构建特定规则所需的操作的地方。它的基本单元是一个“已配置的目标”，相当明智地是一个（目标，配置）对。\n它被称为“加载/分析阶段”，因为它可以分为两个不同的部分，这些部分过去是序列化的，但现在它们可以在时间上重叠：\n加载包，即将BUILD文件转换为Package代表它们的对象 分析配置的目标，即运行规则的实现以生成动作图 在命令行上请求的已配置目标的传递闭包中的每个已配置目标都必须自下而上进行分析，即首先分析叶节点，然后再分析命令行上的叶节点。分析单个配置目标的输入是：\n配置。（“如何”构建该规则；例如，目标平台以及用户希望传递给 C++ 编译器的命令行选项） **直接依赖。**他们的传递信息提供者可用于正在分析的规则。之所以这样称呼它们，是因为它们在已配置目标的传递闭包中提供了信息的“汇总”，例如类路径上的所有 .jar 文件或需要链接到 C++ 二进制文件中的所有 .o 文件) 目标本身。这是加载目标所在包的结果。对于规则，这包括它的属性，这通常是最重要的。 **配置目标的执行。**对于规则，这可以是 Starlark 或 Java。所有非规则配置的目标都是用 Java 实现的。 分析已配置目标的输出是：\n配置依赖于它的目标的传递信息提供者可以访问 它可以创建的工件以及产生它们的操作。 提供给 Java 规则的 API 是RuleContext，相当于ctxStarlark 规则的 参数。它的 API 更强大，但同时更容易做 Bad Things™，例如编写时间或空间复杂度为二次（或更糟）的代码，使 Bazel 服务器因 Java 异常而崩溃或违反不变量（例如通过无意中修改 Options实例或使配置的目标可变）\n确定已配置目标的直接依赖关系的算法位于DependencyResolver.dependentNodeMap().\n配置 # 配置是构建目标的“方式”：针对什么平台，使用什么命令行选项等。\n可以在同一构建中为多个配置构建相同的目标。这很有用，例如，当相同的代码用于构建期间运行的工具和目标代码并且我们正在交叉编译或构建胖 Android 应用程序（包含用于多 CPU 的本机代码的应用程序时）架构）\n从概念上讲，配置是一个BuildOptions实例。然而，在实践中，BuildOptions被包裹通过BuildConfiguration其提供的功能的附加杂件。它从依赖图的顶部传播到底部。如果它发生变化，则需要重新分析构建。\n这会导致异常，例如，如果请求的测试运行的数量发生变化，则必须重新分析整个构建，即使这只影响测试目标（我们计划“修剪”配置，因此情况并非如此，但事实并非如此准备好了吗）\n当规则实现需要配置的一部分时，它需要在其定义中使用RuleClass.Builder.requiresConfigurationFragments() . 这既是为了避免错误（例如使用 Java 片段的 Python 规则），也是为了便于配置调整，以便例如如果 Python 选项发生变化，则无需重新分析 C++ 目标。\n规则的配置不一定与其“父”规则的配置相同。在依赖边缘中更改配置的过程称为“配置转换”。它可能发生在两个地方：\n在依赖边缘。这些转换在Attribute.Builder.cfg()a Rule（发生转换的地方）和 a BuildOptions（原始配置）到一个或多个BuildOptions（输出配置）中指定 并且是函数。 在配置目标的任何传入边缘上。这些在 中指定 RuleClass.Builder.cfg()。 相关类是TransitionFactory和ConfigurationTransition。\n使用配置转换，例如：\n声明在构建期间使用了特定的依赖项，因此应该在执行架构中构建它 声明必须为多种架构构建特定依赖项（例如，对于胖 Android APK 中的本机代码） 如果配置转换导致多个配置，则称为 拆分转换。\n配置转换也可以在 Starlark 中实现（此处的文档 ）\n传递信息提供者 # 传递信息提供者是配置目标的一种方式（和 _only _way），用于告诉依赖它的其他配置目标。“传递”在他们的名字中的原因是这通常是配置目标的传递闭包的某种汇总。\nJava 传递信息提供者和 Starlark 提供者之间通常存在 1:1 的对应关系（例外是DefaultInfo它是 的合并 FileProvider，FilesToRunProvider并且RunfilesProvider因为该 API 被认为比 Java 的直接音译更类似于 Starlark）。他们的关键是以下事情之一：\nJava 类对象。这仅适用于无法从 Starlark 访问的提供商。这些提供程序是 TransitiveInfoProvider. 一个字符串。这是遗留问题并且非常不鼓励，因为它容易受到名称冲突的影响。这种传递信息提供者是 build.lib.packages.Info. 提供者符号。这可以使用该provider() 函数从 Starlark 创建，并且是创建新提供程序的推荐方法。该符号由Provider.KeyJava 中的实例表示。 用 Java 实现的新提供者应该使用BuiltinProvider. NativeProvider已弃用（我们还没有时间删除它）并且 TransitiveInfoProvider无法从 Starlark 访问子类。\n配置的目标 # 配置的目标实现为RuleConfiguredTargetFactory. 在 Java 中实现的每个规则类都有一个子类。Starlark 配置的目标是通过StarlarkRuleConfiguredTargetUtil.buildRule().\n配置的目标工厂应该RuleConfiguredTargetBuilder用来构造它们的返回值。它由以下内容组成：\n它们filesToBuild，即“这条规则所代表的文件集”的模糊概念。这些是在配置的目标位于命令行或 genrule 的 srcs 时构建的文件。 他们的运行文件，常规和数据。 他们的输出组。这些是规则可以构建的各种“其他文件集”。可以使用 BUILD 中的文件组规则的 output_group 属性和使用OutputGroupInfoJava 中的提供程序来访问它们。 运行文件 # 一些二进制文件需要数据文件才能运行。一个突出的例子是需要输入文件的测试。这在 Bazel 中由“运行文件”的概念表示。“运行文件树”是特定二进制文件的数据文件的目录树。它在文件系统中创建为符号链接树，其中单个符号链接指向输出树源中的文件。\n一组运行文件表示为一个Runfiles实例。从概念上讲，它是从运行文件树中的文件路径到Artifact表示它的实例的映射。它比单一的Map要复杂一些，原因有两个：\n大多数时候，文件的运行文件路径与其执行路径相同。我们用它来节省一些 RAM。 运行文件树中有各种遗留类型的条目，它们也需要表示。 运行文件使用RunfilesProvider以下方法收集：此类的一个实例表示配置目标（例如库）及其传递闭包需要的运行文件，它们像嵌套集一样被收集（实际上，它们是使用嵌套集实现的）：每个目标联合其依赖的运行文件，添加一些自己的，然后将结果集向上发送到依赖图中。一个RunfilesProvider实例包含两个Runfiles 实例，一个用于当规则通过“数据”属性依赖时，一个用于所有其他类型的传入依赖。这是因为目标有时会在通过数据属性依赖时呈现不同的运行文件。这是我们尚未消除的不良遗留行为。\n二进制文件的运行文件表示为RunfilesSupport. 这不同于Runfiles因为RunfilesSupport具有实际构建的能力（不像Runfiles，它只是一个映射）。这需要以下附加组件：\n**输入运行文件清单。**这是运行文件树的序列化描述。它用作运行文件树内容的代理，Bazel 假设当且仅当清单的内容发生更改时，运行文件树才会更改。 **输出运行文件清单。**这由处理运行文件树的运行时库使用，特别是在 Windows 上，有时不支持符号链接。 **运行文件中间人。**为了存在运行文件树，需要构建符号链接树和符号链接指向的工件。为了减少依赖边的数量，可以使用运行文件中间人来表示所有这些。 用于运行RunfilesSupport对象所代表的运行文件的二进制文件的 命令行参数。 aspect # aspect是一种“沿着依赖图传播并执行相关操作”的方法。说人话就是，它可以用来增加构建依赖图的额外信息和操作。一般来说，我们使用aspect往往是为了能够在规则的基础上进行拓展执行一些其它的操作，比方说用到了哪些代码？怎么做代码检查\nWhen a rule declares an attribute that uses an aspect such as attr.label(aspects = ['foo_aspect'], bazel looks at the definition of the aspect to see what attributes it propogates down. For example, it might say attr_aspects = ['deps].\nWhen that rule is invoked, bazel will:\nTraverse down the dependency graph from the originating rule in depth-first fashion, following edges named \u0026lsquo;deps\u0026rsquo;. Apply the aspect rule to each matched rule (in this example java_library and java_binary). As an aspect implementor, your job is to:\nGet oriented to the kind of rule you are visiting via aspect_ctx.rule.kind property. Do something (ctx.file_action, ctx.action, etc..). Collect a transitive set of generated output files and pass them off somewhere to be consumed (either from the command line or a another rule). # 很多细节的问题可以参考https://github.com/pcj/bazel_aspects\n平台和工具链 # Bazel 支持多平台构建，即在可能存在运行构建操作的多个体系结构和为其构建代码的多个体系结构的情况下构建。这些架构在 Bazel 用语中被称为平台（完整文档 在这里）\n平台由从约束设置（例如“CPU 架构”的概念）到约束值（例如 x86_64 等特定 CPU）的键值映射来描述。我们有一个@platforms存储库中最常用的约束设置和值的“字典” 。\n工具链的概念来源于这样一个事实：根据构建运行的平台和目标平台，可能需要使用不同的编译器；例如，特定的 C++ 工具链可能在特定的操作系统上运行，并且能够以其他一些操作系统为目标。Bazel 必须根据设置的执行和目标平台确定使用的 C++ 编译器（此处的工具链文档 ）。\n为了做到这一点，工具链使用它们支持的一组执行和目标平台约束进行注释。为了做到这一点，工具链的定义分为两部分：\n甲toolchain()的工具链它是描述该组的执行和目标约束的工具链载体和一种告诉什么规则（例如C ++或Java）（后者是由表示toolchain_type()规则） 描述实际工具链的特定语言规则（例如 cc_toolchain()） 这样做是因为我们需要知道每个工具链的约束才能进行工具链解析，并且特定于语言的 *_toolchain()规则包含比这更多的信息，因此它们需要更多时间来加载。\n执行平台通过以下方式之一指定：\n在WORKSPACE文件中使用register_execution_platforms()函数 在命令行上使用 \u0026ndash;extra_execution_platforms 命令行选项 可用执行平台的集合在 中计算 RegisteredExecutionPlatformsFunction。\n已配置目标的目标平台由 确定 PlatformOptions.computeTargetPlatform()。这是一个平台列表，因为我们最终希望支持多个目标平台，但它还没有实现。\n用于已配置目标的工具链集由 确定 ToolchainResolutionFunction。它是以下功能：\n已注册的工具链集（在 WORKSPACE 文件和配置中） 所需的执行和目标平台（在配置中） 已配置目标所需的工具链类型集（在 UnloadedToolchainContextKey) 配置的目标（exec_compatible_with属性）和配置（--experimental_add_exec_constraints_to_targets）的执行平台约束集 ，在 UnloadedToolchainContextKey 其结果是UnloadedToolchainContext，它本质上是从工具链类型（表示为ToolchainTypeInfo实例）到所选工具链的标签的映射。它被称为“卸载”，因为它不包含工具链本身，只包含它们的标签。\n然后工具链被实际加载ResolvedToolchainContext.load() 并由请求它们的配置目标的实现使用。\n我们还有一个遗留系统，它依赖于一个单一的“主机”配置和由各种配置标志表示的目标配置，例如--cpu. 我们正在逐步过渡到上述系统。为了处理人们依赖旧配置值的情况，我们实施了“平台映射”来在旧标志和新型平台约束之间进行转换。他们的代码在PlatformMappingFunction并使用非 Starlark 的“小语言”。\n约束 # 有时，人们希望将目标指定为仅与少数几个平台兼容。Bazel（不幸的是）有多种机制来实现这一目标：\n特定于规则的约束 environment_group() / environment() 平台限制 特定于规则的约束主要在 Google for Java 规则中使用；它们即将退出，在 Bazel 中不可用，但源代码可能包含对它的引用。控制这一点的属性称为 constraints=。\nenvironment_group() 和 environment() # 这些规则是一种遗留机制，并未广泛使用。\n所有构建规则都可以声明它们可以为哪些“环境”构建，其中“环境”是environment()规则的一个实例。\n可以通过多种方式为规则指定支持的环境：\n通过restricted_to=属性。这是最直接的规范形式；它声明了规则支持该组的确切环境集。 通过compatible_with=属性。除了默认支持的“标准”环境之外，这还声明了规则支持的环境。 通过包级属性default_restricted_to=和 default_compatible_with=. 通过environment_group()规则中的默认规范。每个环境都属于一组主题相关的对等体（例如“CPU 架构”、“JDK 版本”或“移动操作系统”）。如果restricted_to=/environment()属性没有另外指定，环境组的定义包括“默认”应支持哪些环境 。没有此类属性的规则将继承所有默认值。 通过规则类默认。这会覆盖给定规则类的所有实例的全局默认值。例如，这可以用于使所有*_test规则都可测试，而无需每个实例都必须显式声明此功能。 environment()是作为常规规则实现的，而environment_group() 它既是Target但不是Rule( EnvironmentGroup)的子类，也是默认情况下可从 Starlark ( StarlarkLibrary.environmentGroup())获得的函数，最终创建同名目标。这是为了避免出现循环依赖，因为每个环境都需要声明它所属的环境组，每个环境组都需要声明其默认环境。\n可以使用--target_environment命令行选项将构建限制在特定环境中 。\n约束检查的实现在 RuleContextConstraintSemantics和 中TopLevelConstraintSemantics。\n平台限制 # 当前描述目标与哪些平台兼容的“官方”方式是使用用于描述工具链和平台的相同约束。它在 pull request #10945 中正在审查中 。\n能见度 # 如果您与许多开发人员（例如在 Google）一起使用大型代码库，您不一定希望其他人都能够依赖您的代码，以便您保留更改您认为是实现细节的事情的自由（否则，根据Hyrum 定律，人们 将依赖您代码的所有部分）。\nBazel 通过称为 _visibility 的机制支持这一点：_you 可以声明一个特定的规则只能依赖于使用 visibility 属性（此处的文档 ）。这个属性有点特别，因为与其他所有属性不同，它生成的依赖集不仅仅是列出的标签集（是的，这是一个设计缺陷）。\n这是在以下地方实现的：\n该RuleVisibility接口表示可见性声明。它可以是常量（完全公开或完全私有）或标签列表。 标签可以指包组（包的预定义列表）、包直接（//pkg:__pkg__）或包的子树（//pkg:__subpackages__）。这与使用//pkg:*or的命令行语法不同//pkg/...。 包组被实现为它们自己的目标和配置的目标类型（PackageGroup和PackageGroupConfiguredTarget）。如果我们愿意，我们可能可以用简单的规则替换这些。 从可见性标签列表到依赖DependencyResolver.visitTargetVisibility项的转换在 其他一些地方完成。 实际检查是在 CommonPrerequisiteValidator.validateDirectPrerequisiteVisibility() 嵌套集 # 通常，已配置的目标从其依赖项中聚合一组文件，添加自己的文件，并将聚合集包装到传递信息提供程序中，以便依赖于它的已配置目标可以执行相同的操作。例子：\n用于构建的 C++ 头文件 表示传递闭包的目标文件 cc_library Java 规则编译或运行需要位于类路径上的一组 .jar 文件 Python 规则的传递闭包中的 Python 文件集 如果我们通过使用 egList或以天真的方式做到这一点Set，我们最终会得到二次内存使用：如果有 N 条规则链并且每个规则添加一个文件，我们将有 1+2+\u0026hellip;+N收藏成员。\n为了解决这个问题，我们提出了 a 的概念 NestedSet。它是一种数据结构，由其他NestedSet 实例和它自己的一些成员组成，从而形成集合的有向无环图。它们是不可变的，它们的成员可以被迭代。我们定义了多次迭代顺序（NestedSet.Order）：前序、后序、拓扑（一个节点总是在其祖先之后）和“不关心，但每次都应该相同”。\ndepsetStarlark 中调用了相同的数据结构。\n工件和动作 # 实际构建包含一组需要运行以生成用户想要的输出的命令。命令表示为类的实例，Action文件表示为类的实例 Artifact。它们排列在称为“动作图”的二分、有向、无环图中。\n工件有两种：源工件（即在 Bazel 开始执行之前可用的工件）和派生工件（需要构建的工件）。派生的工件本身可以是多种：\n**常规文物。**通过计算它们的校验和来检查它们的最新性，mtime 作为快捷方式；如果文件的 ctime 没有改变，我们不会对文件进行校验和。 **未解决的符号链接工件。**通过调用 readlink() 检查它们的最新性。与常规工件不同，这些可以是悬空符号链接。通常用于将一些文件打包成某种档案的情况。 **树神器。**这些不是单个文件，而是目录树。通过检查其中的文件集及其内容来检查它们的最新性。它们表示为TreeArtifact. **恒定的元数据工件。**对这些工件的更改不会触发重建。这仅用于构建标记信息：我们不想仅仅因为当前时间改变而进行重建。 源构件不能是树构件或未解析的符号链接构件没有根本原因，只是我们还没有实现它（不过，我们应该——在 BUILD 文件中引用源目录是少数已知的长期项目之一—— Bazel 存在不正确的问题；我们有一个由BAZEL_TRACK_SOURCE_DIRECTORIES=1JVM 属性启用的实现 ）\n一种值得注意的Artifact是中间人。它们由Artifact 作为 的输出的实例指示MiddlemanAction。它们用于特殊情况：\n聚合中间人用于将工件组合在一起。这样一来，如果很多动作使用相同的大输入集，我们就没有 N*M 依赖边，只有 N+M（它们被嵌套集替换） 调度依赖中间人确保一个动作在另一个动作之前运行。它们主要用于 linting，但也用于 C++ 编译（参见 CcCompilationContext.createMiddleman()解释） 运行文件中间人用于确保运行文件树的存在，这样就不需要单独依赖输出清单和运行文件树引用的每个工件。 最好将操作理解为需要运行的命令、它需要的环境以及它产生的一组输出。以下是动作描述的主要组成部分：\n需要运行的命令行 它需要的输入工件 需要设置的环境变量 描述它需要在 \\ 中运行的环境（例如平台）的注释 还有一些其他特殊情况，例如编写内容为 Bazel 所知的文件。它们是 的子类AbstractAction。大多数动作都是一个SpawnAction或一个StarlarkAction（同样，他们应该可以说是没有独立的类），尽管Java和C ++有自己的操作类型（JavaCompileAction，CppCompileAction和CppLinkAction）。\n我们最终希望将所有内容移至SpawnAction; JavaCompileAction非常接近，但是由于 .d 文件解析和包含扫描，C++ 有点特殊。\n动作图主要“嵌入”到 Skyframe 图中：从概念上讲，动作的执行表示为对 ActionExecutionFunction. 从动作图依赖边到 Skyframe 依赖边的映射在 中进行了描述 ActionExecutionFunction.getInputDeps()，Artifact.key()并进行了一些优化，以保持 Skyframe 边的数量较少：\n派生的工件没有自己的SkyValues。相反， Artifact.getGeneratingActionKey()用于找出生成它的操作的关键 嵌套集有自己的 Skyframe 键。 共享操作 # 一些动作是由多个配置的目标生成的；Starlark 规则受到更多限制，因为它们只允许将其派生操作放入由其配置和包确定的目录中（但即便如此，同一包中的规则可能会发生冲突），但用 Java 实现的规则可以将派生工件放在任何地方。\n这被认为是一个错误功能，但要摆脱它真的很难，因为当源文件需要以某种方式处理并且该文件被多个规则（handwave-handwave）引用时，它会显着节省执行时间。这是以一些 RAM 为代价的：共享操作的每个实例都需要单独存储在内存中。\n如果两个动作生成相同的输出文件，它们必须完全相同：具有相同的输入、相同的输出并运行相同的命令行。这种等价关系Actions.canBeShared()在分析和执行阶段之间实现，并通过查看每个动作来验证。这是SkyframeActionExecutor.findAndStoreArtifactConflicts() 在 Bazel 中实现的，也是少数几个需要构建“全局”视图的地方之一。\n执行阶段 # 这是 Bazel 真正开始运行构建操作的时候，即产生输出的命令。\nBazel 在分析阶段之后做的第一件事是确定需要构建哪些 Artifact。其逻辑编码在 TopLevelArtifactHelper; 粗略地说，它是filesToBuild命令行上配置的目标和一个特殊输出组的内容，用于明确表达“如果此目标在命令行上，则构建这些工件”。\n下一步是创建执行根。由于 Bazel 可以选择从文件系统 ( --package_path)中的不同位置读取源包，因此它需要为本地执行的操作提供完整的源树。这由类处理，SymlinkForest并通过记录分析阶段使用的每个目标并构建单个目录树来处理，该目录树将每个包与从其实际位置使用的目标进行符号链接。另一种方法是将正确的路径传递给命令（考虑--package_path到）。这是不可取的，因为：\n当一个包从一个包路径条目移动到另一个包时，它会更改操作命令行（过去很常见） 如果一个动作是远程运行的，它会导致不同的命令行，而不是它在本地运行 它需要特定于正在使用的工具的命令行转换（考虑 Java 类路径和 C++ 包含路径之间的区别） 更改操作的命令行会使其操作缓存条目无效 --package_path 正在缓慢而稳定地被弃用 然后，Bazel 开始遍历动作图（由动作及其输入和输出工件组成的二分有向图）并运行动作。每个动作的执行由SkyValue 类的一个实例表示ActionExecutionValue。\n由于运行一个动作很昂贵，我们有几层缓存可以在 Skyframe 后面命中：\nActionExecutionFunction.stateMap包含使 Skyframe 重新启动ActionExecutionFunction便宜的数据 本地操作缓存包含有关文件系统状态的数据 远程执行系统通常也包含自己的缓存 本地动作缓存 # 这个缓存是位于 Skyframe 后面的另一层；即使一个动作在 Skyframe 中重新执行，它仍然可以在本地动作缓存中命中。它表示本地文件系统的状态，并被序列化到磁盘，这意味着当启动新的 Bazel 服务器时，即使 Skyframe 图表为空，也可以获得本地操作缓存命中。\n使用 方法检查此缓存的命中 ActionCacheChecker.getTokenIfNeedToExecute()。\n与其名称相反，它是从派生工件的路径到发出它的动作的映射。动作描述为：\n其输入和输出文件的集合及其校验和 它的“动作键”，通常是执行的命令行，但一般来说，表示输入文件的校验和未捕获的所有内容（例如，对于FileWriteAction，它是写入数据的校验和） 还有一个仍在开发中的高度实验性的“自上而下的动作缓存”，它使用传递哈希来避免多次访问缓存。\n输入发现和输入修剪 # 有些动作比只有一组输入更复杂。对动作输入集的更改有两种形式：\n一个动作可能会在其执行之前发现新的输入，或者决定它的某些输入实际上是不必要的。典型的例子是 C++，最好从其传递闭包中对 C++ 文件使用哪些头文件进行有根据的猜测，这样我们就不会注意将每个文件发送到远程执行程序；因此，我们可以选择不将每个头文件都注册为“输入”，而是扫描源文件以查找可传递包含的头文件，并且只将这些头文件标记为#include语句中提到的输入（我们高估了我们不需要实现完整的 C 预处理器）此选项目前在 Bazel 中硬连线为“false”，并且仅在 Google 中使用。 一个动作可能会意识到一些文件在其执行期间没有被使用。在 C++ 中，这称为“.d 文件”：编译器会在事后告知使用了哪些头文件，并且为了避免增量比 Make 更差的尴尬，Bazel 利用了这一事实。这提供了比包含扫描器更好的估计，因为它依赖于编译器。 这些是使用 Action 上的方法实现的：\nAction.discoverInputs()叫做。它应该返回一组被确定为需要的嵌套工件。这些必须是源工件，以便动作图中没有在配置的目标图中没有等效项的依赖边。 该动作通过调用来执行Action.execute()。 在 结束时Action.execute()，动作可以调用 Action.updateInputs()告诉 Bazel 并非所有的输入都是需要的。如果已使用的输入报告为未使用，这可能会导致不正确的增量构建。 当动作缓存返回对新动作实例的命中（例如，在服务器重新启动后创建）时，Bazel 会调用updateInputs()自身，以便输入集反映之前完成的输入发现和修剪的结果。\nStarlark 动作可以利用该工具使用 的unused_inputs_list=参数将 某些输入声明为未使用ctx.actions.run()。\n运行操作的各种方式：策略/ActionContexts # 一些动作可以以不同的方式运行。例如，可以在本地、本地但在各种沙箱中或远程执行命令行。体现这一点的概念被称为ActionContext（或Strategy，因为我们成功地只进行了一半的重命名\u0026hellip;\u0026hellip;）\n动作上下文的生命周期如下：\n当执行阶段开始时，BlazeModule会询问实例它们有哪些动作上下文。这发生在 ExecutionTool. 动作上下文类型由 JavaClass 实例标识，该实例引用ActionContext动作上下文的子接口以及动作上下文必须实现的接口。 从可用的动作上下文中选择适当的动作上下文并转发到ActionExecutionContext和BlazeExecutor。 操作使用ActionExecutionContext.getContext()and 请求上下文BlazeExecutor.getStrategy()（实际上应该只有一种方法可以做到……） 策略可以自由调用其他策略来完成它们的工作；例如，这用于在本地和远程启动操作的动态策略中，然后使用先完成的操作。\n一种值得注意的策略是实现持久工作进程的策略（WorkerSpawnStrategy）。这个想法是一些工具有很长的启动时间，因此应该在动作之间重用，而不是为每个动作重新启动一个（这确实代表了一个潜在的正确性问题，因为 Bazel 依赖于工作进程的承诺，它不会在各个请求之间携带可观察的状态）\n如果工具发生变化，则需要重新启动工作进程。通过计算使用的工具的校验和来确定工人是否可以重用 WorkerFilesHash。它依赖于知道动作的哪些输入代表工具的一部分，哪些代表输入；这是由 Action 的创建者决定的：Spawn.getToolFiles()并且运行文件Spawn被算作工具的一部分。\n有关策略（或行动背景！）的更多信息：\n此处提供了有关运行动作的各种策略的信息 。 关于动态策略的信息，我们在本地和远程运行操作以查看先完成的操作[在这里](https://jmmv.dev/series.html#Bazel dynamic execution)可用 。 有关在本地执行操作的复杂性的信息可 在此处获得。 本地资源管理器 # Bazel可以并行运行许多操作。应该并行运行的本地动作的数量 因动作而异：动作需要的资源越多，同时运行的实例就越少，以避免本地机器过载。\n这是在类中实现的ResourceManager：每个动作都必须用ResourceSet实例（CPU 和 RAM）形式所需的本地资源的估计进行注释 。然后，当操作上下文执行需要本地资源的操作时，它们会调用ResourceManager.acquireResources() 并被阻止，直到所需资源可用为止。\n有关本地资源管理的更详细说明，请参见 此处。\n输出目录结构 # 每个操作都需要在输出目录中放置一个单独的位置来放置其输出。派生工件的位置通常如下：\n$EXECROOT/bazel-out/\u0026lt;configuration\u0026gt;/bin/\u0026lt;package\u0026gt;/\u0026lt;artifact name\u0026gt; 与特定配置关联的目录名称是如何确定的？有两个相互矛盾的理想属性：\n如果两个配置可以发生在同一个构建中，它们应该有不同的目录，这样它们就可以有自己的相同操作版本；否则，如果两个配置在生成相同输出文件的操作的命令行上存在分歧，Bazel 不知道要选择哪个操作（“操作冲突”） 如果两个配置代表“大致”相同的东西，它们应该具有相同的名称，以便在命令行匹配时可以将在一个中执行的操作重用于另一个：例如，不应该更改 Java 编译器的命令行选项导致重新运行 C++ 编译操作。 到目前为止，我们还没有想出一个原则性的方法来解决这个问题，这与配置修剪的问题有相似之处。此处提供了有关选项的更长讨论 。主要的问题领域是 Starlark 规则（其作者通常对 Bazel 并不十分熟悉）和方面，它们为可以生成“相同”输出文件的事物空间增加了另一个维度。\n当前的方法是配置的路径段 \u0026lt;CPU\u0026gt;-\u0026lt;compilation mode\u0026gt;添加了各种后缀，以便在 Java 中实现的配置转换不会导致操作冲突。此外，还添加了 Starlark 配置转换集的校验和，以便用户不会导致操作冲突。它远非完美。这是OutputDirectories.buildMnemonic()在每个配置片段中实现 并依赖于将其自己的部分添加到输出目录的名称。\n测试 # Bazel 对运行测试有丰富的支持。它支持：\n远程运行测试（如果远程执行后端可用） 并行运行多次测试（用于去剥落或收集时序数据） 分片测试（将同一测试中的测试用例拆分到多个进程中以提高速度） 重新运行易碎测试 将测试分组到测试套件中 测试是具有 TestProvider 的常规配置目标，它描述了应该如何运行测试：\n构建导致运行测试的工件。这是一个包含序列化TestResultData消息的“缓存状态”文件 测试应该运行的次数 测试应该分成的分片数量 关于如何运行测试的一些参数（例如测试超时） 确定要运行的测试 # 确定运行哪些测试是一个复杂的过程。\n首先，在目标模式解析期间，测试套件被递归扩展。扩展在TestsForTargetPatternFunction. 一个有点令人惊讶的问题是，如果一个测试套件声明没有测试，它会引用 其包中的每个测试。这是Package.beforeBuild()通过添加一个调用$implicit_tests测试套件规则的隐式属性来实现的。\n然后，根据命令行选项过滤测试的大小、标签、超时和语言。这在目标解析期间实现TestFilter并从其中调用 TargetPatternPhaseFunction.determineTests()，并将结果放入TargetPatternPhaseValue.getTestsToRunLabels(). 可以过滤的规则属性不可配置的原因是这发生在分析阶段之前，因此配置不可用。\n然后进一步处理BuildView.createResult()：分析失败的目标被过滤掉，测试分为排他性和非排他性测试。然后将其放入AnalysisResult，这就是如何 ExecutionTool知道要运行哪些测试。\n为了给这个复杂的过程提供一些透明度，tests() 查询运算符（在 中实现TestsFunction）可用于告诉在命令行上指定特定目标时运行哪些测试。不幸的是，这是一个重新实现，因此它可能以多种微妙的方式偏离上述内容。\n运行测试 # 运行测试的方式是请求缓存状态工件。这将导致 a 的执行TestRunnerAction，最终调用 TestActionContext由--test_strategy命令行选项选择的以请求的方式运行测试的选项。\n测试是根据精心设计的协议运行的，该协议使用环境变量来告诉测试对它们的期望。有关 Bazel 对测试的期望以及对 Bazel 的期望的详细描述，请参见 此处。在最简单的情况下，退出代码 0 表示成功，其他任何值都表示失败。\n除了缓存状态文件之外，每个测试进程都会发出许多其他文件。它们被放在“测试日志目录”中，这是testlogs目标配置的输出目录的子目录 ：\ntest.xml，一个 JUnit 样式的 XML 文件，详细说明了测试分片中的各个测试用例 test.log，测试的控制台输出。 stdout 和 stderr 没有分开。 test.outputs，“未声明的输出目录”；除了打印到终端的内容之外，它还被想要输出文件的测试使用。 在构建常规目标期间，测试执行期间可能会发生两件事：独占测试执行和输出流。\n有些测试需要以独占模式执行，即不与其他测试并行执行。这可以通过添加tags=[\u0026quot;exclusive\u0026quot;]到测试规则或使用--test_strategy=exclusive. 每个独占测试由单独的 Skyframe 调用运行，请求在“主”构建之后执行测试。这是在 SkyframeExecutor.runExclusiveTest().\n与常规操作不同，后者的终端输出在操作完成时被转储，用户可以请求流式传输测试的输出，以便他们了解长时间运行的测试的进度。这是由--test_output=streamed命令行选项指定的， 并且意味着独占测试执行，因此不同测试的输出不会散布。\n这是在恰当命名的StreamedTestOutput类中实现的，通过轮询test.log对相关测试文件的更改并将新字节转储到 Bazel 规则的终端来工作。\n通过观察各种事件（例如TestAttempt，TestResult或TestingCompleteEvent），可以在事件总线上获得已执行测试的结果。它们被转储到构建事件协议，并由AggregatingTestListener.\n覆盖收集 # 覆盖率由文件中的 LCOV 格式的测试报告 bazel-testlogs/$PACKAGE/$TARGET/coverage.dat。\n为了收集覆盖率，每个测试执行都包含在一个名为 collect_coverage.sh.\n此脚本设置测试环境以启用覆盖率收集并确定覆盖率运行时将覆盖率文件写入何处。然后它运行测试。一个测试本身可以运行多个子进程，并且由用多种不同编程语言编写的部分组成（具有单独的覆盖收集运行时）。包装脚本负责在必要时将生成的文件转换为 LCOV 格式，并将它们合并到一个文件中。\n的插入collect_coverage.sh是由测试策略完成的，并且需要collect_coverage.sh在测试的输入上。这是通过:coverage_support解析为配置标志的值的隐式属性来完成的--coverage_support（请参阅 参考资料 TestConfiguration.TestOptions.coverageSupport）\n一些语言进行离线检测，这意味着在编译时添加覆盖检测（例如 C++），而其他语言进行在线检测，这意味着在执行时添加覆盖检测。\n另一个核心概念是基线覆盖率。这是库、二进制文件或测试的覆盖范围（如果其中没有运行代码）。它解决的问题是，如果您想计算二进制文件的测试覆盖率，仅合并所有测试的覆盖率是不够的，因为二进制文件中可能存在未链接到任何测试的代码。因此，我们要做的是为每个二进制文件发出一个覆盖文件，该文件只包含我们收集覆盖的文件，没有覆盖的行。目标的基线覆盖率文件位于 bazel-testlogs/$PACKAGE/$TARGET/baseline_coverage.dat. 如果您将--nobuild_tests_only标志传递给 Bazel ，除了测试之外，它还会为二进制文件和库生成 。\n基线覆盖范围目前已被打破。\n我们为每个规则跟踪两组文件以进行覆盖收集：检测文件集和检测元数据文件集。\n检测文件集就是这样，一组要检测的文件。对于在线覆盖运行时，可以在运行时使用它来决定要检测哪些文件。它还用于实现基线覆盖。\n仪表元数据文件集是测试需要从中生成 LCOV 文件所需的额外文件集。实际上，这由特定于运行时的文件组成；例如，gcc 在编译期间发出 .gcno 文件。如果启用了覆盖模式，这些将添加到测试操作的输入集中。\n是否正在收集覆盖率存储在 BuildConfiguration. 这很方便，因为它是一种根据该位更改测试动作和动作图的简单方法，但这也意味着如果翻转该位，则需要重新分析所有目标（某些语言，例如 C++ 需要不同的编译器选项来发出可以收集覆盖率的代码，这在一定程度上缓解了这个问题，因为无论如何都需要重新分析）。\n覆盖支持文件通过隐式依赖中的标签依赖，以便它们可以被调用策略覆盖，这允许它们在不同版本的 Bazel 之间有所不同。理想情况下，这些差异将被消除，我们将其中之一标准化。\n我们还生成一个“覆盖率报告”，它合并了在 Bazel 调用中为每个测试收集的覆盖率。这由 处理 CoverageReportActionFactory并从 调用BuildView.createResult()。它通过查看:coverage_report_generator 执行的第一个测试的属性来访问所需的工具。\n查询引擎 # 该文档的原版，参考https://docs.bazel.build/versions/main/query-how-to.html\n对于具体语言的细节和\u0026ndash;output选项的的细节，看：\nhttps://docs.bazel.build/versions/main/query.html，命令的帮助调用bazel help query https://docs.bazel.build/versions/main/cquery.html，bazel help cquery 在执行的时候可能遇到各种错误，比方说targets不存在，如果想忽略，加上 --keep_going flag.\n查找依赖 # 用bazel query \u0026ldquo;deps(xxx)\u0026ldquo;来查找依赖，这个命令会显示target所有的依赖，甚至会显示具体的文件。我一般查从文件触发的时候会这么查询\n$ bazel query \u0026#34;deps(//foo)\u0026#34; //foo:foo //foo:foo-dep ... 查找两个target怎么建立的依赖 # target //third_party/zlib:zlibonly 没有直接写到 //foo的BUILD文件里，所以它是个间接依赖, 如何查询依赖的路径呢?\nallpaths ，会检索出来所有的依赖路径，这个结果是一个压扁的list\n$ bazel query \u0026#34;allpaths(//foo, third_party/...)\u0026#34; ...many errors detected in BUILD files... //foo:foo //translations/tools:translator //translations/tools:aggregator //translations/base:base //tools/pkg:pex //tools/pkg:pex_phase_one //tools/pkg:pex_lib //third_party/python:python_lib //translations/tools:messages //third_party/py/xml:xml //third_party/py/xml:utils/boolean.so //third_party/py/xml:parsers/sgmlop.so //third_party/py/xml:parsers/pyexpat.so //third_party/py/MySQL:MySQL //third_party/py/MySQL:_MySQL.so //third_party/mysql:mysql //third_party/openssl:openssl //third_party/zlib:zlibonly //third_party/zlib:zlibonly_v1_2_3 //third_party/python:headers //third_party/openssl:crypto 使用dot来转换依赖链为svg图片，这样子好看一些\n$ bazel query \u0026#34;allpaths(//foo, third_party/...)\u0026#34; --notool_deps --output graph | dot -Tsvg \u0026gt; /tmp/deps.svg somepath，会检索出来一条路径\n$ bazel query \u0026#34;somepath(//foo:foo, third_party/zlib:zlibonly)\u0026#34; //foo:foo //translations/tools:translator //translations/base:base //third_party/py/MySQL:MySQL //third_party/py/MySQL:_MySQL.so //third_party/mysql:mysql //third_party/zlib:zlibonly --notool_deps可能也有\nAside: implicit dependencies # //foo 的BUILD文件从来没引用 //translations/tools:aggregator. 直接的依赖链是什么呢？\n有时候一部分的编译需要引入很多隐式的依赖，比方说编译proto文件的时候需要先编译protocol compiler，因此引入了很多的不必要的依赖，使用--noimplicit_deps移除这些依赖\n查找反向的依赖 # 有时候希望查找哪些targets依赖了具体的目标，比方说你改动了部分的文件，你想知道你的代码改动会影响到哪些target，可以使用 rdeps(u, x) 来执行反向查找， x 是 u的闭包，Bazel\u0026rsquo;s Sky Query 支持 allrdeps 函数, 可以方便的自定检索方式\nbazel query \u0026#39;rdeps(//offboard/dashboard:sim_server, //offboard/dashboard/services/health:health)\u0026#39; #查找反向依赖链,查找health到sim_server bazel query \u0026#39;rdeps(//..., //offboard/dashboard/services/health:health)\u0026#39; --keep_going #这个命令检索所有的依赖health的target What packages exist beneath foo? # bazel query \u0026#39;foo/...\u0026#39; --output package What rules are defined in the foo package? # bazel query \u0026#39;kind(rule, foo:*)\u0026#39; --output label_kind What files are generated by rules in the foo package? # bazel query \u0026#39;kind(\u0026#34;generated file\u0026#34;, //foo:*)\u0026#39; What targets are generated by starlark macro foo? # bazel query \u0026#39;attr(generator_function, foo, //path/to/search/...)\u0026#39; What\u0026rsquo;s the set of BUILD files needed to build //foo? # bazel query \u0026#39;buildfiles(deps(//foo))\u0026#39; | cut -f1 -d: What are the individual tests that a test_suite expands to? # bazel query \u0026#39;tests(//foo:smoke_tests)\u0026#39; Which of those are C++ tests? # bazel query \u0026#39;kind(cc_.*, tests(//foo:smoke_tests))\u0026#39; Which of those are small? Medium? Large? # bazel query \u0026#39;attr(size, small, tests(//foo:smoke_tests))\u0026#39; bazel query \u0026#39;attr(size, medium, tests(//foo:smoke_tests))\u0026#39; bazel query \u0026#39;attr(size, large, tests(//foo:smoke_tests))\u0026#39; What are the tests beneath foo that match a pattern? # bazel query \u0026#39;filter(\u0026#34;pa?t\u0026#34;, kind(\u0026#34;.*_test rule\u0026#34;, //foo/...))\u0026#39; The pattern is a regex and is applied to the full name of the rule. It\u0026rsquo;s similar to doing\nbazel query \u0026#39;kind(\u0026#34;.*_test rule\u0026#34;, //foo/...)\u0026#39; | grep -E \u0026#39;pa?t\u0026#39; What package contains file path/to/file/bar.java? # bazel query path/to/file/bar.java --output=package What is the build label for path/to/file/bar.java? # bazel query path/to/file/bar.java What rule target(s) contain file path/to/file/bar.java as a source? # fullname=$(bazel query path/to/file/bar.java) bazel query \u0026#34;attr(\u0026#39;srcs\u0026#39;, $fullname, ${fullname//:*/}:*)\u0026#34; What package dependencies exist \u0026hellip; # What packages does foo depend on? (What do I need to check out to build foo) # bazel query \u0026#39;buildfiles(deps(//foo:foo))\u0026#39; --output package Note, buildfiles is required in order to correctly obtain all files referenced by subinclude; see the reference manual for details.\nWhat packages does the foo tree depend on, excluding foo/contrib? # bazel query \u0026#39;deps(foo/... except foo/contrib/...)\u0026#39; --output package What rule dependencies exist \u0026hellip; # What genproto rules does bar depend upon? # bazel query \u0026#39;kind(genproto, deps(bar/...))\u0026#39; Find the definition of some JNI (C++) library that is transitively depended upon by a Java binary rule in the servlet tree. # bazel query \u0026#39;some(kind(cc_.*library, deps(kind(java_binary, //java/com/example/frontend/...))))\u0026#39; --output location \u0026hellip;Now find the definitions of all the Java binaries that depend on them # bazel query \u0026#39;let jbs = kind(java_binary, //java/com/example/frontend/...) in let cls = kind(cc_.*library, deps($jbs)) in $jbs intersect allpaths($jbs, $cls)\u0026#39; What file dependencies exist \u0026hellip; # What\u0026rsquo;s the complete set of Java source files required to build foo? # Source files:\nbazel query \u0026#39;kind(\u0026#34;source file\u0026#34;, deps(//path/to/target/foo/...))\u0026#39; | grep java$ Generated files:\nbazel query \u0026#39;kind(\u0026#34;generated file\u0026#34;, deps(//path/to/target/foo/...))\u0026#39; | grep java$ What is the complete set of Java source files required to build QUX\u0026rsquo;s tests? # Source files:\nbazel query \u0026#39;kind(\u0026#34;source file\u0026#34;, deps(kind(\u0026#34;.*_test rule\u0026#34;, javatests/com/example/qux/...)))\u0026#39; | grep java$ Generated files:\nbazel query \u0026#39;kind(\u0026#34;generated file\u0026#34;, deps(kind(\u0026#34;.*_test rule\u0026#34;, javatests/com/example/qux/...)))\u0026#39; | grep java$ What differences in dependencies between X and Y exist \u0026hellip; # What targets does //foo depend on that //foo:foolib does not? # bazel query \u0026#39;deps(//foo) except deps(//foo:foolib)\u0026#39; What C++ libraries do the foo tests depend on that the //foo production binary does not depend on? # bazel query \u0026#39;kind(\u0026#34;cc_library\u0026#34;, deps(kind(\u0026#34;.*test rule\u0026#34;, foo/...)) except deps(//foo))\u0026#39; Why does this dependency exist \u0026hellip; # Why does bar depend on groups2? # bazel query \u0026#39;somepath(bar/...,groups2/...:*)\u0026#39; Once you have the results of this query, you will often find that a single target stands out as being an unexpected or egregious and undesirable dependency of bar. The query can then be further refined to:\nShow me a path from docker/updater:updater_systest (a py_test) to some cc_library that it depends upon: # bazel query \u0026#39;let cc = kind(cc_library, deps(docker/updater:updater_systest)) in somepath(docker/updater:updater_systest, $cc)\u0026#39; Why does library //photos/frontend:lib depend on two variants of the same library //third_party/jpeglib and //third_party/jpeg? # This query boils down to: \u0026ldquo;show me the subgraph of //photos/frontend:lib that depends on both libraries\u0026rdquo;. When shown in topological order, the last element of the result is the most likely culprit.\nbazel query \u0026#39;allpaths(//photos/frontend:lib, //third_party/jpeglib) intersect allpaths(//photos/frontend:lib, //third_party/jpeg)\u0026#39; //photos/frontend:lib //photos/frontend:lib_impl //photos/frontend:lib_dispatcher //photos/frontend:icons //photos/frontend/modules/gadgets:gadget_icon //photos/thumbnailer:thumbnail_lib //third_party/jpeg/img:renderer What depends on \u0026hellip; # What rules under bar depend on Y? # bazel query \u0026#39;bar/... intersect allpaths(bar/..., Y)\u0026#39; Note: X intersect allpaths(X, Y) is the general idiom for the query \u0026ldquo;which X depend on Y?\u0026rdquo; If expression X is non-trivial, it may be convenient to bind a name to it using let to avoid duplication.\nWhat targets directly depend on T, in T\u0026rsquo;s package? # bazel query \u0026#39;same_pkg_direct_rdeps(T)\u0026#39; How do I break a dependency \u0026hellip; # What dependency paths do I have to break to make bar no longer depend on X? # To output the graph to a svg file:\nbazel query \u0026#39;allpaths(bar/...,X)\u0026#39; --output graph | dot -Tsvg \u0026gt; /tmp/dep.svg Misc \u0026hellip; # How many sequential steps are there in the //foo-tests build? # Unfortunately, the query language can\u0026rsquo;t currently give you the longest path from x to y, but it can find the (or rather a) most distant node from the starting point, or show you the lengths of the longest path from x to every y that it depends on. Use maxrank:\nbazel query \u0026#39;deps(//foo-tests)\u0026#39; --output maxrank | tail -1 85 //third_party/zlib:zutil.c The result indicates that there exist paths of length 85 that must occur in order in this build.\n性能评估 # 模块系统 # Bazel 可以通过添加模块来扩展。每个模块都必须子类化 BlazeModule（该名称是 Bazel 过去称为 Blaze 的历史遗物）并在命令执行期间获取有关各种事件的信息。\n它们主要用于实现只有某些版本的 Bazel（例如我们在 Google 使用的那个）需要的各种“非核心”功能：\n远程执行系统的接口 新命令 BlazeModule提供的扩展点集有些随意。不要将其用作良好设计原则的示例。\n活动巴士 # BlazeModules与巴泽尔的其余部分通信的主要方式是通过事件总线（EventBus）：每构建创建一个新的实例，巴泽尔的各个部分可以发布事件，它和模块可以注册他们感兴趣的事件侦听器。例如，以下事物表示为事件：\n已确定要构建的构建目标列表 ( TargetParsingCompleteEvent) 顶层配置已确定 ( BuildConfigurationEvent) 目标是否已构建成功与否 ( TargetCompleteEvent) 运行测试 ( TestAttempt, TestSummary) 其中一些事件在构建事件协议中的 Bazel 之外表示 （它们是BuildEvents）。这不仅允许BlazeModules，而且还允许Bazel 进程之外的事物来观察构建。它们可以作为包含协议消息的文件进行访问，或者 Bazel 可以连接到服务器（称为构建事件服务）以流式传输事件。\n这是在build.lib.buildeventservice和 build.lib.buildeventstreamJava 包中实现的。\n外部存储库 # Bazel 最初设计用于 monorepo（包含构建所需的所有内容的单一源代码树），但 Bazel 生活在一个不一定正确的世界中。“外部存储库”是用于连接这两个世界的抽象：它们表示构建所需但不在主源代码树中的代码。\n工作空间文件 # 外部存储库的集合是通过解析 WORKSPACE 文件来确定的。例如，这样的声明：\nlocal_repository(name=\u0026#34;foo\u0026#34;, path=\u0026#34;/foo/bar\u0026#34;) 存储库中的结果称为@foo可用。这变得复杂的地方在于，可以在 Starlark 文件中定义新的存储库规则，然后可以使用这些文件加载新的 Starlark 代码，可以用来定义新的存储库规则等等……\n为了处理这种情况，WORKSPACE 文件的解析（in WorkspaceFileFunction）被分成由load() 语句描述的块。块索引由指示WorkspaceFileKey.getIndex()和计算WorkspaceFileFunction直到索引 X 意味着评估它直到第 X 条load()语句。\n获取存储库 # 在 Bazel 可以使用存储库的代码之前，需要 fetch。这导致 Bazel 在 $OUTPUT_BASE/external/\u0026lt;repository name\u0026gt;.\n获取存储库的步骤如下：\nPackageLookupFunction意识到它需要一个存储库并创建 a RepositoryNameas a SkyKey，它调用RepositoryLoaderFunction RepositoryLoaderFunction将请求转发给 RepositoryDelegatorFunction不明原因（代码说这是为了避免在 Skyframe 重新启动的情况下重新下载东西，但这不是一个非常可靠的推理） RepositoryDelegatorFunction 通过遍历 WORKSPACE 文件的块，直到找到请求的存储库，找出它被要求获取的存储库规则 RepositoryFunction找到合适的实现repository fetching；它可以是存储库的 Starlark 实现，也可以是用 Java 实现的存储库的硬编码映射。 由于获取存储库可能非常昂贵，因此存在各种缓存层：\n下载的文件有一个缓存，由它们的校验和 ( RepositoryCache)键控。这要求校验和在 WORKSPACE 文件中可用，但无论如何这对密封性都有好处。这是由同一工作站上的每个 Bazel 服务器实例共享的，无论它们在哪个工作区或输出库中运行。 为每个存储库编写一个“标记文件” $OUTPUT_BASE/external ，其中包含用于获取它的规则的校验和。如果 Bazel 服务器重新启动但校验和没有更改，则不会重新获取它。这是在RepositoryDelegatorFunction.DigestWriter. 该--distdir命令行选项指定要下载用来查找文物另外一个缓存。这在 Bazel 不应从 Internet 获取随机内容的企业环境中很有用。这是由DownloadManager. 下载存储库后，其中的工件将被视为源工件。这带来了一个问题，因为 Bazel 通常通过调用 stat() 检查源工件的最新性，并且当它们所在的存储库的定义发生更改时，这些工件也会失效。因此， FileStateValue外部存储库中工件的 s 需要依赖于它们的外部存储库。这是由ExternalFilesHelper.\n托管目录 # 有时，外部存储库需要修改工作空间根目录下的文件（例如，将下载的包存放在源代码树的子目录中的包管理器）。这与 Bazel 假设源文件仅由用户而不是自己修改并允许包引用工作区根目录下的每个目录的假设不一致。为了使这种外部存储库工作，Bazel 做了两件事：\n允许用户指定 Bazel 不允许进入的工作区的子目录。它们列在一个名为的文件中.bazelignore，功能在BlacklistedPackagePrefixesFunction. 我们对从工作空间的子目录到外部存储库的映射进行编码，ManagedDirectoriesKnowledge并 FileStateValue以与常规外部存储库相同的方式引用它们。 存储库映射 # 可能会发生多个存储库想要依赖于同一个存储库，但版本不同（这是“钻石依赖问题”的一个实例）。例如，如果构建中不同存储库中的两个二进制文件想要依赖 Guava，它们可能都会引用带有标签的 Guava，@guava//并期望这意味着它的不同版本。\n因此，Bazel 允许重新映射外部存储库标签，以便字符串@guava//可以引用@guava1//一个二进制存储库中的一个 Guava 存储库（例如@guava2//）和另一个 Guava 存储库（例如）另一个的存储库。\n或者，这也可用于连接钻石。如果一个存储库依赖于@guava1//，而另一个依赖于@guava2//，存储库映射允许重新映射两个存储库以使用规范@guava//存储库。\n该映射在 WORKSPACE 文件中指定repo_mapping为各个存储库定义的属性。然后，它作为 的成员出现在 Skyframe 中 WorkspaceFileValue，并连接到：\nPackage.Builder.repositoryMapping 它用于通过以下方式转换包中规则的标签值属性 RuleClass.populateRuleAttributeValues() Package.repositoryMapping在分析阶段使用（用于解决$(location)加载阶段未解析的问题） BzlLoadFunction 用于解析 load() 语句中的标签 BUILDFARM # CI的BUILDFARM相关的路线图\nBuildfarm 升级 1.12 =\u0026gt; 1.15 1.15 =\u0026gt; 2.0.0 2.0.0 =\u0026gt; 2.3.1 监控 export execute_slot_usage export pre queue export build slow issue 故障分析 filesystem XFS升级解决hard link问题 write-cancell问题分析 性能优化 nginx负载均衡 bowb启用 用户使用场景\n用户希望远程执行命令 用户首先上传相应的Command，Action到ContentAddressableStorage。这里面意味着用户需要首先上传文件。 用户调用Execute执行任务，服务端会执行Action。客户可以调用WaitExecution来等待任务完成，收到一串的stream反馈结果 Action在执行完毕之后可以直接缓存ActionResult到Server端 ActionCache或者相关服务CAS 调用GetActionResult检索ActionCache 上传CAS Action需要上传CAS文件，如果（which may occur in the middle of a single upload if another client uploads the same blob concurrently）有其它用户已经上传完了CAS文件 用户需要确定CAS文件是否存在FindMissingBlobs BatchUpdateBlobs， BatchReadBlobs，用户上传文件的时候会同时上传Digest和byte内容，其中bytes就是文件的原始内容对于BatchUpdateBlobsRequest，它的BatchUpdateBlobsResponse实际上是一样的结构。 GetTreeRequest buildfarm架构：\n简单理解，可以将buildfarm分为三块：server，worker，backplane（redis）。其中backplane是分布式同步信息的唯一方法，这里的信息包括state of the Instance，可以简单理解为server/worker的 状态。ActionCache, Operations,和ContentAddressableStorage流等信息。简单来说公用的状态同步板。server和worker都不断的通过backplane，阻塞式地（不断重试）检索任务。\n如果worker在执行任务的时候发现某个action缺失，或者找不到对应的文件，这时候有两种方法，一种是请求用户上传，另一种是\n客户端实际上远程执行也是不断轮训任务是不是完成了。\nserver，我们只看核心 ActionCacheService 核心函数 getActionResult。Essentially the \u0026ldquo;get\u0026rdquo; method, which is responsible for finding an ActionResult and retrieving it. ContentAddressableStorageService ExecutionService executionservice提供面向用户的远程执行服务，本质对应admin\\main\\src\\main\\resources\\proto\\remote_execution.proto文件。ExecutionService的内容会更新ActionCacheService + worker worker提供 buildfarm从2.0开始做了大规模的简化工作，只需要指定一两个配置选项就可以，不需要再写冗长的配置\nbackplane: redisUri: \u0026#34;xxx\u0026#34; queues: - name: \u0026#34;cpu\u0026#34; properties: - name: \u0026#34;min-cores\u0026#34; value: \u0026#34;*\u0026#34; - name: \u0026#34;max-cores\u0026#34; value: \u0026#34;*\u0026#34; digestFunction: SHA256 server: name: \u0026#34;shard\u0026#34; recordBesEvents: true maxEntrySizeBytes: 214748364800 # 200 * 1024 * 1024 * 1024 backplane: redisUri: \u0026#34;xxx\u0026#34; queues: - name: \u0026#34;cpu\u0026#34; properties: - name: \u0026#34;min-cores\u0026#34; value: \u0026#34;*\u0026#34; - name: \u0026#34;max-cores\u0026#34; value: \u0026#34;*\u0026#34; digestFunction: SHA256 worker: port: 8982 publicName: \u0026#34;localhost:8982\u0026#34; inputFetchStageWidth: 8 realInputDirectories: - \u0026#34;external\u0026#34; cas: type: FILESYSTEM maxSizeBytes: 536870912000 # 500 * 1024 * 1024 * 1024 maxEntrySizeBytes: 214748364800 # 200 * 1024 * 1024 * 1024 前提条件，需要对java的并发编程 \u0026amp; google的Guava有一定的了解，需要了解：\nListenableFuture， 使用addListener(Runnable, Executor)来添加由executor执行的回调函数Runnable，也可以用Futures.addCallback(ListenableFuture, FutureCallback, Executor)，添加回调函数。具体参考：https://github.com/google/guava/wiki/ListenableFutureExplained \u0026amp; https://guava.dev/releases/29.0-jre/api/docs/com/google/common/util/concurrent/ListenableFuture.html SettableFuture，A ListenableFuture whose result can be set by a set(Object), setException(Throwable) or setFuture(ListenableFuture) call. 具体参考：https://guava.dev/releases/23.0/api/docs/com/google/common/util/concurrent/SettableFuture.html \u0026amp; https://zhuanlan.zhihu.com/p/356808315 Cache，参考：https://segmentfault.com/a/1190000011105644 \u0026amp; https://www.baeldung.com/guava-cache 基础知识：\n远程执行主要参考admin/main/src/main/resources/proto/remote_execution.proto文件，\n执行前，用户检查是不是已经缓存了对应的action，调用ActionCache api相关的查询函数，获取或者更新等操作。\n客户端上传所有的输入，要运行的命令（command），要存入CAS的Action，然后调用Execute命令并传入参数action_digest来执行。\n用户需要上传执行命令需要的bolb，这个时候就需要ContentAddressableStorage服务，这个服务负责上传/下载编译出来的binary，每个content都是通过计算hash得出。\n对于小文件，bazle使用BatchUpdateBlobs上传 对于大文件，需要使用Write method来执行写操作，实际上我们目前观测到的worker stuck，好几次都是由于write method引起的。下载资源的时候，需要使用Read method。成功后返回commitsize FindMissingBlobs，用这个函数来查询blob是不是已经存在 这里面实际上有个问题，我上传了文件到worker，可是怎么保证执行execute的时候，worker就一定找到我想要的文件呢？ Action，关于执行所有的信息都通过action来hold，action执行的command存储在ContentAddressableStorage里面，input_root_digest就是输入的文件啥的也需要缓存好，换存在ContentAddressableStorage\nCommand\nDirectory，代表文件树里面的一个目录节点，包含文件nodes，目录nodes，软连接node等子节点\n重点需要关注\ninstance: operationQueuer DispatchedMonitor：The DispatchedMonitor exists to requeue operations that go missing. For example, if a worker leaves the cluster in the middle of executing an action. 会尝试一直往一个queueentry压executiveteentry进去 worker backplane Operations 架构：\nA backplane is a communication medium for all of the members of a shard instance. All distributed communication and shared truth flows through or is retained by it.Buildfarm sees the backplane as an Interface (i.e. Java) that it can use to retrieve and broadcast information about the state of the Instance. Messages about the ActionCache, Operations, and ContentAddressableStorage flow in and out of it.\nBoth Schedulers and Workers have an instance of a Backplane implementation (i.e. concrete class object) upon which they invoke methods. \u0026lsquo;Long polling\u0026rsquo; for dequeues (Operation Arrivals and Ready-to-Run) occurs within the backplane implementation, and the usage is as a blocking dequeue. Similar long-polling occurs on clients waiting for Operation completion, but with an active monitor for each waiting method invocation. Schedulers insist that they are updated frequently, or can positively determine the current known position, for each Operation that is being waited for.\nstock redis cluster, and even a single stock non-clustered redis node now, will suffice to be a backplane target. And yes, it is one example, and the main/only one provided for now.\nThe workers are actively waiting on the backplane at all times that they are idle, yes. The BalancedRedisQueue implementation actually goes through several states while waiting for work, polling a queue on each shard of a redis cluster initially unblocking (with rpoplpush), then blocking (with brpoplpush) with an exponential timeout in sequence. Any work response resets this procedure. This distributes the queue load amongst redis cluster members equally.\nThe Scheduler is listening for OperationChange messages, implemented as subscriptions via redis pub/sub, on behalf of the client, to respond to it with updates. This is an event-driven interface, not a polling one, so the responses are as immediate as the pub/sub communication channel is at any moment. Per \u0026lsquo;jobs that depend on those ones\u0026rsquo;: the Remote Execution API does not currently allow for the presentation of inter-Operation dependencies. Each Operation is considered its own isolated activity (except with relative priority), and any dependent enqueueing is undertaken by the client in response to the Operation updates.\nIt is important as you\u0026rsquo;ve indicated to reduce overhead here. For reference, we have a moderately sized and scaling cluster of hosts supporting 100s of concurrently executing builds, each with 10k to 100k remote actions. We\u0026rsquo;ve benchmarked arrival rates through multiple schedulers and workers at up to 10k/s without queueing (negating action-dependent transform and execute times). Operation round trips have been seen as low as 10ms, but this varies dramatically as Schedulers and Workers need to fetch and retain information throughout the cluster to transform, validate, store, check cache, and retrieve inputs and inject outputs over its lifecycle, to say nothing of execution time.\nWe find it easiest to monitor these transition costs systemically as opposed to cumulatively, dealing with each phase transition cost as an individual stage, and assume that the average cost of a stage is transferrable to all operations: i.e. \u0026ldquo;Operation input fetch is slow today\u0026rdquo;\nShardInstance Server相关代码阅读 # java的future相关的看这个文档：https://www.baeldung.com/guava-futures-listenablefuture\n中文的listenablefuture看这个https://zhuanlan.zhihu.com/p/349038746\nschedulor和backplane交互，用redis的backplane，最后还是和redis通信。不过这样子也好，让redis管理包括任务有序啥的东西了，做消息队列了。\n简单说：\nshardinstance\n创建一个包含24个线程的actionCacheFetchService，用来获取actioncache；之后创建相应的actioncache 创建remoteInputStreamFactory 创建dispatchedMonitor，一个线程 创建operationQueuer 创建prometheusMetricsThread，单线程 key功能：\n函数start\n启动backplane 启动dispatchedMonitor 启动operationQueuer 启动prometheusMetricsThread 函数stop：这个不细说了，我们基本没主动停机过\n函数findMissingBlobs：查找missingblob的位置的关键函数\n先遍历一遍找到非空的blobdigest 然后获取worker，丢到一个双端队列中。这里面有个问题啊，某些blob可能只存储在特定的worker上，随便找一个worker可能找不到啊？明白了，这个只是查找，获取到底在哪个worker上？ 调用findMissingBlobsOnWorker，创意的requestid是个UUID.randomUUID().toString() 最后返回ListenableFuture\u0026lt;Iterable\u0026lt;Digest\u0026gt;\u0026gt; 类别FindMissingResponseEntry\n就一个构造函数，指定worker，metric，exception啥的 findMissingBlobsOnWorker\n调用 workers.removeFirst()来获得双端队列的第一个worker\n调用workerstub去查找丢失的blob，实际上是创建listenablefuture：\nListenableFuture\u0026lt;Iterable\u0026lt;Digest\u0026gt;\u0026gt; workerMissingBlobsFuture = workerStub(worker).findMissingBlobs(blobDigests, requestMetadata); 给listenablefuture加个回调函数\n成功：worker会返回一个missingDigests，这个应该指代可以找到的digests？继续调用findMissingBlobsOnWorker去查找。这个实际上\n失败：\n如果是response没实现或者不可用（Code.UNAVAILABLE；Code.UNIMPLEMENTED），就removeMalfunctioningWorker。实际上这个可以解决我们最近经常遇到的某个worker stuck in settable future的问题。当然，我们目前还没明白为什么会stuck 如果是超时了 如果是被cancell了，那么什么也不做 其它的类型再把worker加到worker的末尾 除非已经找到了，否则继续\nfetchBlobFromWorker\n还是先deque一个worker 调用getblob去获取blob getBlob\nexecute：执行的关键逻辑\n检查backplane.canPrequeue，是否可以prequeue shardinstace启动流程几个函数的创建\npublic class ShardInstance extends AbstractServerInstance... public ShardInstance( String name, String identifier, DigestUtil digestUtil, ShardInstanceConfig config, Runnable onStop) {... //step 1 在这里创建出来shardbackplane，也就是说每个server instance都会有自己的backplane。 //backplane创建出来了，但是具体的更进一步的操作还没发生，shardinstance自己这么做的？backplane又是这么决定把哪个operation发到那里呢？ 内部调用 ===\u0026gt; RedisShardBackplane,而RedisShardBackplane有RedisShardSubscriber,这里有订阅的逻辑在里面 //step 2 创建actionCacheFetchService，或者叫做ListeningExecutorService，这里实际上就是给listeningfuture创建线程池呗 /* actionCacheFetchService=*/ listeningDecorator(newFixedThreadPool(24))); } ====\u0026gt; private ShardInstance( String name, DigestUtil digestUtil, Backplane backplane, ShardInstanceConfig config, Runnable onStop, ListeningExecutorService actionCacheFetchService) { // step 1，创建新的ShardActionCache new ShardActionCache(DEFAULT_MAX_LOCAL_ACTION_CACHE_SIZE, backplane, actionCacheFetchService) // step 2,创建workerstub,workersub用来做什么？ WorkerStubs.create(digestUtil, config.getGrpcTimeout()), } ===\u0026gt; public ShardInstance( String name, DigestUtil digestUtil, Backplane backplane, ReadThroughActionCache readThroughActionCache, boolean runDispatchedMonitor, int dispatchedMonitorIntervalSeconds, boolean runOperationQueuer, long maxEntrySizeBytes, int maxCpu, int maxRequeueAttempts, Duration maxActionTimeout, boolean useDenyList, Runnable onStop, LoadingCache\u0026lt;String, Instance\u0026gt; workerStubs, ListeningExecutorService actionCacheFetchService, boolean ensureOutputsPresent) { //所有的核心逻辑都在这里，换言之这里就把每个需要用到的东西都创建出来 //core step 0 起DispatchedMonitor之前，我们看一下这个requeueOperation的函数逻辑 public ListenableFuture\u0026lt;Void\u0026gt; requeueOperation(QueueEntry queueEntry, Duration timeout) { // step 1 获取executeEntry \u0026amp; Operation，executeEntry在buildfarm.proto内部定义，包含operation_name // execution_policy，request_metadata等信息 // step 2 检查能不能requeue, // step 3 validate \u0026amp; requeue private ListenableFuture\u0026lt;Void\u0026gt; validateAndRequeueOperation { //这里的重点就是四个future ListenableFuture\u0026lt;QueuedOperation\u0026gt; fetchQueuedOperationFuture； ListenableFuture\u0026lt;QueuedOperation\u0026gt; queuedOperationFuture； ListenableFuture\u0026lt;QueuedOperation\u0026gt; validatedFuture； ListenableFuture\u0026lt;QueuedOperationResult\u0026gt; uploadedFuture； SettableFuture\u0026lt;Void\u0026gt; requeuedFuture = SettableFuture.create(); ==\u0026gt; QueuedOperationResult \u0026amp; uploadQueuedOperation ==\u0026gt; backplane.queue核心是queue } } //core step 1 起一个线程来做DispatchedMonitor dispatchedMonitor = new Thread( new DispatchedMonitor( backplane, this::requeueOperation, dispatchedMonitorIntervalSeconds)); { //dispatchedMonitor负责把已经dispatched的operation（action）重新压入，是固定的压倒一个queue吗？或者说是稳定的worker去dequeue这个queentry吗？ //重点关注这个requeue函数， private ListenableFuture\u0026lt;Void\u0026gt; requeueDispatchedOperation(DispatchedOperation o, long now) { // step 1 内部调用private void logOverdueOperation(DispatchedOperation o, long now) 记录下 logOverdueOperation(o, now); // step 2 requeue，这里就要关注requeued的逻辑是什么了, ListenableFuture\u0026lt;Void\u0026gt; requeuedFuture = requeuer.apply(queueEntry, Durations.fromSeconds(60)); } //core step 2 起一个线程做operationQueuer，这个Runnable在不断的往队列里面丢东西， ListenableFuture\u0026lt;Void\u0026gt; iterate() { //拿一个prequeueoperation， backplane.deprequeueOperation() //为了能够理解poller，我们看看poller干了些什么，poller起了一个线程ActivePoller监视，第一个参数是BooleanSupplier，实际上就是看是不是出异常的时候是不是终止了shardinstance //然后poller resume，先把结果poll出来，再调用ListenableFuture把结果再查到对立里，但是查队列的时候这么找到客户段的？就是buildfarm-worker的？ poller.resume } //core step 3 起promethues metric 线程，具体的代码就不贴了，没啥意思 } @Override public ListenableFuture\u0026lt;Void\u0026gt; execute( Digest actionDigest, boolean skipCacheLookup, ExecutionPolicy executionPolicy, ResultsCachePolicy resultsCachePolicy, RequestMetadata requestMetadata, Watcher watcher) { try { if (!backplane.canPrequeue()) { return immediateFailedFuture( Status.RESOURCE_EXHAUSTED.withDescription(\u0026#34;Too many jobs pending\u0026#34;).asException()); } String operationName = createOperationName(UUID.randomUUID().toString()); executionSuccess.inc(); log.log( Level.FINE, new StringBuilder() .append(\u0026#34;ExecutionSuccess: \u0026#34;) .append(requestMetadata.getToolInvocationId()) .append(\u0026#34; -\u0026gt; \u0026#34;) .append(operationName) .append(\u0026#34;: \u0026#34;) .append(DigestUtil.toString(actionDigest)) .toString()); actionCache.invalidate(DigestUtil.asActionKey(actionDigest)); if (!skipCacheLookup \u0026amp;\u0026amp; recentCacheServedExecutions.getIfPresent(requestMetadata) != null) { log.log( Level.FINE, format(\u0026#34;Operation %s will have skip_cache_lookup = true due to retry\u0026#34;, operationName)); skipCacheLookup = true; } String stdoutStreamName = operationName + \u0026#34;/streams/stdout\u0026#34;; String stderrStreamName = operationName + \u0026#34;/streams/stderr\u0026#34;; ExecuteEntry executeEntry = ExecuteEntry.newBuilder() .setOperationName(operationName) .setActionDigest(actionDigest) .setExecutionPolicy(executionPolicy) .setResultsCachePolicy(resultsCachePolicy) .setSkipCacheLookup(skipCacheLookup) .setRequestMetadata(requestMetadata) .setStdoutStreamName(stdoutStreamName) .setStderrStreamName(stderrStreamName) .setQueuedTimestamp(Timestamps.fromMillis(System.currentTimeMillis())) .build(); ExecuteOperationMetadata metadata = ExecuteOperationMetadata.newBuilder() .setActionDigest(actionDigest) .setStdoutStreamName(stdoutStreamName) .setStderrStreamName(stderrStreamName) .build(); Operation operation = Operation.newBuilder().setName(operationName).setMetadata(Any.pack(metadata)).build(); try { watcher.observe(operation); } catch (Exception e) { return immediateFailedFuture(e); } if (inDenyList(requestMetadata)) { watcher.observe( operation .toBuilder() .setDone(true) .setResponse(Any.pack(denyActionResponse(actionDigest, BLOCK_LIST_ERROR))) .build()); return immediateFuture(null); } backplane.prequeue(executeEntry, operation); return watchOperation( operation, newActionResultWatcher(DigestUtil.asActionKey(actionDigest), watcher), /* initial=*/ false); } catch (IOException e) { return immediateFailedFuture(e); } } BackPlane相关 # private void queue( JedisCluster jedis, String operationName, List\u0026lt;Platform.Property\u0026gt; provisions, String queueEntryJson, int priority) { if (state.dispatchedOperations.remove(jedis, operationName)) { logger.log(Level.WARNING, format(\u0026#34;removed dispatched operation %s\u0026#34;, operationName)); } state.operationQueue.push(jedis, provisions, queueEntryJson, priority); } @SuppressWarnings(\u0026#34;ConstantConditions\u0026#34;) @Override public void queue(QueueEntry queueEntry, Operation operation) throws IOException { String operationName = operation.getName(); String operationJson = operationPrinter.print(operation); String queueEntryJson = JsonFormat.printer().print(queueEntry); Operation publishOperation = onPublish.apply(operation); int priority = queueEntry.getExecuteEntry().getExecutionPolicy().getPriority(); client.run( jedis -\u0026gt; { jedis.setex(operationKey(operationName), config.getOperationExpire(), operationJson); queue( jedis, operation.getName(), queueEntry.getPlatform().getPropertiesList(), queueEntryJson, priority); publishReset(jedis, publishOperation); }); } ShardInstance Worker相关代码阅读 # 我们先大致理解下worker，以shardworker为例，到底是个怎么的架构。\n什么是operationContext包含operation，action，command，queuentry，poller等信息。operation或者说com.google.longrunning.Operation，即为This resource represents a long-running operation that is the result of a network API call，这实际上可以认为是个凭证，客户端可以一直轮训这个来获取结果。action，command。poller，内部包含一个继承自Runnable的ActivePoller，puller的构造函数每次都会指定到点时间，poller有两个函数，一个是resume：构造一个activePoller然后起个线程去执行它，pause：停止activePoller，然后置空。这里注意，activePoller会不断检查是不是超时了，执行操作，如果stop了，那么函数会调用notify去通知，通知谁？\nWorker首先会配置好一个worker context，然后创建每个service：\nContentAddressableStorageService，这个服务是查询数据/缓存数据的核心操作。\nByteStreamService，写文件实际上的服务发生在这里发生在这里。这里面有个java的streamobserver的基础知识，看这里https://grpc.io/docs/languages/java/basics/ 和 https://blog.csdn.net/u010900754/article/details/106203724\n客户端(这个客户端）会调用函数StreamObserver write(StreamObserver responseObserver)，服务端（也就是我们的worker）搞一个双向的流式传输，返回给客户端一个WriteStreamObserver，从而每当客户端发来一些数据就会做一些操作。这里的WriteStreamObserver.onNext()就是针对客户端的一些操作的回调：我们在根据客户端的操作做一系列的行为\n下面的栈显示了，WriteStreamObserver发过来一个Request的时候，我们就触发了个一个操作，根据具体write的类型决定是getOperationStreamWrite还是getUploadBlobWrite，先加一个回调函数，然后开始handleRequest这个请求。这时候实际上就是等待获取写入的commitsize的过程，这个closedfuture实际上就是真正的写入。\nSettableFuture is waiting for executor? \u0026#34;grpc-default-executor-7\u0026#34; #418 daemon prio=5 os_prio=0 cpu=8.65ms elapsed=182086.43s allocated=1427K defined_classes=0 tid=0x00007f662c04f800 nid=0x257 waiting on condition [0x00007f61a70f3000] java.lang.Thread.State: WAITING (parking) at jdk.internal.misc.Unsafe.park(java.base@11.0.15/Native Method) - parking to wait for \u0026lt;0x000000010598b288\u0026gt; (a com.google.common.util.concurrent.SettableFuture) at java.util.concurrent.locks.LockSupport.park(java.base@11.0.15/LockSupport.java:194) at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:537) at com.google.common.util.concurrent.AbstractFuture$TrustedFuture.get(AbstractFuture.java:104) at build.buildfarm.cas.cfc.CASFileCache$3.getOutput(CASFileCache.java:855) - locked \u0026lt;0x00000001059897b8\u0026gt; (a build.buildfarm.cas.cfc.CASFileCache$3) at build.buildfarm.server.WriteStreamObserver.getOutput(WriteStreamObserver.java:414) at build.buildfarm.server.WriteStreamObserver.getCommittedSizeForWrite(WriteStreamObserver.java:288) at build.buildfarm.server.WriteStreamObserver.handleWrite(WriteStreamObserver.java:297) at build.buildfarm.server.WriteStreamObserver.handleRequest(WriteStreamObserver.java:282) at build.buildfarm.server.WriteStreamObserver.initialize(WriteStreamObserver.java:228) at build.buildfarm.server.WriteStreamObserver.onUncommittedNext(WriteStreamObserver.java:115) at build.buildfarm.server.WriteStreamObserver.onNext(WriteStreamObserver.java:95) - locked \u0026lt;0x0000000091795828\u0026gt; (a build.buildfarm.server.WriteStreamObserver) at build.buildfarm.server.WriteStreamObserver.onNext(WriteStreamObserver.java:53) ... 然后创建一个pipeline，包含多个stage，执行任务。\nMatchStage继承PipelineStage，显式调用iterate函数来执行ShardWorkerContext.match函数，调用redis的阻塞方式读取operation，这里有个小点，provisionqueue没有注册在backplane里面，是在取的时候显式的从本地配置读取的，栈如下。所以如果没有什么match的，那么实际上是阻塞在标记处\nat build.buildfarm.common.redis.ProvisionedRedisQueue.isEligible(ProvisionedRedisQueue.java:182) at build.buildfarm.instance.shard.OperationQueue.chooseEligibleQueue(OperationQueue.java:271) at build.buildfarm.instance.shard.OperationQueue.dequeue(OperationQueue.java:189) \u0026lt;== stuck at build.buildfarm.instance.shard.RedisShardBackplane.dispatchOperation(RedisShardBackplane.java:1153) at build.buildfarm.instance.shard.RedisShardBackplane.lambda$dispatchOperation$27(RedisShardBackplane.java:1210) at build.buildfarm.common.redis.RedisClient.lambda$blockingCall$1(RedisClient.java:99) at build.buildfarm.common.redis.RedisClient.call(RedisClient.java:117) at build.buildfarm.common.redis.RedisClient.blockingCall(RedisClient.java:96) at build.buildfarm.instance.shard.RedisShardBackplane.dispatchOperation(RedisShardBackplane.java:1210) at build.buildfarm.worker.shard.ShardWorkerContext.matchInterruptible(ShardWorkerContext.java:279) at build.buildfarm.worker.shard.ShardWorkerContext.match(ShardWorkerContext.java:361) at build.buildfarm.worker.MatchStage.iterate(MatchStage.java:143) at build.buildfarm.worker.PipelineStage.runInterruptible(PipelineStage.java:44) at build.buildfarm.worker.PipelineStage.run(PipelineStage.java:51) at java.base/java.lang.Thread.run(Thread.java:829) bazel build -c opt --config=cpu offboard/playback:playback_client InputFetchStage继承SuperscalarPipelineStage，创建新线程InputFetcher，去获取相关的信息\nInputFetcher拿到要使用的文件，下载到本地。该过程在workercontext.createExecDir调用execFileSystem的同名函数，会批量创建fetchedFutures拿取文件，这里要理解fetchInputs阶段如何创建fetchedFutures\nfetchInputs遍历每个目录里面的文件并且下载到本地，这里要注意，运行到的东西实际上是已经存储到了CAS中。其调用Directory(见admin/main/src/main/resources/proto/remote_execution.proto)里面的FileNode files field字段，然后对每个FileNode使用src/main/java/build/buildfarm/worker/shard/CFCExecFileSystem.java里面的put函数，简单来说就是调用fileCache来获取文件，真正的执行者是（src/main/java/build/buildfarm/server/services/FetchService.java）FetchService\nPutOperationStage包含InterruptingConsumer onPut结构，InterruptingConsumer是一个范型。每次往这个stage放OperationContext，就是往onPut里面放operation。\nReportResultStage继承自PipelineStage，它包含一个BlockingQueue，这个queue里面放的是OperationContext。这个stage只有一个workerContext，这个stage的tick函数里，workerContext会resumePoller，然后会尝试调用reportPolled。reportPolled函数，先构造一个resultBuilder，然后调用唯一的workerContext.uploadOutputs，并且保存执行完的action，然后构造一个completedOperation，//待确定，执行完后会调用after函数去摧毁execdir，因此实际上大量hardlink重复到一个node上的情况理论上不会特别高的概率出现。\nExecuteActionStage继承SuperscalarPipelineStage，它的iterate函数，覆盖了默认的iterate函数，对每个context，新建一个executor和executorThread，每个thread都会加到保存的executors里面。然后启动每个线程，开始执行。所以实际上启动的线程数量是无限的吗？这里肯定有什么我漏了的\nexecutor是个runnable，它的核心是runInterruptible:获取operation的metadata，更新为处于正在执行的stage。然后尝试更新operation，更新成功以后调用workerContext.resumePoller，然后调用executePolled workerContext.resumePoller，因为我们的buildfarm是shardinstace，所以关注ShardWorkerContext：传进来的poller.resume调用operationPoller.poll，就是backplane::pollOperation.poll；简单来说，就是传进来的poller.resume会然后创建新的ActivePoller，在超时的时候调用operationPoller.poll，就是backplane::pollOperation.poll。这时候还没有开始执行呢，只是把东西都启动了拿回来\nActivePoller，超时后调用onExpiration. executePolled，真正关心的东西，执行command，remote execute就是在这里做的操作，换言之build/test都是在这里做的。先把io资源相关的东西搞出来，然后调用executeCommand\nexecuteCommand函数 这几个说完了，说点其他的，我们看inputfetch stage似乎只是获取operation，没有拿到具体的data，那么数据从哪里来呢？\nBuildFarm Worker负责执行执行test，保存本地的cache，插入blob，我们先看构造函数。\n#src/main/java/build/buildfarm/worker/shard/Worker.java public Worker(String session, ServerBuilder\u0026lt;?\u0026gt; serverBuilder, ShardWorkerConfig config) throws ConfigurationException { //step 1 先设置一些基本配置，获取些cas容量和remote executive的设置，然后指定worker的名字,启动backplane，创建workerstub，用来通信,代码省略 //step 2 创建removeDirectoryService，accessRecorder,remoteInputStreamFactory,cas和execfs。这里有一点要注意，就是 ExecutorService removeDirectoryService =; ExecutorService accessRecorder = newSingleThreadExecutor(); InputStreamFactory remoteInputStreamFactory =...; //removeDirectoryService参与到了ContentAddressableStorage \u0026amp; execFileSystem的创建，或者说实际上就是具体执行操作的线程池 //让我们具体到上面几个什么ContentAddressableStorage/execFileSystem看看这个removeDirectoryService都干了些什么操作 ContentAddressableStorage storage = createStorages(remoteInputStreamFactory, removeDirectoryService, accessRecorder, config.getCasList()); { //我们是filesystem类型的cas，经过两轮调用,创建casfilecache。removeDirectoryService对应代码里面的expireService，用来做删除的 ShardCASFileCache(....,removeDirectoryService,accessRecorder...); { //shardcasfilecache是casfilecache内部的代码 //情况1 实际就是本地文件没有，要重新生成，这个时候发现路径或者entry重复了，就需要删除文件会用 newTransparentInput/newInput{ newLocalInput { dischargeEntry(entry, expireService); } } //情况2 有新的输出文件或内容产生，要放到本地就会被调用 putImpl { putOrReference { putOrReferenceGuarded { charge{ //内部调用expireService，或者说就是我们的removeDirectoryService } } } } } } execFileSystem = createExecFileSystem(remoteInputStreamFactory, removeDirectoryService, accessRecorder, storage);{ //因为是casfilecache，所以创建对应的execfilesystem createCFCExecFileSystem(removeDirectoryService, accessRecorder, cfc, owner) { CFCExecFileSystem(..., removeDirectoryService, accessRecorder ) { //继续看哪里用了removeDirectoryService，将removeDirectoryService作为参数传递到filecache，就是上面的storage里面 ImmutableList.Builder\u0026lt;Digest\u0026gt; blobDigests = ImmutableList.builder(); fileCache.start( digest -\u0026gt; { synchronized (blobDigests) { blobDigests.add(digest); } }, removeDirectoryService, skipLoad); } } } instance = new ShardWorkerInstance(config.getPublicName(), digestUtil, backplane, storage); // step 3 Create the appropriate writer for the context，并创建对应的pipeline，就是说我们的worker需要能执行操作，所以需要buildfarm worker提供 CasWriter writer; ShardWorkerContext context =...; //ShardWorkerContext是执行，汇报，获取中的核心 pipeline = new Pipeline(); //pipeline有四个pipeline stage：matchStage；inputFetchStage；executeActionStage；reportResultStage //step 4， 最终创建server，开始提供服务。本身buildfarm worker实际上也是个服务器 server = createServer(serverBuilder, storage, instance, pipeline, context); { PipelineStage completeStage ===\u0026gt; PipelineStage errorStage PipelineStage reportResultStage PipelineStage executeActionStage } //pipelinestage实际上是可执行的程序， } public static void main(String[] args) { ==\u0026gt; startWorker(args) { worker.start() { backplane.start(config.getPublicName()); //启动backplane execFileSystem.start((digests) -\u0026gt; addBlobsLocation(digests, config.getPublicName()), skipLoad); //execfs启动 } worker.blockUntilShutdown(); //和worker.start同级 } } pipelinestage 部分结构的伪代码，主要关注核心\nPipelineStage\nrunInterruptible { while(活着) { iterate { take operationContext; tick(operationContext) 来获取结果 } } } SuperscalarPipelineStage 继承PipelineStage，结构没有大的不一样。但是它会自己创建PipelineStage error，用来处理出错的operationContext。唯一不同点是它的take是takeOrDrain，没10ms就take一次，不为空返回。但是如果interrupted，那么就会丢exception来终止自己\n\u0026#34;ForkJoinPool-1-worker-141\u0026#34; #663238 daemon prio=5 os_prio=0 cpu=102165.90ms elapsed=33159.90s tid=0x00007f6fe4003800 nid=0x1be14a runnable [0x00007f73652d8000] java.lang.Thread.State: RUNNABLE at sun.nio.fs.UnixNativeDispatcher.link0(java.base@11.0.15/Native Method) at sun.nio.fs.UnixNativeDispatcher.link(java.base@11.0.15/UnixNativeDispatcher.java:141) at sun.nio.fs.UnixFileSystemProvider.createLink(java.base@11.0.15/UnixFileSystemProvider.java:479) at java.nio.file.Files.createLink(java.base@11.0.15/Files.java:1102) at build.buildfarm.worker.shard.CFCExecFileSystem.lambda$put$3(CFCExecFileSystem.java:202) at build.buildfarm.worker.shard.CFCExecFileSystem$$Lambda$298/0x00000008403c3840.apply(Unknown Source) at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:213) at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:202) at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:118) at java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(java.base@11.0.15/ForkJoinTask.java:1426) at java.util.concurrent.ForkJoinTask.doExec(java.base@11.0.15/ForkJoinTask.java:290) at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(java.base@11.0.15/ForkJoinPool.java:1020) at java.util.concurrent.ForkJoinPool.scan(java.base@11.0.15/ForkJoinPool.java:1656) at java.util.concurrent.ForkJoinPool.runWorker(java.base@11.0.15/ForkJoinPool.java:1594) at java.util.concurrent.ForkJoinWorkerThread.run(java.base@11.0.15/ForkJoinWorkerThread.java:183) 另外一个fetchinputstage的栈\n\u0026#34;Thread-687829\u0026#34; #698760 prio=5 os_prio=0 cpu=7.20ms elapsed=0.02s tid=0x00007f75e86b2800 nid=0x1d2adf runnable [0x00007f718b2f0000] java.lang.Thread.State: RUNNABLE at com.google.protobuf.Utf8.decodeUtf8(Utf8.java:340) at com.google.protobuf.CodedInputStream$StreamDecoder.readStringRequireUtf8(CodedInputStream.java:2299) at build.bazel.remote.execution.v2.Digest.\u0026lt;init\u0026gt;(Digest.java:82) at build.bazel.remote.execution.v2.Digest.\u0026lt;init\u0026gt;(Digest.java:38) at build.bazel.remote.execution.v2.Digest$1.parsePartialFrom(Digest.java:712) at build.bazel.remote.execution.v2.Digest$1.parsePartialFrom(Digest.java:706) at com.google.protobuf.CodedInputStream$StreamDecoder.readMessage(CodedInputStream.java:2367) at build.bazel.remote.execution.v2.FileNode.\u0026lt;init\u0026gt;(FileNode.java:67) at build.bazel.remote.execution.v2.FileNode.\u0026lt;init\u0026gt;(FileNode.java:13) at build.bazel.remote.execution.v2.FileNode$1.parsePartialFrom(FileNode.java:1079) at build.bazel.remote.execution.v2.FileNode$1.parsePartialFrom(FileNode.java:1073) at com.google.protobuf.CodedInputStream$StreamDecoder.readMessage(CodedInputStream.java:2367) at build.bazel.remote.execution.v2.Directory.\u0026lt;init\u0026gt;(Directory.java:134) at build.bazel.remote.execution.v2.Directory.\u0026lt;init\u0026gt;(Directory.java:82) at build.bazel.remote.execution.v2.Directory$1.parsePartialFrom(Directory.java:2057) at build.bazel.remote.execution.v2.Directory$1.parsePartialFrom(Directory.java:2051) at build.bazel.remote.execution.v2.Directory$Builder.mergeFrom(Directory.java:957) at build.bazel.remote.execution.v2.Directory$Builder.mergeFrom(Directory.java:690) at com.google.protobuf.CodedInputStream$StreamDecoder.readMessage(CodedInputStream.java:2351) at com.google.protobuf.MapEntryLite.parseField(MapEntryLite.java:128) at com.google.protobuf.MapEntryLite.parseEntry(MapEntryLite.java:184) at com.google.protobuf.MapEntry.\u0026lt;init\u0026gt;(MapEntry.java:107) at com.google.protobuf.MapEntry.\u0026lt;init\u0026gt;(MapEntry.java:50) at com.google.protobuf.MapEntry$Metadata$1.parsePartialFrom(MapEntry.java:71) at com.google.protobuf.MapEntry$Metadata$1.parsePartialFrom(MapEntry.java:65) at com.google.protobuf.CodedInputStream$StreamDecoder.readMessage(CodedInputStream.java:2367) at build.buildfarm.v1test.Tree.\u0026lt;init\u0026gt;(Tree.java:79) at build.buildfarm.v1test.Tree.\u0026lt;init\u0026gt;(Tree.java:16) at build.buildfarm.v1test.Tree$1.parsePartialFrom(Tree.java:936) at build.buildfarm.v1test.Tree$1.parsePartialFrom(Tree.java:930) at com.google.protobuf.CodedInputStream$StreamDecoder.readMessage(CodedInputStream.java:2367) at build.buildfarm.v1test.QueuedOperation.\u0026lt;init\u0026gt;(QueuedOperation.java:95) at build.buildfarm.v1test.QueuedOperation.\u0026lt;init\u0026gt;(QueuedOperation.java:9) at build.buildfarm.v1test.QueuedOperation$1.parsePartialFrom(QueuedOperation.java:1152) at build.buildfarm.v1test.QueuedOperation$1.parsePartialFrom(QueuedOperation.java:1146) at com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:100) at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:120) at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:125) at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48) at build.buildfarm.v1test.QueuedOperation.parseFrom(QueuedOperation.java:371) at build.buildfarm.common.ProtoUtils.parseQueuedOperation(ProtoUtils.java:47) at build.buildfarm.worker.shard.ShardWorkerContext.getQueuedOperation(ShardWorkerContext.java:272) at build.buildfarm.worker.InputFetcher.fetchPolled(InputFetcher.java:178) at build.buildfarm.worker.InputFetcher.runInterruptibly(InputFetcher.java:101) at build.buildfarm.worker.InputFetcher.run(InputFetcher.java:288) at java.lang.Thread.run(java.base@11.0.15/Thread.java:829) 关于\nBUILDFARM的奇怪问题 # 1 BUILDFARM上传模型失败 # 这个问题实际上困扰我们已经很久了，我们的buildfarm worker有时候离线了，需要重新触发blob上传就会报这个错误。只不过一直没找到稳定复现的机会，因为buildfarm-worker也不是一直出问题。。。这两天上传有仿真同事一直说bazel test出错，开始正式追踪，错误信息贴在了下面\n(06:17:44) [13,512 / 13,544] 337 / 3997 tests; Testing //onboard/planner/speed:speed_optimizer_test; 37s remote ... (30 actions, 0 running) (06:18:14) [13,512 / 13,544] 337 / 3997 tests; Testing //onboard/planner/speed:speed_optimizer_test; 67s remote ... (30 actions, 0 running) (06:18:25) ERROR: /builds/MSfUsJda/15/root/qcraft/onboard/planner/initializer/geometry/BUILD:158:8: Testing //onboard/planner/initializer/geometry:geometry_form_builder_test failed: (Exit 34): Error while uploading artifact with digest \u0026#39;c7a5774bd97a9bee99d19dcfa8a7f5d6216dbe7ec842c1719d1ec9121ea732b3/684019619\u0026#39; com.google.devtools.build.lib.remote.BulkTransferException: Error while uploading artifact with digest \u0026#39;c7a5774bd97a9bee99d19dcfa8a7f5d6216dbe7ec842c1719d1ec9121ea732b3/684019619\u0026#39; ... at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) ... 3 more Caused by: io.grpc.StatusRuntimeException: UNKNOWN: HTTP status code 413 invalid content-type: text/html headers: Metadata(:status=413,date=Wed, 01 Jun 2022 06:18:25 GMT,content-type=text/html,content-length=176,strict-transport-security=max-age=15724800; includeSubDomains,access-control-allow-origin=*,access-control-allow-credentials=true) DATA----------------------------- \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;413 Request Entity Too Large\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;413 Request Entity Too Large\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; at io.grpc.Status.asRuntimeException(Status.java:524) at com.google.devtools.build.lib.remote.ByteStreamUploader$AsyncUpload$1.onClose(ByteStreamUploader.java:551) ... 13 more 我们的架构是一个ack-ingress在前面整个代理。后面是buildfarm-server\u0026amp; buildfarm-worker。我开始介入debug，然后发现很奇怪的现象是buildfarm-server端没出错的信息，也没有什么日志记录这个bolb，然后开始怀疑是不是中间的ack-ingress的问题。然后去查ingress的日志看到这种日志\n2022/06/01 13:40:49 [error] 18994#18994: *1457627908 client intended to send too large chunked body: 20972665 bytes while sending request to upstream, client: 172.20.1.18, server: buildfarm-all.qcraftai.com, request: \u0026#34;POST /google.bytestream.ByteStream/Write HTTP/2.0\u0026#34;, upstream: \u0026#34;grpc://10.150.1.56:8980\u0026#34;, host: \u0026#34;buildfarm-all.qcraftai.com:443\u0026#34; 感觉不对劲，查配置发现对应ingress里面的proxy-body-size这个有点不对，才8m。而我们用户的模型动不动就600多m，改成了1024重试，成功了。。。\n2 BUILDFARM WORKER STUCK # 相比较第一个问题，第二个问题更令人无奈一些。我们的buildfarm worker有的时候会卡住，使用jstack观察打印出来的栈。会发现所有的remove-directory-pool的线程都会卡在parking to wait for \u0026lt;0x00000000934039d0\u0026gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)，其它的forkjonpool也会卡住：parking to wait for \u0026lt;0x00000000957aed30\u0026gt; (a java.util.concurrent.ForkJoinPool)，然后buildfarm会启动一大堆其它的thread，然后每个都在等，最后buildfarm的线程数量会超过1000个，而且这个worker就会进入无法相应的状态，也就是说，server会不断往这个worker发任务，但是一直无法完成，最终block到用户的编译任务。\nSettableFuture is waiting for executor? \u0026#34;grpc-default-executor-7\u0026#34; #418 daemon prio=5 os_prio=0 cpu=8.65ms elapsed=182086.43s allocated=1427K defined_classes=0 tid=0x00007f662c04f800 nid=0x257 waiting on condition [0x00007f61a70f3000] java.lang.Thread.State: WAITING (parking) at jdk.internal.misc.Unsafe.park(java.base@11.0.15/Native Method) - parking to wait for \u0026lt;0x000000010598b288\u0026gt; (a com.google.common.util.concurrent.SettableFuture) at java.util.concurrent.locks.LockSupport.park(java.base@11.0.15/LockSupport.java:194) at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:537) at com.google.common.util.concurrent.AbstractFuture$TrustedFuture.get(AbstractFuture.java:104) at build.buildfarm.cas.cfc.CASFileCache$3.getOutput(CASFileCache.java:855) - locked \u0026lt;0x00000001059897b8\u0026gt; (a build.buildfarm.cas.cfc.CASFileCache$3) at build.buildfarm.server.WriteStreamObserver.getOutput(WriteStreamObserver.java:414) at build.buildfarm.server.WriteStreamObserver.getCommittedSizeForWrite(WriteStreamObserver.java:288) at build.buildfarm.server.WriteStreamObserver.handleWrite(WriteStreamObserver.java:297) at build.buildfarm.server.WriteStreamObserver.handleRequest(WriteStreamObserver.java:282) at build.buildfarm.server.WriteStreamObserver.initialize(WriteStreamObserver.java:228) at build.buildfarm.server.WriteStreamObserver.onUncommittedNext(WriteStreamObserver.java:115) at build.buildfarm.server.WriteStreamObserver.onNext(WriteStreamObserver.java:95) - locked \u0026lt;0x0000000091795828\u0026gt; (a build.buildfarm.server.WriteStreamObserver) at build.buildfarm.server.WriteStreamObserver.onNext(WriteStreamObserver.java:53) at io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:255) at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309) at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292) at io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:765) at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@11.0.15/ThreadPoolExecutor.java:1128) at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@11.0.15/ThreadPoolExecutor.java:628) at java.lang.Thread.run(java.base@11.0.15/Thread.java:829) 目前发现的部分现象，上面实际上针对worker的分析已经有了部分分析，我们清楚：\nhandleWrite执行写入cas的操作，然而这个时候还没真的执行写入，只是调用getCommittedSizeForWrite获取commitsize，执行的代码是WriteStreamObserver.getOutput，它实际上是在等一个write.getOutput()，一个阻塞的操作。 而write.ouput函数实际上是拿到FeedbackOutputStream，顾名思义，有回馈的outputstream，调用write.getOutput来获取FeedbackOutputStream（这东西实际上是用来做反馈的。。。），这个地方可能有个小坑，这个write的实现在src/main/java/build/buildfarm/cas/cfc/CASFileCache.java里面，Write newWrite(BlobWriteKey key, ListenableFuture future)这个函数。 这个时候虽然没有执行真正的写入，但是必然已经调用过getOutput，否则closedFuture == null，因此已经调用commitOpenState初始化了closedfuture，（第一次调用的时候使用createUniqueWriteOutput创建uniqueOut）这一步还只是 @GuardedBy(\u0026#34;this\u0026#34;) private void initialize(WriteRequest request) { String resourceName = request.getResourceName(); if (resourceName.isEmpty()) { errorResponse(INVALID_ARGUMENT.withDescription(\u0026#34;resource_name is empty\u0026#34;).asException()); } else { name = resourceName; try { write = getWrite(resourceName); // \u0026lt;===== we need to check this out logger.log( Level.FINER, format( \u0026#34;registering callback for %s: committed_size = %d (transient), complete = %s\u0026#34;, resourceName, write.getCommittedSize(), write.isComplete())); Futures.addCallback( write.getFuture(), new FutureCallback\u0026lt;Long\u0026gt;() { @Override public void onSuccess(Long committedSize) { commit(committedSize); } @SuppressWarnings(\u0026#34;NullableProblems\u0026#34;) @Override public void onFailure(Throwable t) { errorResponse(t); } }, withCancellation.fixedContextExecutor(directExecutor())); if (!write.isComplete()) { initialized = true; handleRequest(request); } } catch (EntryLimitException e) { errorResponse(e); } catch (Exception e) { if (errorResponse(Status.fromThrowable(e).asException())) { logWriteRequest(request, e); } } } } 下面的代码是伪代码，我删去了一些无用的东西。所以实际上最后Write就是blobWrites.get(key, () -\u0026gt; newWrite(key))，Cache的get方法有两个参数，第一个参数是要从Cache中获取记录的key，第二个记录是一个Callable对象。当缓存中已经存在key对应的记录时，get方法直接返回key对应的记录。如果缓存中不包含key对应的记录，Guava会启动一个线程执行Callable对象中的call方法，call方法的返回值会作为key对应的值被存储到缓存中，并且被get方法返回。所以这里会先造一个Write出来。\nprivate Write getWrite(String resourceName){ switch (detectResourceOperation(resourceName)) { case UploadBlob: return ByteStreamService.getUploadBlobWrite(instance, uploadBlobDigest, parseUploadBlobUUID(resourceName)); { instance.getBlobWrite { //我们是shardinstance，所以得找shardinstace对应的代码 writes.get(digest, uuid, requestMetadata); { blobWrites.get(key, () -\u0026gt; newWrite(key)) { //blobWrites是Cache\u0026lt;BlobWriteKey, Write\u0026gt; Write newWrite(BlobWriteKey key, ListenableFuture\u0026lt;Long\u0026gt; future) //CASFileCache.java:761，所以调用的时候getoutput也是直接在casfilecache里面。这一圈实际上绕的有点晕。。。 } } } } case OperationStream: return ByteStreamService.getOperationStreamWrite(instance, resourceName); { instance.getOperationStreamWrite(resourceName) { } } case Blob: default: throw INVALID_ARGUMENT .withDescription(\u0026#34;unknown resource operation for \u0026#34; + resourceName) .asRuntimeException(); } } 3 BUILD 任务很慢 # 这两天日常CI维护，我在盯CI任务的时候，发现有些用户的编译任务比较慢，开始排查怎么回事。参考文档https://bazel.build/rules/performance#performance-profiling\n随便找了两个profile的文件，然后用chrome://tracing打开，第一张是编译很快，第二章是编译比较慢。能够非常明显的看出来有大量的queue操作，查看buildfarm的execute_slot_usage会发现60c用满了，可能是负载的问题，ok，用analysis-profile来分析下\n相比较而言，execution phase time的时间明显增长，符合我们观察到的信息，那么大概率是buildfarm的负载太重了，那么有没有可能是io，cpu，文件系统遇到了瓶颈呢？\n[qcraft@qcraft-dev-qcraft:/hosthome/Downloads] $ bazel analyze-profile fast-build-213465-6957259.profile.gz WARNING: Invoking Bazel in batch mode since it is not invoked from within a workspace (below a directory having a WORKSPACE file). WARNING: This information is intended for consumption by Bazel developers only, and may change at any time. Script against it at your own risk INFO: Profile created on Thu Jul 21 11:46:06 UTC 2022, build ID: d37327ed-2404-4c26-b9d8-a065086d3a24, output base: /home/qcrafter/.cache/bazel/_bazel_qcrafter/de91dfe5bfd7ed036386d41fdb745489 === PHASE SUMMARY INFORMATION === Total launch phase time 3.499 s 1.57% Total init phase time 7.940 s 3.57% Total target pattern evaluation phase time 2.357 s 1.06% Total interleaved loading-and-analysis phase time 62.404 s 28.08% Total preparation phase time 0.092 s 0.04% Total execution phase time 145.721 s 65.57% Total finish phase time 0.237 s 0.11% ------------------------------------------------ Total run time 222.252 s 100.00% ... [qcraft@qcraft-dev-qcraft:/hosthome/Downloads] $ bazel analyze-profile slow-build-213242-6943808.profile.gz WARNING: Invoking Bazel in batch mode since it is not invoked from within a workspace (below a directory having a WORKSPACE file). WARNING: This information is intended for consumption by Bazel developers only, and may change at any time. Script against it at your own risk INFO: Profile created on Thu Jul 21 08:20:06 UTC 2022, build ID: 1733eb6e-f3e0-42d9-a52c-5087c5dd93e0, output base: /home/qcrafter/.cache/bazel/_bazel_qcrafter/4cc6af9c7ea2a1930fc83c0b6578c460 === PHASE SUMMARY INFORMATION === Total launch phase time 2.158 s 0.03% Total init phase time 6.007 s 0.09% Total target pattern evaluation phase time 2.456 s 0.04% Total interleaved loading-and-analysis phase time 62.822 s 0.95% Total preparation phase time 0.127 s 0.00% Total execution phase time 6532.905 s 98.88% Total finish phase time 0.332 s 0.01% ------------------------------------------------ Total run time 6606.809 s 100.00% ... 4 BUILDFARM USE TWO SERVICE AT SAME TIME # 我们有两套buildfarm服务，每个都是三个server，六个worker，最近通过看metric:execulte_slog_usage发现buildfarm1的负载很重，需要启用两套环境，看了ingress和service都不太成，所以只能启用nginx来做负载均衡，然后发现nginx的ip_hash不起效果，我们内网环境，ip的前三个字段都是一致的，和这个链接https://stackoverflow.com/questions/69481839/nginx-ip-hash-balancing-method-not-working-as-expected 写的一样，就改成了。然后才生效\nupstream xxxxx { server A; server B; hash $remote_addr; #需要使用这种方法，而不是第二种方法，为什么呢 # hash $remote_addr consistent; } 然后发现了另外一个问题，我们起了一个nginxpod做ingress的反向代理，然后发现大量的buildfarm 任务都过它的时候，任务依然非常慢，也就是说即使bf2将文件和具体的operation(action)已经cache住了，依然很慢。然后我修改nginx的副本数量，调整到两位数，编译的时间再次回到了10min以内，编译时间才恢复正常。至于为什么还在排查中，现在暂时没确定原因。\n下面是改完了的效果，去除了启动失败的runner错误打断编译的情况，计算平均时间参考了\ntotal duration (s) / counts / 60 不启用nginx,2022-07-21 14:30:00-18:00:00 启用nginx,2022-07-27 14:30:00-18:00:00 g-build-presubmit-edge 106577.64329499999 / 65 / 60 = 27.3 108007.82199799998 / 84 / 60= 21.4 k8s-gpu-build-presubmit-edge 102611.17144700004 / 58 / 60 = 29.5 117250.97695900007 / 78 / 60 = 25 bazel-build-postsubmit: 41239.953479 / 16 / 60 = 43 30597.056951000002 / 19 / 60 = 26.9 gpu-bazel-build-postsubmit 48058.69408200001 / 17 / 60 = 47 31474.201981000002 / 19 / 60 = 27.6 5 BAZEL的内存占用 # 这两天在统计CI/CD的JOB占用的资源的情况，以更好地提升资源利用率，然后发现了一个很蛋疼的事情，就是我们启用了buildfarm之后的bazel cpu \u0026amp; gpu build任务吃掉了40～50G内存，导致了机器OOM，经过排查发现有两个地方可能是吃内存的大户：\nBAZEL的真实工作者JAVA进程，JVM吃掉了太多的内存，在\u0026ndash;jobs为30的情况下，明显的观察到吃掉了20多G的内存 pod内部的buff/cache吃掉了大量的内存，这并不奇怪，本来buff/cache在有读写文件的时候就会消耗很多内存 所以开始针对性地进行优化，尝试了多种手段：\n首先按照bazel的官方文档，启用--discard_analysis_cache, --notrack_incremental_state \u0026amp; --nokeep_state_after_build这三个编译选项，毕竟在CI上是不需要增量编译的。经过测试节省内存0～4GB，符合官方文档的\u0026quot;thus freeing up additional memory (around 10%) \u0026ldquo;，但是还是有点少，毕竟远程执行又不需要你本地做什么事情。 官方方法不好用，开始考虑JVM相关的优化，启用JVM参数：--host_jvm_args=\u0026quot;-XX:-TieredCompilation\u0026quot; --host_jvm_args=-Xmx2g --host_jvm_args=\u0026quot;-XX:+UseParallelGC\u0026quot;, ，内存有效削减10～20GB，通过让JAVA频繁触发GC，砍掉了一半的内存消耗 限制并发的\u0026ndash;jobs数量，从30减到20，又砍掉了3个GB。这并不奇怪，毕竟每个线程都要维护环境和一些符号，杯水车薪也不错 定时性的触发\u0026quot;echo 3 \u0026gt; /proc/sys/vm/drop_caches\u0026quot;来释放buff/cache的内存消耗，从而减少kernel的内存，这个砍掉了差不多10GB的内存 全用的话，pod稳定在8G，和同事讨论以后被教育第四个过于hack，job数量限制又可能导致运行过久，最后用了第一个和第二个，砍掉了0～25G\n6 BUILDFARM的代理优化 # 4 BUILDFARM USE TWO SERVICE AT SAME TIME里面说到了启用了nginx作为我们buildfarm的前面代理，当时提到了启用多个nginx才能使编译的速度加快，一个nginx pod作为代理，编译速度还是拖慢了，因此开始尝试nginx调节参数，加了\n# 自动调优 worker_processes auto; worker_cpu_affinity auto; events { worker_connections 4000; use epoll; # If multi_accept is disabled, a worker process will accept one new connection at a time. Otherwise, a worker process will accept all new connections at a time multi_accept on; # When buffering is enabled, nginx receives a response from the proxied server as soon as possible, saving it into the buffers set by the proxy_buffer_size and proxy_buffers directives. If the whole response does not fit into memory, a part of it can be saved to a temporary file on the disk. Writing to temporary files is controlled by the proxy_max_temp_file_size and proxy_temp_file_write_size directives. # proxy_buffering off; 这个实际上没启用 } http { server { # 调整server的backlog为65535，启用reuse port listen 80 reuseport backlog=65535 } } multi_accept这个选项令人怀疑nginx的关键点是因为我们的客户端和nginx就是多条连接，参考这个问题https://serverfault.com/questions/763597/why-is-multi-accept-off-as-default-in-nginx，怀疑可能是一个减慢了速度的点\nproxy_buffering关闭，是认为行为cache结果没必要，不如直接利用buildfarm本身cache的结果。\nserver 的backlog调大，每个pod的默认值为128，认为确实有点小，看nginx的ingress controller的/proc/sys/net/core/somaxconn默认是65535，那么给这些pod也调整成这么大试试。参考了这篇文章使用了如下的几条命令来使内核的somaxconn也调大\nsysctl -w net.core.somaxconn=65535 sysctl -w net.ipv4.ip_local_port_range=\u0026#34;1024 65535\u0026#34; # 实际上是busybox的优化用initcontainer initContainers: - command: - /bin/sh - \u0026#39;-c\u0026#39; - | mount -o remount rw /proc/sys sysctl -w net.core.somaxconn=65535 sysctl -w net.ipv4.ip_local_port_range=\u0026#34;1024 65535\u0026#34; sysctl -w kernel.core_uses_pid=0 image: \u0026#39;registry-vpc.cn-zhangjiakou.aliyuncs.com/acs/busybox:v1.29.2\u0026#39; imagePullPolicy: IfNotPresent name: init-sysctl resources: {} securityContext: capabilities: add: - SYS_ADMIN drop: - ALL terminationMessagePath: /dev/termination-log terminationMessagePolicy: File 重新启用后，一个cache住的bazel job耗时从12min压缩2min，嘿嘿\n7 SANDBOX的选择 # 这个问题是一个比较早的问题，今天在做一个编译的时候忽然需要在程序当中调用bazel，然后我们都清楚默认bazel是在sandbox里面跑命令，然后我有很多的外部文件/配置希望直接同步到沙盒内，而不是使用\n参考这个链接：https://github.com/bazelbuild/bazel/issues/14734\nThe local strategy does not do any kind of sandboxing. It simply executes the action\u0026#39;s command line with the working directory set to the execroot of your workspace. processwrapper-sandbox is a sandboxing strategy that does not require any \u0026#34;advanced\u0026#34; features - it should work on any POSIX system out of the box. It builds a sandbox directory consisting of symlinks that point to the original source files, executes the action\u0026#39;s command line with the working directory set to this directory instead of the execroot, then moves the known output artifacts out of the sandbox into the execroot and deletes the sandbox. This prevents the action from accidentally using any input files that are not declared and from littering the execroot with unknown output files. linux-sandbox goes one step further and builds on top of the processwrapper-sandbox. Similar to what Docker does under the hood, it uses Linux Namespaces (User, Mount, PID, Network and IPC namespaces) to isolate the action from the host: It makes the entire filesystem read-only except for the sandbox directory, so the action cannot accidentally modify anything on the host filesystem (imagine a buggy test accidentally rm -rf\u0026#39;ing your $HOME directory...). It optionally prevents the action from accessing the network. It uses PID namespaces to prevent the action from seeing any other processes and to reliably kill all processes (even daemons spawned by the action) at the end. darwin-sandbox is similar, but for macOS. It uses Apple\u0026#39;s sandbox-exec tool to achieve roughly the same as the Linux sandbox. Both the linux-sandbox and the darwin-sandbox do not work in a \u0026#34;nested\u0026#34; scenario due to restrictions in the mechanisms provided by the operating systems: Because Docker also uses Linux namespaces for its container magic, you cannot easily run linux-sandbox inside a Docker container. (Only if you use docker run --privileged.) On macOS, you cannot run sandbox-exec inside a process that\u0026#39;s already being sandboxed. Thus, in these cases, Bazel automatically falls back to using processwrapper-sandbox. You can prevent this, if you would rather get a build error (e.g. to not accidentally build with a less strict execution strategy) by modifying the list of execution strategies explicitly that Bazel tries to use e.g. bazel build --spawn_strategy=worker,linux-sandbox. 8 BUILDFARM STUCK 2.0 # 表现的现象为所有的worker都处于stuck状态，每一个worker实际上都堆积了大量的任务，但是每一个实际上都没在跑，反而是卡着等一个操作。\n9 BUILDFARM ENTRY SIZE # 这几天测试新版本buildfarm在不断报错下面的内容，简单看了一下，实际上增大maxSizeBytes \u0026amp; maxEntrySizeBytes即可\n[qcraft@qcraft-dev-qcraft:/qcraft(vgdog/ci_update_buildfarm) ] $ bazel build -c opt --remote_executor=grpc://172.20.4.22:80 --remote_cache= -- //... -release/... INFO: Invocation ID: 30d10363-0edd-4a9a-a635-cbe790e20ddf INFO: Analyzed 15398 targets (0 packages loaded, 0 targets configured). INFO: Found 15398 targets... ERROR: /qcraft/cyber_modules/control/proto/BUILD:85:17: ProtocInvocation cyber_modules/control/proto/input_debug_pb2.py failed: (Exit 34): Remote Execution Failure: Failed Precondition: Action 85b4743e429e556bb6bfd4a88a07fb51e6473f8043723585cb6994648e3eec71/144 is invalid: A requested input (or the `Action` or its `Command`) was not found in the CAS.; A requested input (or the `Action` or its `Command`) was not found in the CAS.; A requested input (or the `Action` or its `Command`) was not found in the CAS. ... Precondition Failure: (MISSING) blobs/75f2f6295961d267b8eda1c5b5c99886b095ef225583df5f24a8d9051d024a9c/4156240: A requested input (or the `Action` or its `Command`) was not found in the CAS. (MISSING) blobs/38ecdb1c94e269e483acd31ee39aefe37f465015ddcdb7f53af2031fb99767d9/2121: A requested input (or the `Action` or its `Command`) was not found in the CAS. (MISSING) blobs/a6b3ad56297d3e759b63516a51d6057f2a7eb6fe8b72cbce3e0e587b62792cf0/878: A requested input (or the `Action` or its `Command`) was not found in the CAS. (MISSING) blobs/a837495ba065847bf3be22a07f9b8a43d31388a690df3766dce6fa76b8b36655/428: A requested input (or the `Action` or its `Command`) was not found in the CAS. 10 BAZEL ANALYSIS 阶段大量时间消耗 # 从profile来看主要是alibaba cloud sdk很慢，\n其中_go_repository_impl花费大量时间。\n利用背景知识，参考：\nhttps://sluongng.hashnode.dev/bazel-caching-explained-pt-3-repository-cache https://bazel.build/docs/external#offline-builds https://cs.opensource.google/bazel/bazel/+/refs/tags/5.2.0:src/main/java/com/google/devtools/build/lib/bazel/repository/downloader/DownloadManager.java java的downloadmanager代码 https://github.com/bazelbuild/bazel-gazelle/blob/master/internal/go_repository.bzl:112 go_repo的代码， 可知，第三方的cache，只有采用了 ctx.download or ctx.download_and_extract 才会往distdir/repo cache里面去找cache的结果，\n仔细检查go_repository的代码，实际上也能发现使用的是vcs方式管理的代码，因此往output base里面放这个external的cloud go sdk，花费大量时间，走的是go mod download。因此最简单的解决方法实际上就是修改为urls。\n解决了go_repo的问题之后，又有新的问题出现，即http_archive的对象每次都在fetching，花费大量时间，这个本身应该是cache到repo cache里面的，有一种加速的方法是存储到distdir里面，但是bazle没有提供直接存取到distdir的方法，有一种间接获取的方法：\nbazel sync --experimental_repository_resolved_file=resolved.bzl 会把下面结构的属性，拽出来\n\u0026#34;repositories\u0026#34;: [ { \u0026#34;rule_class\u0026#34;: \u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl%http_archive\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;urls\u0026#34;: [ \u0026#34;https://github.com/embree/embree/archive/v2.16.5.zip\u0026#34; ], \u0026#34;sha256\u0026#34;: \u0026#34;9c4c0c385a7725946648578c1b58e887caa8b4a675a9356e76b9501d9e2e9e42\u0026#34;, \u0026#34;netrc\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;auth_patterns\u0026#34;: {}, \u0026#34;canonical_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;strip_prefix\u0026#34;: \u0026#34;embree-2.16.5\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;patches\u0026#34;: [], \u0026#34;patch_tool\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;patch_args\u0026#34;: [ \u0026#34;-p0\u0026#34; ], \u0026#34;patch_cmds\u0026#34;: [], \u0026#34;patch_cmds_win\u0026#34;: [], \u0026#34;build_file\u0026#34;: \u0026#34;//ThirdParty:embree.BUILD\u0026#34;, \u0026#34;build_file_content\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;workspace_file_content\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;embree\u0026#34; }, \u0026#34;output_tree_hash\u0026#34;: \u0026#34;b96d3a8db2ddd4bbc7ccde297a1d12e8be48c768bddde1ade53a4987861a1fe7\u0026#34; } ] 11 buildfarm的shm # 我们的buildfarm运行在k8s的pod里面，这辆遇到一个问题，buildfarm是远程执行，因此任何本地\n12 buildfarm的cache瓶颈 # 这个问题严格来讲也不是buildfarm的问题，我们的ci除了启动buildfarm来做远程执行之外，还使用了一些固定的cache目录来加速编译，金丹来说就是用了一块nas来做distdir和repository_cache，这几天分析profile文件，发现bazel的analysis stage依然花费了大量的时间去load external package，一开始我怀疑是distdir目录里面http_archive外部库没生效，我修改http_archive的urls为错误的url，然后打开distdir，发现能够编译成功，证明distdir确实是生效的，然后问题就变成了，为什么有了cache还是这么慢。。。\n查了下我们作为cache的nas，发现吞吐带宽吃满了。。。。\nDevsecops bazel # 两个方面，一方面是在开发阶段另一个是在运维阶段，开发阶段可以使用sast来进行分析，除了sast静态代码扫描，也可以使用动态污点分析。另一方面对于常见的漏洞要有分析的手段。\nDTA PARTS # 三个步骤：\n定义污点源，taint source，污点源是指选择追踪的数据所在的程序的位置，系统调用，函数入口或者单挑指令都可作为污点源 定义污点槽，taint sink，污点槽是指进行检查的程序位置，以确定这些位置是否会收到污点数据的影响 追踪污点传播，taint propagation，插桩所有的处理数据的指令来追踪程序中的污点数据流 程序内存布局，指的是从上到下的东西\n函数后面加const的作用\nstatic\n常量指针和指针常量\n集成派生的作用\n","date":"2021 年 11 月 20 日","externalUrl":null,"permalink":"/posts/2021-11-20-bazel%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B/","section":"Posts","summary":"","title":"bazel学习实例","type":"posts"},{"content":" 一些网页内容的摘抄 # 在公司做了三年总经理，到了该走的时候了，写下一些心得，后面再来看。 # 链接为https://www.hi-pda.com/forum/viewthread.php?tid=2773488\u0026amp;extra=page%3D1\u0026amp;page=1\n1、你可能因为生活的要求、现实的无奈选择了一份工作，没法遵从你的本心，但是你不要忘记它，你总是有一点点机会的。 2、成功过的老板想再成功的可能性，比你成功的可能性要低。 3、如果这个老板能再成功，那是因为他觉得他现在还没成功。 4、如果你学过系统的管理，你在老板的身边通常学不到什么，但是可以锻炼心智。 5、老板很容易犯“把大象装进冰箱的四步”的错误，把宏观战略当成手段。你落实具体工作，如果太慢，他就会认为你在拖时间。不要老实干，要会“叫”。 6、“马上开干”通常是无谋的表现。 7、企业有没有前景主要在于能不能“寻求合作、建立壁垒”。如果你的企业各方面非常强势，那么他不会有跨越式的发展；如果你的企业一直干份内的基础工作，比如一直干销售，通常它也没有什么前景。 8、每年股东都完全分红的企业，不会是好企业。 9、如果大股东/老板，能够压倒性地决策，那么其他股东跟他的关系一定是从属关系，并且他们的利益相对来说是对立的。 10、如果你能力突出升职了，在较短的时间内你得谈待遇，别跟老板交朋友，也不需要他表示认同，因为事情认同你了。 11、你想实现的目标尽量要跟老板的利益统一。如果无法统一，这个平衡点很难找得到，尽早离开。其实这是一句老话“办事不由东，累死也无功。” 12、大多数民营老板，让他选择利润率15%的模式和50%的模式，他会选他喜欢的那个，或者是能理解的那个。 13、大多数民营老板，总结不出来他成功的原因，所以他认为他偶然成功的因素占主导，并且沾沾自喜，或者迷信。 14、大多数民营老板，不会去参加科学管理相关的培训，他们会去参加一些私董会和洗脑式的管理成功学，一般结交不到什么资源，主要是寻求“认同”。 15、你可以尝试去理解所有的员工，调动他们积极性，但是不用交什么朋友，因为你有目标，大多数基层员工只是来拿薪的。 16、一个能力强的中层，一般都多会一些人力资源的东西。 17、如果你老板觉得大型企业的“互联网化”都很艰难，但是他的“互联网化”程度还比较高，那是因为他还没入门。 18、下级要走，不要挽留，帮他找条路，人往高处走是很正常的，混吃等死也是很正常的。 19、如果一个企业说它是做“大健康”的，一定发展战略不清晰，因为“大健康”本身就不清晰。 20、健康相关的行业，壁垒都是相对比较高的，如果在做低端的事儿，说白了没有做“健康”。 21、未来十年，健康行业的机会应该很多，市场会非常好。 22、跟第7条相关，一个有基础的企业的二次创业，一定是在“技术”和“资本”上建立壁垒开始起步的，如果继续干销售、干电商，白手起家一样，还是早点选择其他的道路。 23、跟第5条相关，如果老板觉得你慢，你要尽力拆分工作任务，必须让下级尽可能加班，让老板满意，才能保障你组织结构的完善，大家的分工明确，都有饭吃。 24、大多数老板反智而追求信念，这也是他成功的因素，跟你的区别。 25、如果你是高管，停止学习问题不大，多思考你知道的，要重要得多。 26、在“金融”和“法务”上的基本理解，老板比你要少得多，而这两个不体现你的能力，体现你简单问题复杂化的缺点。 27、根据科学管理的成功研究，发展的机会是诞生于你的员工之中的，找到那个人做的事情，别望着你老板。 28、如果要大动组织结构，动作要快，在老板和员工都没明白之前签字并且搞完。 29、老板通过很多年的发展之后，逐渐就不懂业务了，但是你必须让他能刷存在感，要经常向他汇报工作，让他点评和给出意见。 30、规模小的企业，人事管理没那么重要，行政管理很重要，财务管理你要管，但是要让老板坐镇。 31、你没必要喝酒，让老板喝。坐得久了，腰和体重就会出问题，虽然你前几年看起来还是不错的。 32、存钱很重要，存多了理财就很重要，否则你想干事儿的时候，没有子弹。 33、战略目标是最最重要的，没有战略目标，人人都是行尸走肉。有目标的话，三千月薪大家也能咬紧牙关干过去。\n","date":"2021 年 11 月 9 日","externalUrl":null,"permalink":"/posts/2021-11-09-%E4%B8%80%E4%BA%9B%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9%E7%9A%84%E6%91%98%E6%8A%84/","section":"Posts","summary":"","title":"一些网页内容的摘抄","type":"posts"},{"content":" ci_cd相关学习 # 1 CI/CD使用原理相关 # 2 Bazel编译部署相关 # 2.1 part1 bazel入门 # 文章链接为：https://zhuanlan.zhihu.com/p/262171925\n为何需要自动构建系统？\n代码无需人工干涉即可构建、测试并发布生产 提交代码到code review的时候可以直接测试 底层库可以对整个代码库测试代码修改，确保修改是安全的 程序员可以进行大规模的代码修改 如果没有构建系统呢？可以想见华耀的时候：\n漫长的编译时间 不能单独编译并替换单个文件 没办法共享其它语言的模块和代码（比方说php和python） 大量的脚本文件，不断地修修补补 因此我们需要一个moder build system。\n但是我们需要解决哪些问题呢？\n如何解决脚本无法保证完成任务的问题？ 如何并发？避免出现记录文件的冲突 如何实现增量构建？ 维护和调试脚本的难度 为了解决这些问题，google（bazel）的解决方法是\n我们需要从程序员手里拿走一些能力，把这些能力交换到系统本身，并且重新定义系统角色不再是执行任务(running tasks)，而是生成制品(artifacts)。这就是Google对于Blaze和Bazel的做法，我们下面就会讲到。\n2.2 part2 了解bazel # 文章链接为：https://zhuanlan.zhihu.com/p/262497747\n与其让程序员自己定义任务，不如让系统定义一组任务，程序员受限的情况下进行配置。\n一个构建系统最重要的功能是去构建代码。程序员仍然需要告诉系统他们想去build什么东西，但是“如何构建“则是系统自己的事情。\n这就是Blaze以及其它基于artifact的构建系统（如Bazel, Pants, 及Buck）所采用的方案。和基于task任务的系统一样，我们仍然需要buildfile，但是这些buildfile的内容就很不一样了。相对于之前使用图灵完备的脚本语言来实现各种命令(an imperative set of commands)，以描述如何生成结果的方式，Blaze的buildfile是一种声明式的形式(declarative manifest)来描述一组制品(artifacts)如何去构建，他们的相互依赖，以及一组受限的选项来定义如何构建。当程序员运行blaze命令行时，他们会定义一组要构建的目标(what)，然后blaze负责配置、运行和调度编译步骤(how)。由于现在构建系统完全控制了运行时所用的工具，它才能确保运行期间的高效和正确。\n但是有个问题，即任务的定义还是来自程序员，只不过程序员只关心成品，还是有点迷惑bazel的\n2.2.1 走进Bazel # 先看一个bazel的语法：\njava_binary( name = \u0026#34;MyBinary\u0026#34;, srcs = [\u0026#34;MyBinary.java\u0026#34;], deps = [\u0026#34;:mylib\u0026#34;, ], ) java_library( name = \u0026#34;mylib\u0026#34;, srcs = [\u0026#34;MyLibrary.java\u0026#34;, \u0026#34;MyHelper.java\u0026#34;], visibility = [\u0026#34;//java/com/example/myproduct:__subpackages__\u0026#34;], deps = [ \u0026#34;//java/com/example/common\u0026#34;, \u0026#34;//java/com/example/myproduct/otherlib\u0026#34;, \u0026#34;@com_google_common_guava_guava//jar\u0026#34;, ], ) 在Bazel中，BUILD文件定义了targets。上面的两个targets分别是java_binary和java_library. 每个target都对应着bazel能够创建的一种artifact.\nbinary targets生成能够直接运行的二进制文件，library targets生成能够被其它binary或者library所使用的内容。每个target都有一个name（定义它在命令行和其它target中应该如何被引用)，srcs（定义必须被编译的相关源文件以生成对应的target制品），以及deps（定义前置必须先构建或链接的依赖）。\n依赖关系可以限制在当前package以内（e.g. MyBinary依赖于:mylib），也可以是在同一个源代码层级中的不同package(e.g. mylib依赖于//java/com/example/common)，或者源代码层级之外的第三方artifact(e.g. mylib依赖于\u0026quot;@com_google_common_grava_grava//jar\u0026quot;). 每个源代码层级(source hierarchy)都被称为一个workspace，并由根目录下的一个WORKSPACE文件来标示。\n2.2.2 其它bazel解决的问题和技巧 # 对工具的依赖（比方说开发authsdk时依赖boost \u0026amp; gcc的版本），解决方式是将工具当成依赖，即Tools as dependencies\n拓展构建系统，Bazel允许通过自定义规则(custom rules)来扩展所支持的target类型。要定义一个Bazel的rule，开发者首先要定义rule需要的input(以BUILD文件中传递的参数形式)和该rule所生成的output。开发者还要定义该rule所要生成的actions. 每个action同样也要声明input和output，运行一个特定可执行文件或在文件中写入特定字符串，并能够通过input/output连接到其它的action. 这也意味着在Bazel里面，action是最底层的可编辑单元(lowest-level composable unit)\u0026ndash;只要一个action只使用它所声明的input/output，它就能做任何它想做的事情，而Bazel则会负责对action进行规划安排并在合适的时候缓存其执行结果。\n环境隔离，使用沙盒来实现action后果的隔离\n可确定的外部依赖，更新一个依赖应该是一个有意识的行为，但这个行为应该由一个中心控制来一次完成，而不是由单独的程序员或者系统自动完成。这是因为我们希望构建本身是可确定的(deterministic)，这意味着如果你check out上周的一个commit，你应该看到所有的依赖都和上周时一样，而不会仍然是今天的版本。\nBazel和其它构建系统通过workspace范围内的清单(manifest)来处理这个问题，这个清单列出了所有外部依赖的加密hash值(cryptographic hash)。这个hash值是一个相当简洁的方式来唯一标示外部依赖文件，而无需将文件本身提交到source control. 只要workspace中有任何新的外部依赖被引用时，该依赖的hash值就会加入到清单中，有可能是自动的，也可能是手动。当Bazel执行一个构建的时候，它会去检查缓存中的依赖(dependency)的hash值，和清单中的hash值做比较，如果不同的话则再去重新下载。\n2.2.3 分布式构建 # 远程缓存，多个developer workstations，都共享一个指向公用缓存服务，bazel本身就支持保证共享artifact和其输入是相同的 远程执行， Google的分布式构建（Distributed Builds at Google） 时间、规模与取舍(Time, Scale, Trade-Offs) 2.2.4 处理模块与依赖 # 使用精调的模块和1:1:1规则(Using Fine-Grained Modules and the 1:1:1 Rule)，需要决定一个独立模块到底要包含多少功能。对于Bazel而言，一个“模块”则是用target来定义的一个可构建的单位，例如java_library或go_library. 最小化模块可见度(Minimizing Module Visibility) 内部依赖(INTERNAL DEPENDENCIES)，内部依赖主要是A=\u0026gt;B=\u0026gt;C，本来A包含B\u0026amp;C，但是某天B不在包含C那么，A就找不到C了，但这个问题并不是依赖本身的问题，是开发者对依赖脚本的编写导致的。因此最终Google在bazel中严格传递依赖模式：在这个模式中，Blaze如果监测到一个target试图引用一个没有直接依赖的符号(symbol)，就直接报错，同时提供一个脚本命令来直接插入该依赖。对Google内部推广这种形式并重构几百万个targets，让他们显式列出自己的依赖项是一个需要多年时间的投入，但是很值得。现在google的构建快了很多，因为不必要的依赖项都移除了，同时开发人员也不再担心会错误移除依赖项。 2.2.5 外部依赖 # 外部依赖，和内部依赖不同，外部依赖存在版本。因此外部依赖采用了三个规则：\nBazel要求所有依赖项都手动定义。即便在中等规模项目中，手工定义版本号所带来的额外工作，相对于所带来的稳定性而言也是非常值得的；\n不同的library版本通常用不同的artifacts来表示，所以理论上讲，一个构建系统中没有理由对一个相同的外部依赖采用不同版本。尽管如此，每个target实际上都能选择它自己想要的依赖项。Google则发现这会导致很多实践问题，所以我们强制了严格的单一版本规则(One-version rule)，要求所有内部代码库的第三方依赖都是用同样的版本。（实际上这个问题就可以解决当时遇见到的authsdk使用多个log4cplus问题：clogv2用了1.2.2的log4cplus，而我们用的默认log4cplus，冲突了，实际上我们是避免宝石状依赖）；\n使用外部依赖缓存构建结果\n外部依赖的安全性和可靠性，依赖第三方源的artifacts本质上是有风险的。例如存在可用性风险，如果第三方源因为某些原因挂掉，而你的整个构建就可能会因为无法下载外部依赖项而停止。这也可能有安全风险，如果第三方系统被人攻击，攻击者可能会把你用到的artifact用他们自己的东西替换，从而在你的构建中注入他们的代码。\n这两个问题都可以通过对artifacts做镜像来解决，这样你就可以控制并阻止你的系统访问第三方仓库如Maven Central. 然而代价就是需要投入时间和资源去维护镜像，所以是否采用这种方式取决于你的项目规模。安全问题也可以被解决，只需要要求每个第三方artifact都在代码仓库中定义它的hash值，这样如果artifact被污染，构建就会直接终止。\n另一个可选方案是把你项目的依赖项完全独立出去（原文有外包/出租的意思，vendor）。当一个项目独立之后，他会把这些依赖项和源代码一起check in到项目的source control中，用源代码或二进制都可以。这就以为和所有的外部依赖都变成了内部依赖。实际上，Google内部就采用了这种方式，把引用到的每个第三方库都提交到一个叫third_party的目录。然而，Google用这种方式也是因为Google自己的source control系统是设计来处理巨大的monorepo的形式，所以这种方式未必适合其它公司。\n2.3 part3 bazel简单demo # 原文链接为：https://zhuanlan.zhihu.com/p/263600968\n以https://github.com/bazelbuild/examples/ 为例，参照里面的文件为例子\n希望同时编译两个binary，两者不是同级的，两种解决方法：\n#一种是把第二个binary变为第一个binary的依赖，加入的src里面 #另一种是filegroup，或者deps里面，但是可能会导致默认的文件位置错误 3 gitlab的CI \u0026amp; CD # 关于环境相关：\n相关文档：\nhttps://zhuanlan.zhihu.com/p/105157319\n单元测试pipeline部分教学：https://nick-chen.medium.com/gitlab-ci-%E5%85%A5%E9%96%80%E7%AD%86%E8%A8%98-%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%AF%87-156455e2ad9f\ngitlab-pipeline：可以由一个或多个Stage 组成，即是一次CI/CD 的所有执行阶段，且会依序执行Stage。如果执行过程中只要有一个Job 错误了，预设后续的Stage 都会被略过（skip），一次pipeline其实相当于一次任务构建，里面可以包含多个流程，如安装依赖、运行测试、编译代码、部署测试服务器、部署生产服务器等。\ngitlab-stage：可以包含一个或多个Job，代表一个执行阶段，Stage表示一个构建阶段，我们可以在一个Pipeline中定义多个Stage，这些Stage会有以下特点：\ngitlab-job：是整个Gitlab-CI 里面最小的执行单位，job表示构建工作，即某个Stage里面执行的工作内容。我们可以在同一个Stage里面定义多个Job，相同的stage里面job并行执行，只有所有job成功才会成功\ngitlab runner：实际上是一个docker 的image，在Gitlab CI/CD 中每一个工作(Job) 都是在此运行的，优点是可以确保每次执行的环境都是干净的，且可以让多个工作同时进行，比如执行多种测试项目就可以启用不同的runner 同步进行。\ngitlab-ci：会在专案资料夹中侦测到Gitlab-ci.yml 这个设定档的时候触发，主要是负责协调在各种不同情境时Runner 该启动是否该启用及先后顺序，比如流程是先测试后部署，就会限制是测试成功后才能部属，不成功则中断。\n简单总结：实际上是gitlab-ci/cd集成bazel+k8s进行runner test的环境，所以首先需要关注gitlab-ci/cd的基础命令。\n简单来说我们使用gitlab ci/cd实现先编译，然后打tag（打tag的目的是标记本地镜像，并将之归为某一个仓库），再进行部署的操作。那么如何打tag的\n3.1 .gitlab-ci.yml 文件 # 关键词详细参考文档为：https://docs.gitlab.com/ee/ci/yaml/\nyml文件中主要是设定自动化部署的任务Job和脚本内。我们可以看到yml是一种文档方式的存储记录，以利用结构化优势。\nyml文件首先通过stage区分阶段，一个阶段完成做下个阶段的内容。另一方面，stage内部再利用job来区分阶段。\n简单举例，\nimage: lorisleiva/laravel-docker:latest //表示镜像或者docker的东西 stages: //阶段，必须完成每个阶段再执行下一个阶段 - testing - deployment unit_test: stage: testing //表明属于哪个阶段，单元测试阶段 script: - composer install --prefer-dist --no-ansi --no-interaction --no-progress --no-scripts - ./vendor/bin/phpunit --testsuit Unit production_deploy: //job，下面的内容用于指定阶段，变量，内容等东西 stage: deployment //部署阶段 tags: //tag用于说明哪些runner可以执行job，从而可以挑选机器来进行相关的job，方便选择runner - server1 - server2 variables: //执行脚本时内部的变量内容 HEROKU_PROJECT_NAME: $HEROKU_PRODUCTION_PROJECT_NAME HEROKU_API_KEY: $HEROKU_PRODUCTION_API_KEY before_script: //每个job执行关键script之前执行的内容 - apk add ruby ruby-dev ruby-irb ruby-rake ruby-io-console ruby-bigdecimal ruby-json ruby-bundler yarn ruby-rdoc \u0026gt;\u0026gt; /dev/null - apk update - gem install dpl \u0026gt;\u0026gt; /dev/null script: //具体执行脚本内容，每个job的关键步骤 - dpl --provider=heroku --app=$HEROKU_PRODUCTION_PROJECT_NAME --api-key=$HEROKU_API_KEY only: //设定只能在哪些分支进行部署 - master 再看一个例子，实际上我需要做的工作就是将deploy流程自动化，添加灰度发布。换言之，build，打包，发布融入代码当中\nimage: name: golang:1.10.3-stretch entrypoint: [\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;] # 为了能够使用go get，需要将代码放在 $GOPATH 中，比如你的 gitlab 域名是 mydomain.com，你的代码仓库是 repos/projectname，默认的 GOPATH 是 /go，然后你就需要将你的代码放置到 GOPATH 下面，/go/src/mydomain.com/repos/projectname，用一个软链接指过来就可以了 before_script: - mkdir -p \u0026#34;/go/src/git.qikqiak.com/${CI_PROJECT_NAMESPACE}\u0026#34; - ln -sf \u0026#34;${CI_PROJECT_DIR}\u0026#34; \u0026#34;/go/src/git.qikqiak.com/${CI_PROJECT_PATH}\u0026#34; - cd \u0026#34;/go/src/git.qikqiak.com/${CI_PROJECT_PATH}/\u0026#34; stages: - test - build - release - review - deploy test: stage: test script: - make test test2: stage: test script: - sleep 3 - echo \u0026#34;We did it! Something else runs in parallel!\u0026#34; compile: stage: build script: # 添加所有的依赖，或者使用 glide/govendor/... - make build artifacts: paths: - app image_build: stage: release image: docker:latest variables: DOCKER_DRIVER: overlay DOCKER_HOST: tcp://localhost:2375 services: - name: docker:17.03-dind command: [\u0026#34;--insecure-registry=registry.qikqiak.com\u0026#34;] script: - docker info - docker login -u \u0026#34;${CI_REGISTRY_USER}\u0026#34; -p \u0026#34;${CI_REGISTRY_PASSWORD}\u0026#34; registry.qikqiak.com - docker build -t \u0026#34;${CI_REGISTRY_IMAGE}:latest\u0026#34; . - docker tag \u0026#34;${CI_REGISTRY_IMAGE}:latest\u0026#34; \u0026#34;${CI_REGISTRY_IMAGE}:${CI_COMMIT_REF_NAME}\u0026#34; - test ! -z \u0026#34;${CI_COMMIT_TAG}\u0026#34; \u0026amp;\u0026amp; docker push \u0026#34;${CI_REGISTRY_IMAGE}:latest\u0026#34; - docker push \u0026#34;${CI_REGISTRY_IMAGE}:${CI_COMMIT_REF_NAME}\u0026#34; deploy_review: image: cnych/kubectl #用于镜像，具体含义为 stage: review only: - branches except: - tags # 环境，用于指定具体部署的环境，我们的希望部署到哪个环境，就往哪个name发出数据 environment: # 环境名字，想往哪个环境进行部署就需要对这个name进行修改 name: dev # a URL, which determines the deployment URL。但是说实话我没明白这个url是干啥的？ url: https://dev-gitlab-k8s-demo.qikqiak.com on_stop: stop_review script: - kubectl version - cd manifests/ - sed -i \u0026#34;s/__CI_ENVIRONMENT_SLUG__/${CI_ENVIRONMENT_SLUG}/\u0026#34; deployment.yaml ingress.yaml service.yaml - sed -i \u0026#34;s/__VERSION__/${CI_COMMIT_REF_NAME}/\u0026#34; deployment.yaml ingress.yaml service.yaml - | if kubectl apply -f deployment.yaml | grep -q unchanged; then echo \u0026#34;=\u0026gt; Patching deployment to force image update.\u0026#34; kubectl patch -f deployment.yaml -p \u0026#34;{\\\u0026#34;spec\\\u0026#34;:{\\\u0026#34;template\\\u0026#34;:{\\\u0026#34;metadata\\\u0026#34;:{\\\u0026#34;annotations\\\u0026#34;:{\\\u0026#34;ci-last-updated\\\u0026#34;:\\\u0026#34;$(date +\u0026#39;%s\u0026#39;)\\\u0026#34;}}}}}\u0026#34; else echo \u0026#34;=\u0026gt; Deployment apply has changed the object, no need to force image update.\u0026#34; fi - kubectl apply -f service.yaml || true - kubectl apply -f ingress.yaml - kubectl rollout status -f deployment.yaml - kubectl get all,ing -l ref=${CI_ENVIRONMENT_SLUG} stop_review: image: cnych/kubectl stage: review variables: GIT_STRATEGY: none when: manual only: - branches except: - master - tags environment: name: dev action: stop script: - kubectl version - kubectl delete ing -l ref=${CI_ENVIRONMENT_SLUG} - kubectl delete all -l ref=${CI_ENVIRONMENT_SLUG} deploy_live: image: cnych/kubectl stage: deploy environment: name: live url: https://live-gitlab-k8s-demo.qikqiak.com only: - tags when: manual script: - kubectl version - cd manifests/ - sed -i \u0026#34;s/__CI_ENVIRONMENT_SLUG__/${CI_ENVIRONMENT_SLUG}/\u0026#34; deployment.yaml ingress.yaml service.yaml - sed -i \u0026#34;s/__VERSION__/${CI_COMMIT_REF_NAME}/\u0026#34; deployment.yaml ingress.yaml service.yaml - kubectl apply -f deployment.yaml - kubectl apply -f service.yaml - kubectl apply -f ingress.yaml - kubectl rollout status -f deployment.yaml - kubectl get all,ing -l ref=${CI_ENVIRONMENT_SLUG} 我们的pipeline触发的条件很大，\nonly: refs: - merge_requests //只有merge request试用 variables: - $CI_MERGE_REQUEST_LABELS =~ /ci::pipeline_passed/ interruptible: true only: refs: - merge_requests rules: - !reference [.mr_rule_templates, skip_rule] - !reference [.mr_rule_templates, bazel_rule] - !reference [.mr_rule_templates, default_rule] 4 学习kubernetes # 参考的书籍是《每天5分钟玩转kubernetes》，使用minikube学习，命令为https://minikube.sigs.k8s.io/docs/start/\n基础概念：\ncluster：集群 master：调度的关键，决定调度给哪个node node：执行任务的单位，负责监控并汇报容器状态 pod：最小工作单元，每个pod包含一个或多个容器。POD的容器会作为一个整体被master调度到一个node上运行。 Controller： Service： Namespace： 4.1 k8s架构 # master节点：\nAPI Server：提供各种http/https/restful管理方式，前端接口，通过api server进行管理 scheduler：决定将pod放在哪个nod运行 controller manager：资源管理 etcd：保存资源的信息方便检索 pod网络：方便pod之间通信 nod节点：\nkubelet：node的agent，scheduler获得在某个node上运行pod后，会将pod的具体配置信息（image，volume）发送给该节点的kubelet，然后该节点创建和运行容器，进行工作 kube-proxy：部署完了pod，外界实际是访问服务。kube-proxy负责实现请求转发 pod网络：pod之间通信使用 4.2 运行应用 # 4.2.1 deployment # 4.2.1.1 手动部署 # 手动部署的方式：创建deployment之后会创建replicast再创建pod，简单描述过程就是：从deployment ==\u0026gt; replicast ==\u0026gt; pod。这里要注意k8s会按照replicaset的数量创建副本，如果某个node挂了，上面的pod的状态就变为unknown，然后会在别的node上创建足够数量的pod。等故障node恢复以后，不会恢复这个node上的pod，而是删除这个node上的pod\n具体的命令参看下面：\n#该命令用于发起一个部署 kubectl run nginx-deployment --image=nginx:1.7.9 --replicase=2 #该命令用于获得部署状态 kubectl get deployment nginx-deployment #该命令用于获得部署的详细状况 kubectl describe deployment nginx-deployment #获得replicaset \u0026amp; 获得replicaset详细信息 kubectl get replicast kubectl describe replicast #然后再获得pod信息，和描述pod kubectl get pod kubectl describe pod - scripts/build_sim_server_v2.sh # replace image name - sed -i \u0026#34;s#qcraft-docker.qcraft.ai/qcraft/offboard/dashboard/sim_server:live#qcraft-docker.qcraft.ai/qcraft/offboard/dashboard/sim_server:${CI_COMMIT_SHA}#g\u0026#34; \u0026#34;production/k8s/offboard/dashboard/sim_server/base/deployment.yaml\u0026#34; # replace namespace name - sed -i \u0026#34;s#production:${KUBE_NAMESPACE}#g\u0026#34; - kubectl apply -k production/k8s/offboard/dashboard/sim_server/cn_edge dependencies: [] 4.2.1.2 文件部署 # 再来看通过文件方式部署，看下部署到哪里\n4.2.1.3 label控制部署到哪里 # 如果向控制具体部署到哪里，可以通过给node添加标签，然后再修改部署文件里面的nodeSelector添加disktype:ssd即可实现部署到特定机器上：\n#添加一个标签， kubectl label node k8s-node1 disktype=ssd 4.2.2 daemon set # 和deployment不同，daemon set在每个node上只能有一个副本\n# 4.2.3 Job # 容器分为两种，一种是服务类容器，另一种是工作类容器，其中服务类容器需要一直运行，而工作类容器只需要运行一次\n4.3 service # # 5 Docker相关内容的简单学习 # Docker是什么？\n6 SHELL遇到的一些小问题和教程 # 6.1 SED替换问题 # 今天在做一个很简单的事情，利用commit hash作为tag，获取commit hash很简单git rev-parse HEAD，然后使用sed命令替换镜像名称，然后遇到一个问题就是sed替换的原始名称当中包含\u0026quot;/\u0026quot;，这个会导致sed报错\nsed: -e expression #1, char 34: unknown option to `s\u0026#39; 如何解决呢？有一个很简单的解决方法，因为sed的分隔符并不是固定的，它是sed -s后面的第一个字符当成分隔符，也就是说如果把命令改成\nsed -i \u0026#34;s#$FROM:live#$TO:${TAG}#g\u0026#34; \u0026#34;$FILE_NAME\u0026#34; 就会以#为分隔符，而不需要自己进行地址里面\u0026quot;/\u0026ldquo;的转义了。\n6.2 SHELL脚本当中变量的部分含义 # 缺省值（:-） # ${var:-string} 若变量var为空或者未定义,则用在命令行中用string来替换${var:-string} 否则变量var不为空时,则用变量var的值来替换${var:-string}\n$ COMPANY= $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY:-Unknown Company}\u0026#34; Unknown Company $ echo $COMPANY 变量的实际值保持不变。\n指定缺省值（:=） # 如果变量后面跟着冒号和等号，则给空变量指定一个缺省值。\n$ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY:=Nightlight Inc.}\u0026#34; Nightlight Inc. $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY}” Nightlight Inc. 变量的实际值已经改变了。 比较${var:-string}和${var:=string} 后者发现$var为空时,把string赋值给了var 后者是一种赋值默认值的常见做法\n变量是否存在检查（:?） # 替换规则:若变量var不为空,则用变量var的值来替换${var:?string} 若变量var为空,则把string输出到标准错误中,并从脚本中退出。 可利用此特性来检查是否设置了变量的值\n根据变量是否存在，显示不同的信息。信息不是必选的。\nprintf \u0026#34;Company is %s\\n\u0026#34; \u0026#34;${COMPANY:?Error: Company has notbeen defined—aborting}\u0026#34; 覆盖缺省值(:+) # ${var:+string} 规则和${var:-string},${var:=string}的完全相反 即只有当var不是空的时候才替换成string,若var为空时则不替换或者说是替换成变量var的值,即空值\n$ COMPANY=\u0026#34;Nightlight Inc.\u0026#34; $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY:+Company has been overridden}\u0026#34; Company has been overridden 替换部分字符串（:n） # 如果变量后面跟着一个冒号和数字，则返回该数字开始的一个子字符串，如果后面还跟着一个冒号和数字。则第一个数字表示开始的字符，后面数字表示字符的长度。\n$ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY:5}\u0026#34; light Inc. $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY:5:5}\u0026#34; light 根据模板删除字串（%，#，%%，##） #删除左边,%删除右边 如果变量后面跟着井号，则返回匹配模板被删除后的字串。一个井号为最小可能性的匹配，两个井号为自大可能性的匹配。表达式返回模板右边的字符。\n$ COMPANY=\u0026#34;Nightlight Inc.\u0026#34; $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY#Ni*}\u0026#34; ghtlight Inc. $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY##Ni*}\u0026#34; $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY##*t}\u0026#34; Inc. $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY#*t}\u0026#34; light Inc. #使用百分号，表达式返回模板左边的字符 $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY%t*}\u0026#34; Nightligh $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY%%t*}\u0026#34; Nigh 案例: 获取文件名和后缀名\n$ f=file.tar.gz $ echo ${f##*.} gz $ echo ${f%%.*} file #假设我们定义了一个变量为： file=/dir1/dir2/dir3/my.file.txt #可以用${ }分别替换得到不同的值： ${file#*/}：删掉第一个 / 及其左边的字符串：dir1/dir2/dir3/my.file.txt ${file##*/}：删掉最后一个 / 及其左边的字符串：my.file.txt ${file#*.}：删掉第一个 . 及其左边的字符串：file.txt ${file##*.}：删掉最后一个 . 及其左边的字符串：txt ${file%/*}：删掉最后一个 / 及其右边的字符串：/dir1/dir2/dir3 ${file%%/*}：删掉第一个 / 及其右边的字符串：(空值) ${file%.*}：删掉最后一个 . 及其右边的字符串：/dir1/dir2/dir3/my.file ${file%%.*}：删掉第一个 . 及其右边的字符串：/dir1/dir2/dir3/my 记忆的方法为： #是 去掉左边（键盘上#在 $ 的左边） %是去掉右边（键盘上% 在$ 的右边） 单一符号是最小匹配；两个符号是最大匹配\n使用模板进行子字符串的替换（//） # 如果变量后只有一个斜杠，则两个斜杠中间的字符串是要被替换的字符串，而第二个斜杠后面的字符串是要替换的字符串。如果变量后面跟着两个斜杠，则所有出现在两个斜杠中间的字符都要被替换为最后一个斜杠后面的字符。\n$ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY/Inc./Incorporated}\u0026#34; Nightlight Incorporated $ printf \u0026#34;You are the I in %s\\n\u0026#34; \u0026#34;${COMPANY//i/I}\u0026#34; You are the I in NIghtlIght Inc. 如果模板以#号开始，则匹配以模板开始的字符，如果模板以%号结尾(在centos7上测试不生效)，则匹配以模板结尾的字符。\n$ COMPANY=\u0026#34;NightLight Night Lighting Inc.\u0026#34; $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;$COMPANY\u0026#34; NightLight Night Lighting Inc. $ printf \u0026#34;%s\u0026#34; \u0026#34;${COMPANY//Night/NIGHT}\u0026#34; NIGHTLight NIGHT Lighting Inc. $ printf \u0026#34;%s\u0026#34; \u0026#34;${COMPANY//#Night/NIGHT}\u0026#34; NIGHTLight Night Lighting Inc. 如果没有指定新的值，则匹配的字符会被删除。\n$ COMPANY=\u0026#34;Nightlight Inc.\u0026#34; $ printf \u0026#34;%s\\n\u0026#34; \u0026#34;${COMPANY/light}\u0026#34; Night Inc. 也可以使用范围符号。例如：删除所有字符串中的标点符号，使用范围[:punct:]。\n$ printf \u0026#34;%s\u0026#34; \u0026#34;${COMPANY//[[:punct:]]}\u0026#34; Nightlight Inc 使用号或@符号替换变量会替换shell脚本中所有的参数，同样，在数组中使用号或@符号也会替换数组中的所有元素\n结尾 # 唉，尴尬\n","date":"2021 年 10 月 11 日","externalUrl":null,"permalink":"/posts/2021-10-11-ci_cd%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0/","section":"Posts","summary":"","title":"ci_cd相关学习","type":"posts"},{"content":" gitlab常见问题总结 # 记录一些遇到的问题和解决方法\n1.1 push镜像失败 # push到阿里云服务器时候失败，有两种可能的原因：\n没登录，需要登陆下 image的名字过于长了，简单说就是本来image的名字应该是repo_name/namespace/image_name:tag，如果image_name特别长比方说是/xxx/yyy/zzz/ddd/aaa/eee/ccc这种，name就会出现push失败的情况。提示requested access to the resource is denied。这种情况属于阿里云本身的问题 The push refers to repository [registry.qcraftai.com/qcraft/sim_server] ... 21639b09744f: Waiting 78220a8ee18f: Waiting c65cd6950943: Waiting 29c579ad1c5a: Waiting 767a7c7801b5: Waiting a24b8da85c42: Waiting denied: requested access to the resource is denied 1.2 本地format.sh格式化过了，ci还是不过 # 错误原因是dev docker过旧，新版本的format.sh有变化，所以更新dev docker即可\n[ OK ] Congrats, commit author check pass [ OK ] Done buildifier /builds/root/qcraft/offboard/dashboard/BUILD [INFO] Done formatting /builds/root/qcraft/offboard/dashboard/health.proto [ OK ] Done buildifier /builds/root/qcraft/offboard/dashboard/services/health/BUILD [INFO] Done formatting /builds/root/qcraft/offboard/dashboard/services/health/health.cc [INFO] Done formatting /builds/root/qcraft/offboard/dashboard/services/health/health.h [INFO] Done formatting /builds/root/qcraft/offboard/dashboard/services/health/health_client.cc [INFO] Done formatting /builds/root/qcraft/offboard/dashboard/sim_server_main.cc [ OK ] Done formatting /builds/root/qcraft/production/k8s/offboard/dashboard/sim_server_v2/deploy.sh [ERROR] Format issue found, please run \u0026#34;scripts/format.sh --git\u0026#34; before commit offboard/dashboard/services/health/health_client.cc | 4 ++-- 1 file changed, 2 insertions(+), 2 deletions(-) 1.3 Job一直pending # job一直在pending，任务很忙，一直拿不到？目前看起来有什么可能的原因呢？有多种可能：\nmaster发布升级命令，然后pod开始升级，包括拉取镜像，挂载设备等等。如果镜像仓库有问题，一直拉不下来，那么就会一直pending，比方说2021/11/11号早上，阿里云仓库出了问题，镜像一直拉不下来。这里多说一句，CI的镜像是在master里面通过对CN_IMG/USA_IMG指定的 Waiting for pod gitlab-runner/runner-u15fg-a7-project-4-concurrent-0tw4c2 to be running, status is Pending ContainersNotReady: \u0026#34;containers with unready status: [build helper]\u0026#34; ContainersNotReady: \u0026#34;containers with unready status: [build helper]\u0026#34; Waiting for pod gitlab-runner/runner-u15fg-a7-project-4-concurrent-0tw4c2 to be running, status is Pending ContainersNotReady: \u0026#34;containers with unready status: [build helper]\u0026#34; ContainersNotReady: \u0026#34;containers with unready status: [build helper]\u0026#34; Waiting for pod gitlab-runner/runner-u15fg-a7-project-4-concurrent-0tw4c2 to be running, status is Pending ContainersNotReady: \u0026#34;containers with unready status: [build helper]\u0026#34; ContainersNotReady: \u0026#34;containers with unready status: [build helper]\u0026#34; Waiting for pod gitlab-runner/runner-u15fg-a7-project-4-concurrent-0tw4c2 to be running, status is Pending ContainersNotReady: \u0026#34;containers with unready status: [build helper]\u0026#34; ContainersNotReady: \u0026#34;containers with unready status: [build helper]\u0026#34; 1.4 代码保护报错 # 代码保护导致的错误，代码保护软件似乎有个问题，即白名单加多了以后就不生效了，然后gitlab-runner拉代码就会出先下面的错误。今天虽然加了代码但是没生效的原因是因为gitlab-runner上的客户端死了，所以没同步配置。代码就没拉下来。\n[580s] can not find refs/pipelines/90402, retry later ... fatal: unable to access \u0026#39;https://gitlab-cn.qcraftai.com/root/qcraft.git/\u0026#39;: error:1408F10B:SSL routines:ssl3_get_record:wrong version number [585s] can not find refs/pipelines/90402, retry later ... fatal: unable to access \u0026#39;https://gitlab-cn.qcraftai.com/root/qcraft.git/\u0026#39;: error:1408F10B:SSL routines:ssl3_get_record:wrong version number [590s] can not find refs/pipelines/90402, retry later ... fatal: unable to access \u0026#39;https://gitlab-cn.qcraftai.com/root/qcraft.git/\u0026#39;: error:1408F10B:SSL routines:ssl3_get_record:wrong version number [595s] can not find refs/pipelines/90402, retry later ... fatal: unable to access \u0026#39;https://gitlab-cn.qcraftai.com/root/qcraft.git/\u0026#39;: error:1408F10B:SSL routines:ssl3_get_record:wrong version number [600s] can not find refs/pipelines/90402, retry later ... can not find refs/pipelines/90402, exit! Cleaning up file based variables 00:01 ERROR: Job failed: command terminated with exit code 1 1.5 sim-server的奇怪错误 # 今天gitlab部署sim-server出错了，然后报错的地方和原因八杆子打不着，原来是配置文件写错哦了\n- name: GITLAB_ACCESS_TOKEN valueFrom: //这里多写了一行 valueFrom: secretKeyRef: name: gitlab-access-token 具体报错信息在这里\n... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 3m7s default-scheduler Successfully assigned staging/sim-server-grey-6bc7997545-mx4t8 to cn-zhangjiakou.172.20.2.197 Warning Unhealthy 90s kubelet Liveness probe failed: OCI runtime exec failed: exec failed: container_linux.go:346: starting container process caused \u0026#34;process_linux.go:101: executing setns process caused \\\u0026#34;exit status 1\\\u0026#34;\u0026#34;: unknown Warning Unhealthy 84s (x2 over 94s) kubelet Readiness probe failed: Normal Started 67s (x3 over 99s) kubelet Started container sim-server Warning Unhealthy 60s kubelet Liveness probe failed: Warning Unhealthy 59s kubelet Readiness probe errored: rpc error: code = Unknown desc = container not running (b47a56e00cddda91ee7e446a77ece77d8c6955320dd11a031a3d8c71372ab3d4) Warning BackOff 44s (x5 over 82s) kubelet Back-off restarting failed container Normal Pulling 28s (x4 over 3m5s) kubelet Pulling image \u0026#34;registry.qcraftai.com/global/sim_server:c8ad37ec94ebfda0a08106f77210cb92ed67387d\u0026#34; Normal Pulled 28s (x4 over 101s) kubelet Successfully pulled image \u0026#34;registry.qcraftai.com/global/sim_server:c8ad37ec94ebfda0a08106f77210cb92ed67387d\u0026#34; Normal Created 27s (x4 over 100s) kubelet Created container sim-server 看起来是你不小心编辑了/home/qcraft/.aws/credentials 这个文件导致的，要么想办法还原，要么重新setup一次，删了重新跑aws configure\n有人碰到过这个问题吗？初始化tools报错 [INFO] Start goofys mounting from /qcraftroaddata to /media/s3/run_data_2 2021/12/20 11:02:22.424581 main.FATAL Unable to mount file system, see syslog for details 查看syslog信息是 Dec 20 11:18:28 yanguodong /usr/local/bin/goofys[7687]: main.ERROR Unable to setup backend: SharedConfigLoadError: failed to load config file, /home/qcraft/.aws/credentials#012caused by: INIParseError: invalid state with ASTKind {completed_stmt {0 NONE 0 []} false [{section_stmt {1 STRING 0 [78 111 110 101]} true []}]} and TokenType {4 NONE 0 [58]} Dec 20 11:18:28 yanguodong /usr/local/bin/goofys[7687]: main.FATAL Mounting file system: Mount: initialization failed 1.6 安装升级cuda和nvidia驱动 # 我们的cuda的runtime library已经是11.3了，但是新建的centos7没有装驱动，需要手动装驱动。参考的链接是https://blog.csdn.net/JimmyOrigin/article/details/112972883\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 2m36s default-scheduler Successfully assigned gitlab-runner/runner-fcakjyg6-project-4-concurrent-0dgs2w to cn-gpu03016ack Normal Pulled 2m29s kubelet Container image \u0026#34;registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-58ba2b95\u0026#34; already present on machine Normal Created 2m29s kubelet Created container init-permissions Normal Started 2m29s kubelet Started container init-permissions Normal Pulling 2m28s kubelet Pulling image \u0026#34;registry.qcraftai.com/global/qcraft-ci:dev-libgit-20211214_0012\u0026#34; Normal Pulled 91s kubelet Successfully pulled image \u0026#34;registry.qcraftai.com/global/qcraft-ci:dev-libgit-20211214_0012\u0026#34; in 56.658518838s Normal Created 81s kubelet Created container build Warning Failed 81s kubelet Error: failed to start container \u0026#34;build\u0026#34;: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: requirement error: unsatisfied condition: cuda\u0026gt;=11.3, please update your driver to a newer version, or use an earlier cuda container: unknown Normal Pulled 81s kubelet Container image \u0026#34;registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-58ba2b95\u0026#34; already present on machine Normal Created 81s kubelet Created container helper Normal Started 81s kubelet Started container helper centos7系统安装gpu机器驱动和cuda：\n# 以root用户登录进centos7.9系统，删除旧的nvidia驱动 yum remove nvidia* # 需要重启才能卸载当前正在运行的nvidia mod shutdown -r now # 大部分的驱动安装都说要禁用nouveau，但是我使用默认的centos7检查的时候lsmod nouveau直接就没有，所以我们省略了这一步 # 下载nvidia驱动文件 # 更新依赖组件和包 yum update yum groupinstall \u0026#34;Development Tools\u0026#34; yum install kernel-devel epel-release # 确定提示出来的内核的版本一致，不一致使用yum -y upgrade kernel kernel-devel uname -r rpm -q kernel-devel # 运行驱动，执行安装.安装32bit nvidia驱动时选择no,update your x configuration选择yes。剩下的都ok即可 chmod +x ./NVIDIA-Linux-x86_64-470.94.run ./NVIDIA-Linux-x86_64-470.94.run # 查看匹配的cuda版本 nvidia smi #执行结果见下 [root@cn-gpu03016ack ~]# nvidia-smi Tue Dec 21 13:06:23 2021 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 470.94 Driver Version: 470.94 CUDA Version: 11.4 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 NVIDIA GeForce ... Off | 00000000:00:08.0 Off | N/A | | 15% 41C P0 64W / 250W | 0MiB / 11019MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ # 下载对应的CUDA版本 wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run # 进行安装,这里有几点要注意: 出现一个文档，这里要输入accept。然后CUDA installer里面组件选择去掉驱动的选中，我们已经装了驱动了，然后再Install sh cuda_11.4.0_470.42.01_linux.run # 添加CUDA到环境变量 export PATH=/usr/local/cuda-11.4/bin:$PATH export LD_LIBRARY_PATH=$LDLIBRARY_PATH:/usr/local/cuda-11.4/lib64 source ~/.bashrc # 测试cuda指令，可以看到cuda已经安装成功，版本为11.4 nvcc -V # 第一步的时候把nvidia-docker啥的都删除了，所以需要重新添加repo源 distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo # 更新 yum cache yum clean expire-cache # 安装nvidia-docker yum install -y nvidia-docker2 # 重启docker systemctl restart docker 最后整理出来的总共的初始化脚本如下：\n#!/bin/bash set -e function add_current_script_to_rc_local() { script_path=$(realpath $0) echo \u0026#34;Adding boot shell $script_path\u0026#34; echo \u0026#34;$script_path\u0026#34; \u0026gt;\u0026gt; /etc/rc.d/rc.local } function remove_current_script_from_rc_local() { script_path=$(realpath $0) echo \u0026#34;Removing boot shell $script_path\u0026#34; sed -i \u0026#34;s#$script_path##g\u0026#34; /etc/rc.d/rc.local } function remove_nvidia_driver() { echo \u0026#34;Remove existing driver\u0026#34; echo \u0026#34;Remove existing nvidia driver container cli\u0026#34; yum remove -y nvidia* # Use default nvidia-uninstall bin to perform uninstall if [[ -x \u0026#34;/usr/bin/nvidia-uninstall\u0026#34; ]]; then echo \u0026#34;Remove existing nvidia driver using nvidia-uninstall\u0026#34; /usr/bin/nvidia-uninstall --silent fi } function create_nvidia_cuda_folder() { echo \u0026#34;Create folder /root/nvidia_cuda\u0026#34; if [[ ! -d \u0026#34;/root/nvidia_cuda\u0026#34; ]]; then mkdir \u0026#34;/root/nvidia_cuda\u0026#34; fi } function get_nvidia_driver_version() { echo $(nvidia-smi --query-gpu=driver_version --format=csv,noheader) } function download_nvidia_11_4_0_470_42_01() { wget -O cuda_11.4.0_470.42.01_linux.run \u0026#34;https://qcraft-images.oss-cn-zhangjiakou-internal.aliyuncs.com/cuda_470_42_01/cuda_11.4.0_470.42.01_linux.run\u0026#34; cuda_md5=$(md5sum ./cuda_11.4.0_470.42.01_linux.run | awk \u0026#39;{print $1}\u0026#39;) if [[ $cuda_md5 == \u0026#34;cbcc1bca492d449c53ab51c782ffb0a2\u0026#34; ]]; then echo \u0026#34;Download cuda successfull\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log else echo \u0026#34;Download cuda failed\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log exit 1 fi } function install_driver_needed_files() { echo \u0026#34;Installing needed header files\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log yum update -y yum groupinstall -y \u0026#34;Development Tools\u0026#34; yum install -y kernel-devel epel-release } function install_nvidia_cuda_driver() { driver_installed=$(get_nvidia_driver_version) if [[ $driver_installed == \u0026#34;470.42.01\u0026#34; ]]; then echo \u0026#34;Already install nvidia driver 470.42.01, Abort install\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log exit 0 else echo \u0026#34;Planning to install 470.42.01 cuda \u0026amp; driver\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log install_driver_needed_files download_nvidia_11_4_0_470_42_01 echo \u0026#34;Start to install 470.42.01 cuda \u0026amp; driver\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log chmod +x ./cuda_11.4.0_470.42.01_linux.run ./cuda_11.4.0_470.42.01_linux.run --silent echo \u0026#34;Success installed 470.42.01 cuda \u0026amp; driver\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log fi } function install_nvidia_docker_2() { echo \u0026#34;Installing nvidia-docker 2\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log distribution=$( . /etc/os-release echo $ID$VERSION_ID ) \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo yum clean expire-cache yum install -y nvidia-docker2 echo \u0026#34;Installed nvidia-docker 2\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log } function overwrite_daemon_json() { wget -O daemon.json \u0026#34;https://qcraft-images.oss-cn-zhangjiakou-internal.aliyuncs.com/cuda_470_42_01/daemon.json\u0026#34; json_md5=$(md5sum ./daemon.json | awk \u0026#39;{print $1}\u0026#39;) if [[ $json_md5 == \u0026#34;8f8be065977394c8c75c0b4c23a2258d\u0026#34; ]]; then echo \u0026#34;Download daemon.json successfull\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log else echo \u0026#34;Download daemon.json failed\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log exit 1 fi mv -f daemon.json /etc/docker/daemon.json } function modify_docker_sock_permission() { if [[ -f \u0026#34;/var/run/docker.sock\u0026#34; ]]; then echo \u0026#34;Modify docker.sock permission to 666\u0026#34; chmod 666 /var/run/docker.sock fi } if [ ! -d \u0026#34;/root/nvidia_cuda\u0026#34; ]; then remove_nvidia_driver create_nvidia_cuda_folder add_current_script_to_rc_local echo \u0026#34;Finish fisrt stage: remove current nvidia driver \u0026amp; add current stage to boot\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log shutdown -r now else remove_current_script_from_rc_local cd /root/nvidia_cuda install_nvidia_cuda_driver install_nvidia_docker_2 overwrite_daemon_json echo \u0026#34;Finish second stage: install nvidia driver \u0026amp; cuda \u0026amp; nvidia docker 2 \u0026amp; daemon.json\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log fi modify_docker_sock_permission echo \u0026#34;Install nvidia driver \u0026amp; cuda success\u0026#34; \u0026gt;\u0026gt; /root/nvidia_cuda/install.log 这里的报错虽然是driver name nasplugin.csi.alibabacloud.com not found，但是实际上是运行在每个node上的daemonset没有启动，因此需要启动相对应的守护进程集。之所以出现这个问题是因为在上一步我更新驱动文件的时候将所有的nvidia相关的组件/驱动全删除了，也就罢nvidia-docker2也给删除了，因此日志里面报错：\nWarning FailedCreatePodSandBox 4m2s (x4 over 4m5s) kubelet (combined from similar events): Failed to create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container for pod \u0026#34;csi-plugin-n8wgn\u0026#34;: Error response from daemon: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v1.linux/moby/238bd4e5cf01dd61498969daacae01454eb59624e9e11732d4bd8aa356fcbaec/log.json: no such file or directory): fork/exec /usr/bin/nvidia-container-runtime: no such file or directory: unknown 表现出来的报错信息为\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 3m9s default-scheduler Successfully assigned gitlab-runner/runner-cm89m7vp-project-4-concurrent-0drj7g to cn-gpu03016ack Warning FailedMount 2m6s (x8 over 3m10s) kubelet MountVolume.MountDevice failed for volume \u0026#34;gitlab-runner-pvc-bazel-distdir\u0026#34; : kubernetes.io/csi: attacher.MountDevice failed to create newCsiDriverClient: driver name nasplugin.csi.alibabacloud.com not found in the list of registered CSI drivers Warning FailedMount 2m6s (x8 over 3m10s) kubelet MountVolume.MountDevice failed for volume \u0026#34;gitlab-runner-pvc-bazel-repo-cache\u0026#34; : kubernetes.io/csi: attacher.MountDevice failed to create newCsiDriverClient: driver name nasplugin.csi.alibabacloud.com not found in the list of registered CSI drivers Warning FailedMount 2m6s (x8 over 3m10s) kubelet MountVolume.MountDevice failed for volume \u0026#34;gitlab-runner-pvc-qcraft-maps-china\u0026#34; : kubernetes.io/csi: attacher.MountDevice failed to create newCsiDriverClient: driver name nasplugin.csi.alibabacloud.com not found in the list of registered CSI drivers Warning FailedMount 67s kubelet Unable to attach or mount volumes: unmounted volumes=[bazel-distdir qcraft-maps-china bazel-repo-cache], unattached volumes=[bazel-distdir qcraft-maps-china default-token-g2v9p docksock logs hosthostname aws repo bazel-repo-cache scripts]: timed out waiting for the condition 即使安装了完了诸如nvidia \u0026amp; cuda \u0026amp; nvidia-docker，依然会发现Job没有使用gpu运行，这个时候需要修改/etc/docker/daemon.json文件下面的文件.\n还有一个要注意的地方，即使添加了gpu也不一定代表着test会一定rerun，\n{ \u0026#34;default-runtime\u0026#34;: \u0026#34;nvidia\u0026#34;, \u0026#34;runtimes\u0026#34;: { \u0026#34;nvidia\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;nvidia-container-runtime\u0026#34;, \u0026#34;runtimeArgs\u0026#34;: [] } }, \u0026#34;registry-mirror\u0026#34;: [ \u0026#34;https://registry.docker-cn.com\u0026#34; ], \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;live-restore\u0026#34;: true, \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;50m\u0026#34;, \u0026#34;max-file\u0026#34;: \u0026#34;5\u0026#34; }, \u0026#34;bip\u0026#34;: \u0026#34;169.254.123.1/24\u0026#34;, \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://pqbap4ya.mirror.aliyuncs.com\u0026#34;] } 报错信息为\nPASSED ] 0 tests. [ FAILED ] 2 tests, listed below: [ FAILED ] list_add_test.ListAdd [ FAILED ] list_add_test.ListAddHalf 2 FAILED TESTS ================================================================================ FAIL: //onboard/nets/custom_ops:gen_coordinates_test (see /home/qcrafter/.cache/bazel/_bazel_qcrafter/b7b2ac012bd759fe3fc931a5a52099ce/execroot/com_qcraft/bazel-out/k8-opt/testlogs/onboard/nets/custom_ops/gen_coordinates_test/test.log) INFO: From Testing //onboard/nets/custom_ops:gen_coordinates_test: ==================== Test output for //onboard/nets/custom_ops:gen_coordinates_test: [NVBLAS] No Gpu available [NVBLAS] NVBLAS_CONFIG_FILE environment variable is NOT set : relying on default config filename \u0026#39;nvblas.conf\u0026#39; [NVBLAS] Cannot open default config file \u0026#39;nvblas.conf\u0026#39; [NVBLAS] Config parsed [NVBLAS] CPU Blas library need to be provided 这里还有一个奇怪的问题，就是job报错找不到GPU，然后运行失败，但是在docker里面执行却没有问题执行成功。具体参考这个job 。为什么出这个错误？为此我把bazel run -c opt //onboard/nets/custom_ops:multiply_value_test这个扔到那个job里面。问题出现了bazel run是成功的，而bazel test是失败的。。。。有个类似的链接https://github.com/bazelbuild/rules_nodejs/issues/2325 为什么出现这个问题？因为指定了具体用不用cpu_only_flag，为了能够先跳过这个job，先\nbazel run -c opt //onboard/nets/custom_ops:multiply_value_test\nbazel test \u0026ndash;cache_test_results=no -c opt \u0026ndash;config=nolint $CPU_ONLY_PARAM \u0026ndash;test_tag_filters=hxn \u0026ndash; //\u0026hellip;\n是这两个commit\n# Docker 内部运行的结果 qcrafter@runner-yeb5xrzz-project-4-concurrent-0st2sc:/qcraft$ bazel run -c opt //onboard/nets/custom_ops:multiply_value_test INFO: Invocation ID: 99fdcd7d-047b-4086-a572-722da639841f INFO: Analyzed target //onboard/nets/custom_ops:multiply_value_test (9 packages loaded, 234 targets configured). INFO: Found 1 target... Target //onboard/nets/custom_ops:multiply_value_test up-to-date: bazel-bin/onboard/nets/custom_ops/multiply_value_test INFO: Elapsed time: 6.002s, Critical Path: 0.36s INFO: 196 processes: 65 remote cache hit, 130 internal, 1 processwrapper-sandbox. INFO: Build completed successfully, 196 total actions INFO: Build completed successfully, 196 total actions exec ${PAGER:-/usr/bin/less} \u0026#34;$0\u0026#34; || exit 1 Executing tests from //onboard/nets/custom_ops:multiply_value_test ----------------------------------------------------------------------------- [NVBLAS] NVBLAS_CONFIG_FILE environment variable is NOT set : relying on default config filename \u0026#39;nvblas.conf\u0026#39; [NVBLAS] Cannot open default config file \u0026#39;nvblas.conf\u0026#39; [NVBLAS] Config parsed [NVBLAS] CPU Blas library need to be provided Running main() from gmock_main.cc [==========] Running 2 tests from 1 test suite. [----------] Global test environment set-up. [----------] 2 tests from multiply_value_test [ RUN ] multiply_value_test.MultiplyValue [ OK ] multiply_value_test.MultiplyValue (117 ms) [ RUN ] multiply_value_test.MultiplyValueHalf [ OK ] multiply_value_test.MultiplyValueHalf (0 ms) [----------] 2 tests from multiply_value_test (117 ms total) [----------] Global test environment tear-down [==========] 2 tests from 1 test suite ran. (117 ms total) [ PASSED ] 2 tests. # 在CI节点里面执行job的日志 FAIL: //onboard/nets/custom_ops:multiply_value_test (see /home/qcrafter/.cache/bazel/_bazel_qcrafter/b7b2ac012bd759fe3fc931a5a52099ce/execroot/com_qcraft/bazel-out/k8-opt/testlogs/onboard/nets/custom_ops/multiply_value_test/test.log) INFO: From Testing //onboard/nets/custom_ops:multiply_value_test: ==================== Test output for //onboard/nets/custom_ops:multiply_value_test: [NVBLAS] No Gpu available 这个失败的原因实际上可能是编译build导致的 [NVBLAS] NVBLAS_CONFIG_FILE environment variable is NOT set : relying on default config filename \u0026#39;nvblas.conf\u0026#39; [NVBLAS] Cannot open default config file \u0026#39;nvblas.conf\u0026#39; [NVBLAS] Config parsed [NVBLAS] CPU Blas library need to be provided Running main() from gmock_main.cc [==========] Running 2 tests from 1 test suite. [----------] Global test environment set-up. [----------] 2 tests from multiply_value_test [ RUN ] multiply_value_test.MultiplyValue onboard/nets/custom_ops/multiply_value_test.cc:55: Failure The difference between result[i] and kOutputResult[i] is 7350900951613439, which exceeds kMaxDiffFloat, where result[i] evaluates to 7350900951613440, kOutputResult[i] evaluates to 1, and kMaxDiffFloat evaluates to 9.9999999747524271e-07. onboard/nets/custom_ops/multiply_value_test.cc:55: Failure The difference between result[i] and kOutputResult[i] is 4, which exceeds kMaxDiffFloat, where result[i] evaluates to 3.0677225980998895e-41, kOutputResult[i] evaluates to 4, and kMaxDiffFloat evaluates to 9.9999999747524271e-07. onboard/nets/custom_ops/multiply_value_test.cc:55: Failure The difference between result[i] and kOutputResult[i] is 5.9999999997455671, which exceeds kMaxDiffFloat, where result[i] evaluates to 2.544326138664843e-10, kOutputResult[i] evaluates to 6, and kMaxDiffFloat evaluates to 9.9999999747524271e-07. onboard/nets/custom_ops/multiply_value_test.cc:55: Failure The difference between result[i] and kOutputResult[i] is 4, which exceeds kMaxDiffFloat, where ... kOutputResultHalf[i] evaluates to 18, and kMaxDiffHalf evaluates to 0.00039999998989515007. [ FAILED ] multiply_value_test.MultiplyValueHalf (0 ms) [----------] 2 tests from multiply_value_test (1 ms total) [----------] Global test environment tear-down [==========] 2 tests from 1 test suite ran. (1 ms total) [ PASSED ] 0 tests. [ FAILED ] 2 tests, listed below: [ FAILED ] multiply_value_test.MultiplyValue [ FAILED ] multiply_value_test.MultiplyValueHalf 2 FAILED TESTS 1.7 aliyun机器怎么格式化数据盘为xfs # 数据盘为/dev/vdb，默认是ext4的格式\n#给机器打掉label，避免相关的任务/pod/daemonset被调度这个机器上 #一路umount,去掉所有正在使用vdb的挂载，执行完了还是不能做挂载或者格式化，因为有进程再用，需要重启 umount -l /dev/vdb umount -l /var/lib/container umount -l /var/lib/kubelet/ umount -l /var/lib/docker #注释掉原先挂载/dev/vdb的内容，里面有很多挂载的配置，避免重启后还是会挂载 vim /etc/fstab #重启 shutdown -r now #格式化创建xfs的文件系统 mkfs.xfs -f /dev/vdb #，把下面命令写入到/etc/fstab里面，保证正确的挂载 /dev/vdb /var/lib/container xfs defaults 0 0 /var/lib/container/kubelet /var/lib/kubelet none defaults,bind 0 0 /var/lib/container/docker /var/lib/docker none defaults,bind 0 0 #重启 # 这个时候vdb已经是xfs的了，可以注册到阿里云的机器里面了 # 首先进入节点节点，选择机器后批量移除，然后选择手动添加节点，需要每一台每一台操作，在具体的机器上执行拷贝的命令 #给机器打上对应的label 1.8 怎么计算需要机器 # 这个问题一般是和实际的job运行时长相关的，实际上计算起来并不困难：\n计算相关任务的运行时间，统计近几天的job数量和运行时间，计算一个平均时长t 计算任务对资源的需求从而计算出目前的单台机器的qps，一般是qps=(并发数)/(运行时间) 统计每天job运行的时间分布范围，这里的运行时间是正常的平均时间，这里可以按照28定律估算需要的qps，简单来说就是每天的20%的时间，跑了80%的任务，所以一般是all-qps=(job count * 0.8)/(总运行时间*0.2) 使用all-qps/qps计算需要的机器数量，再留出30%的富余。最终得出机器总量。 1.9 怎么拆分计算的runner的个数 # 面临的问题主要有三个：\n如何按照所有job的运行时候的资源区分出来不同的runner（的个数）？ 如果按照第一个问题正确地设置了不同的runner，那么如何设置每个runner的job运行时候的资源呢？ 前两个问题都解决的情况下，怎么设置每个runner的并发数量呢？ 前两个问题感觉是一致的，是个散点图的聚类分类问题，类别确定了就可以计算。首先需要收集历史数据pod对于内存的需求，然后画出散点图。这个时候就可以开始按照范围进行筛选了，筛选完了之后1h内统计出来，min/midum/large = 2/1/3，使用加权平均，和取最大值同时考虑，内存request拆分为：0.5G，7G，17G。关于第三个问题，设置runner的并发数量，实际上是和资源的数量相关联的，有两种分析手段：\n统计一下一个下午并发的job的数量和种类，看应该设置runner的并发数量多少 单纯按照机器支持的最大量来计算同时能够跑多少 实际上这里面的问题是，第二种方法是纯贪心，两个结合到一起更合理一些。统计了我们任务发现我们的job实际上分歧特别大，按照small:medium:large的比例和运行时间来简单加权，计算出来的比例为15:30:60，经过一个繁忙的一下午最后发现可以容纳为15:30:70的容量，基本就打到了极限\n目前我们的资源利用率不够高，大概四五台机器的请求值为90%，其真正的使用值只有50%查出来了30%的余地\n1.10 git的奇怪问题 # 我们有一个巨大的地图仓库，里面混杂着大量的git lfs文件，这个仓库非常大，因此我拉取了重点关注的单个分支即clone的时候挤上了\u0026ndash;single-branch的选项。这两天遇到了一个奇怪的问题，执行git push 会报错\nLocking support detected on remote \u0026#34;origin\u0026#34;. Consider enabling it with: $ git config lfs.https://xxxxxxx.git/info/lfs.locksverify true ref HEAD:: missing object: 003d38e4b3d22ee0610d9ec800bca7ce3cf70ef9 Uploading LFS objects: 100% (125882/125882), 16 GB | 3.9 MB/s, done. error: failed to push some refs to \u0026#39;xxxxxxxxx.git\u0026#39; git push [MAP-CI-DAILY/20221126_0252] failed. 查了一部分issue:https://github.com/git-lfs/git-lfs/issues/3587, https://stackoverflow.com/questions/70923109/git-lfs-missing-object-on-push-even-if-it-shouldnt-be\n执行了下面的命令，修复了单次的push，但是第二天又出现了问题，简单来说发现是只要拉single-branch就会出现这个问题\ngit repack -adf 怎么办。。。头太大了，最后我切换了新版本的git并且除了拉取单个分支，并且拉取了所有的分支之后，再次进行track就没问题了\n结尾 # 唉，尴尬\n","date":"2021 年 10 月 11 日","externalUrl":null,"permalink":"/posts/2021-10-28-gitlabjob%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/","section":"Posts","summary":"","title":"gitlab常见问题总结","type":"posts"},{"content":" CPP奇技淫巧 # 3 parameter pack # 参考：\nhttps://en.cppreference.com/w/cpp/language/parameter_pack\nhttps://kheresy.wordpress.com/2017/05/05/parameter-pack-in-c11/\n今天在写一个redis执行命令的函数，然后需要用到不定函数，所以写了一个不定函数的redis调用的函数.代码非常简单就是一个不定函数的调用和执行\ntemplate\u0026lt;class ... Types\u0026gt; redisReply* perfom_redis_action(Types ... args) { redisReply *reply = redisCommand(context_, args...); int try_times = 0; int ret_value = SET_TO_REDIS_INTERNAL_ERROR; /* Connection error will abort directly, connect but reply error will retry */ while (reply == NULL \u0026amp;\u0026amp; try_times \u0026lt;= MAX_CONNECT_TIMES) { LOG(error) \u0026lt;\u0026lt; \u0026#34;Error: \u0026#34;\u0026lt;\u0026lt; context_-\u0026gt;err; int connect_status = reconnect(); if (connect_status != CACHE_SERVER_CONNECTED) { if (try_times == MAX_CONNECT_TIMES) { return reply; } continue; } reply = redisCommand(context_, args...); ++try_times; } return reply; } 今天又写了一次parameter pack的奇怪写法，不过理论上使用std::function更合适。\n上下文：简单来说就是我有个函数想要每次调用，这个调用的函数应该是可以变化的，可以随意指定\n方法1 泛型编程 parameter pack\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;optional\u0026gt; // Assuming you have a DataFrame class defined class DataFrame { public: int ref = 0; // ... Define the DataFrame class implementation }; void myCallbackFunction(const DataFrame\u0026amp; data, int x, double y) { std::cout \u0026lt;\u0026lt; \u0026#34;Callback function called with DataFrame and arguments: \u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; \u0026#34;, \u0026#34;\u0026lt;\u0026lt; data.ref\u0026lt;\u0026lt;std::endl; } class Test { public: template \u0026lt;class... Types\u0026gt; using CallbackFunction = std::function\u0026lt;void(const DataFrame\u0026amp;, Types...)\u0026gt;; template \u0026lt;class... Types\u0026gt; void setCallback(CallbackFunction\u0026lt;Types...\u0026gt;\u0026amp;\u0026amp; callback) { void* voidPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;callback); cb_ = voidPtr; } template \u0026lt;class... Types\u0026gt; void executeCallback(const DataFrame\u0026amp; data, Types... args) const { if (cb_) { CallbackFunction\u0026lt;Types...\u0026gt;* function_pointer = static_cast\u0026lt;CallbackFunction\u0026lt;Types...\u0026gt;*\u0026gt;(*cb_); (*function_pointer)(data, args...); } else { std::cout \u0026lt;\u0026lt; \u0026#34;Callback not set!\u0026#34; \u0026lt;\u0026lt; std::endl; } } std::optional\u0026lt;void*\u0026gt; cb_; template \u0026lt;class... Types\u0026gt; void executeFunction(CallbackFunction\u0026lt;Types...\u0026gt;\u0026amp; callback, const DataFrame\u0026amp; data, Types... args) const { callback(data, args...); } }; Test::CallbackFunction\u0026lt;int, double\u0026gt; globalCallbackFunc = myCallbackFunction; // Outside function that takes Test as an argument void outsideFunction(Test\u0026amp; testObject) { testObject.setCallback\u0026lt;int,double\u0026gt;(std::move(globalCallbackFunc)); // Execute the callback using a sample DataFrame DataFrame data; data.ref=100; int arg1 = 4; double arg2 = 3.1415926; testObject.executeCallback(data, arg1, arg2); } int main() { Test testObject; outsideFunction(testObject); return 0; } 方法2 使用std::function，更通用的函数对象并不是函数指针，只能感慨真是个菜狗\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;optional\u0026gt; // Assuming you have a DataFrame class defined class DataFrame { public: int ref = 0; // ... Define the DataFrame class implementation }; void myCallbackFunction(const DataFrame\u0026amp; data, int x, double y) { std::cout \u0026lt;\u0026lt; \u0026#34;Callback function called with DataFrame and arguments: \u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; \u0026#34;, \u0026#34;\u0026lt;\u0026lt; data.ref\u0026lt;\u0026lt;std::endl; } class Test { public: using CallbackFunction = std::function\u0026lt;void(const DataFrame\u0026amp;)\u0026gt;; void setCallback(CallbackFunction\u0026amp;\u0026amp; callback) { cb_ = callback; } void executeCallback(const DataFrame\u0026amp; data) const { if (cb_) { (*cb_)(data); } else { std::cout \u0026lt;\u0026lt; \u0026#34;Callback not set!\u0026#34; \u0026lt;\u0026lt; std::endl; } } std::optional\u0026lt;CallbackFunction\u0026gt; cb_; }; // Outside function that takes Test as an argument void outsideFunction(Test\u0026amp; testObject) { int arg1 = 4; double arg2 = 3.1415926; auto callback_function = std::bind(myCallbackFunction,std::placeholders::_1, arg1, arg2); testObject.setCallback(std::move(callback_function)); // Execute the callback using a sample DataFrame DataFrame data; data.ref=100; testObject.executeCallback(data); } int main() { Test testObject; outsideFunction(testObject); return 0; } 结尾 # 唉，尴尬\n","date":"2021 年 9 月 16 日","externalUrl":null,"permalink":"/posts/2021-09-16-cpp%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/","section":"Posts","summary":"","title":"CPP奇技淫巧","type":"posts"},{"content":" 0 前言 # 很多东西记不住了，所以写一写\n1 Linux进程线程 # 和Unix不同，\n2 Linux进程调度 # 2.1 Linux CFS调度器 # 公平调度器的实现\n时间记账 调度器的实体结构 虚拟实时 进程选择 CFS使用红黑树组织进程 调度器入口 schedule()函数， 睡眠和唤醒 综上CFS的实现了解了，那么何时发生抢占和上下文切换？\n用户抢占，当从内核返回用户空间的时候，因为可以继续执行当前程序，那么自然就可以选择新的进程执行任务。所以再从中断处理程序或者系统调用返回的时候，都会检查need_resched标志，如果设置了就切换。总之，切换发生在\n从系统调用返回用户空间时 从中断处理程序返回用户空间时（这里注意，有人会疑问要是没有中断，那这个程序不是一直运行？时钟中断是一直运行的，所以必然会出现切换） 内核抢占\n问题，按照CFS的方法，何时会发生\n1 相关问题 # RISC和CISC区别：精简指令集和复杂指令集，相比CISC，RISC只保留了常用的简单指令。\n大端/小端：高地址在低位是大端，高地址在高位是小端，比方说0x12345678，大端就是0x12在低地址，而0x78在高地址。\n简述在你熟悉的CPU里面，一条存储读写指令的执行全过程：经典计算机的流水线架构是5级流水线，分别是取指，译码，执行，数据内存访问和返回，但是现代CPU加了超标量架构和乱序执行技术。\n这里面有个问题，乱序执行并不是指提交结果的时候是乱序的，提交结果的时候是按照指令次序的方式执行的，只不过\n内存屏障产生的原因\n高速缓存的工作方式。处理器先将虚拟地址传给高速缓存和tlb，处理器先用有效页帧号查找真实页帧号，如果未命中那么就去查询也表，如果命中了那么就能迅速拿到物理地址。\n同时，处理器可以根据索引找到对应的高速缓存行，这个时候就需要拿高速缓存行的标记和MMU的标记比较，如果命中那就可以通过对齐和选择直接拿到数据。如果未命中，那么处理器就使用物理地址来访问主存储器获得最终数据，并且填充高速缓存。这种事VIPT的高速缓存。\n高速缓存的映射方式\nPIPT和VIPT的区别，重名和同名又是什么？PIPT，物理地址的索引域和物理地址的标记，因此PIPT需要先查询TLB/MMU获得物理地址，然后才能查询高速缓存。而VIPT使用虚拟地址做index，物理地址做标记。可以直接查询高速缓存，而不需要获得物理地址。VIVT使用虚拟地址做索引，虚拟地址做标记。重名问题是指不同虚拟地址映射了同一个物理地址，而同名值得是相同的虚拟地址对应不同的物理地址。\n给出访问内存的流程：分页机制引入了虚拟存储器的概念。虚拟地址分为两个部分，以32位为例子VA[31:0]，如果每个页的大小为4kb，那么VA[11:0]，是内部偏移量；另一部分是虚拟页帧号，MMU的作用就是从虚拟页帧号转换为物理页帧号。处理器一般使用一张表来存储VPN到PFN的转移。由于访问内存比较慢，因此操作系统会使用TLB缓存虚拟地址对应的PFN，从而加速访问。\nHUGEPAGE的作用是什么？HUGEPAGE一方面是节省了从VPN到PFN存储的数量，毕竟原先是4MB，另一方面减少了TLB miss的概率。\nMESI协议的细节？\n如果4个核对一段数组写操作，这四个核的CPU L1 L2cache的状态变化，比方说数组是四个相邻的uint64，每个核只写自己对应的元素。\n唉，尴尬\n","date":"2021 年 8 月 23 日","externalUrl":null,"permalink":"/posts/2021-08-23-%E5%86%85%E6%A0%B8%E5%AD%A6%E4%B9%A0/","section":"Posts","summary":"","title":"内核学习","type":"posts"},{"content":" 2021-08-09-llvm学习 # 我最近想往我们代码库引入一个静态分析，所以需要使用clang AST matcher，所以下面的内容实际上包含两部分即AST的学习和我要用AST MATCHER解决什么东西？最后我使用Clang-Tidy建立了什么检查条件和解决了什么问题\n1 AST # 参考：\nhttps://clang.llvm.org/docs/IntroductionToTheClangAST.html 一些基础的概念的介绍，介绍起始的概念 https://jywhy6.zone/2020/11/27/clang-notes/#RecursiveASTVisitor-%20%E7%9B%B8%E5%85%B3 一片介绍比较详细的blog https://blog.csdn.net/qq_23599965/article/details/94595735 clang里面AST的基础类型的关系等东西 Clang参考的文档为：\nhttps://clang.llvm.org/doxygen/ 完整文档 https://clang.llvm.org/docs/LibASTMatchersReference.html ASTMatcher的内容 简单来说\n2 AST MATCHER # 可以阅读第二个链接的英文的话建议直接阅读，下面实际上就是个比较粗糙的翻译。\n参考：\nhttps://clang.llvm.org/docs/LibASTMatchers.html 如何使用AST-Matcher https://clang.llvm.org/docs/LibASTMatchersReference.html 一个具体的，使用AST Matcher的内容 https://xinhuang.github.io/posts/2015-02-08-clang-tutorial-the-ast-matcher.html 给了一个AST Matcher的例子 AST Matcher主要包含三种不同类型的match：\nNode Matchers: 用来匹配特定类型的AST节点的MATCHER Narrowing Matchers: 用来匹配AST节点属性的MATCHER，可以用来缩小范围 Traversal Matchers: 用来匹配在AST节点之间遍历的MATCHER 这里有几点要注意，AST节点完全展开实际上内部有很多的隐式转换，默认的AST Matcher运行的结构为AsIs模式，这个模式要求必须精确匹配/忽略内部节点，因此如果不追求精确匹配，建议使用IgnoreUnlessSpelledInSource模式。\n使用clang query的话，需要使用下面命令来修改匹配模式\nset traversal IgnoreUnlessSpelledInSource 如果是C++代码，比方说修改clang-tidy的源码，使用这个源码\nFinder-\u0026gt;addMatcher(traverse(TK_IgnoreUnlessSpelledInSource, returnStmt(hasReturnArgument(integerLiteral(equals(0)))) ), this); 2.1 匹配构造函数里面调用两次 # stackoverflow上面的原链接：https://stackoverflow.com/questions/60435722/clang-ast-matchers-how-to-find-function-body-from-a-function-declaration\n想匹配的代码是\nclass Dummy_file { FILE *f1_; FILE *f2_; public: Dummy_file(const char* f1_name, const char* f2_name, const char * mode){ f1_ = fopen(f1_name, mode); f2_ = fopen(f2_name, mode); } ~Dummy_file(){ fclose(f1_); fclose(f2_); } }; 看上去还是比较直接的，相匹配的类别，其构造函数调用了两次fopen。对应到语法当中是有子节点，且子节点调用了两次fopen\n直接看\n//匹配构造函数 cxxConstructorDecl( //有子节点,这不不能用has是为了传递 hasDescendant( //调用了函数 callExpr( callee( //函数有名字fopen functionDecl(hasName(\u0026#34;fopen\u0026#34;)) ) ).bind(\u0026#34;fopencall\u0026#34;) ) ).bind(\u0026#34;ctr\u0026#34;) 2.2 检测比较，比较对象一个是自定的类型 # stackoverflow上面的原链接：https://stackoverflow.com/questions/59404925/clang-ast-matcher-for-variables-compared-to-different-variable-types\n代码为\ntypedef int my_type; void foo() { int x = 0;//this should be identified as need to be fixed my_type z = 0; if( x == z){ //match this case } } 比较的Matcher为\n// Match binary operators binaryOperator( // that are equality comparisons, hasOperatorName(\u0026#34;==\u0026#34;), // where one side refers to a variable hasEitherOperand(ignoringImpCasts(declRefExpr(to(varDecl( // whose type is a typedef or type alias hasType(typedefNameDecl( // named \u0026#34;::my_type\u0026#34; hasName(\u0026#34;::my_type\u0026#34;), // that aliases any type, which is bound to the name \u0026#34;aliased\u0026#34;, hasType(type().bind(\u0026#34;aliased\u0026#34;))))))))), // and where one side refers to a variable hasEitherOperand(ignoringImpCasts(declRefExpr(to(varDecl( // whose type is the same as the type bound to \u0026#34;aliased\u0026#34;, // which is bound to the name \u0026#34;declToChange\u0026#34;. hasType(type(equalsBoundNode(\u0026#34;aliased\u0026#34;)))).bind(\u0026#34;declToChange\u0026#34;)))))); 3 CLANG-QUERY # 这里我要先写一点东西，ast matcher是匹配到一个就完了的，也就是说\nhttps://firefox-source-docs.mozilla.org/code-quality/static-analysis/writing-new/clang-query.html 如何使用clang-query https://devblogs.microsoft.com/cppblog/exploring-clang-tooling-part-2-examining-the-clang-ast-with-clang-query/ 另一篇教学例子 单独拿出来CLANG-QUERY是为了能够验证AST或者看AST是否正常\n举一个简单的例子，下面的代码\nint f(int x) { int result = (x / 42); return result; } class un_init_double { public: un_init_double() { init_param_ = 0; } bool compare(un_init_double\u0026amp; other) { if (other.un_init_param_ == un_init_param_) { return true; } return false; } private: double un_init_param_; double init_param_; }; 先dump一下AST树看下。\n函数f的dump就很简单。就是一个FunctionDecl（附带着ParmVarDecl，这个后面用了DeclRefExpr引用）包着一个CompoundStmt：先一个DeclStmt\u0026mdash;VarDecl，里面用了BinaryOperator。这里注意这里面有一个ImplicitCastExpr的隐式转换（从左值到右值），然后除以一个整数字面量IntegerLiteral。最后一个ReturnStmt内部有个隐式转换从左值到右值，而且用了旧的引用DeclRefExpr 然后是un_init_double的定义，可以看到提供了几个生成的构造函数。 TranslationUnitDecl 0x138046208 \u0026lt;\u0026lt;invalid sloc\u0026gt;\u0026gt; \u0026lt;invalid sloc\u0026gt; ......... |-FunctionDecl 0x1300133a0 \u0026lt;test.cc:1:1, line:4:1\u0026gt; line:1:5 f \u0026#39;int (int)\u0026#39; | |-ParmVarDecl 0x1300132d0 \u0026lt;col:7, col:11\u0026gt; col:11 used x \u0026#39;int\u0026#39; | `-CompoundStmt 0x130013608 \u0026lt;col:14, line:4:1\u0026gt; | |-DeclStmt 0x1300135a8 \u0026lt;line:2:3, col:24\u0026gt; | | `-VarDecl 0x1300134a8 \u0026lt;col:3, col:23\u0026gt; col:7 used result \u0026#39;int\u0026#39; cinit | | `-ParenExpr 0x130013588 \u0026lt;col:16, col:23\u0026gt; \u0026#39;int\u0026#39; | | `-BinaryOperator 0x130013568 \u0026lt;col:17, col:21\u0026gt; \u0026#39;int\u0026#39; \u0026#39;/\u0026#39; | | |-ImplicitCastExpr 0x130013550 \u0026lt;col:17\u0026gt; \u0026#39;int\u0026#39; \u0026lt;LValueToRValue\u0026gt; | | | `-DeclRefExpr 0x130013510 \u0026lt;col:17\u0026gt; \u0026#39;int\u0026#39; lvalue ParmVar 0x1300132d0 \u0026#39;x\u0026#39; \u0026#39;int\u0026#39; | | `-IntegerLiteral 0x130013530 \u0026lt;col:21\u0026gt; \u0026#39;int\u0026#39; 42 | `-ReturnStmt 0x1300135f8 \u0026lt;line:3:3, col:10\u0026gt; | `-ImplicitCastExpr 0x1300135e0 \u0026lt;col:10\u0026gt; \u0026#39;int\u0026#39; \u0026lt;LValueToRValue\u0026gt; | `-DeclRefExpr 0x1300135c0 \u0026lt;col:10\u0026gt; \u0026#39;int\u0026#39; lvalue Var 0x1300134a8 \u0026#39;result\u0026#39; \u0026#39;int\u0026#39; `-CXXRecordDecl 0x130013628 \u0026lt;line:6:1, line:20:1\u0026gt; line:6:7 class un_init_double definition |-DefinitionData pass_in_registers standard_layout trivially_copyable has_user_declared_ctor can_const_default_init | |-DefaultConstructor exists non_trivial user_provided | |-CopyConstructor simple trivial has_const_param needs_implicit implicit_has_const_param | |-MoveConstructor exists simple trivial needs_implicit | |-CopyAssignment simple trivial has_const_param needs_implicit implicit_has_const_param | |-MoveAssignment exists simple trivial needs_implicit | `-Destructor simple irrelevant trivial needs_implicit |-CXXRecordDecl 0x130013748 \u0026lt;col:1, col:7\u0026gt; col:7 implicit referenced class un_init_double |-AccessSpecDecl 0x1300137d8 \u0026lt;line:7:3, col:9\u0026gt; col:3 public |-CXXConstructorDecl 0x130013888 \u0026lt;line:8:5, line:10:5\u0026gt; line:8:5 un_init_double \u0026#39;void ()\u0026#39; | `-CompoundStmt 0x130044ec0 \u0026lt;col:22, line:10:5\u0026gt; | `-BinaryOperator 0x130044ea0 \u0026lt;line:9:7, col:21\u0026gt; \u0026#39;double\u0026#39; lvalue \u0026#39;=\u0026#39; | |-MemberExpr 0x130044e38 \u0026lt;col:7\u0026gt; \u0026#39;double\u0026#39; lvalue -\u0026gt;init_param_ 0x130044d78 | | `-CXXThisExpr 0x130044e28 \u0026lt;col:7\u0026gt; \u0026#39;un_init_double *\u0026#39; implicit this | `-ImplicitCastExpr 0x130044e88 \u0026lt;col:21\u0026gt; \u0026#39;double\u0026#39; \u0026lt;IntegralToFloating\u0026gt; | `-IntegerLiteral 0x130044e68 \u0026lt;col:21\u0026gt; \u0026#39;int\u0026#39; 0 |-CXXMethodDecl 0x130044c28 \u0026lt;line:11:5, line:16:5\u0026gt; line:11:10 compare \u0026#39;bool (un_init_double \u0026amp;)\u0026#39; | |-ParmVarDecl 0x130013968 \u0026lt;col:18, col:34\u0026gt; col:34 used other \u0026#39;un_init_double \u0026amp;\u0026#39; | `-CompoundStmt 0x130045030 \u0026lt;col:41, line:16:5\u0026gt; | |-IfStmt 0x130044ff0 \u0026lt;line:12:7, line:14:7\u0026gt; | | |-BinaryOperator 0x130044f98 \u0026lt;line:12:11, col:35\u0026gt; \u0026#39;bool\u0026#39; \u0026#39;==\u0026#39; | | | |-ImplicitCastExpr 0x130044f68 \u0026lt;col:11, col:17\u0026gt; \u0026#39;double\u0026#39; \u0026lt;LValueToRValue\u0026gt; | | | | `-MemberExpr 0x130044ef8 \u0026lt;col:11, col:17\u0026gt; \u0026#39;double\u0026#39; lvalue .un_init_param_ 0x130044d10 | | | | `-DeclRefExpr 0x130044ed8 \u0026lt;col:11\u0026gt; \u0026#39;un_init_double\u0026#39; lvalue ParmVar 0x130013968 \u0026#39;other\u0026#39; \u0026#39;un_init_double \u0026amp;\u0026#39; | | | `-ImplicitCastExpr 0x130044f80 \u0026lt;col:35\u0026gt; \u0026#39;double\u0026#39; \u0026lt;LValueToRValue\u0026gt; | | | `-MemberExpr 0x130044f38 \u0026lt;col:35\u0026gt; \u0026#39;double\u0026#39; lvalue -\u0026gt;un_init_param_ 0x130044d10 | | | `-CXXThisExpr 0x130044f28 \u0026lt;col:35\u0026gt; \u0026#39;un_init_double *\u0026#39; implicit this | | `-CompoundStmt 0x130044fd8 \u0026lt;col:51, line:14:7\u0026gt; | | `-ReturnStmt 0x130044fc8 \u0026lt;line:13:9, col:16\u0026gt; | | `-CXXBoolLiteralExpr 0x130044fb8 \u0026lt;col:16\u0026gt; \u0026#39;bool\u0026#39; true | `-ReturnStmt 0x130045020 \u0026lt;line:15:7, col:14\u0026gt; | `-CXXBoolLiteralExpr 0x130045010 \u0026lt;col:14\u0026gt; \u0026#39;bool\u0026#39; false |-AccessSpecDecl 0x130044cd0 \u0026lt;line:17:3, col:10\u0026gt; col:3 private |-FieldDecl 0x130044d10 \u0026lt;line:18:5, col:12\u0026gt; col:12 referenced un_init_param_ \u0026#39;double\u0026#39; `-FieldDecl 0x130044d78 \u0026lt;line:19:5, col:12\u0026gt; col:12 referenced init_param_ \u0026#39;double\u0026#39; ld: file too small (length=0) file \u0026#39;/var/folders/70/sz5vlj3n0qj2t4ktcw4qbpy00000gn/T/test-e8b440.o\u0026#39; for architecture arm64 clang-13: error: linker command failed with exit code 1 (use -v to see invocation) 希望找到一下几个地方：\n返回值为int的函数 存在double成员，且未显式初始化的类别 存在double成员，且比较直接用的==而不是double减法比较 使用clang-query查看文件\nclang-query test.cc -- 3.1 匹配返回int的函数 # 首先看第一个匹配，返回值为int的函数，下面的匹配能够拿到这个结果。可是在老版本的clang-query(llvm 13)的版本会报错说没有hasReturnTyoeLoc这个matcher。老版本的clang-query怎么办呢？看第二个方法\n# 这种方法在clang13 里面用不了 clang-query\u0026gt; match functionDecl(hasReturnTypeLoc(loc(asString(\u0026#34;int\u0026#34;)))) # 这种理论上可以用，但是我还没有测试 clang-query\u0026gt; match functionDecl(returns(asString(\u0026#34;int\u0026#34;))) 3.2 匹配存在double成员，且未显式初始化的类别 # 这里面我参考了这篇文章：Detecting Uninitialized Variables in C++ with the Clang Static Analyzer∗\n我理解这里未显式初始化匹配实际上就是匹配构造函数没有给double成员赋值。那么第一个思路类别的属性匹配，且没有调用=号。这个时候需要注意，我们需要引入逻辑运算属性matcher：allOf, anyOf, anything and unless。\n一步一步来\n构造函数调用了binaryOperator\u0026quot;=\u0026ldquo;号 匹配函数体里面有属性表达式的构造函数 # 匹配调用了=的构造函数 clang-query\u0026gt; match cxxConstructorDecl(hasDescendant(binaryOperator(hasOperatorName(\u0026#34;=\u0026#34;)))) Match #1: /home/qcraft/code_test/ast_dump/test.cpp:8:5: note: \u0026#34;root\u0026#34; binds here un_init_double() { ^~~~~~~~~~~~~~~~~~ 1 match. clang-query\u0026gt; #匹配函数体里面有属性表达式的构造函数 clang-query\u0026gt; match cxxConstructorDecl(hasDescendant(memberExpr())) Match #1: /home/qcraft/code_test/ast_dump/test.cpp:8:5: note: \u0026#34;root\u0026#34; binds here un_init_double() { ^~~~~~~~~~~~~~~~~~ 1 match. clang-query\u0026gt; 最后再加上我们要匹配的是构造函数，fieldDecl没赋值的。我目前没想到特别合适的，所以写了一个比较复杂的\n// match record cxxRecordDecl( has( // constuctor has init double fieldDecl with binaryoperator = , bind to init_double_field cxxConstructorDecl( hasDescendant( binaryOperator( hasOperatorName(\u0026#34;=\u0026#34;), hasEitherOperand(memberExpr(hasDeclaration(fieldDecl(hasType(asString(\u0026#34;double\u0026#34;))).bind(\u0026#34;init_double_field\u0026#34;)))) ) ) ) ), has( // match double field which didn\u0026#39;t call binaryoperator = in constructor fieldDecl(hasType(asString(\u0026#34;double\u0026#34;)), unless(equalsBoundNode(\u0026#34;init_double_field\u0026#34;))).bind(\u0026#34;un_init_double_field\u0026#34;) ) ) 这个写起来比较复杂，但是目前看起来可以初步解决问题。但是实际上这个结果是错误的，为什么呢？因为init_double_field实际上只匹配到了第一个init_param，即找到匹配的就返回，因此init_double_field是不充足的，如果也对un_init_param_做了赋值，那么init_doubel_field没办法匹配出来这个。因此要想办法让init_double_field的matcher绑定到每个binaryOperator上。最后我改成了下面的语法\ncxxRecordDecl( has( cxxConstructorDecl( forEachDescendant( binaryOperator( hasOperatorName(\u0026#34;=\u0026#34;), hasEitherOperand(memberExpr(hasDeclaration(fieldDecl(hasType(asString(\u0026#34;double\u0026#34;))).bind(\u0026#34;init_double_field\u0026#34;)))) ) ) ) ), has( fieldDecl(hasType(asString(\u0026#34;double\u0026#34;)), unless(equalsBoundNode(\u0026#34;init_double_field\u0026#34;))).bind(\u0026#34;un_init_double_field\u0026#34;) ) ) 使用新的match匹配能够正确的进行检查\nclang-query\u0026gt; match cxxRecordDecl(has(cxxConstructorDecl(forEachDescendant(binaryOperator(hasOperatorName(\u0026#34;=\u0026#34;),hasEitherOperand(memberExpr(hasDeclaration(fieldDecl(hasType(asString(\u0026#34;double\u0026#34;))).bind(\u0026#34;init_double_field\u0026#34;)))))))), has(fieldDecl(hasType(asString(\u0026#34;double\u0026#34;)), unless(equalsBoundNode(\u0026#34;init_double_field\u0026#34;))).bind(\u0026#34;un_init_double_field\u0026#34;))) Match #1: /home/qcraft/code_test/ast_dump/test.cpp:19:5: note: \u0026#34;init_double_field\u0026#34; binds here double init_param_; ^~~~~~~~~~~~~~~~~~ /home/qcraft/code_test/ast_dump/test.cpp:6:1: note: \u0026#34;root\u0026#34; binds here class un_init_double { ^~~~~~~~~~~~~~~~~~~~~~ /home/qcraft/code_test/ast_dump/test.cpp:18:5: note: \u0026#34;un_init_double_field\u0026#34; binds here double un_init_param_; ^~~~~~~~~~~~~~~~~~~~~ 1 match. clang-query\u0026gt; 3.3 存在double成员，且比较直接用的==而不是减法 # 相比于第二种，感觉这个就简单很多。毕竟没有那么复杂的环境\nfunctionDecl( hasDescendant( binaryOperator( hasOperatorName(\u0026#34;==\u0026#34;), hasEitherOperand(hasType(asString(\u0026#34;double\u0026#34;))) ) ) ) clang-query\u0026gt; match functionDecl(hasDescendant(binaryOperator(hasOperatorName(\u0026#34;==\u0026#34;), hasEitherOperand(hasType(asString(\u0026#34;double\u0026#34;)))))) Match #1: /home/qcraft/code_test/ast_dump/test.cpp:11:5: note: \u0026#34;root\u0026#34; binds here bool compare(un_init_double\u0026amp; other) { ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1 match. 4 Clang-Tidy # 参考链接：\nhttps://clang.llvm.org/extra/clang-tidy/Contributing.html 两个例子：\n一个是检查出来，函数/类的名字以smzdm开头的 检查出来类，这个类要么有未初始化的double成员，要么有double成员的比较，而这个比较使用的是等号，而不是两个相减，小于某个数值 5 用clang-query来做些简单的代码分析 # 一些可以供参考的cpp-rule\nhttps://rules.sonarsource.com/cpp 源码分析软件sonar的规则 目前可以做到的\n检测double的==比较 检测某些不安全的函数 检测boost:: 唉，尴尬\n","date":"2021 年 8 月 9 日","externalUrl":null,"permalink":"/posts/2021-08-09-llvm%E5%AD%A6%E4%B9%A0/","section":"Posts","summary":"","title":"llvm学习","type":"posts"},{"content":" C++开发工具库 # 1 并发多线程map # 坦白讲核心思想都是一样子的，多个bucket，然后每个bucket下面挂一个红黑树(实际上就是stl的map），红黑树使用boost的读写锁来保护，源代码里面我禁用了拷贝构造和赋值运算符，因为RA2（锁）不可拷贝是一个通识，如果想拷贝那么就注释调宏标记的地方，但是尽量建议使用shared_ptr来做这个事情。\n#ifndef __CONCURRENT_MAP_H__ #define __CONCURRENT_MAP_H__ #include \u0026lt;map\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;boost/thread/locks.hpp\u0026gt; #include \u0026lt;boost/thread/shared_mutex.hpp\u0026gt; /* 使用此代码时请注意，直接用.h文件，不要写.cpp，使用置入式模型*/ using std::map; using namespace boost; /* bucket的代码没什么难度，只需要注意一点，更新和插入的区别。 更新是原先必须有这个值 */ /* 因为每次查询更新数据都只会锁住一个元素，不会锁住多个元素，所以不会产生死锁 */ template\u0026lt;class KEY_T, class VALUE_T, class Compare\u0026gt; class ConcurrentBucket { public: ConcurrentBucket() { } virtual ~ConcurrentBucket() { write_lock lock(rwlock_); map_.clear(); } bool Lookup(const KEY_T \u0026amp;key, VALUE_T \u0026amp;value) { bool ret = false; /* 锁单独的生命周期要短，最好不要和原子变量混在一起 */ read_lock lock(rwlock_); typename std::map\u0026lt;KEY_T, VALUE_T\u0026gt;::iterator find = map_.find(key); if (find != map_.end()) { value = (*find).second; /* 从生成的代码来看，编译器会生成一个默认的赋值运算符函数，每个对象都会执行拷贝 */ ret = true; } return ret; } uint64_t Size() { read_lock lock(rwlock_); return map_.size(); } void Clear() { write_lock lock(rwlock_); map_.clear(); } bool Contain(const KEY_T \u0026amp;key) { bool ret = false; /* 锁单独的生命周期要短，最好不要和原子变量混在一起 */ read_lock lock(rwlock_); typename std::map\u0026lt;KEY_T, VALUE_T\u0026gt;::iterator find = map_.find(key); if (find != map_.end()) { ret = true; } return ret; } bool Insert(const KEY_T \u0026amp;key, const VALUE_T \u0026amp;value) { bool ret = false; { write_lock lock(rwlock_); ret = InsertWithoutLock(key, value); } return ret; } bool Update(const KEY_T \u0026amp;key, const VALUE_T \u0026amp;value) { bool ret = false; { write_lock lock(rwlock_); ret = UpdateWithoutLock(key, value); } return ret; } void Remove(const KEY_T \u0026amp;key) { { write_lock lock(rwlock_); RemoveWithoutLock(key); } } void GetAllKey(std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026amp;list) { read_lock lock(rwlock_); typename std::map\u0026lt;KEY_T, VALUE_T\u0026gt;::iterator iter = map_.begin(); for ( ; iter != map_.end(); ++iter) { list.push_back(std::pair\u0026lt;KEY_T, VALUE_T\u0026gt;(iter-\u0026gt;first, iter-\u0026gt;second)); } return; } void UpdateKeyBatch(std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026amp;list) { { write_lock lock(rwlock_); typename std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt;::iterator iter = list.begin(); for (; iter != list.end(); ++iter) { UpdateWithoutLock(iter-\u0026gt;first, iter-\u0026gt;second); } } return; } void InsertKeyBatch(std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026amp;list) { { write_lock lock(rwlock_); typename std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt;::iterator iter = list.begin(); for (; iter != list.end(); ++iter) { InsertWithoutLock(iter-\u0026gt;first, iter-\u0026gt;second); } } return; } void RemoveKeyBatch(std::vector\u0026lt;KEY_T\u0026gt; \u0026amp;list) { { write_lock lock(rwlock_); typename std::vector\u0026lt;KEY_T\u0026gt;::iterator iter = list.begin(); for (; iter != list.end(); ++iter) { RemoveWithoutLock((*iter)); } } return; } void Echo() const { std::cout \u0026lt;\u0026lt; \u0026#34; oh ho\u0026#34; \u0026lt;\u0026lt; std::endl; } private: void RemoveWithoutLock(const KEY_T \u0026amp;key) { typename std::map\u0026lt;KEY_T, VALUE_T\u0026gt;::iterator find = map_.find(key); if (find != map_.end()) { map_.erase(find); } return; } bool InsertWithoutLock(const KEY_T \u0026amp;key, const VALUE_T \u0026amp;value) { bool ret = false; typename std::map\u0026lt;KEY_T, VALUE_T\u0026gt;::iterator find = map_.find(key); if (find == map_.end()) { map_.insert(std::pair\u0026lt;KEY_T, VALUE_T\u0026gt;(key, value)); ret = true; } else { if (Compare()(value, find-\u0026gt;second)) { map_.erase(find); map_.insert(std::pair\u0026lt;KEY_T, VALUE_T\u0026gt;(key, value)); ret = true; } } return ret; } bool UpdateWithoutLock(const KEY_T \u0026amp;key, const VALUE_T \u0026amp;value) { bool ret = false; typename std::map\u0026lt;KEY_T, VALUE_T\u0026gt;::iterator find = map_.find(key); if (find != map_.end()) { if (Compare()(value, find-\u0026gt;second)) { map_.erase(find); map_.insert(std::pair\u0026lt;KEY_T, VALUE_T\u0026gt;(key, value)); ret = true; } } return ret; } private: typedef boost::shared_lock\u0026lt;boost::shared_mutex\u0026gt; read_lock; typedef boost::unique_lock\u0026lt;boost::shared_mutex\u0026gt; write_lock; std::map\u0026lt;KEY_T, VALUE_T\u0026gt; map_; /* using boost shared_mutex, boost version 1.6.9 */ boost::shared_mutex rwlock_; }; template\u0026lt;typename KEY_T, typename VALUE_T, typename Compare, typename Hash=std::hash\u0026lt;KEY_T\u0026gt; \u0026gt; class ConcurrentMap { public: ConcurrentMap(uint64_t bucket_nums = 61, Hash const\u0026amp; hasher = Hash()) : buckets_(bucket_nums), hasher_ (hasher) { for (uint64_t i = 0; i \u0026lt; bucket_nums; ++i) { buckets_[i].reset(new ConcurrentBucket\u0026lt;KEY_T, VALUE_T, Compare\u0026gt;); } } bool LookUp(const KEY_T \u0026amp;key, VALUE_T \u0026amp;value) { return GetBucket(key).Lookup(key, value); } bool Contain(const KEY_T \u0026amp;key) { return GetBucket(key).Contain(key); } bool Insert(const KEY_T \u0026amp;key, const VALUE_T \u0026amp;value) { return GetBucket(key).Insert(key, value); } bool Update(const KEY_T \u0026amp;key, const VALUE_T \u0026amp;value) { return GetBucket(key).Update(key, value); } bool Delete(const KEY_T \u0026amp;key) { GetBucket(key).Remove(key); return true; } void GetAllKey(std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026amp;list) { list.clear(); #if 0 //auto iter = buckets_.begin(); //这里要注意，先得对iter做解引用，得到uniqueptr,然后对unique_ptr做解引用或者用-\u0026gt;才能进行调用 typename std::vector\u0026lt;std::unique_ptr\u0026lt;ConcurrentBucket\u0026lt;KEY_T, VALUE_T, Compare\u0026gt; \u0026gt; \u0026gt;::iterator iter = buckets_.begin(); for ( ; iter != buckets_.end(); ++iter ) { (*iter)-\u0026gt;GetAllKey(list); } #endif for (size_t bucket_index = 0; bucket_index \u0026lt; buckets_.size(); ++bucket_index) { buckets_[bucket_index]-\u0026gt;GetAllKey(list); } return; } void UpdateKeyBatch(std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026amp;list) { /* 更新数组的个数需要和桶的个数一致 */ std::vector\u0026lt;std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026gt; update_lists(buckets_.size()); /* 将更新的元素丢入数组之中 */ typename std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt;::iterator iter = list.begin(); for (; iter != list.end(); ++iter) { std::size_t bucket_index = hasher_(iter-\u0026gt;first) % buckets_.size(); update_lists[bucket_index].push_back(std::pair\u0026lt;KEY_T, VALUE_T\u0026gt;(iter-\u0026gt;first, iter-\u0026gt;second)); } /* 将对应的元素更新到对应的bucket里面 */ for (size_t bucket_index = 0; bucket_index \u0026lt; buckets_.size(); ++bucket_index) { buckets_[bucket_index]-\u0026gt;UpdateKeyBatch(update_lists[bucket_index]); } } void RemoveKeyBatch(std::vector\u0026lt;KEY_T\u0026gt; \u0026amp;list) { /* 删除数组的个数需要和桶的个数一致 */ std::vector\u0026lt;std::vector\u0026lt;KEY_T\u0026gt; \u0026gt; remove_lists(buckets_.size()); /* 将删除的元素丢入数组之中 */ typename std::vector\u0026lt;KEY_T\u0026gt;::iterator iter = list.begin(); for (; iter != list.end(); ++iter) { std::size_t bucket_index = hasher_(*iter) % buckets_.size(); remove_lists[bucket_index].push_back(*iter); } /* 将对应的元素更新到对应的bucket里面 */ for (size_t bucket_index = 0; bucket_index \u0026lt; buckets_.size(); ++bucket_index) { buckets_[bucket_index]-\u0026gt;RemoveKeyBatch(remove_lists[bucket_index]); } } void InsertKeyBatch(std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026amp;list) { /* 更新数组的个数需要和桶的个数一致 */ std::vector\u0026lt;std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026gt; Insert_lists(buckets_.size()); /* 将更新的元素丢入数组之中 */ typename std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt;::iterator iter = list.begin(); for (; iter != list.end(); ++iter) { std::size_t bucket_index = hasher_(iter-\u0026gt;first) % buckets_.size(); Insert_lists[bucket_index].push_back(std::pair\u0026lt;KEY_T, VALUE_T\u0026gt;(iter-\u0026gt;first, iter-\u0026gt;second)); } /* 将对应的元素更新到对应的bucket里面 */ for (size_t bucket_index = 0; bucket_index \u0026lt; buckets_.size(); ++bucket_index) { buckets_[bucket_index]-\u0026gt;InsertKeyBatch(Insert_lists[bucket_index]); } } ConcurrentBucket\u0026lt;KEY_T, VALUE_T, Compare\u0026gt;\u0026amp; GetBucket(KEY_T const\u0026amp; key) const { std::size_t const bucket_index = hasher_(key)% buckets_.size(); return *buckets_[bucket_index]; } uint64_t Size() { uint64_t total_size = 0; for (size_t i = 0 ; i \u0026lt; buckets_.size(); ++i) { total_size += buckets_[i]-\u0026gt;Size(); } return total_size; } void Clear() { for (size_t i = 0 ; i \u0026lt; buckets_.size(); ++i) { buckets_[i]-\u0026gt;Clear(); } } /* 禁用这两者来保证绝对的安全，主要是本身mutex就是禁止拷贝的*/ /* 禁用拷贝构造 */ ConcurrentMap(ConcurrentMap const \u0026amp;other) = delete; /* 禁用赋值运算符 */ ConcurrentMap\u0026amp; operator=(ConcurrentMap const \u0026amp;other) = delete; #if 0 /* 线程安全的拷贝构造函数 */ ConcurrentMap(ConcurrentMap const \u0026amp;other) : buckets_(other.buckets_.size()), hasher_(other.hasher_) { for (uint64_t i = 0; i \u0026lt; buckets_.size(); ++i) { buckets_[i].reset(new ConcurrentBucket\u0026lt;KEY_T, VALUE_T, Compare\u0026gt;); } std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; list; other.GetAllKey(list); InsertKeyBatch(list); } ConcurrentMap\u0026amp; operator=(ConcurrentMap const \u0026amp;other) { /* 务必保证两个bucket的大小一致，不提供可伸缩的bucket*/ assert(buckets_.size() == other.buckets_.size()); hasher_ = other.hasher_; for (uint64_t i = 0; i \u0026lt; buckets_.size(); ++i) { buckets_[i].reset(new ConcurrentBucket\u0026lt;KEY_T, VALUE_T, Compare\u0026gt;); } std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; list; other.GetAllKey(list); InsertKeyBatch(list); } #endif private: /* 使用unique_ptr保证内存安全 */ std::vector\u0026lt;std::unique_ptr\u0026lt;ConcurrentBucket\u0026lt;KEY_T, VALUE_T, Compare\u0026gt; \u0026gt; \u0026gt; buckets_; Hash hasher_; }; #endif 2 并发LRU实现 # 实际上并发LRU的实现和并发MAP是非常相似的，并发MAP是挂了一堆的BUCKET，而并发LRU实际上也是挂了一堆的LRUBucket，然后每个找到对应的LRU。但是这个严格说，并不是完全的LRU，因为它拆分了几个不同的链表出来。我目前在用的时候使用的还是最简单的LRU，性能比较低但是严格。\n#ifndef __LRU_H__ #define __LRU_H__ #include \u0026lt;boost/thread/locks.hpp\u0026gt; #include \u0026lt;boost/thread/shared_mutex.hpp\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;unordered_map\u0026gt; template\u0026lt;typename KEY_T, typename VALUE_T\u0026gt; class LRU { public: LRU(uint64_t capacity = 31) : capacity_(capacity), size_(0) { } void Put(const KEY_T \u0026amp;key, const VALUE_T \u0026amp;value) { write_lock lock(rwlock_); auto iter = map_.find(key); if (iter != map_.end()) { touch(iter); } else { if (map_.size() == capacity_) { map_.erase(list_.back()); list_.pop_back(); } list_.push_front(key); } map_[key] = {value, list_.begin()}; } bool Get(const KEY_T \u0026amp;key, VALUE_T \u0026amp;value) { write_lock lock(rwlock_); auto iter = cache_.find(key); if (iter == cache_.end()) { return false; } touch(iter); value = iter-\u0026gt;second.first return true; } /* 没有的话返回一个新的VALUE_T回去，此时缓存是没有的 */ /* 如果有的话放到最开始的地方 */ VALUE_T Get(const KEY_T \u0026amp;key) { write_lock lock(rwlock_); auto iter = cache_.find(key); if (iter == cache_.end()) { return VALUE_T(); } touch(iter); return iter-\u0026gt;second.first; } bool GetAllKey(std::vector\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026amp;res) { read_lock lock(rwlock_); for (auto iter : map_) { res.push_back(std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; (iter.first, iter.second.second)); } return true; } private: void touch(typename std::map\u0026lt;KEY_T, std::pair\u0026lt;VALUE_T, typename std::list\u0026lt;KEY_T\u0026gt;::iterator\u0026gt; \u0026gt;::iterator iter) { KEY_T key = iter-\u0026gt;first; list_.erase(iter-\u0026gt;second.second); list_.push_front(key); iter-\u0026gt;second.second = list_.begin(); } private: typedef boost::shared_lock\u0026lt;boost::shared_mutex\u0026gt; read_lock; typedef boost::unique_lock\u0026lt;boost::shared_mutex\u0026gt; write_lock; uint64_t capacity_; uint64_t size_; boost::shared_mutex rwlock_; /* iterator前面需要加一个typename */ std::list\u0026lt;KEY_T\u0026gt; list_; std::map\u0026lt;KEY_T, std::pair\u0026lt;VALUE_T, typename std::list\u0026lt;KEY_T\u0026gt;::iterator\u0026gt; \u0026gt; map_; }; template\u0026lt;typename KEY_T, typename VALUE_T, typename Hash=std::hash\u0026lt;KEY_T\u0026gt; \u0026gt; class ConcurrentLRU { public: ConcurrentLRU(uint64_t bucket_nums = 11, Hash const\u0026amp; hasher = Hash()) : buckets_(bucket_nums), hasher_ (hasher) { for (uint64_t i = 0; i \u0026lt; bucket_nums; ++i) { buckets_[i].reset(new LRU\u0026lt;KEY_T, VALUE_T\u0026gt;); } } void Put(const KEY_T \u0026amp;key, const VALUE_T \u0026amp;value) { GetBucket(key).Put(key, value); return; } bool Get(const KEY_T \u0026amp;key, VALUE_T \u0026amp;value) { return GetBucket(key).Get(key, value); } /* 没有的话返回一个新的VALUE_T回去，此时缓存是没有的 */ /* 如果有的话放到最开始的地方 */ VALUE_T Get(const KEY_T \u0026amp;key) { return GetBucket(key).Get(key); } void GetAllKey(std::vector\u0026lt;std::pair\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026amp;list) { list.clear(); #if 0 //auto iter = buckets_.begin(); //这里要注意，先得对iter做解引用，得到uniqueptr,然后对unique_ptr做解引用或者用-\u0026gt;才能进行调用 typename std::vector\u0026lt;std::unique_ptr\u0026lt;LRU\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026gt;::iterator iter = buckets_.begin(); for ( ; iter != buckets_.end(); ++iter ) { (*iter)-\u0026gt;GetAllKey(list); } #endif for (size_t bucket_index = 0; bucket_index \u0026lt; buckets_.size(); ++bucket_index) { buckets_[bucket_index]-\u0026gt;GetAllKey(list); } return; } LRU\u0026lt;KEY_T, VALUE_T\u0026gt;\u0026amp; GetBucket(KEY_T const\u0026amp; key) const { std::size_t const bucket_index = hasher_(key)% buckets_.size(); return *buckets_[bucket_index]; } /* 禁用拷贝构造 */ ConcurrentLRU(ConcurrentLRU const \u0026amp;other) = delete; /* 禁用赋值运算符 */ ConcurrentLRU\u0026amp; operator=(ConcurrentLRU const \u0026amp;other) = delete; private: /* 使用unique_ptr保证内存安全 */ std::vector\u0026lt;std::unique_ptr\u0026lt;LRU\u0026lt;KEY_T, VALUE_T\u0026gt; \u0026gt; \u0026gt; buckets_; Hash hasher_; }; #endif 3 一个线程安全的连接池 # 下面这个连接池在写的时候由于需要证书更新，因此需要使用TLSSocketWrapper来包裹证书/密钥/ca证书。这里要注意为了实现每次握手的时候只使用新的证书，所以这里会加一个证书的时间戳，来保证用的都是新的证书。可以发现这样子即使证书握手失败也依然会拿新的证书来执行握手。\n该连接池首先执行tls握手，然后将tls握手的socket（boost::shared_ptr\u0026lt;ssl::stream\u0026lt;ip::tcp::socket\u0026gt; \u0026gt;）丢到LRU中，来保证lru总是缓存了最新的值，然后发送数据失败的情况下会重新建立连接。为了保活使用了http get对连接做get来探活，每15秒执行一次探活 。\n头文件：\n#ifndef __SYNC_TLS_CLIENT_H__ #define __SYNC_TLS_CLIENT_H__ #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026#34;lru.h\u0026#34; #include \u0026#34;singleton.h\u0026#34; #include \u0026#34;repeated_timer.h\u0026#34; #include \u0026lt;string\u0026gt; #include \u0026lt;istream\u0026gt; #include \u0026lt;ostream\u0026gt; #include \u0026lt;cstdlib\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026lt;boost/asio.hpp\u0026gt; #include \u0026lt;boost/asio/ssl.hpp\u0026gt; #include \u0026#34;boost/thread.hpp\u0026#34; #include \u0026#34;boost/function.hpp\u0026#34; #include \u0026#34;boost/shared_ptr.hpp\u0026#34; #include \u0026#34;boost/move/unique_ptr.hpp\u0026#34; #include \u0026#34;boost/make_shared.hpp\u0026#34; #include \u0026#34;boost/lockfree/spsc_queue.hpp\u0026#34; #include \u0026lt;boost/beast/core.hpp\u0026gt; #include \u0026lt;boost/beast/http.hpp\u0026gt; #include \u0026lt;boost/beast/version.hpp\u0026gt; #include \u0026lt;boost/asio/connect.hpp\u0026gt; #include \u0026lt;boost/asio/ip/tcp.hpp\u0026gt; #include \u0026lt;boost/asio/ssl/error.hpp\u0026gt; #include \u0026lt;boost/asio/ssl/stream.hpp\u0026gt; using tcp = boost::asio::ip::tcp; // from \u0026lt;boost/asio/ip/tcp.hpp\u0026gt; namespace ssl = boost::asio::ssl; // from \u0026lt;boost/asio/ssl.hpp\u0026gt; namespace http = boost::beast::http; // from \u0026lt;boost/beast/http.hpp\u0026gt; using namespace boost::asio; #define HTTP_11_VERSION 11 #define DEFAULT_HTTP_ALIVE_CONFIG \u0026#34;timeout=60, max=1000\u0026#34; #define CONTENT_TYPE_JSON \u0026#34;application/json; charset=utf-8\u0026#34; #define CONTENT_TYPE_PLAIN \u0026#34;text/plain; charset=utf-8\u0026#34; #define CONTENT_TYPE_HTML \u0026#34;text/html; charset=utf-8\u0026#34; #define CONNECT_MAX_TRY_TIMES 4 class TLSSocketWrapper { public: /* 连接函数被封装到了TLSSocketWrapper的构造函数里面 */ TLSSocketWrapper(const std::string \u0026amp;ip, const std::string \u0026amp;port, boost::asio::io_context \u0026amp;global_io_context, const std::string \u0026amp;cert, const std::string \u0026amp;key, const std::string \u0026amp;ca_cert, uint64_t time_stamp); std::string GetCert() const; std::string GetKey() const; std::string GetCaCert() const; uint64_t GetTimeStamp() const; bool HandshakeFinished() const; /* 下面两个不是线程安全的 */ int GetMessageCore(const std::string \u0026amp;server_path, std::string \u0026amp;header, std::string \u0026amp;body); int PostMessageCore(const std::string \u0026amp;server_path, const std::string \u0026amp;request_content_type, const std::string \u0026amp;request_body, std::string \u0026amp;header, std::string \u0026amp;body); private: typedef boost::shared_lock\u0026lt;boost::shared_mutex\u0026gt; read_lock; typedef boost::unique_lock\u0026lt;boost::shared_mutex\u0026gt; write_lock; boost::unique_ptr\u0026lt;ssl::stream\u0026lt;ip::tcp::socket\u0026gt; \u0026gt; real_socket_; boost::shared_mutex rwlock_; std::string ip_; std::string port_; std::string cert_; std::string key_; std::string ca_cert_; uint64_t time_stamp_; }; class TlsWrapperCompare { public: bool operator() (const boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; \u0026amp;a, const boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; \u0026amp;b) { return a-\u0026gt;GetTimeStamp() \u0026gt;= b-\u0026gt;GetTimeStamp(); } }; class SyncTlsConnectionManager : public hxn::Singleton\u0026lt;SyncTlsConnectionManager\u0026gt; { public: /* 目前，该实例负责维护数据并保活 */ void Init(); void HttpHeartBeat(); io_context\u0026amp; GetGlobalIOContext(); ConcurrentLRU\u0026lt;std::string, boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt;, TlsWrapperCompare\u0026gt;\u0026amp; GetGlobalSocketWrapper(); private: /* 第一个io context是给所有的tls连接用的 */ boost::asio::io_context global_io_context_; ConcurrentLRU\u0026lt;std::string, boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt;, TlsWrapperCompare\u0026gt; global_sockets_; /* 异步定时器+线程, 使用boost asio + chrono实现*/ boost::shared_ptr\u0026lt;boost::thread\u0026gt; loop_; boost::shared_ptr\u0026lt;RepeatedTimer\u0026gt; timer_; /* 该context负责给全局定时器使用 */ boost::shared_ptr\u0026lt;io_service\u0026gt; io_service_; }; /* asio socket的同步读写是线程安全的 */ class SyncTlsClient { public: /* 探活/保活接口专用构造函数 */ SyncTlsClient(const std::string \u0026amp;ip, const std::string \u0026amp;port, const boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; \u0026amp;connection); /* 时间戳为证书时间戳，或者说证书文件的时间戳 */ SyncTlsClient(const std::string \u0026amp;ip, const std::string \u0026amp;port, const std::string \u0026amp;cert, const std::string \u0026amp;key, const std::string \u0026amp;ca_cert, const uint64_t \u0026amp;time_stamp); /* http心跳报文实际上是个get请求 */ int HeartBeat(const std::string \u0026amp;server_path, std::string \u0026amp;response_header, std::string \u0026amp;response_body); int GetMessage(const std::string \u0026amp;server_path, std::string \u0026amp;response_header, std::string \u0026amp;response_body); int PostMessage(const std::string \u0026amp;server_path, const std::string \u0026amp;request_content_type, const std::string \u0026amp;request_body, std::string \u0026amp;response_header, std::string \u0026amp;response_body); private: boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; socket_wrapper_; /* 可以是ip/port也可能是host/port */ std::string ip_; std::string port_; }; #endif cpp文件\n#include \u0026#34;sync_tls_client.h\u0026#34; /* 构造函数只会在每个线程构造所以必然是线程安全的 */ TLSSocketWrapper::TLSSocketWrapper(const std::string \u0026amp;ip, const std::string \u0026amp;port, boost::asio::io_context \u0026amp;global_io_context, const std::string \u0026amp;cert, const std::string \u0026amp;key, const std::string \u0026amp;ca_cert, uint64_t time_stamp) : ip_(ip), port_(port), cert_(cert), key_(key), ca_cert_(ca_cert), time_stamp_(time_stamp) { int try_times = 0; while ((real_socket_ == nullptr) \u0026amp;\u0026amp; (try_times \u0026lt; CONNECT_MAX_TRY_TIMES)) { try { ssl::context ssl_context{ssl::context::sslv23_client}; /* 两者都不为空, 才执行load */ if (!(cert.empty() || key.empty())) { ssl_context.use_certificate_chain(buffer(cert.data(), cert.size())); ssl_context.use_private_key(buffer(key.data(), key.size()), ssl::context::file_format::pem); } if (!ca_cert.empty()) { ssl_context.add_certificate_authority(buffer(ca_cert.data(), ca_cert.size())); } real_socket_.reset(new ssl::stream\u0026lt;tcp::socket\u0026gt;(global_io_context, ssl_context)); boost::system::error_code ip_invalid; ip::address ip_address = ip::address::from_string(ip, ip_invalid); if (ip_invalid) { /* url */ tcp::resolver resolver{global_io_context}; auto const results = resolver.resolve(ip, port); connect(real_socket_-\u0026gt;next_layer(), results.begin(), results.end()); } else { tcp::endpoint endpoint(ip_address, std::stoi(port)); real_socket_-\u0026gt;next_layer().connect(endpoint); } /* keep下层socket alive */ real_socket_-\u0026gt;next_layer().set_option(socket_base::keep_alive(true)); real_socket_-\u0026gt;handshake(ssl::stream_base::client); } catch(std::exception const\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026#34;Handshake Error: \u0026#34; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; real_socket_ = nullptr; } ++try_times; } } std::string TLSSocketWrapper::GetCert() const { return cert_; } std::string TLSSocketWrapper::GetKey() const { return key_; } uint64_t TLSSocketWrapper::GetTimeStamp() const { return time_stamp_; } bool TLSSocketWrapper::HandshakeFinished() const { return real_socket_ != nullptr; } std::string TLSSocketWrapper::GetCaCert() const { return ca_cert_; } /* 返回的错误码是200表示get成功了，其它代表失败 */ int TLSSocketWrapper::GetMessageCore(const std::string \u0026amp;server_path, std::string \u0026amp;header, std::string \u0026amp;body) { int error_code; try { http::request\u0026lt;http::string_body\u0026gt; req(http::verb::get, server_path, HTTP_11_VERSION); req.set(http::field::host, ip_); req.set(http::field::user_agent, BOOST_BEAST_VERSION_STRING); req.set(http::field::keep_alive, DEFAULT_HTTP_ALIVE_CONFIG); boost::beast::flat_buffer buffer; http::response\u0026lt;http::dynamic_body\u0026gt; res; /* 保持锁的时间最短 */ { write_lock lock(rwlock_); http::write(*real_socket_, req); http::read(*real_socket_, buffer, res); } std::string response_body{ buffers_begin(res.body().data()),buffers_end(res.body().data()) }; body = response_body; //http错误码是返回值 error_code = res.result_int(); } catch(std::exception const\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026#34;Get Message Error: \u0026#34; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; error_code = 500; } return error_code; } /* 返回的错误码是200表示get成功了，其它代表失败 */ int TLSSocketWrapper::PostMessageCore(const std::string \u0026amp;server_path, const std::string \u0026amp;request_content_type, const std::string \u0026amp;request_body, std::string \u0026amp;header, std::string \u0026amp;body) { int error_code; try { http::request\u0026lt;http::string_body\u0026gt; req(http::verb::post, server_path, HTTP_11_VERSION); req.set(http::field::host, ip_); req.set(http::field::user_agent, BOOST_BEAST_VERSION_STRING); req.set(http::field::keep_alive, DEFAULT_HTTP_ALIVE_CONFIG); req.set(http::field::content_type, request_content_type); req.body() = request_body; /* 设定完了使用prepare_payload来更新header里面的content_length */ req.prepare_payload(); boost::beast::flat_buffer buffer; http::response\u0026lt;http::dynamic_body\u0026gt; res; /* 保持锁的时间最短 */ { write_lock lock(rwlock_); http::write(*real_socket_, req); http::read(*real_socket_, buffer, res); } std::string response_body{ buffers_begin(res.body().data()),buffers_end(res.body().data()) }; body = response_body; //http错误码是返回值 error_code = res.result_int(); } catch(std::exception const\u0026amp; e) { std::cerr \u0026lt;\u0026lt; \u0026#34;Post Message Error: \u0026#34; \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; error_code = 500; } return error_code; } void SyncTlsConnectionManager::Init() { io_service_ = boost::shared_ptr\u0026lt;io_service\u0026gt;(new io_service()); /* 添加work防止io_service 在pending时退出*/ io_service::work work{*io_service_}; this-\u0026gt;loop_ = boost::shared_ptr\u0026lt;boost::thread\u0026gt; (new boost::thread([\u0026amp;]{ io_service_-\u0026gt;run(); })); /* lambda需要捕获this才能调用this的函数，如果是静态或者全局函数那么不需要执行捕获 */ timer_ = boost::shared_ptr\u0026lt;RepeatedTimer\u0026gt; (new RepeatedTimer(*io_service_, [this](const boost::system::error_code \u0026amp;e) { this-\u0026gt;HttpHeartBeat();})); /* 15秒钟运行一次心跳保活线程 */ timer_-\u0026gt;Start(/*ms=*/1000*15); } void SyncTlsConnectionManager::HttpHeartBeat() { std::vector\u0026lt;std::pair\u0026lt;std::string, boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; \u0026gt; \u0026gt; list; global_sockets_.GetAllKey(list); for (auto iter : list) { size_t pos = iter.first.find(\u0026#39;#\u0026#39;); if (pos == iter.first.npos) { /* 理论上不可能发生这问题 */ continue; } std::string ip(iter.first.substr(0, pos)); std::string port(iter.first.substr(pos+1)); /* SyncTlsClient heartbeat(ip, port, iter.second); std::string header; std::string body; int error_code = heartbeat.HeartBeat(\u0026#34;/monitor/alive\u0026#34;, header, body); if (error_code != 200) { } */ } } io_context\u0026amp; SyncTlsConnectionManager::GetGlobalIOContext() { return global_io_context_; } ConcurrentLRU\u0026lt;std::string, boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt;, TlsWrapperCompare\u0026gt;\u0026amp; SyncTlsConnectionManager::GetGlobalSocketWrapper() { return global_sockets_; } /* 探活/保活接口专用构造函数 */ SyncTlsClient::SyncTlsClient(const std::string \u0026amp;ip, const std::string \u0026amp;port, const boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; \u0026amp;connection): ip_(ip), port_(port), socket_wrapper_(connection) { ; } /* 时间戳为证书时间戳，或者说证书文件的时间戳 */ SyncTlsClient::SyncTlsClient(const std::string \u0026amp;ip, const std::string \u0026amp;port, const std::string \u0026amp;cert, const std::string \u0026amp;key, const std::string \u0026amp;ca_cert, const uint64_t \u0026amp;time_stamp) : ip_(ip), port_(port) { std::string ref = ip+\u0026#34;#\u0026#34;+port; if (SyncTlsConnectionManager::instance().GetGlobalSocketWrapper().Get(ref, socket_wrapper_)) { /* 能查到且时间戳没超时意味着可用 */ if (time_stamp \u0026lt;= socket_wrapper_-\u0026gt;GetTimeStamp()) { /* 不需要执行重新握手的唯一情况只有这一种，直接使用缓存数据 */ return; } } boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; new_socket_wrapper = boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; (new TLSSocketWrapper(ip, port, SyncTlsConnectionManager::instance().GetGlobalIOContext(), cert, key, ca_cert, time_stamp)); if (new_socket_wrapper != nullptr \u0026amp;\u0026amp; new_socket_wrapper-\u0026gt;HandshakeFinished()) { /* 建立连接失败，不会更新全局缓存的，全局缓存只在握手成功的情况下更新*/ SyncTlsConnectionManager::instance().GetGlobalSocketWrapper().Put(ref, new_socket_wrapper); } socket_wrapper_ = new_socket_wrapper; } /* http心跳报文实际上是个get请求 */ int SyncTlsClient::HeartBeat(const std::string \u0026amp;server_path, std::string \u0026amp;response_header, std::string \u0026amp;response_body) { int error_code; /* real_socket_理论来说不能为空，为空直接说明一开始尝试连接失败，直接返回错误码500即可 */ if (socket_wrapper_ != nullptr \u0026amp;\u0026amp; socket_wrapper_-\u0026gt;HandshakeFinished()) { /* asio的is_open是个无效函数，因此只能通过尝试发送数据来探测是否该socket还活着/出现异常 */ error_code = socket_wrapper_-\u0026gt;GetMessageCore(server_path, response_header, response_body); /* 500代表连接失效了，需要重新连接，并发起请求 */ if (error_code == 500) { /* 因为永远保证socket_wrapper的证书/私钥/时间戳都是最新版，所以使用socket_wrapper_的证书私钥建立连接 */ boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; new_socket_wrapper = boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; (new TLSSocketWrapper(ip_, port_, SyncTlsConnectionManager::instance().GetGlobalIOContext(), socket_wrapper_-\u0026gt;GetCert(), socket_wrapper_-\u0026gt;GetKey(), socket_wrapper_-\u0026gt;GetCaCert(), socket_wrapper_-\u0026gt;GetTimeStamp())); if (new_socket_wrapper != nullptr \u0026amp;\u0026amp; new_socket_wrapper-\u0026gt;HandshakeFinished()) { error_code = new_socket_wrapper-\u0026gt;GetMessageCore(server_path, response_header, response_body); if (error_code == 200) { std::string ref = ip_+\u0026#34;#\u0026#34;+port_; SyncTlsConnectionManager::instance().GetGlobalSocketWrapper().Put(ref, new_socket_wrapper); socket_wrapper_ = new_socket_wrapper; } } } } else { error_code = 500; } return error_code; } int SyncTlsClient::GetMessage(const std::string \u0026amp;server_path, std::string \u0026amp;response_header, std::string \u0026amp;response_body) { int error_code; /* real_socket_理论来说不能为空，为空直接说明一开始尝试连接失败，直接返回错误码500即可 */ if (socket_wrapper_ != nullptr \u0026amp;\u0026amp; socket_wrapper_-\u0026gt;HandshakeFinished()) { /* asio的is_open是个无效函数，因此只能通过尝试发送数据来探测是否该socket还活着/出现异常 */ error_code = socket_wrapper_-\u0026gt;GetMessageCore(server_path, response_header, response_body); /* 500代表连接失效了，需要重新连接，并发起请求 */ if (error_code == 500) { /* 因为永远保证socket_wrapper的证书/私钥/时间戳都是最新版，所以使用socket_wrapper_的证书私钥建立连接 */ boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; new_socket_wrapper = boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; (new TLSSocketWrapper(ip_, port_, SyncTlsConnectionManager::instance().GetGlobalIOContext(), socket_wrapper_-\u0026gt;GetCert(), socket_wrapper_-\u0026gt;GetKey(), socket_wrapper_-\u0026gt;GetCaCert(), socket_wrapper_-\u0026gt;GetTimeStamp())); if (new_socket_wrapper != nullptr \u0026amp;\u0026amp; new_socket_wrapper-\u0026gt;HandshakeFinished()) { error_code = new_socket_wrapper-\u0026gt;GetMessageCore(server_path, response_header, response_body); if (error_code == 200) { std::string ref = ip_+\u0026#34;#\u0026#34;+port_; SyncTlsConnectionManager::instance().GetGlobalSocketWrapper().Put(ref, new_socket_wrapper); socket_wrapper_ = new_socket_wrapper; } } } } else { error_code = 500; } return error_code; } int SyncTlsClient::PostMessage(const std::string \u0026amp;server_path, const std::string \u0026amp;request_content_type, const std::string \u0026amp;request_body, std::string \u0026amp;response_header, std::string \u0026amp;response_body) { int error_code; /* socket_理论来说不能为空，为空直接说明地址无效了，直接返回错误码500即可 */ if (socket_wrapper_ != nullptr \u0026amp;\u0026amp; socket_wrapper_-\u0026gt;HandshakeFinished()) { /* asio的is_open是个无效函数，因此只能通过尝试发送数据来探测是否该socket还活着 */ error_code = socket_wrapper_-\u0026gt;PostMessageCore(server_path, request_content_type, request_body, response_header, response_body); /* 500代表连接失效了，需要重新连接，并发起请求 */ if (error_code == 500) { /* 因为永远保证socket_wrapper的证书/私钥/时间戳都是最新版，所以使用socket_wrapper_的证书私钥建立连接 */ boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; new_socket_wrapper = boost::shared_ptr\u0026lt;TLSSocketWrapper\u0026gt; (new TLSSocketWrapper(ip_, port_, SyncTlsConnectionManager::instance().GetGlobalIOContext(), socket_wrapper_-\u0026gt;GetCert(), socket_wrapper_-\u0026gt;GetKey(), socket_wrapper_-\u0026gt;GetCaCert(), socket_wrapper_-\u0026gt;GetTimeStamp())); if (new_socket_wrapper != nullptr \u0026amp;\u0026amp; new_socket_wrapper-\u0026gt;HandshakeFinished()) { error_code = new_socket_wrapper-\u0026gt;PostMessageCore(server_path, request_content_type, request_body, response_header, response_body); if (error_code == 200) { std::string ref = ip_+\u0026#34;#\u0026#34;+port_; SyncTlsConnectionManager::instance().GetGlobalSocketWrapper().Put(ref, new_socket_wrapper); socket_wrapper_ = new_socket_wrapper; } } } } else { error_code = 500; } return error_code; } 5 OPENSSL签名验证签名代码 # 本来是指用crypto++库做的，然后惊讶的发现crypto++的签名/验签的性能低的令人发指。所以最后又采用了openssl的代码\n头文件\n#ifndef __SIGN_ALGORITHM_H__ #define __SIGN_ALGORITHM_H__ /* inf cbom的crypto后面没有pp，mac装的需要加个pp */ #ifndef MAC_BUILD #include \u0026lt;crypto/eccrypto.h\u0026gt; #include \u0026lt;crypto/osrng.h\u0026gt; #include \u0026lt;crypto/rsa.h\u0026gt; #include \u0026lt;crypto/pssr.h\u0026gt; #include \u0026lt;crypto/base64.h\u0026gt; #else #include \u0026lt;cryptopp/eccrypto.h\u0026gt; #include \u0026lt;cryptopp/osrng.h\u0026gt; #include \u0026lt;cryptopp/rsa.h\u0026gt; #include \u0026lt;cryptopp/pssr.h\u0026gt; #include \u0026lt;cryptopp/base64.h\u0026gt; #endif #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026#34;sts_enum.h\u0026#34; #include \u0026#34;openssl/ecdsa.h\u0026#34; #include \u0026#34;openssl/rsa.h\u0026#34; #include \u0026#34;openssl/ssl.h\u0026#34; #include \u0026#34;openssl/ecdh.h\u0026#34; #include \u0026#34;openssl/evp.h\u0026#34; #include \u0026#34;openssl/sha.h\u0026#34; #include \u0026#34;openssl/bio.h\u0026#34; #include \u0026#34;openssl/pem.h\u0026#34; #include \u0026#34;openssl/err.h\u0026#34; #include \u0026#34;openssl/hmac.h\u0026#34; #define EVP_MAX_SIGNATURE_SIZE 1024 using std::string; class SignAlgorithm{ public: static bool sign_with_pem(const int \u0026amp;algorithm, const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature); static bool verify_with_pem(const int \u0026amp;algorithm, const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature); static bool base64_url_encode(const std::string \u0026amp;in, std::string \u0026amp;out); static bool base64_url_decode(const std::string \u0026amp;in, std::string \u0026amp;out); static bool base64_encode(const std::string \u0026amp;in, std::string \u0026amp;out); static bool base64_decode(const std::string \u0026amp;in, std::string \u0026amp;out); template \u0026lt;typename T\u0026gt; static bool load_base64_raw_key(const std::string \u0026amp;pem, T \u0026amp;key) { ByteQueue queue; Base64Decoder decoder; decoder.Attach(new Redirector(queue)); decoder.Put((const byte*)pem.data(), pem.length()); decoder.MessageEnd(); try { key.BERDecode(queue); #ifdef AUTH_SDK_VALIDATE_KEY AutoSeededRandomPool prng; bool valid = key.Validate(prng, 3); if (!valid) { return false; } #endif } catch (const Exception\u0026amp; ex) { return false; } return true; } private: /* 公私密钥均为pem格式*/ static bool ecdsa_sha256_sign(const std::string \u0026amp;message, const std::string \u0026amp;pem_private_key, std::string \u0026amp;signature); static bool ecdsa_sha256_verify(const std::string \u0026amp;message, const std::string \u0026amp;pem_pub_key, std::string \u0026amp;signature); static bool ecdsa_sha256_sign_openssl(const std::string \u0026amp;message, const std::string \u0026amp;pem_private_key, std::string \u0026amp;signature); static bool ecdsa_sha256_verify_openssl(const std::string \u0026amp;message, const std::string \u0026amp;pem_pub_key, std::string \u0026amp;signature); static bool rsa_sha256_sign_openssl(const std::string \u0026amp;message, const std::string \u0026amp;pem_private_key, std::string \u0026amp;signature); static bool rsa_sha256_verify_openssl(const std::string \u0026amp;message, const std::string \u0026amp;pem_pub_key, std::string \u0026amp;signature); static bool rsa_sha256_sign(const std::string \u0026amp;message, const std::string \u0026amp;pem_private_key, std::string \u0026amp;signature) ; static bool rsa_sha256_verify(const std::string \u0026amp;message, const std::string \u0026amp;pem_pub_key, std::string \u0026amp;signature); static bool hmac_sha256_sign(const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature); static bool hmac_sha256_verify(const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature); static bool hmac_sha256_sign_openssl(const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature); static bool hmac_sha256_verify_openssl(const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature); }; #endif cpp文件\n#include \u0026#34;sign_algorithm.h\u0026#34; bool SignAlgorithm::sign_with_pem(const int \u0026amp;algorithm, const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature) { switch (algorithm) { #ifdef USE_CRYPTOPP_ALG case STS_ALG_TYPE_RS256: return SignAlgorithm::rsa_sha256_sign(message, key, signature); case STS_ALG_TYPE_ES256: return SignAlgorithm::ecdsa_sha256_sign(message, key, signature); case STS_ALG_TYPE_HS256: return SignAlgorithm::hmac_sha256_sign(message, key, signature); #else case STS_ALG_TYPE_RS256: return SignAlgorithm::rsa_sha256_sign_openssl(message, key, signature); case STS_ALG_TYPE_ES256: return SignAlgorithm::ecdsa_sha256_sign_openssl(message, key, signature); case STS_ALG_TYPE_HS256: return SignAlgorithm::hmac_sha256_sign_openssl(message, key, signature); #endif } return false; } bool SignAlgorithm::verify_with_pem(const int \u0026amp;algorithm, const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature) { switch (algorithm) { #ifdef USE_CRYPTOPP_ALG case STS_ALG_TYPE_RS256: return SignAlgorithm::rsa_sha256_verify(message, key, signature); case STS_ALG_TYPE_ES256: return SignAlgorithm::ecdsa_sha256_verify(message, key, signature); case STS_ALG_TYPE_HS256: return SignAlgorithm::hmac_sha256_verify(message, key, signature); #else case STS_ALG_TYPE_RS256: return SignAlgorithm::rsa_sha256_verify_openssl(message, key, signature); case STS_ALG_TYPE_ES256: return SignAlgorithm::ecdsa_sha256_verify_openssl(message, key, signature); case STS_ALG_TYPE_HS256: return SignAlgorithm::hmac_sha256_verify_openssl(message, key, signature); #endif } return false; } bool SignAlgorithm::ecdsa_sha256_sign(const std::string \u0026amp;message, const std::string \u0026amp;pem_private_key, std::string \u0026amp;signature) { CryptoPP::ECDSA\u0026lt;CryptoPP::ECP, CryptoPP::SHA256\u0026gt;::PrivateKey private_key; if (!load_base64_raw_key(pem_private_key, private_key)) { return false; } CryptoPP::AutoSeededRandomPool prng; CryptoPP::ECDSA\u0026lt;CryptoPP::ECP, CryptoPP::SHA256\u0026gt;::Signer signer(private_key); try { CryptoPP::StringSource s( message, true /* pump all */, new CryptoPP::SignerFilter(prng, signer, new CryptoPP::StringSink( signature ) ) ); } catch (CryptoPP::Exception e) { return false; } return true; } bool SignAlgorithm::ecdsa_sha256_verify(const std::string \u0026amp;message, const std::string \u0026amp;pem_pub_key, std::string \u0026amp;signature) { CryptoPP::ECDSA\u0026lt;CryptoPP::ECP, CryptoPP::SHA256\u0026gt;::PublicKey public_key; if (!load_base64_raw_key(pem_pub_key, public_key)) { return false; } bool ret = false; CryptoPP::ECDSA\u0026lt;CryptoPP::ECP, CryptoPP::SHA256\u0026gt;::Verifier verifier(public_key); try { CryptoPP::StringSource s( signature+message, true /* pump all */, /* 默认就是把校验结果放到ret里 */ new CryptoPP::SignatureVerificationFilter( verifier, new CryptoPP::ArraySink( (byte*)\u0026amp;ret, sizeof(ret) ) ) ); } catch (CryptoPP::Exception e) { ret = false; } return ret; } bool SignAlgorithm::rsa_sha256_sign(const std::string \u0026amp;message, const std::string \u0026amp;pem_private_key, std::string \u0026amp;signature) { CryptoPP::RSA::PrivateKey private_key; if (!load_base64_raw_key(pem_private_key, private_key)) { return false; } CryptoPP::RSASS\u0026lt;CryptoPP::PSS, CryptoPP::SHA256\u0026gt;::Signer signer(private_key); CryptoPP::AutoSeededRandomPool prng; bool ret = true; try { CryptoPP::StringSource s(message, true, new CryptoPP::SignerFilter(prng, signer, new CryptoPP::StringSink( signature ) ) ); } catch (CryptoPP::Exception e) { ret = false; } return ret; } bool SignAlgorithm::rsa_sha256_verify(const std::string \u0026amp;message, const std::string \u0026amp;pem_pub_key, std::string \u0026amp;signature) { CryptoPP::RSA::PublicKey public_key; if (!load_base64_raw_key(pem_pub_key, public_key)) { return false; } CryptoPP::RSASS\u0026lt;CryptoPP::PSS, CryptoPP::SHA256\u0026gt;::Verifier verifier(public_key); bool ret = true; try { CryptoPP::StringSource s(signature+message, true, new CryptoPP::SignatureVerificationFilter( verifier, new CryptoPP::ArraySink( (byte*)\u0026amp;ret, sizeof(ret) ) ) ); } catch (CryptoPP::Exception e) { ret = false; } return ret; } bool SignAlgorithm::hmac_sha256_sign(const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature) { bool ret = true; try { /* 输入的密钥是base64编码的，所以需要先解码 */ std::string base64_key; SignAlgorithm::base64_decode(key, base64_key); CryptoPP::HMAC\u0026lt;CryptoPP::SHA256\u0026gt; hmac((byte*) base64_key.c_str(), base64_key.length()); CryptoPP::StringSource(message, true, new CryptoPP::HashFilter(hmac, new CryptoPP::StringSink(signature))); } catch (CryptoPP::Exception e) { ret = false; } return ret; } bool SignAlgorithm::hmac_sha256_verify(const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature) { bool ret = true; std::string computed_signature; try { /* 输入的密钥是base64编码的，所以需要先解码 */ std::string base64_key; SignAlgorithm::base64_decode(key, base64_key); CryptoPP::HMAC\u0026lt;CryptoPP::SHA256\u0026gt; hmac((byte*) base64_key.c_str(), base64_key.length()); CryptoPP::StringSource(message, true, new CryptoPP::HashFilter(hmac, new CryptoPP::StringSink(computed_signature))); if (computed_signature.compare(signature) != 0) { ret = false; } } catch (CryptoPP::Exception e) { ret = false; } return ret; } bool SignAlgorithm::base64_url_encode(const std::string \u0026amp;in, std::string \u0026amp;out) { bool ret = true; out.clear(); try { CryptoPP::StringSource(in, true, new CryptoPP::Base64URLEncoder(new CryptoPP::StringSink(out))); } catch (CryptoPP::Exception e) { ret = false; } return ret; } bool SignAlgorithm::base64_url_decode(const std::string \u0026amp;in, std::string \u0026amp;out) { bool ret = true; out.clear(); try { CryptoPP::StringSource(in, true, new CryptoPP::Base64URLDecoder(new CryptoPP::StringSink(out))); } catch (CryptoPP::Exception e) { ret = false; } return ret; } bool SignAlgorithm::base64_encode(const std::string \u0026amp;in, std::string \u0026amp;out) { bool ret = true; out.clear(); try { CryptoPP::StringSource(in, true, new CryptoPP::Base64Encoder(new CryptoPP::StringSink(out))); } catch (CryptoPP::Exception e) { ret = false; } return ret; } bool SignAlgorithm::base64_decode(const std::string \u0026amp;in, std::string \u0026amp;out) { bool ret = true; out.clear(); try { CryptoPP::StringSource(in, true, new CryptoPP::Base64Decoder(new CryptoPP::StringSink(out))); } catch (CryptoPP::Exception e) { ret = false; } return ret; } /* 签名的最后结果并不一定小于64，对ECDSA而言256bit可以达到72字节。所以signature_buf长度最好保存1024，直接防备rsa 4096/1024*8的密钥 */ bool SignAlgorithm::ecdsa_sha256_sign_openssl(const std::string \u0026amp;message, const std::string \u0026amp;pem_private_key, std::string \u0026amp;signature) { uint32_t digest_len = 0; uint32_t signature_len = 0; unsigned char digest[EVP_MAX_MD_SIZE]; char signature_buf[EVP_MAX_SIGNATURE_SIZE]; std::string key = \u0026#34;-----BEGIN PRIVATE KEY-----\\n\u0026#34; + pem_private_key + \u0026#34;\\n-----END PRIVATE KEY-----\u0026#34;; BIO *bio = BIO_new(BIO_s_mem()); if (bio == nullptr) { return false; } BIO_puts(bio, key.c_str()); EC_KEY *ec_key = PEM_read_bio_ECPrivateKey(bio, NULL, NULL, NULL);; if (ec_key == nullptr) { BIO_free(bio); return false; } EVP_MD_CTX *md_ctx = EVP_MD_CTX_create(); if (md_ctx == nullptr) { BIO_free(bio); EC_KEY_free(ec_key); return false; } bool ret = true; bzero(digest, EVP_MAX_MD_SIZE); if (EVP_DigestInit(md_ctx, EVP_sha256()) \u0026lt;= 0 ||EVP_DigestUpdate(md_ctx, (const void *)message.c_str(), message.length()) \u0026lt;= 0 ||EVP_DigestFinal(md_ctx, digest, \u0026amp;digest_len) \u0026lt;= 0 ||ECDSA_sign(0, digest, digest_len, (unsigned char*)signature_buf, \u0026amp;signature_len, ec_key) \u0026lt;= 0) { ret = false; } if (ret == true) { std::string final_sig(signature_buf, signature_len); signature = final_sig; } BIO_free(bio); EC_KEY_free(ec_key); EVP_MD_CTX_destroy(md_ctx); return ret; } bool SignAlgorithm::ecdsa_sha256_verify_openssl(const std::string \u0026amp;message, const std::string \u0026amp;pem_pub_key, std::string \u0026amp;signature) { uint32_t digest_len = 0; int signature_len = signature.length(); unsigned char digest[EVP_MAX_MD_SIZE]; std::string key = \u0026#34;-----BEGIN PUBLIC KEY-----\\n\u0026#34; + pem_pub_key + \u0026#34;\\n-----END PUBLIC KEY-----\u0026#34;; BIO *bio = BIO_new(BIO_s_mem()); if (bio == nullptr) { return false; } BIO_puts(bio, key.c_str()); EC_KEY *ec_key = PEM_read_bio_EC_PUBKEY(bio, NULL, NULL, NULL);; if (ec_key == nullptr) { BIO_free(bio); return false; } EVP_MD_CTX *md_ctx = EVP_MD_CTX_create(); if (md_ctx == nullptr) { BIO_free(bio); EC_KEY_free(ec_key); return false; } bool ret = true; bzero(digest, EVP_MAX_MD_SIZE); if (EVP_DigestInit(md_ctx, EVP_sha256()) \u0026lt;= 0 ||EVP_DigestUpdate(md_ctx, (const void *)message.c_str(), message.length()) \u0026lt;= 0 ||EVP_DigestFinal(md_ctx, digest, \u0026amp;digest_len) \u0026lt;= 0 ||ECDSA_verify(0, digest, digest_len, (const unsigned char*)signature.c_str(), signature_len, ec_key) \u0026lt;= 0) { ret = false; } BIO_free(bio); EC_KEY_free(ec_key); EVP_MD_CTX_destroy(md_ctx); return ret; } bool SignAlgorithm::rsa_sha256_sign_openssl(const std::string \u0026amp;message, const std::string \u0026amp;pem_private_key, std::string \u0026amp;signature) { uint32_t digest_len = 0; uint32_t signature_len = 0; unsigned char digest[EVP_MAX_MD_SIZE]; char signature_buf[EVP_MAX_SIGNATURE_SIZE]; std::string key = \u0026#34;-----BEGIN PRIVATE KEY-----\\n\u0026#34; + pem_private_key + \u0026#34;\\n-----END PRIVATE KEY-----\u0026#34;; BIO *bio = BIO_new(BIO_s_mem()); if (bio == nullptr) { return false; } BIO_puts(bio, key.c_str()); RSA *rsa_key = PEM_read_bio_RSAPrivateKey(bio, NULL, NULL, NULL);; if (rsa_key == nullptr) { BIO_free(bio); return false; } EVP_MD_CTX *md_ctx = EVP_MD_CTX_create(); if (md_ctx == nullptr) { BIO_free(bio); RSA_free(rsa_key); return false; } bool ret = true; if (EVP_DigestInit(md_ctx, EVP_sha256()) \u0026lt;= 0 ||EVP_DigestUpdate(md_ctx, (const void *)message.c_str(), message.length()) \u0026lt;= 0 ||EVP_DigestFinal(md_ctx, digest, \u0026amp;digest_len) \u0026lt;= 0 ||RSA_sign(NID_sha256, digest, digest_len, (unsigned char*)signature_buf, \u0026amp;signature_len, rsa_key) \u0026lt;= 0) { ret = false; } if (ret == true) { std::string final_sig(signature_buf, signature_len); signature = final_sig; } BIO_free(bio); RSA_free(rsa_key); EVP_MD_CTX_destroy(md_ctx); return ret; } bool SignAlgorithm::rsa_sha256_verify_openssl(const std::string \u0026amp;message, const std::string \u0026amp;pem_pub_key, std::string \u0026amp;signature) { uint32_t digest_len = 0; int signature_len = signature.length(); unsigned char digest[EVP_MAX_MD_SIZE]; std::string key = \u0026#34;-----BEGIN PUBLIC KEY-----\\n\u0026#34; + pem_pub_key + \u0026#34;\\n-----END PUBLIC KEY-----\u0026#34;; BIO *bio = BIO_new(BIO_s_mem()); if (bio == nullptr) { return false; } BIO_puts(bio, key.c_str()); RSA* rsa_key = PEM_read_bio_RSA_PUBKEY(bio, NULL, NULL, NULL); if (rsa_key == nullptr) { BIO_free(bio); return false; } EVP_MD_CTX *md_ctx = EVP_MD_CTX_create(); if (md_ctx == nullptr) { BIO_free(bio); RSA_free(rsa_key); return false; } bool ret = true; if (EVP_DigestInit(md_ctx, EVP_sha256()) \u0026lt;= 0 ||EVP_DigestUpdate(md_ctx, (const void *)message.c_str(), message.length())\u0026lt;= 0 ||EVP_DigestFinal(md_ctx, digest, \u0026amp;digest_len)\u0026lt;= 0 ||RSA_verify(NID_sha256, digest, digest_len, (const unsigned char*)signature.c_str(), signature_len, rsa_key)\u0026lt;= 0) { ret = false; } BIO_free(bio); RSA_free(rsa_key); EVP_MD_CTX_destroy(md_ctx); return ret; } bool SignAlgorithm::hmac_sha256_sign_openssl(const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature) { char signature_buf[EVP_MAX_MD_SIZE]; unsigned int signature_len = 0; HMAC_CTX *hmac = HMAC_CTX_new(); if (hmac == nullptr) { return false; } std::string real_key; base64_decode(key, real_key); bool ret = true; if (HMAC_Init_ex(hmac, real_key.c_str(), real_key.length(), EVP_sha256(), NULL) \u0026lt;= 0 ||HMAC_Update(hmac, ( unsigned char* )message.c_str(), message.length()) \u0026lt;= 0 ||HMAC_Final(hmac, (unsigned char*)signature_buf, \u0026amp;signature_len) \u0026lt;= 0 ) { ret = false; } if (ret == true) { std::string final_sig(signature_buf, signature_len); signature = final_sig; } HMAC_CTX_free(hmac); return ret; } bool SignAlgorithm::hmac_sha256_verify_openssl(const std::string \u0026amp;message, const std::string \u0026amp;key, std::string \u0026amp;signature) { std::string compute_signature; if (!hmac_sha256_sign_openssl(message, key, compute_signature)) { return false; } if (compute_signature.compare(signature) == 0) { return true; } return false; } 6 log库 # 6.1 boost log使用版本 # 使用boost的log实现的方法，简单来说基本不需要做什么操作，就是初始化完成就可以调用记录日志的函数了。需要注意的是这个是同步的sink\n/* .h文件 */ #ifndef __BOOST_BASE_LOG__ #define __BOOST_BASE_LOG__ #include \u0026lt;iostream\u0026gt; #include \u0026lt;boost/log/core.hpp\u0026gt; #include \u0026lt;boost/log/trivial.hpp\u0026gt; #include \u0026lt;boost/log/expressions.hpp\u0026gt; #include \u0026lt;boost/log/sinks/text_file_backend.hpp\u0026gt; #include \u0026lt;boost/log/utility/setup/file.hpp\u0026gt; #include \u0026lt;boost/log/utility/setup/common_attributes.hpp\u0026gt; #include \u0026lt;boost/log/sources/severity_logger.hpp\u0026gt; #include \u0026lt;boost/log/sources/record_ostream.hpp\u0026gt; void init_boost_base_log(); #endif /* .cpp文件 */ #include \u0026#34;boost_base_log.h\u0026#34; void init_boost_base_log() { boost::log::add_file_log( /* 具体记录日志的名称 */ boost::log::keywords::file_name = \u0026#34;sample_%N.log\u0026#34;, /* 文件10MB的时候rotate一次 */ boost::log::keywords::rotation_size = 10 * 1024 * 1024, /* 或者每天午夜的时候rotate一次 */ boost::log::keywords::time_based_rotation = boost::log::sinks::file::rotation_at_time_point(0, 0, 0), /* 消息格式 */ boost::log::keywords::format = \u0026#34;[%TimeStamp%]: %Message%\u0026#34; ); /* 添加附加属性比方说时间戳，行号，线程号等 */ boost::log::add_common_attributes(); } /* 具体用法 */ BOOST_LOG_TRIVIAL(trace) \u0026lt;\u0026lt; \u0026#34;log message\u0026#34;; BOOST_LOG_TRIVIAL(debug) \u0026lt;\u0026lt; \u0026#34;log message\u0026#34;; BOOST_LOG_TRIVIAL(info) \u0026lt;\u0026lt; \u0026#34;log message\u0026#34;; BOOST_LOG_TRIVIAL(warning) \u0026lt;\u0026lt; \u0026#34;log message\u0026#34;; BOOST_LOG_TRIVIAL(error) \u0026lt;\u0026lt; \u0026#34;log message\u0026#34;; BOOST_LOG_TRIVIAL(fatal) \u0026lt;\u0026lt; \u0026#34;log message\u0026#34;; /* 编译链接的命令 * 如果使用cmake，需要加一条add_definitions(-DBOOST_LOG_DYN_LINK) * 然后链接的命令为 * target_link_libraries(boost_log_test -lboost_log-mt -lboost_log_setup-mt -lboost_thread-mt) */ 6.2 spdlog # #include \u0026lt;memory\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026#34;spdlog/spdlog.h\u0026#34; #include \u0026#34;spdlog/sinks/rotating_file_sink.h\u0026#34; #include \u0026#34;spdlog/sinks/daily_file_sink.h\u0026#34; #include \u0026#34;spdlog/sinks/stdout_color_sinks.h\u0026#34; #if 0 #define LOG_DEBUG(...) SPDLOG_LOGGER_DEBUG(spdlog::default_logger_raw(), __VA_ARGS__);SPDLOG_LOGGER_DEBUG(spdlog::get(\u0026#34;file_log\u0026#34;), __VA_ARGS__) #define LOG_INFO(...) SPDLOG_LOGGER_INFO(spdlog::default_logger_raw(), __VA_ARGS__);SPDLOG_LOGGER_INFO(spdlog::get(\u0026#34;file_log\u0026#34;), __VA_ARGS__) #define LOG_WARN(...) SPDLOG_LOGGER_WARN(spdlog::default_logger_raw(), __VA_ARGS__);SPDLOG_LOGGER_WARN(spdlog::get(\u0026#34;file_log\u0026#34;), __VA_ARGS__) #define LOG_ERROR(...) SPDLOG_LOGGER_ERROR(spdlog::default_logger_raw(), __VA_ARGS__);SPDLOG_LOGGER_ERROR(spdlog::get(\u0026#34;file_log\u0026#34;), __VA_ARGS__) #else #define LOG_DEBUG(...) SPDLOG_LOGGER_DEBUG(spdlog::get(\u0026#34;file_log\u0026#34;), __VA_ARGS__) #define LOG_INFO(...) SPDLOG_LOGGER_INFO(spdlog::get(\u0026#34;file_log\u0026#34;), __VA_ARGS__) #define LOG_WARN(...) SPDLOG_LOGGER_WARN(spdlog::get(\u0026#34;file_log\u0026#34;), __VA_ARGS__) #define LOG_ERROR(...) SPDLOG_LOGGER_ERROR(spdlog::get(\u0026#34;file_log\u0026#34;), __VA_ARGS__) #endif std::shared_ptr\u0026lt;spdlog::logger\u0026gt; file_logger; void init_log() { file_logger = spdlog::rotating_logger_mt(\u0026#34;file_log\u0026#34;, \u0026#34;log\u0026#34;, 1024 * 1024 * 100, 3); //auto logger = spdlog::daily_logger_mt(\u0026#34;daily_logger\u0026#34;, \u0026#34;logs/daily.txt\u0026#34;, 2, 30); /* 遇到warn，冲洗一次*/ //file_logger-\u0026gt;flush_on(spdlog::level::warn); /* 三秒冲洗一次数据 */ spdlog::flush_every(std::chrono::seconds(3)); spdlog::set_pattern(\u0026#34;%Y-%m-%d %H:%M:%S [%l] [%t] - \u0026lt;%s\u0026gt;|\u0026lt;%#\u0026gt;|\u0026lt;%!\u0026gt;,%v\u0026#34;); } void stop_log() { spdlog::drop_all(); } 7 varint编解码 # 在实现内部工程的时候遇到一个问题，就是varint编解码的实现，借鉴了网上开源代码，并修复了原本代码只适合unsigned int类型数据bug，并且添加了一个解码时获得varint长度的函数。但是需要注意一点，就是varint解码时，具体解码的对象是否合法需要自己判断，检查的方法也非常简单，无非就是检查解码varint的时候是不少超过5字节，解码varlong是不是超过10字节，或者到边界了，最后一字节第一个位为1，显示还有下个字节。代码差不多就是\nint varint_size = 1; for (int i = 0 ; i \u0026lt; length; ++i) { if (input[i] \u0026amp; 0x80) { varint_size += 1; if (varint_size \u0026gt; 5) { return false; } } else { break; } } /* 能走到这里说明没超出5的限制，但是也可能是序列到头，即最后一个字符最高位不是0，也不合法 */ if (varint_size == length + 1) { return false; } 头文件\n#ifndef __VARINT_HPP__ #define __VARINT_HPP__ #include \u0026lt;iostream\u0026gt; std::size_t varintSize(std::size_t value); /** * Encodes an unsigned variable-length integer using the MSB algorithm. * This function assumes that the value is stored as little endian. * @param value The input value. Any standard integer type is allowed. * @param output A pointer to a piece of reserved memory. Must have a minimum size dependent on the input size (32 bit = 5 bytes, 64 bit = 10 bytes). * @return The number of bytes used in the output memory. */ template\u0026lt;typename int_t = uint64_t\u0026gt; std::size_t encodeVarint(int_t value, uint8_t* output) { size_t outputSize = 0; //While more than 7 bits of data are left, occupy the last output byte // and set the next byte flag while (value \u0026gt; 127) { //|128: Set the next byte flag output[outputSize] = ((uint8_t)(value \u0026amp; 127)) | 128; //Remove the seven bits we just wrote value \u0026gt;\u0026gt;= 7; outputSize++; } output[outputSize++] = ((uint8_t)value) \u0026amp; 127; return outputSize; } /** * Decodes an unsigned variable-length integer using the MSB algorithm. * @param value A variable-length encoded integer of arbitrary size. * @param inputSize How many bytes are */ template\u0026lt;typename int_t = uint64_t\u0026gt; int_t decodeVarint(uint8_t* input, std::size_t inputSize) { int_t ret = 0; for (size_t i = 0; i \u0026lt; inputSize; i++) { ret |= (static_cast\u0026lt;size_t\u0026gt;(input[i] \u0026amp; 127)) \u0026lt;\u0026lt; (7 * i); //If the next-byte flag is set if(!(input[i] \u0026amp; 128)) { break; } } return ret; } #endif cpp文件\n#include \u0026#34;varint.hpp\u0026#34; std::size_t varintSize(std::size_t value) { std::size_t n = 1; while(value \u0026gt; 127) { ++n; value /= 128; } return n; } 8 IO 计算分离 # 一般来说，针对Libevnet的IO计算分离之后的计算部分有两种解决办法\nIO线程的请求均等地发送到每个计算线程，计算线程有自己的待处理队列，计算线程自己处理即可 IO线程的请求发到任务池子里面，计算线程抢任务，抢一个算一个，造成忙等。 实现时：\n第一个可以让每个IO线程和每个计算线程分别共享一个spsc的队列，然后让IO线程轮训发任务即可。这个队列使用lfbb的队列即可实现 第二个每个IO线程发请求到mpmc里面，然后多个计算线程是consumer，不断争抢，消化即可。 下面的代码我们使用libevent库做IO库，使用C++实现第二个解决办法，拆分为IO worker，IO Server，Process Worker假设通信格式很简单就是网络字节序四个字节代表长度，后面是这个长度的内容。这里我们没有任何的发送行为，Process Worker只打印内容。\nIo_server.h : 注册的IO worker，Process worker都挂到上面，使用MPMC来放任务供 IO Worker生产，Process Worker消费。所以MPMC需要它提前申请，然后赋值给两种Worker\nio_server.h\n#ifndef IO_SERVER_H #define IO_SERVER_H #include \u0026#34;io_worker.h\u0026#34; #include \u0026#34;process_worker.h\u0026#34; #include \u0026#34;mpmc.h\u0026#34; #include \u0026lt;vector\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026lt;event2/bufferevent.h\u0026gt; #include \u0026lt;event2/event.h\u0026gt; constexpr size_t kMPMCLength = 65535; constexpr int kServerPort = 8888; // IOServer类声明 class IOServer { public: // 明确地初始化，指定io worker和process worker的数量 explicit IOServer(size_t io_worker_count, size_t process_worker_count); ~IOServer(); void Start(); private: // 这几个都是为了配合libevent采用的函数，而不是函数对象 static void AcceptConnection(struct evconnlistener *listener, evutil_socket_t fd, struct sockaddr *sa, int socklen, void *arg); // static void ErrorCallback(struct evconnlistener *listener, void *arg); // 事件循环，server能够处理IO连接事件的结构体 struct event_base *base_; // 记录两种worker，方便调用他们函数 std::vector\u0026lt;std::shared_ptr\u0026lt;IOWorker\u0026gt;\u0026gt; workers_; std::vector\u0026lt;std::shared_ptr\u0026lt;ProcessWorker\u0026gt;\u0026gt; de_workers_; // mpmc，用来在两种worker传递任务 rigtorp::MPMCQueue\u0026lt;Task*\u0026gt; mpmc_; // 用来轮训将新的连接传递给哪个io worker std::atomic\u0026lt;uint64_t\u0026gt; counter_; uint64_t io_worker_count_; uint64_t process_worker_count_; std::atomic\u0026lt;int\u0026gt; state_; }; #endif // IO_SERVER_H io_server.cc\n#include \u0026#34;io_server.h\u0026#34; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;event2/buffer.h\u0026gt; #include \u0026lt;event2/event.h\u0026gt; #include \u0026lt;event2/listener.h\u0026gt; #include \u0026lt;iostream\u0026gt; // 注意这个mpmc_，这个必须在初始化的时候调用初始化列表操作，不能在构造完成之后修改 IOServer::IOServer(size_t io_worker_count, size_t process_worker_count):io_worker_count_(io_worker_count), process_worker_count_(process_worker_count), mpmc_(kMPMCLength) { // 显式初始化两种worker for (size_t i = 0; i \u0026lt; io_worker_count; ++i) { auto worker = std::make_shared\u0026lt;IOWorker\u0026gt;(\u0026amp;mpmc_); workers_.push_back(worker); } for (size_t i = 0; i \u0026lt; process_worker_count; ++i) { auto de_worker = std::make_shared\u0026lt;ProcessWorker\u0026gt;(\u0026amp;mpmc_); de_workers_.push_back(de_worker); } struct sockaddr_in sin; sin.sin_family = AF_INET; sin.sin_addr.s_addr = htonl(INADDR_ANY); sin.sin_port = htons(kServerPort); // should never failed base_ = event_base_new(); // 初始化监听 struct evconnlistener *listener; // should never failed, if failed, just panic listener = evconnlistener_new_bind(base_, AcceptConnection, (void *)this, LEV_OPT_CLOSE_ON_FREE | LEV_OPT_REUSEABLE, -1, (struct sockaddr *)\u0026amp;sin, sizeof(sin)); } void IOServer::AcceptConnection(struct evconnlistener * /*listener*/, evutil_socket_t fd, struct sockaddr * /*sa*/, int /*socklen*/, void *arg) { IOServer *server = static_cast\u0026lt;IOServer*\u0026gt;(arg); evutil_make_socket_nonblocking(fd); std::cout \u0026lt;\u0026lt;\u0026#34; I got connection\u0026#34; \u0026lt;\u0026lt; std::endl; uint64_t value = ++(server-\u0026gt;counter_); auto worker = server-\u0026gt;workers_[value % server-\u0026gt;io_worker_count_]; // 把连接丢给io worker worker-\u0026gt;AddConnection(fd); } IOServer::~IOServer() { } // 启动各种worker void IOServer::Start() { std::cout \u0026lt;\u0026lt;\u0026#34; Server start looping\u0026#34; \u0026lt;\u0026lt; std::endl; for (auto\u0026amp; worker : workers_) { worker-\u0026gt;Start(); } for (auto\u0026amp; de_worker : de_workers_) { de_worker-\u0026gt;Start(); } // 这里注意，会把当前线程阻塞住，所以server必须是在主线程 event_base_dispatch(base_); std::cout \u0026lt;\u0026lt;\u0026#34; Server exit looping\u0026#34; \u0026lt;\u0026lt; std::endl; } Io_worker.h ： 这个就是纯粹的打工的\n#ifndef IO_WORKER_H #define IO_WORKER_H #include \u0026lt;thread\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;event2/bufferevent.h\u0026gt; #include \u0026lt;event2/event.h\u0026gt; #include \u0026#34;process_worker.h\u0026#34; #include \u0026#34;mpmc.h\u0026#34; constexpr int kFrameMinHeader = 4; constexpr int kFrameDecodeInvalidError = -1; constexpr int kFrameDecodeInternalError = -2; constexpr int kFrameNeedMore = 1; // IOWorker类声明 class IOWorker { public: IOWorker(rigtorp::MPMCQueue\u0026lt;Task*\u0026gt; *mpmc); void Start(); void AddConnection(evutil_socket_t fd); void EnqueueTask(Task* task); private: static void ProcessData(struct bufferevent *bev, void *arg); static void ProcessError(struct bufferevent *bev, short events, void *arg); static size_t WriteFrame(struct bufferevent *bev, const char *msg, size_t msg_len); static int64_t ReadFrame(struct bufferevent *bev, std::string \u0026amp;content, int *msg_type); void Run(); struct event_base *base_; rigtorp::MPMCQueue\u0026lt;Task*\u0026gt; *mpmc_; std::thread thread_; std::atomic\u0026lt;int\u0026gt; state_; }; #endif // IO_WORKER_H io_worker.cc\n#include \u0026#34;io_worker.h\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;event2/buffer.h\u0026gt; #include \u0026lt;event2/event.h\u0026gt; #include \u0026lt;event2/listener.h\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; IOWorker::IOWorker(rigtorp::MPMCQueue\u0026lt;Task*\u0026gt; *mpmc):mpmc_(mpmc) { // should never failed base_ = event_base_new(); } // 线程启动，使用函数对象操作 void IOWorker::Start() { thread_ = std::thread(\u0026amp;IOWorker::Run, this); } void IOWorker::Run() { // 这里需要注意，worker的base_可能没有关联任何事件（没有客户端建立连接），这个时候 // event_base_dispatch就会直接返回，所以必须得拿while包起来 std::cout \u0026lt;\u0026lt;\u0026#34; Worker start looping\u0026#34; \u0026lt;\u0026lt; std::endl; while (1) { // 这里是io worker线程的真正的dispatch开始，等着处理IO事件 event_base_dispatch(base_); } } void IOWorker::AddConnection(evutil_socket_t fd) { struct bufferevent *bev = bufferevent_socket_new(base_, fd, BEV_OPT_CLOSE_ON_FREE); if (!bev) { close(fd); return; } bufferevent_setcb(bev, ProcessData, NULL, ProcessError, (void*)this); bufferevent_enable(bev, EV_READ | EV_WRITE); } void IOWorker::ProcessData(struct bufferevent *bev, void *arg) { IOWorker *worker = static_cast\u0026lt;IOWorker*\u0026gt;(arg); int n; size_t readed_len = 0; struct evbuffer *buf = bufferevent_get_input(bev); /* * | 4 byte length | encoded protobuf message | */ while (evbuffer_get_length(buf) \u0026gt; kFrameMinHeader) { std::string content; int data_type; int64_t decode_result = ReadFrame(bev, content, \u0026amp;data_type); if (decode_result \u0026lt; 0) { if ((decode_result == kFrameDecodeInvalidError) || (decode_result == kFrameDecodeInternalError)) { size_t buf_len = evbuffer_get_length(buf); evbuffer_drain(buf, buf_len); return; } if (decode_result == kFrameNeedMore) { return; } } evutil_socket_t fd = bufferevent_getfd(bev); Task *task = new Task(content, fd); if (task == NULL) { continue; } // 把Task放起来 worker-\u0026gt;EnqueueTask(task); } } void IOWorker::EnqueueTask(Task* task) { // 实际上就是往mpmc里面放数据 mpmc_-\u0026gt;push(task); } void IOWorker::ProcessError(struct bufferevent *bev, short events, void * arg) { // if (event \u0026amp; BEV_EVENT_TIMEOUT) { // // printf(\u0026#34;Timed out\\n\u0026#34;); //if bufferevent_set_timeouts() called // } else if (event \u0026amp; BEV_EVENT_EOF) { // // printf(\u0026#34;connection closed\\n\u0026#34;); // } else if (event \u0026amp; BEV_EVENT_ERROR) { // // printf(\u0026#34;some other error: %s\\n\u0026#34;, // // evutil_socket_error_to_string(EVUTIL_SOCKET_ERROR())); // } bufferevent_free(bev); } // 纯粹占个位置，实际上没啥用 size_t IOWorker::WriteFrame(struct bufferevent *bev, const char *msg, size_t msg_len) { size_t frame_size = kFrameMinHeader + msg_len; return frame_size; } int64_t IOWorker::ReadFrame(struct bufferevent *bev, std::string \u0026amp;content, int *msg_type) { struct evbuffer *buf = bufferevent_get_input(bev); if (evbuffer_get_length(buf) \u0026lt;= kFrameMinHeader) { return kFrameNeedMore; } uint8_t read_buf[kFrameMinHeader]; memset(read_buf, 0, kFrameMinHeader); evbuffer_copyout(buf, read_buf, kFrameMinHeader); // 从四字节内容拿出来内容的长度 uint32_t total_length = ((read_buf[0] \u0026lt;\u0026lt; 24) | (read_buf[1] \u0026lt;\u0026lt; 16) | (read_buf[2] \u0026lt;\u0026lt; 8) | read_buf[3]) + kFrameMinHeader; if (evbuffer_get_length(buf) \u0026lt; total_length ) { return kFrameNeedMore; } memset(read_buf, 0, kFrameMinHeader); evbuffer_remove(buf, read_buf, kFrameMinHeader); // 也没啥用，纯粹记录用 (*msg_type) = 1; // msg length + 1 uint8_t *data_buf = (uint8_t*)malloc(total_length - kFrameMinHeader); if (data_buf == NULL) { return kFrameDecodeInternalError; } memset(data_buf, 0, total_length - kFrameMinHeader); evbuffer_remove(buf, data_buf, total_length - kFrameMinHeader); // 拷贝出来读取到的内容 content.assign((char*)data_buf, total_length - kFrameMinHeader); free(data_buf); return total_length; } process_worker.h\n#ifndef MOD_PROCESS_H #define MOD_PROCESS_H #include \u0026lt;string\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026#34;mpmc.h\u0026#34; class Task { public: Task(std::string content, int fd); std::string GetTaskContent(); private: std::string content_; int fd_; }; class ProcessWorker { public: ProcessWorker(rigtorp::MPMCQueue\u0026lt;Task*\u0026gt; *mpmc); void Start(); private: void Run(); rigtorp::MPMCQueue\u0026lt;Task*\u0026gt; *mpmc_; std::thread thread_; std::atomic\u0026lt;uint64_t\u0026gt; state_; }; #endif process_worker.cc\n#include \u0026#34;process_worker.h\u0026#34; #include \u0026lt;iostream\u0026gt; Task::Task(std::string content, int fd):content_(content), fd_(fd) {} std::string Task::GetTaskContent() { return content_; } ProcessWorker::ProcessWorker(rigtorp::MPMCQueue\u0026lt;Task*\u0026gt; *mpmc):mpmc_(mpmc) { } void ProcessWorker::Start() { thread_ = std::thread(\u0026amp;ProcessWorker::Run, this); } void ProcessWorker::Run() { std::cout \u0026lt;\u0026lt;\u0026#34; Process worker start looping\u0026#34; \u0026lt;\u0026lt; std::endl; while(true) { Task *task = nullptr; // 这里注意，加了id用于将来判断是不是process worker均等地抢任务 std::cout\u0026lt;\u0026lt; \u0026#34;Process worker \u0026#34; \u0026lt;\u0026lt; std::this_thread::get_id() \u0026lt;\u0026lt; \u0026#34; Prepare to pop task \u0026#34; \u0026lt;\u0026lt; std::endl; // 这里注意，mpmc没数据会卡住，pop不出来 mpmc_-\u0026gt;pop(task); std::string content = task-\u0026gt;GetTaskContent(); std::cout\u0026lt;\u0026lt; \u0026#34;Process worker \u0026#34; \u0026lt;\u0026lt; std::this_thread::get_id() \u0026lt;\u0026lt; \u0026#34; Pop task, Content is \u0026#34; \u0026lt;\u0026lt; content \u0026lt;\u0026lt; std::endl; free(task); } } Mcmc.h\n请参考https://github.com/rigtorp/MPMCQueue\n最后main调用就很简单了，直接\nsize_t io_worker_count = 2; size_t process_worker_count = 2 ; IOServer server(io_worker_count, process_worker_count); // 创建4个worker线程 server.Start(); 等看完第下面线程池的内容，我们再使用future + boost asio实现一版本modern C++版本的代码。\n阅读了https://www.boost.org/doc/libs/1_87_0/doc/html/boost_asio/tutorial.html \u0026amp; 更复杂的例子之后，设计如下结构\ntcp_server绑定io_context，初始化自己的acceptor_，async_accept绑定handle_accept，handle_accept里面再次bind，避免出现io_context空run的情况 acceptor之后新的tcp_connection，绑定到io_context（新还是旧的，旧的会造成多个争抢同一个io_context的事情）分配到不同的thread上面run，然后bind async_read，每次read到足够的数据就创建带检测任务，bind函数到任务池里面（放到mpmc里面，或者放到任务池里面？），任务需要带着tcp_connection 任务池一堆线程抢任务，抢完了任务执行检测，再对tcp_connection调用async_write 感觉实现还是不太好\n8++ IO分离 # 前几天说是用Boost库重新写一般现代的IO分离，开始写一个试试，首先下载安装特定的库\n9 C++ 环形队列 # 我一般使用的都是SPSC的环形队列，MPMC我使用的不多，正好记录一下，\n9.1 原理 # 这个解释是直接抄的https://zhuanlan.zhihu.com/p/455616501，\nSPSC只有一个读和写指针，所以不需要多线程保护，只需要简单的挪动指针即可\nMPMC有多个读和写的对象，它需要保护正在读取的对象，所以需要生产者和消费者都记录两个指针\n生产者指针：prod_head，prod_tail 消费者指针：cons_head，cons_tail 仅以生产者指针类比，其基本原理是拿到的prod_head和局部存储的prod_head一致，才认为是真正的拿到了当前可写的位置，如果不一致就重新拿prod_head，又因为prod_head总是指向要写的对象，所以能保证多个producer不会出现写重合的操作。而结束写的操作的时候，需要等待前面先拿到prod_head的对象修改完了prod_tail再尝试修改。换言之排队修改prod_tail\n在两个CPU core上，ring-\u0026gt; prod_head和ring-\u0026gt; prod_tail都复制到局部变量中。prod_next局部变量指向表的下一个元素，或者在批量入队的情况下指向多个元素。如果环中没有足够的空间（通过检查cons_tail 与 prod_head 差值可以检测到）\n// local variable core 2 cons_tail prod_head prod_next ↓ ↓ ↓ // local variable core 1 cons_tail prod_head prod_next ↓ ↓ ↓ | | | | | obj1 | obj2 |obj3 | | | | ↑ ↑ cons_head prod_head ↑ ↑ cons_tail prod_tail 修改ring结构中的ring-\u0026gt; prod_head以指向与prod_next相同的位置。此操作使用“比较并交换”（CAS）指令完成，该指令自动执行以下操作：\n如果ring-\u0026gt; prod_head与局部变量prod_head不同，则CAS操作失败，并且代码在第一步重新启动。\n[!NOTE]\n在该图中，操作在内核1上成功完成，而第一步在内核2上重新启动。之后在核心2上重试CAS操作，可以看到core2再次拿到prod_head\n// compare and swap succeseds on core1 ,failed on core2 // local variable core 2 cons_tail prod_head prod_next ↓ ↓ ↓ // local variable core 1 cons_tail prod_head prod_next ↓ ↓ ↓ | | | | | obj1 | obj2 |obj3 | | | | ↑ ↑ cons_head prod_head cons_tail prod_tail 否则，将ring-\u0026gt; prod_head设置为本地prod_next，CAS操作成功，然后继续处理。\n[!NOTE]\n最终核心1更新了ring（obj4）的一个元素，核心2更新了另一个（obj5）的元素。\n// compare and swap succeseds on core2 // local variable core 2 cons_tail prod_head prod_next ↓ ↓ ↓ // local variable core 1 cons_tail prod_head prod_next ↓ ↓ ↓ | | | | | obj1 | obj2 |obj3 | obj4 | obj5 | | ↑ ↑ cons_head prod_head ↑ ↑ cons_tail prod_tail 每个内核现在都想更新ring-\u0026gt; prod_tail。仅当ring-\u0026gt; prod_tail等于prod_head局部变量时，内核才能更新它。这仅在内核1上成立。操作已在内核1上完成。\n[!NOTE]\n// core2 wait for real prod_tail = it\u0026#39;s prod_head, core 1 compare real prod_tail to it\u0026#39;s prod_tail, and swap real prod_tail to move forward // local variable core 2 cons_tail prod_head prod_next ↓ ↓ ↓ // local variable core 1 cons_tail prod_head prod_next ↓ ↓ ↓ | | | | | obj1 | obj2 |obj3 | obj4 | obj5 | | ↑ ↑ cons_head prod_head ↑ ↑ cons_tail prod_tail 内核1更新了ring-\u0026gt; prod_tail之后，内核2也可以对其进行更新。该操作也在内核2上完成。\n[!NOTE]\n// core2 wait for real prod_tail = it\u0026#39;s prod_head, core 1 compare real prod_tail to it\u0026#39;s prod_tail, and swap real prod_tail to move forward // local variable core 2 cons_tail prod_head prod_next ↓ ↓ ↓ // local variable core 1 cons_tail prod_head prod_next ↓ ↓ ↓ | | | | | obj1 | obj2 |obj3 | obj4 | obj5 | | ↑ ↑ cons_head prod_head ↑ ↑ cons_tail prod_tail 10 线程池 # 先来点基础知识：\nC++ FUTURE提供了下面这些类型：\nProviders 类：std::promise, std::package_task Futures 类：std::future, shared_future. Providers 函数：std::async() 其他类型：std::future_error, std::future_errc, std::future_status, std::launch. std::future \u0026amp;\u0026amp; std::packaged_task # 什么是std::future? std::future 可以用来获取异步任务的结果，因此可以把它当成一种简单的线程间同步的手段。std::future 通常由某个 Provider 创建，你可以把 Provider 想象成一个异步任务的提供者，Provider 在某个线程中设置共享状态的值，与该共享状态相关联的 std::future 对象调用 get（通常在另外一个线程中） 获取该值，如果共享状态的标志不为 ready，则调用 std::future::get 会阻塞当前的调用者，直到 Provider 设置了共享状态的值（此时共享状态的标志变为 ready），std::future::get 返回异步任务的值或异常（如果发生了异常）。\n什么是std::packaged_task? std::packaged_task 包装一个可调用的对象，并且允许异步获取该可调用对象产生的结果，std::packaged_task 与 std::function 类似，只不过 std::packaged_task 将其包装的可调用对象的执行结果通过task.get_future传递给一个 std::future 对象（该对象通常在另外一个线程中获取 std::packaged_task 任务的执行结果）。\n有了问题就可以用线程池和异步执行，\n#include \u0026lt;memory\u0026gt; #include \u0026lt;utility\u0026gt; #include \u0026#34;thread_pool.h\u0026#34; namespace async { // Schedule a task to the given thread pool. If thread_pool is null, run the // task synchronously on the current thread. template \u0026lt;typename Func, typename... Args\u0026gt; auto ScheduleFuture(ThreadPool* thread_pool, Func\u0026amp;\u0026amp; f, Args\u0026amp;\u0026amp;... args) { if (thread_pool == nullptr) { Future\u0026lt;typename std::result_of\u0026lt;Func(Args...)\u0026gt;::type\u0026gt; future( std::async(std::launch::deferred, std::forward\u0026lt;Func\u0026gt;(f), std::forward\u0026lt;Args\u0026gt;(args)...)); future.Wait(); return future; } return thread_pool-\u0026gt;Schedule(std::forward\u0026lt;Func\u0026gt;(f), std::forward\u0026lt;Args\u0026gt;(args)...); } // Schedule a task to the default thread pool. template \u0026lt;typename Func, typename... Args\u0026gt; auto ScheduleFuture(Func\u0026amp;\u0026amp; f, Args\u0026amp;\u0026amp;... args) { return ScheduleFuture(ThreadPool::DefaultPool(), std::forward\u0026lt;Func\u0026gt;(f), std::forward\u0026lt;Args\u0026gt;(args)...); } // Asynchronously destroy a container. template \u0026lt;typename ContainerT\u0026gt; void DestroyContainerAsync(ThreadPool* thread_pool, ContainerT container) { ScheduleFuture(thread_pool, [_ = std::move(container)]() mutable { const auto unused = std::move(_); }); } // Same, but use the default thread pool. template \u0026lt;typename ContainerT\u0026gt; void DestroyContainerAsync(ContainerT container) { DestroyContainerAsync(ThreadPool::DisposalPool(), std::move(container)); } template \u0026lt;typename T\u0026gt; void WaitForFuture(const Future\u0026lt;T\u0026gt;\u0026amp; future) { future.Wait(); } } // namespace async 下面看线程池的代码，\nclass ThreadPool { public: explicit ThreadPool(int num_workers, const std::function\u0026lt;void(int index)\u0026gt;\u0026amp; init_thread = {}); ~ThreadPool(); // Return the default thread pool. static ThreadPool* DefaultPool(); // Return the disposal thread pool to destroy stuff asynchronously. static ThreadPool* DisposalPool(); ThreadPool(const ThreadPool\u0026amp;) = delete; ThreadPool\u0026amp; operator=(const ThreadPool\u0026amp;) = delete; int NumWorkers() const { return workers_.size(); } template \u0026lt;class Func, class... Args\u0026gt; using FutureType = Future\u0026lt;typename std::result_of\u0026lt;Func(Args...)\u0026gt;::type\u0026gt;; // Schedule a new task. template \u0026lt;class Func, class... Args\u0026gt; FutureType\u0026lt;Func, Args...\u0026gt; Schedule(Func\u0026amp;\u0026amp; f, Args\u0026amp;\u0026amp;... args) LOCKS_EXCLUDED(mutex_); private: absl::Mutex mutex_; absl::CondVar cond_var_ GUARDED_BY(mutex_); std::vector\u0026lt;std::thread\u0026gt; workers_; // A thread safe queue protected by condition_ and mutex_. std::queue\u0026lt;std::function\u0026lt;void()\u0026gt;\u0026gt; tasks_ GUARDED_BY(mutex_); bool stop_requested_ GUARDED_BY(mutex_) = false; }; template \u0026lt;class Func, class... Args\u0026gt; ThreadPool::FutureType\u0026lt;Func, Args...\u0026gt; ThreadPool::Schedule(Func\u0026amp;\u0026amp; f, Args\u0026amp;\u0026amp;... args) { using ReturnType = typename std::result_of\u0026lt;Func(Args...)\u0026gt;::type; const auto task = std::make_shared\u0026lt;std::packaged_task\u0026lt;ReturnType()\u0026gt;\u0026gt;( std::bind(std::forward\u0026lt;Func\u0026gt;(f), std::forward\u0026lt;Args\u0026gt;(args)...)); Future\u0026lt;ReturnType\u0026gt; res(task-\u0026gt;get_future()); // If there is no worker, this is an inline thread pool, and the task will be // immediately run on the current thread. int64_t tasks_size = -1; if (workers_.empty()) { (*task)(); } else { absl::MutexLock lock(\u0026amp;mutex_); // QCHECK(!stop_requested_) \u0026lt;\u0026lt; \u0026#34;The thread pool has been stopped\u0026#34;; tasks_.emplace([task]() { (*task)(); }); tasks_size = tasks_.size(); cond_var_.Signal(); } if (tasks_size \u0026gt;= 0) { QCOUNTER(\u0026#34;schedulefuture_callback_size\u0026#34;, tasks_size); } return res; } } #include \u0026#34;thread_pool.h\u0026#34; ThreadPool::ThreadPool(int num_workers, const std::function\u0026lt;void(int index)\u0026gt;\u0026amp; init_thread) { for (int index = 0; index \u0026lt; num_workers; ++index) { workers_.emplace_back([this, index, init_thread] { if (init_thread) { init_thread(index); } while (true) { std::function\u0026lt;void()\u0026gt; task; { absl::MutexLock lock(\u0026amp;mutex_); while (!stop_requested_ \u0026amp;\u0026amp; tasks_.empty()) { cond_var_.Wait(\u0026amp;mutex_); } if (stop_requested_ \u0026amp;\u0026amp; tasks_.empty()) { return; } task = std::move(tasks_.front()); tasks_.pop(); } task(); } }); } } ThreadPool::~ThreadPool() { { absl::MutexLock lock(\u0026amp;mutex_); stop_requested_ = true; cond_var_.SignalAll(); } for (std::thread\u0026amp; worker : workers_) { worker.join(); } } // static ThreadPool* ThreadPool::DefaultPool() { static ThreadPool* default_pool = new ThreadPool(FLAGS_default_pool_size); return default_pool; } // static ThreadPool* ThreadPool::DisposalPool() { static ThreadPool* disposal_pool = new ThreadPool(1); return disposal_pool; } 11 LFBB的实现 # 这几天看到一个实现很有意思的代码，https://github.com/DNedic/lfbb\n简单看一下头文件和C文件里面的核心代码\n... // 对于嵌入式系统，缓存同步是手动执行的，这个可以设置为false // 对于可能有false sharing的系统，需要设置这个为true，这个会要求将原子变量要求对cacheline size（默认64）对齐 // 对于现代CPU，如果两个不同CPU对同一个cacheline里面的两个对象操作，就会导致false sharing，所以这里需要alignas一下 #ifndef LFBB_MULTICORE_HOSTED #define LFBB_MULTICORE_HOSTED false #endif // 现代CPU体系的cacheline size，看芯片的类型 #ifndef LFBB_CACHELINE_LENGTH #define LFBB_CACHELINE_LENGTH 64U #endif /*************************** TYPES ****************************/ typedef struct { size_t size; /**\u0026lt; Size of the data array */ uint8_t *data; /**\u0026lt; Pointer to the data array */ bool write_wrapped; /**\u0026lt; Write wrapped flag, used only in the producer */ bool read_wrapped; /**\u0026lt; Read wrapped flag, used only in the consumer */ #if LFBB_MULTICORE_HOSTED alignas(LFBB_CACHELINE_LENGTH) atomic_size_t r; /**\u0026lt; Read index */ alignas(LFBB_CACHELINE_LENGTH) atomic_size_t w; /**\u0026lt; Write index */ alignas(LFBB_CACHELINE_LENGTH) atomic_size_t i; /**\u0026lt; Invalidated space index */ #else atomic_size_t r; /**\u0026lt; Read index */ atomic_size_t w; /**\u0026lt; Write index */ atomic_size_t i; /**\u0026lt; Invalidated space index */ #endif } LFBB_Inst_Type; //剩下就是初始化，释放，获取之类的啥的 void LFBB_Init(LFBB_Inst_Type *inst, uint8_t *data_array, size_t size); uint8_t *LFBB_WriteAcquire(LFBB_Inst_Type *inst, size_t free_required); void LFBB_WriteRelease(LFBB_Inst_Type *inst, size_t written); uint8_t *LFBB_ReadAcquire(LFBB_Inst_Type *inst, size_t *available); void LFBB_ReadRelease(LFBB_Inst_Type *inst, size_t read); 看一下.c文件\n// lfbb是单写单读，所以w只有writer自己操作，但是r是另外一个线程能够操作的 // 所以 // 先是memory_order_relaxed获取w，memory_order_acquire获取r（因为w是自己会改，而r是别人会改，所以必须acquire方式获取） uint8_t *LFBB_WriteAcquire(LFBB_Inst_Type *inst, const size_t free_required) { assert(inst != NULL); assert(inst-\u0026gt;data != NULL); /* Preload variables with adequate memory ordering */ const size_t w = atomic_load_explicit(\u0026amp;inst-\u0026gt;w, memory_order_relaxed); const size_t r = atomic_load_explicit(\u0026amp;inst-\u0026gt;r, memory_order_acquire); const size_t size = inst-\u0026gt;size; const size_t free = CalcFree(w, r, size); const size_t linear_space = size - w; const size_t linear_free = MIN(free, linear_space); /* Try to find enough linear space until the end of the buffer */ if (free_required \u0026lt;= linear_free) { return \u0026amp;inst-\u0026gt;data[w]; } /* If that doesn\u0026#39;t work try from the beginning of the buffer */ if (free_required \u0026lt;= free - linear_free) { inst-\u0026gt;write_wrapped = true; return \u0026amp;inst-\u0026gt;data[0]; } /* Could not find free linear space with required size */ return NULL; } // lfbb是单写单读，所以w只有writer自己操作，但是w的修改是需要让另外一个线程能够读取到的 // 所以 // 先是memory_order_relaxed获取w，memory_order_release写入w（因为w是自己会改，但必须让别人知道，所以必须release方式写入） void LFBB_WriteRelease(LFBB_Inst_Type *inst, const size_t written) { assert(inst != NULL); assert(inst-\u0026gt;data != NULL); size_t w = atomic_load_explicit(\u0026amp;inst-\u0026gt;w, memory_order_relaxed); /* If the write wrapped set the invalidate index and reset write index*/ size_t i; if (inst-\u0026gt;write_wrapped) { inst-\u0026gt;write_wrapped = false; i = w; w = 0U; } else { i = atomic_load_explicit(\u0026amp;inst-\u0026gt;i, memory_order_relaxed); } /* Increment the write index */ assert(w + written \u0026lt;= inst-\u0026gt;size); w += written; /* If we wrote over invalidated parts of the buffer move the invalidate * index */ if (w \u0026gt; i) { i = w; } /* Wrap the write index if we reached the end of the buffer */ if (w == inst-\u0026gt;size) { w = 0U; } /* Store the indexes with adequate memory ordering */ atomic_store_explicit(\u0026amp;inst-\u0026gt;i, i, memory_order_relaxed); atomic_store_explicit(\u0026amp;inst-\u0026gt;w, w, memory_order_release); } uint8_t *LFBB_ReadAcquire(LFBB_Inst_Type *inst, size_t *available) { assert(inst != NULL); assert(inst-\u0026gt;data != NULL); assert(available != NULL); /* Preload variables with adequate memory ordering */ const size_t r = atomic_load_explicit(\u0026amp;inst-\u0026gt;r, memory_order_relaxed); const size_t w = atomic_load_explicit(\u0026amp;inst-\u0026gt;w, memory_order_acquire); /* When read and write indexes are equal, the buffer is empty */ if (r == w) { *available = 0; return NULL; } /* Simplest case, read index is behind the write index */ if (r \u0026lt; w) { *available = w - r; return \u0026amp;inst-\u0026gt;data[r]; } /* Read index reached the invalidate index, make the read wrap */ const size_t i = atomic_load_explicit(\u0026amp;inst-\u0026gt;i, memory_order_relaxed); if (r == i) { inst-\u0026gt;read_wrapped = true; *available = w; return \u0026amp;inst-\u0026gt;data[0]; } /* There is some data until the invalidate index */ *available = i - r; return \u0026amp;inst-\u0026gt;data[r]; } void LFBB_ReadRelease(LFBB_Inst_Type *inst, const size_t read) { assert(inst != NULL); assert(inst-\u0026gt;data != NULL); /* If the read wrapped, overflow the read index */ size_t r; if (inst-\u0026gt;read_wrapped) { inst-\u0026gt;read_wrapped = false; r = 0U; } else { r = atomic_load_explicit(\u0026amp;inst-\u0026gt;r, memory_order_relaxed); } /* Increment the read index and wrap to 0 if needed */ r += read; if (r == inst-\u0026gt;size) { r = 0U; } /* Store the indexes with adequate memory ordering */ atomic_store_explicit(\u0026amp;inst-\u0026gt;r, r, memory_order_release); } 12 MPMC \u0026amp; SPSC # 这两天在优化一个混杂了计算和通信的复杂模型，要求在一瞬间有任务冲击的情况下，满足实行性要求，所以在修改网络模型和计算模型，这里面涉及到一个怎么把计算任务 平均 \u0026amp; 高效地分发到每个计算任务\n设计两种模式\n使用SPSC：假设两个IO，两个计算，那么每个IO内置两个SPSC分别指向两个计算，每次来了任务将任务轮训调度到自己的两个队列 使用MPMC：假设多个IO，多个计算，IO和计算之间共享MPMC 希望达到的效果是：\n能够高效的Enqueue和Dequeue 能够保证待Dequeue的任务在最惨的情况 \u0026amp; under heavy contention 下不会等待过久的时间。 因此参考了上面的设计模式，对比了下面的几种情况\n使用SPSC：\nhttps://github.com/DNedic/lfbb 使用MPMC\nhttps://github.com/rigtorp/MPMCQueue\nhttps://github.com/facebook/folly/blob/main/folly/MPMCQueue.h\nhttps://github.com/cameron314/concurrentqueue\n测试方案设计如下：\n客户端\n使用Asio写了一个纯异步的客户端，有一个QPS记录器，尽量快速地增加QPS，（请注意这里我们不是令牌桶，要的就不是均匀的请求分发）如果超过了QPS限制也不能阻塞转而去处理收包事件，等待QPS恢复。\n具体指标200个连接，32个发送连接， 3000的QPS， 持续60S\n服务端\n设计等同于CPU核心数量的计算和等同于CPU核心数量*2的IO，每个计算的Dequeue都让CPU处于一直自旋的状态，假设每个任务计算需要花费2～5ms。要求不能超时超过一个特定的标准值，这个参考值会最终决定我们的选择，一会再单独说。需要测试两种情况 服务端需要同时完成很慢的计算任务处理，Dequeue的效率 服务端无需完成很慢的计算任务，就是单纯较轻松的空转，Dequeue的效率 使用CDF散点图让我们直观看一下效率\n第一张图为服务端需要同时完成很慢的计算任务处理，单位为ms 第二张图为服务端就是较轻松的空转，单位为us 分别针对服务端需要参与大量计算，和服务端没有计算，就是快速响应的情况，分析可知\n服务端有较重的计算任务时\n追求快速响应，那么moodycamel::ConcurrentQueue \u0026amp; moodycamel::BlockingConcurrentQueue 的效果会很好，3.7ms内91.9%的请求被Dequeue，但有长尾效应，有5%的请求慢于223ms才dequeue。如果超时时间的值小于5ms，可以选择这种。LFBB \u0026amp; Rigotorp可以直接排除\nRigotorp最稳定，15ms 99.5%的请求都Dequeue，如果超时时间大于15ms，并且能给任务处理流出足够的响应的时间，Rigotop最合适。这里稍微多说一句，这个Dequeue不是说Rigotorp Dequeue的效率，它实际上是算上了本身计算任务所花费的时延，这就是为什么看起来同时来的一堆任务，这个从任务创建到Dequeue的时间时不断增加的，因为这些增加的时间里面，在处理计算任务\nLFBB，中规中矩。\n服务端较轻松的空转时(注意这里我没再测试moodycamel::BlockingConcurrentQueue)\n追求快速响应，那么moodycamel::ConcurrentQueue的效果会很好，0.6ms内95%的请求被Dequeue，但有长尾效应，有3%的请求慢于1ms才dequeue(这个1ms的结果我没截）。\nRigotorp最稳定，0.8ms 99.5%的请求都Dequeue。\nLFBB，中规中矩。\n因此可以得出结论：\nRigotorp属于性能最稳定，其吞吐量最优，能保证最糟的情况下，也能把任务拿到，不会有长尾效应 追求快速响应，那么moodycamel::ConcurrentQueue的效果会很好，0.6ms内95%的请求被Dequeue，但有长尾效应，有3%的请求慢于1ms才dequeue(这个1ms的结果我没截） 所以接下来看一下Rogtorp的MPMC怎么实现的，参考论文https://dl.acm.org/doi/pdf/10.1145/2086696.2086728，感觉确实做的很牛！\n传统的队列算法有一种或另一种变体试图通过主入口（通常是头指针），这种操作需要CAS来判断是否能够对头部操作。\nRigtorp的解决方案背后的直觉可以用火车站和队列算法的类比来解释：排队过程类似于乘客登上火车，乘客（处理器）可以获得车票（整数），然后登上（排队）火车（队列）直接并行到他们的座位（阵列位置）。换言之，不需要CAS等待某个指针操作完成，而是直接拿到车票，等着座位可以坐。\n那么为什么Rigtorp的效率更高呢，这里结合伪代码来分析下\n其他使用“inquire-then-update”方法的算法（例如 MS-Queue 算法或自旋锁实现）进行一次队列操作至少需要两次完整的内存往返。 针对获取SpinLock的方法，过程为（1）获取锁，（2）读取队列指针，（3）更新队列结构，（4）释放锁。最好的情况下，获取锁需要1个RTT，对当前指针执行获取并写入需要一个RTT，释放只花费0.5RTT。所以一次操作花费1/2.5RTT。但是可能对一个锁的频繁占用造成等待。 针对非常经典的DPDK 多生产多消费环形队列 而Rigtorp的MPMC遵循另一种途径：如果可能的话，每一个单独的内存操作都应该保证成功。其实现的核心在很大程度上依赖于Fetch and Add”操作，这个操作总是能够通过一次内存操作成功地改变队列的状态。 Rigtorp的（写，这里读写都可以，只说写）过程可以模拟为：（1）获取Ticket ，（2）读取Turn判断是否到自己的“回合”可以操作。最好的情况下，FetchAndAdd获取Ticket，一个原子变量RTT，读取Turn花费一个原子变量RTT。所以一个操作花费1/2RTT，最好情况下两个读写两个顺序执行，所以直接写入，效率乘二。多CPU争用的情况很少 分析一下效率\n其它方法，比方说 Rigtorp的效率 假设读写者的效率都极高 假设读写者的效率并不高 这里再看一下Rigtorp的代码，pop \u0026amp; push的代码都非常简单，就和参考文献写的一致，主要看try_pop: try_pop的逻辑会稍微复杂一点点，我画了一个流程图\nvoid pop(T \u0026amp;v) noexcept { auto const tail = tail_.fetch_add(1); auto \u0026amp;slot = slots_[idx(tail)]; while (turn(tail) * 2 + 1 != slot.turn.load(std::memory_order_acquire)) ; v = slot.move(); slot.destroy(); slot.turn.store(turn(tail) * 2 + 2, std::memory_order_release); } // push 包着这个emplace template \u0026lt;typename... Args\u0026gt; void emplace(Args \u0026amp;\u0026amp;...args) noexcept { static_assert(std::is_nothrow_constructible\u0026lt;T, Args \u0026amp;\u0026amp;...\u0026gt;::value, \u0026#34;T must be nothrow constructible with Args\u0026amp;\u0026amp;...\u0026#34;); auto const head = head_.fetch_add(1); auto \u0026amp;slot = slots_[idx(head)]; while (turn(head) * 2 != slot.turn.load(std::memory_order_acquire)) ; slot.construct(std::forward\u0026lt;Args\u0026gt;(args)...); slot.turn.store(turn(head) * 2 + 1, std::memory_order_release); } bool try_pop(T \u0026amp;v) noexcept { auto tail = tail_.load(std::memory_order_acquire); for (;;) { auto \u0026amp;slot = slots_[idx(tail)]; if (turn(tail) * 2 + 1 == slot.turn.load(std::memory_order_acquire)) { if (tail_.compare_exchange_strong(tail, tail + 1)) { v = slot.move(); slot.destroy(); slot.turn.store(turn(tail) * 2 + 2, std::memory_order_release); return true; } } else { auto const prevTail = tail; tail = tail_.load(std::memory_order_acquire); if (tail == prevTail) { return false; } } } } 这里再看下moodycamel::ConcurrentQueue的实现方法，考虑下为什么moodycamel::ConcurrentQueue的最差情况不比rigtorp好，但是它最快的情况下更好\n13 Token Bucket # 这两天测试数据，看到了一个一个令牌桶，写的很有意思，还是Rigtorp大佬的代码库，看了一下使用的实际上是时间戳+原子变量实现。仔细看了一下，发现实现的很简单也很好玩。具体的代码解释和源代码一起写到了下面的注释\n// © 2023 Erik Rigtorp \u0026lt;erik@rigtorp.se\u0026gt; // SPDX-License-Identifier: MIT #pragma once #include \u0026lt;atomic\u0026gt; #include \u0026lt;chrono\u0026gt; // 默认时钟用chrono 的steady_clock template \u0026lt;typename Clock = std::chrono::steady_clock\u0026gt; class TokenBucket { public: TokenBucket() = default; // timePerToken_ 实际上是多久产生一个token，这里的rate理解为qps的话，那么timePerToken_就是1/qps // burstSize 对应于https://en.wikipedia.org/wiki/Token_bucket里面的burstsize，指的是一下子最多拿走多少，可以理解为当前桶的容量 TokenBucket(const uint64_t rate, const uint64_t burstSize) : timePerToken_(std::chrono::nanoseconds(std::chrono::seconds(1)) / rate), timePerBurst_(burstSize * timePerToken_) {} // 这里就是真正的判断是否可以获取的地方 bool consume(const uint64_t tokens) { // 先拿到当前时间戳 const auto now = Clock::now(); // 看看获得对应数量的tokens需要多少时间 const auto timeNeeded = tokens * timePerToken_; const auto minTime = now - timePerBurst_; // 获取上次拿的时间， auto oldTime = time_.load(std::memory_order_relaxed); for (;;) { auto newTime = oldTime; if (minTime \u0026gt; newTime) { newTime = minTime; } // 上次拿的时候到多久才能拿到想要的tokens的个数，计算出来这个时间是多少。 // 如果这个时间比现在还大，那是绝对不能满足的，所以直接返回失败即可 // 这里有个点，如果oldTime被其它的线程抢走了，那下面的if时必然失败的，所以同样需要放弃 newTime += timeNeeded; if (newTime \u0026gt; now) { return false; } // 前面是判断能不能拿，这次就是要挪动time的浮标，来判断是不是真正可以拿走了 // 如果和oldTime一样，说明没有其它的token消费者动它，直接拿了就走返回了 // 如果和oldTime不一样，就说明被其它的token获取者拿走了，此时compare_exchange_weak会把time_的新的值给到oldTime， // 换言之重新执行了，auto oldTime = time_.load(std::memory_order_relaxed);，然后再次进入for循环，直到下一次能拿到 // 但是如果发现token一致不够，或者说要是拿token比当前时间晚才能拿到，那就放弃，就在上面的if里面return false了 if (time_.compare_exchange_weak(oldTime, newTime, std::memory_order_relaxed, std::memory_order_relaxed)) { return true; } } return false; } private: // 这个可以理解为一个单调递增的time std::atomic\u0026lt;typename Clock::time_point\u0026gt; time_ = {Clock::time_point::min()}; // 问题，为什么需要这两个变量？很简单，这个东西是衡量需要多少时间的基本单位 std::chrono::nanoseconds timePerToken_; std::chrono::nanoseconds timePerBurst_; }; 结尾 # 唉，尴尬\n","date":"2021 年 7 月 21 日","externalUrl":null,"permalink":"/posts/2021-07-21-c++%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%E5%BA%93/","section":"Posts","summary":"","title":"C++开发工具库","type":"posts"},{"content":"","date":"2021 年 7 月 21 日","externalUrl":null,"permalink":"/tags/tools/","section":"Tags","summary":"","title":"TOOLS","type":"tags"},{"content":"","date":"2021 年 6 月 1 日","externalUrl":null,"permalink":"/tags/hpke/","section":"Tags","summary":"","title":"HPKE","type":"tags"},{"content":" HPKE笔记 # 这几天看ECH和HPKE的笔记，然后惊讶地发现国内没有人看这个的，就知乎上有个机器人一样的东西提到一句，所以就打算记录下这个东西并简单总结，所以有了这片博客。从某种程度来说，这片博客大部分内容是RFCHybrid Public Key Encryption draft-irtf-cfrg-hpke-09的翻译，当然里面会穿插一些具体的内容。\n2024/07/04，这几天重新翻笔记发现一些错误。再重新看了下HPKE标准发现，已经正式发布，而且内容发生了一些变化，因此做一些更正。\n注意，以“我：”开始的内容，都是我自己写的东西，不在官方内容里。纯粹是方便理解加的。\n0 HPKE是什么（白话版） # HPKE即hybrid public-key encryption(HPKE)，翻译成中文是复合公钥加密方案。HPKE提供的实际上是利用接收端公钥产生会话秘钥，并加密任意长度的明文信息的功能。说的好像很复杂， 举个例子就明白了，TLS协议就是一个关联了一定上下文信息拓展后的HPKE。\n按照具体模块划分，HPKE可以视为秘钥衍生函数（key derivation function (KDF)），密钥封装机制（key encapsulation mechanism(KEM)）与加密并认证机制（authenticated encryption with additional data (AEAD)）三个组合起来一种实现。目前HPKE适用于任何基于非对称密钥封装机制（KEM）、密钥派生函数（KDF）和带有附加数据的认证加密（AEAD）加密函数的组合。\n上面这段话说起来好像还是很难懂，我用最简单（可能会有部分术语需要阅读下面的内容）的话语解释下：\nHPKE实际上是发送方利用接收端的公私钥对里面的公钥，和本地私有或者临时产生的公私钥对里面的私钥计算得出一个共享的密钥。这个共享的密钥是不会明文传递的，它只会把地私有或者临时产生的公私钥对里面的公钥传递给接收方。发送方和接收方除了传递公钥外，还有一些诸如附加信息，比方说认证信息，普通信息参与计算产生一个密钥派生上下文，里面会包含nonce等信息。使用这些上下文信息与共享密钥就可以对明文做加密运算了。\n举个简单的例子，就可以明白了，这里以DH交换协议为例子，请注意这里需要读者知道DH交换的基本前提：\nDH(skX, pkY): 使用私钥skX和公钥pkY执行非交互式Diffie-Hellman交换（这里的非交互我理解是指没有真正的走网络协议啥的传递），以生成长度为Ndh的Diffie-Hellman共享密钥。这个过程说白了就是一个公式DH(skE, pkR)=DH(skR, pkE) 下面给出HPKE在DH上的核心流程，即计算得出KEM共享密钥：\n首先生成一个临时KEM公私密钥对（KEM Ephemeral Key Pair)，使用临时私钥和接受方公钥执行Diffie-Hellman交换计算得出一个共享的DH交换结果（这个结果是只有通信双方知道），DH交换结果参与运算得出KEM共享密钥。而临时公钥经过编码后会发送给接收方。如果关键的代码为\ndef Encap(pkR): skE, pkE = GenerateKeyPair() dh = DH(skE, pkR) enc = SerializePublicKey(pkE) pkRm = SerializePublicKey(pkR) kem_context = concat(enc, pkRm) shared_secret = ExtractAndExpand(dh, kem_context) return shared_secret, enc 接收方收到编码过的发送方临时公钥，解码后和自己的接收方私钥做DH交换，利用DH交换结果得到得出KEM共享密钥\ndef Decap(enc, skR): pkE = DeserializePublicKey(enc) dh = DH(skR, pkE) pkRm = SerializePublicKey(pk(skR)) kem_context = concat(enc, pkRm) shared_secret = ExtractAndExpand(dh, kem_context) return shared_secret 计算\n1 总览 # 自从公钥秘钥体制诞生就有很多尝试结合非对称加密和对称加密来提供机密性的例子，这种结合往往是在利用对称加密的性能优势同时，使用非对称机密的管理优势（我理解指可以方便的暴露公共密钥）。传统的实现方式是使用非对称秘钥加密对称秘钥。HPKE采用了一种不同的手法：使用公钥生迭代生成对称秘钥和封装后的密钥。具体来说，就是加密消息传达了一个用公钥密码体制（交换算法）封装的（对称）加密密钥，以及一个或多个使用该密钥加密的任意大小的密文。\n2 名词定义 # 2.1 基础名词 # 以下术语用于描述 HPKE 的操作、角色和行为，这部分没有任何理解的成本，主要是区分开谁是谁：\n(skX, pkX)：角色X使用的一对密钥封装机制（ Key Encapsulation Mechanism (KEM)）密钥对。X可以是 S（发送方）, R（接收方），或者是E（临时派生，不过一般这个最后会变成S用的密钥），\u0026ldquo;skX\u0026rdquo; 是秘钥 \u0026ldquo;pkX\u0026rdquo; 是公钥。我：这个东西可以视为HPKE最基本的东西了，没有密钥封装机制密钥对或者说公私密钥对就没有安全的派生共享密钥的方法，这里的KEM Key Pair可以理解为（EC）DHE密钥协商的起点。 pk(skX)：和KEM私钥对应的KEM公钥，X代表角色是谁。对发送方而言，skX可能是临时生成的。 Sender (S)：发送者。 Recipient (R)：接受者 Ephemeral (E): 临时产生的随机值，一般是只用一次，大多数情况都是发送方会调用，参与一次“会话”计算共享密钥流程。 concat(x0, ..., xN)：拼接字符串。比方说\u0026quot;concat(0x01, 0x0203, 0x040506) = 0x010203040506\u0026quot;. \u0026ldquo;random(n)\u0026rdquo;: 产生长度为\u0026quot;n\u0026quot; 字节长度的伪随机字符串 \u0026ldquo;I2OSP(n, w)\u0026quot;：转换非负整数n为一个长度为w的使用网络字节序或者说大端的字符串。参考RFC8017 \u0026ldquo;OS2IP(x)\u0026quot;：将字符串 x 转换为一个非负整数，如 [RFC8017] 中所述，这里假定字符串X为大端字节顺序。 2.2 HPKE的加解密基础名词 # 具体到一套HPKE的内部，按照上面提到的三个模块划分，有很多基础的名词需要理解。\nKEM\nGenerateKeyPair()：随机算法用于生成秘钥对 (skX, pkX)。我：很多时候通信发送方是“匿名”的，只能随机生成一个公私密钥对\nDeriveKeyPair(ikm)\u0026quot;：确定性的密钥延生算法，从ikm衍生出固定的秘钥对 \u0026ldquo;(skX, pkX)\u0026rdquo;.\nSerializePublicKey(pkX)：将公钥\u0026quot;pkX\u0026rdquo;.编码为\u0026quot;Npk\u0026quot;长度 的字符串（说白了就是序列化）\n\u0026ldquo;DeserializePublicKey(pkXm)\u0026quot;：反序列化公钥\n\u0026ldquo;Encap(pkR)\u0026ldquo;一整套流程，包括：1 使用随机算法生成一个临时，固定长度的对称密钥（被称为“KEM 共享密钥”）2 生成一个1里面KEM共享密钥的封装结果，这个结果只有pkR，即持有pkR的私钥接收方可以解密。\n\u0026ldquo;Decap(enc, skR)\u0026ldquo;使用私钥skR从KEM共享密钥的封装结果enc中还原临时，固定长度的对称密钥也就是KEM共享秘钥\n\u0026ldquo;AuthEncap(pkR, skS)\u0026quot;：同Encap类似，但是附加一个验证：确保KEM共享秘钥由skS的拥有者，即发送方生成。\n\u0026ldquo;AuthDecap(enc, skR, pkS)\u0026quot;：同Decap类似，但是接收端可以验证KEM共享秘钥由skS的拥有者生成。\nKDF\n\u0026ldquo;Extract(salt, ikm)\u0026quot;：结合可选参数salt，从输入密钥材料ikm里，提取固定长度为Nh字节的伪随机秘钥。\n\u0026ldquo;Expand(prk, info, L)\u0026quot;：利用刚才的伪随机秘钥，即prk，结合可选字符串info，拓展为长度为L的最终产生的秘钥材料。\nAEAD\n\u0026ldquo;Seal(key, nonce, aad, pt)\u0026quot;。使用关联数据aad和对称秘钥key和nonce加密明文pt，产生秘文和tag，最终的结果为ct\n\u0026ldquo;Open(key, nonce, aad, ct)\u0026rdquo; 使用关联数据aad和对称秘钥key和nonce解密秘文ct，产生明文pt。需要验证密文中tag是不是有效的。\n一般说HPKE的时候，都会提具体的密码套件是啥，这里密码套件是一个（KEM、KDF、AEAD）组成的三元组，三元组里面每一项都是具体的算法。\n还有一点要注意，有一个基本的秘钥操作：\ndef LabeledExtract(salt, label, ikm): labeled_ikm = concat(\u0026#34;HPKE-v1\u0026#34;, suite_id, label, ikm) return Extract(salt, labeled_ikm) def LabeledExpand(prk, label, info, L): labeled_info = concat(I2OSP(L, 2), \u0026#34;HPKE-v1\u0026#34;, suite_id, label, info) return Expand(prk, labeled_info, L) 3 HPKE的内容 # 这部分给出HPKE提供的关键函数和完整的流程定义，我把官方的解释做了一下润色，不过直接看英文版文档我理解就够了。\n官方定义了几种 HPKE 变体（这个变体含义好像很难理解，可以这么理解：HPKE对应大类人，而人细分为很多变体，比方说黑人，白人黄种人blablabla）。所有变体都需要输入接收方公钥和明文pt，并生成封装后的密钥enc和一堆密文序列ct。HPKE的构建方式保证只有skR的持有者，即接收端能够从enc解封装密钥并解密密文。所有算法还接受一个info参数，可用于影响密钥的生成（比方说提供密钥身份信息）和一个aad参数，用于给AEAD 算法提供额外的认证数据。¶ 除了将公钥加密产生enc的基本情况外，官方还提供三种认证变体：\n一种认证通过PSK就是预共享密钥，即你有PSK，你是真用户。这种模式叫做mode_psk，用一字节表示，内容为0x01 一种认证通过持有KEM 私钥，就是你有私钥，你是真用户。这种模式叫做mode_auth，用一字节表示，内容为0x02 一种认证同时拥有预共享密钥和 KEM 私钥的情况，这个结合上面两种算法。这种模式叫做mode_auth_psk，用一字节表示，内容为0x03 这三种认证变体都会为加密操作，即产生enc的过程，提供额外的密钥材料。\n综上，可以将HPKE视为包含两步的完整流程：\n建立一个在发送方和接收方之间共享的加密上下文（之所以不是加解密上下文，注意HPKE只用于单向传输，发送方不能又用它加密，又解密，我觉得这是英文里面只提加密上下文的原因）。¶。这里加密上下文可以理解为包含AEAD 算法，密钥进行编码，nonce的结构。这里nonce不会参与多个明文加密行为。这个加密上下文还支持用于导出密钥（用于比方说复用等环境，可以对标TLS） 使用该上下文来加密或解密内容。 接下来细说两个步骤。\n3.1 创建加密上下文 # 无论哪种HPKE的变体需要输入一下内容来参与运算，从而得出加密上下文\nmode，一字节HPKE 模式，就上面提到的三种变体+基础模式\n\u0026ldquo;shared_secret\u0026rdquo;，KEM共享秘钥，本次会话生成\n\u0026ldquo;info\u0026rdquo;，应用程序提供的信息 (可选，初始值为空字符串，就是\u0026rdquo;\u0026rdquo;).\n\u0026ldquo;psk\u0026rdquo;，发送方和接收方都持有的预共享密钥（PSK）（可选；默认值为空字符串）。\n\u0026ldquo;psk_id\u0026rdquo;，PSK 的标识符（可选；默认值 \u0026ldquo;\u0026quot;），因为可能有多个PSK\n在 Auth 和 AuthPSK 模式中，接收方可以确信发送方持有私有密钥skS。对于上面提到的DHKEM 变体，发送端的密钥是可能泄露了的，所以如果可选的话，最好使用PSK或者Auth模式。\n好，现在我们开始看看针对发送方或者接收方如何产生加密上下文，首先需要指明HPKE的ciphersuite，HPKE 算法标识符，包含 KEM kem_id、KDF kdf_id 和 AEAD aead_id 的信息。诸如里面的xxx_id一般是预先定义好的。\nsuite_id = concat( \u0026#34;HPKE\u0026#34;, I2OSP(kem_id, 2), I2OSP(kdf_id, 2), I2OSP(aead_id, 2) ) 具体的计算流程如下（请注意，这里不涉及如何传递Enc），ROLE为接收方或者发送方，简单来说就是：\n检查HPKE模式和传递的PSK信息是否充足，如果不匹配就报错 输入上面的输入内容，计算得出通信密钥 default_psk = \u0026#34;\u0026#34; default_psk_id = \u0026#34;\u0026#34; def VerifyPSKInputs(mode, psk, psk_id): got_psk = (psk != default_psk) got_psk_id = (psk_id != default_psk_id) if got_psk != got_psk_id: raise Exception(\u0026#34;Inconsistent PSK inputs\u0026#34;) if got_psk and (mode in [mode_base, mode_auth]): raise Exception(\u0026#34;PSK input provided when not needed\u0026#34;) if (not got_psk) and (mode in [mode_psk, mode_auth_psk]): raise Exception(\u0026#34;Missing required PSK input\u0026#34;) def KeySchedule\u0026lt;ROLE\u0026gt;(mode, shared_secret, info, psk, psk_id): VerifyPSKInputs(mode, psk, psk_id) psk_id_hash = LabeledExtract(\u0026#34;\u0026#34;, \u0026#34;psk_id_hash\u0026#34;, psk_id) info_hash = LabeledExtract(\u0026#34;\u0026#34;, \u0026#34;info_hash\u0026#34;, info) key_schedule_context = concat(mode, psk_id_hash, info_hash) secret = LabeledExtract(shared_secret, \u0026#34;secret\u0026#34;, psk) key = LabeledExpand(secret, \u0026#34;key\u0026#34;, key_schedule_context, Nk) base_nonce = LabeledExpand(secret, \u0026#34;base_nonce\u0026#34;, key_schedule_context, Nn) exporter_secret = LabeledExpand(secret, \u0026#34;exp\u0026#34;, key_schedule_context, Nh) return Context\u0026lt;ROLE\u0026gt;(key, base_nonce, 0, exporter_secret) 3.1.1 HPKE_BASE Mode 加密公钥 # HPKE 方案的最基本功能是KEM私钥拥有者能够对进行加密操作。调用SetupBaseS()和 SetupBaseR()流程可以针对性地建立用于加密和解密的上下文。\n这里KEM 共享密钥产生需要 KDF函数结合，描述密钥交换的信息以及调用者提供的显式 info 参数来计算得出。。\n流程参数pkR是接受方公钥，enc 是一个封装后的的 KEM 共享密钥。\ndef SetupBaseS(pkR, info): shared_secret, enc = Encap(pkR) return enc, KeyScheduleS(mode_base, shared_secret, info, default_psk, default_psk_id) def SetupBaseR(enc, skR, info): shared_secret = Decap(enc, skR) return KeyScheduleR(mode_base, shared_secret, info, default_psk, default_psk_id) 3.1.2 使用PSK认证 # 这种变体通过允许接收方通过验证发送方拥有给定的预共享密钥（PSK）来认证发送方。在[第 9.1 节][0]中有更详细描述，PSK 是如何在某些对手模型中提供了更高的保密。这里假设双方都都清楚该使用哪个PSK和具体psk_id是什么。\n这种模式和HPKE_BASE模式的主要区别在于，psk和psk_id值被用作 KDF 的ikm输入（而不是使用空字符串）\ndef SetupPSKS(pkR, info, psk, psk_id): shared_secret, enc = Encap(pkR) return enc, KeyScheduleS(mode_psk, shared_secret, info, psk, psk_id) def SetupPSKR(enc, skR, info, psk, psk_id): shared_secret = Decap(enc, skR) return KeyScheduleR(mode_psk, shared_secret, info, psk, psk_id) 3.1.3 使用非对称秘钥认证 # 这种变体通过允许接收方验证发送方拥有给定的 KEM 私钥。说白了就是因为 AuthDecap(enc, skR, pkS) 只有在封装KEM shared key的 enc 由 AuthEncap(pkR, skS) 生成时（其中 skS 是与 pkS 对应的私钥），才会产生正确的 KEM 共享密钥。换句话说，最多两个实体（在 DHKEM 的情况下恰好是两个）可以生成此密钥，因此如果接收方最多为一个，那么发送方极有可能是另一个。\n与base mode的主要区别在于对 Encap() 和 Decap() 的调用被对 AuthEncap() 和 AuthDecap() 的调用所取代，它们将发送方的公钥添加到其内部上下文字符串中。函数参数 pkR 和 pkS 是公钥，而 enc 是封装的 KEM 共享密钥。¶\n显然，这种变体只能与提供 AuthEncap() 和 AuthDecap() 过程的 KEM 一起使用。\n此机制仅验证发送方的密钥对，而不是任何其他标识符。如果应用程序希望将 HPKE 密文或导出的秘密与发送方的其他标识（例如电子邮件地址或域名）绑定，则应将其他标识符包含在 info 参数中，以避免身份错误绑定问题\n使用公钥认证的情况下构建加密环境。\ndef SetupAuthS(pkR, info, skS): shared_secret, enc = AuthEncap(pkR, skS) return enc, KeyScheduleS(mode_auth, shared_secret, info, default_psk, default_psk_id) def SetupAuthR(enc, skR, info, pkS): shared_secret = AuthDecap(enc, skR, pkS) return KeyScheduleR(mode_auth, shared_secret, info, default_psk, default_psk_id) 3.1.5 使用PSK+非对称秘钥认证 # 使用公钥+PSK认证的情况下构建加密环境。这个我就不多赘述了。基本没变化\ndef SetupAuthPSKS(pkR, info, psk, psk_id, skS): shared_secret, enc = AuthEncap(pkR, skS) return enc, KeyScheduleS(mode_auth_psk, shared_secret, info, psk, psk_id) def SetupAuthPSKR(enc, skR, info, psk, psk_id, pkS): shared_secret = AuthDecap(enc, skR, pkS) return KeyScheduleR(mode_auth_psk, shared_secret, info, psk, psk_id) 3.2 加密与解密 # 上面产生了具体的加密上下文，那么接下来就可以进行数据的加密和解密了。\nHPKE 允许在一次会话中进行多次加密操作。由于设置中涉及的公钥操作通常比对称加密或解密更昂贵，这使得应用程序能够分摊公钥操作的成本，降低总体开销。\n然而，为了避免随机数重用，这种加密必须是有状态的。上述每个设置过程都会生成一个特定于角色的上下文对象，该对象存储 AEAD 和秘密导出参数。AEAD 参数包括\n正在使用的 AEAD 算法¶ 回话密钥key¶ 基本随机数base_nonce¶ 序列号（从0开始） 秘钥导出参数为：\nHPKE具体的ciphersuite，可以和上面的suite_id对上 exporter_secret导出秘钥 这些参数除了seq number都是常量，每次加解密操作使用nonce都是base_nonce和当前seq number异或的结果。这里要注意加解密是需要我们上面写的AAD的参与的。具体加解密参数也一并附加上了。\ndef ContextS.Seal(aad, pt): ct = Seal(self.key, self.ComputeNonce(self.seq), aad, pt) self.IncrementSeq() return ct def ContextR.Open(aad, ct): pt = Open(self.key, self.ComputeNonce(self.seq), aad, ct) if pt == OpenError: raise OpenError self.IncrementSeq() return pt def Context\u0026lt;ROLE\u0026gt;.ComputeNonce(seq): seq_bytes = I2OSP(seq, Nn) return xor(self.base_nonce, seq_bytes) def Context\u0026lt;ROLE\u0026gt;.IncrementSeq(): if self.seq \u0026gt;= (1 \u0026lt;\u0026lt; (8*Nn)) - 1: raise MessageLimitReachedError self.seq += 1 5 总结和FAQ # 总结以下几点：\nHPKE的优缺点是什么？ HPKE适用于哪些场景？ 一些具体的问题：\nHPKE和ECDH有什么区别？严格的来说HPKE和ECDH的原理是类似的，都是基于DH交换体系的基础知识产生共享秘钥，无法是多加了一个AEAD。但是两个的场景不一致，HPKE用于混合公钥加密，可以理解为一种加密套件。而ECDH是密钥交换算法，用于握手。 HPKE有哪些具体的应用场景呢？ECH混淆加密等等 6 Streaming AEAD # 今天看到一个流AEAD的概念，原先讨论AEAD的时候第一反应都是块加密，AES-GCM，忽然提到流AEAD就没反应过来，看了下google的文档，说是提供：\n底层加密模式的选择使部分明文可以通过解密和认证部分密文快速获得，而不需要处理整个密文。 加密必须在一个会话中完成。修改现有的密文或对其进行追加是不可能的。 tink的网页里面解释说是对OAE的具体实现，想了想没想明白咋回事，就直接去看了参考的文档Online Authenticated-Encryption and its Nonce-Reuse Misuse-Resistance论文，简单一些的理解就是使用已经算出来的数据和明文做异或作为IV参与到另外一块做运算，然后需要产生对应AAD一起作为输入参数进行运算。然后每次输出的结构都会拥有部分的tag，这个tag就和aes-gcm的tag是类似的，是这一部分数据认证的结果。当然，这个解释没说明白很多细节，比方说nonce如何产生，如何划分数据的segment？所以找了几篇论文和一些算法看下，如果前两篇没看懂，那么可以先看第三篇把里面的方案的都解释的差不多了再继续看：\nGeneral Classification of the Authenticated Encryption Schemes for the CAESAR Competition Online Authenticated-Encryption and its Nonce-Reuse Misuse-Resistance 基于双管道结构的在线加密方案 简单来说OAE分为几个不同版本：\nOAE1：安全特性被多种质疑，mac在数据末尾。 OAE2：对nonce，iv的要求更严格些，mac要随一小段一点一点产生。当然这篇文章里面给出了oae2的一些实现方式，比方说chain/block啥的。 下面我们看几种具体的streaming aead算法落地实践，一个是grain-128aead，另一个是tink提供的算法。\n6.1 Grain-128AEAD # 基础组件为：\nkey长度为128bit，nonce为96bit 具体包含两个building block，一个是预输出生成器，使用线性反馈移位寄存器+非线性反馈移位寄存器+预输出函数构成。第二个building block由认证生成器包含一个移位寄存器和累加器。设计和Grain-128a很相似，但是并不完全一致。 线性反馈移位寄存器和非线性反馈移位寄存器的具体方程可以直接看论文，我就不贴了挺明白的 认证器的寄存器部件保存最近的64个奇数位 key和nonce的生成，使用初始的key和nonce填充线性/非线性反馈移位寄存器 使用方法为：\n使用第一个building block生成流密钥，密文的内容是流密钥和明文异或的结果 累加器需要累加最后的结果到末尾作为tag，但是这也太晚了，所以这个实际上是oae1 总结：嗯，挺复杂，还麻烦。\n6.2 tink的具体实现 # 加密的包裹都是调用stream_segment_encrypter.h的头文件，stream_segment_encrypter会对每个segment做不同的参数派生，借此保证密文是不能调换的。其格式如同下面的注释\n// // | other | header | 1st ciphertext segment | // | ...... 2nd ciphertext segment ..... | // | ...... 3rd ciphertext segment ..... | // | ...... ... ..... | // | ...... last ciphertext segment | // // where the following holds: // * each line above, except for the last one, // contains get_ciphertext_segment_size() bytes // * each segment, except for the 1st and the last one, // encrypts get_plaintext_segment_size() bytes of plaintext // * if the ciphertext stream encrypts at least one byte of plaintext, // then the last segment encrypts at least one byte of plaintext // * \u0026#39;other\u0026#39; is get_ciphertext_offset() bytes long, and represents potential // other bytes already written to the stream; the purpose of ciphertext // offset is to allow alignment of ciphertext segments with segments // of the underlying storage or transmission stream. namespace crypto { namespace tink { namespace subtle { class AesGcmHkdfStreaming : public NonceBasedStreamingAead { public: struct Params { //存储具体的参与运算的参数 util::SecretData ikm; //ikm初始密钥材料 HashType hkdf_hash; //派生密钥的hash方法 int derived_key_size; //派生密钥的大小 int ciphertext_segment_size;//这一个ciphertext的segment的大小 int ciphertext_offset; }; static util::StatusOr\u0026lt;std::unique_ptr\u0026lt;AesGcmHkdfStreaming\u0026gt;\u0026gt; New( Params params); static constexpr crypto::tink::internal::FipsCompatibility kFipsStatus = crypto::tink::internal::FipsCompatibility::kNotFips; protected: util::StatusOr\u0026lt;std::unique_ptr\u0026lt;StreamSegmentEncrypter\u0026gt;\u0026gt; NewSegmentEncrypter( absl::string_view associated_data) const override; //具体加密 util::StatusOr\u0026lt;std::unique_ptr\u0026lt;StreamSegmentDecrypter\u0026gt;\u0026gt; NewSegmentDecrypter( absl::string_view associated_data) const override; //具体解密 private: explicit AesGcmHkdfStreaming(Params params) : ikm_(std::move(params.ikm)), hkdf_hash_(params.hkdf_hash), derived_key_size_(params.derived_key_size), ciphertext_segment_size_(params.ciphertext_segment_size), ciphertext_offset_(params.ciphertext_offset) {} const util::SecretData ikm_; const HashType hkdf_hash_; const int derived_key_size_; const int ciphertext_segment_size_; const int ciphertext_offset_; }; } // namespace subtle } // namespace tink } // namespace crypto #endif // TINK_SUBTLE_AES_GCM_HKDF_STREAMING_H_ 具体的解密包括初始化流程如下，参考aes_gcm_hkdf_streaming.cc 文件，具体流程分为几步：\n使用传入的参数初始化加密解密参数，使用已经生成的相同的原始密钥材料ikm_，随机生成salt，使用相同的associated_data产生hkdf派生密钥，产生固定的nonce prefix。产生aead加解密context，这个aead ctx要参与对每次数据的加密。\n对一段明文进行加密，都使用一开始产生的SegmentEncryptor，每次对一段明文进行加密都递增一个conunter，将counter拼接nonce prefix作为初始化向量IV进行加密。使用该iv和hkdf派生密钥参与到明文数据加密运算当中。\n/* 参与运算的第一步，从ikm计算出来派生的具体的结果*/ util::StatusOr\u0026lt;std::unique_ptr\u0026lt;StreamSegmentEncrypter\u0026gt;\u0026gt; AesGcmHkdfStreaming::NewSegmentEncrypter( absl::string_view associated_data) const { AesGcmHkdfStreamSegmentEncrypter::Params params; params.salt = Random::GetRandomBytes(derived_key_size_); //随机生成salt /* 使用随机生成的salt，ikm_，aad派生出来派生密钥，这个派生密钥参与运算*/ auto hkdf_result = Hkdf::ComputeHkdf(hkdf_hash_, ikm_, params.salt, associated_data, derived_key_size_); if (!hkdf_result.ok()) return hkdf_result.status(); params.key = std::move(hkdf_result).ValueOrDie(); params.ciphertext_offset = ciphertext_offset_; params.ciphertext_segment_size = ciphertext_segment_size_; return AesGcmHkdfStreamSegmentEncrypter::New(std::move(params)); } /* 最后面上面的函数 */ util::StatusOr\u0026lt;std::unique_ptr\u0026lt;StreamSegmentEncrypter\u0026gt;\u0026gt; AesGcmHkdfStreamSegmentEncrypter::New(Params params) { /* 验证参数的有效性 */ auto status = Validate(params); if (!status.ok()) return status; /* 根据密钥创建aead环境，这里的key是上面的派生密钥 */ auto ctx_or = CreateAeadCtx(params.key); if (!ctx_or.ok()) return ctx_or.status(); auto ctx = std::move(ctx_or).ValueOrDie(); return {absl::WrapUnique( new AesGcmHkdfStreamSegmentEncrypter(std::move(ctx), params))}; } /* 当前segment的加密流程 nonce_prefix_是随机产生的*/ AesGcmHkdfStreamSegmentEncrypter::AesGcmHkdfStreamSegmentEncrypter( bssl::UniquePtr\u0026lt;EVP_AEAD_CTX\u0026gt; ctx, const Params\u0026amp; params) : ctx_(std::move(ctx)), nonce_prefix_(Random::GetRandomBytes(kNoncePrefixSizeInBytes)), header_(CreateHeader(params.salt, nonce_prefix_)), ciphertext_segment_size_(params.ciphertext_segment_size), ciphertext_offset_(params.ciphertext_offset) {} /* 具体的解密流程，每个segment实际上就是要加密的一段片段 */ util::Status AesGcmHkdfStreamSegmentEncrypter::EncryptSegment( const std::vector\u0026lt;uint8_t\u0026gt;\u0026amp; plaintext, bool is_last_segment, std::vector\u0026lt;uint8_t\u0026gt;* ciphertext_buffer) { if (plaintext.size() \u0026gt; get_plaintext_segment_size()) { return util::Status(util::error::INVALID_ARGUMENT, \u0026#34;plaintext too long\u0026#34;); } if (ciphertext_buffer == nullptr) { return util::Status(util::error::INVALID_ARGUMENT, \u0026#34;ciphertext_buffer must be non-null\u0026#34;); } if (get_segment_number() \u0026gt; std::numeric_limits\u0026lt;uint32_t\u0026gt;::max() || (get_segment_number() == std::numeric_limits\u0026lt;uint32_t\u0026gt;::max() \u0026amp;\u0026amp; !is_last_segment)) { return util::Status(util::error::INVALID_ARGUMENT, \u0026#34;too many segments\u0026#34;); } /* 进行加密会多出来一个kTagSizeInBytes的长度*/ int ct_size = plaintext.size() + kTagSizeInBytes; ciphertext_buffer-\u0026gt;resize(ct_size); // Construct IV. IV的构建需要是初始的nonce_prefix_的数据+当前segment的数据 std::vector\u0026lt;uint8_t\u0026gt; iv(kNonceSizeInBytes); memcpy(iv.data(), nonce_prefix_.data(), kNoncePrefixSizeInBytes); BigEndianStore32(iv.data() + kNoncePrefixSizeInBytes, static_cast\u0026lt;uint32_t\u0026gt;(get_segment_number())); iv.back() = is_last_segment ? 1 : 0; /* 执行加密，使用IV，已经初始化好了的aead ctx进行加密运算*/ size_t out_len; if (!EVP_AEAD_CTX_seal( ctx_.get(), ciphertext_buffer-\u0026gt;data(), \u0026amp;out_len, ciphertext_buffer-\u0026gt;size(), iv.data(), iv.size(), plaintext.data(), plaintext.size(), /* ad = */ nullptr, /* ad.length() = */ 0)) { return util::Status(util::error::INTERNAL, absl::StrCat(\u0026#34;Encryption failed: \u0026#34;, SubtleUtilBoringSSL::GetErrors())); } /* 将Segment号加一，下次需要使用这个进行运算*/ IncSegmentNumber(); return util::OkStatus(); } 结尾 # 唉，尴尬\n","date":"2021 年 6 月 1 日","externalUrl":null,"permalink":"/posts/2021-06-01-hpke%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"","title":"HPKE笔记","type":"posts"},{"content":" 复习（预习）编译原理笔记 # 2 词法分析器 # 2.1 FA \u0026amp; RE # 编译器的词法分析器读取字符组成的输入流，产生包含单词的输出流。每个单词都标记其语法范畴，等效于英文单词的词类。因此词法分析器会应用一组描述输入程序设计语言的此法结构规则。\n语法范畴\n关键字\n状态转移图充当了状态转换、代码的抽象。转移图可以看成是形式化的数学对象，也就是有限自动机。\n有限自动机（finite automaton）\n有限状态机包含一个有限状态集、一个字母表、一个转移函数、一个起始状态和一个或多个接受状态\n为了能够形式化的表达转移图，使用正则表达式来描述其语言\n符号表示法的形式化，一个正则由三个基本操作组成：\n选择： 连接： 闭包： 优先级是从下往上越来越低\n正则表达式和有限状态机是等价的，也就是说FA和RE是等价的，因此我们需要手段能够在FA \u0026amp; RE之间进行转换。\n2.2 RE \u0026amp; FA \u0026amp; NFA \u0026amp; DFA # 从正则到NFA再到DFA，\n先介绍两种NFA的概念，再继续向内进行深入。\nNFA：对单个字符的输入有多种可能的状态转换，这种是非确定性有限自动机 DFA：对单个字符的输入只有一种可能的状态转换，这种是确定性有限自动机 **从RE（正则表达式）到NFA的转换，即Thompson构造法，**Thompson构造法显示制造了连接、选择、闭包的NFA转换。使用Thompson构造法直接按照优先级将正则表达式转化为NFA。简单来说Thompson是最简单的构造方法。\n**从NFA到DFA的转换，子集构造法。**子集构造法实际上是从每个配置到具体状态的转换。\n简化DFA到最小DFA：Hopcroft算法\nHopcroft算法的理论基础是如果某两个复杂DFA的状态属于同一个集合，那么这两个状态对于同样的字符输入必然指向另一个集合。我们最终的目的就是按照这些集合来简化DFA\n2.4 实现词法分析器 # 常见的词法分析器三种：\n表驱动的词法分析器：两个表，字母表和状态转移表，按照这个来驱动并且回退 直接编码的词法分析器：实际上就是优化了上面两个表，字母表可以直接利用数组的性质计算出来。转移表直接用代码来表示然后互相goto 手工编码的词法分析器：手工编码的词法分析器减少了词法分析器和系统其余组件的接口花销，实际上手工就是为了实际接口的花销 2.5 高级主题 # 为了说明RE和DFA是等价的，我们需要从DFA构建正则表达式，即Kleene构造法，该构造法本质就是利用从小到大的推到\nDFA最小化的另一方法，Brzozowski算法\n3 语法分析器 # 3.1 # 结尾 # 唉，尴尬\n","date":"2021 年 5 月 26 日","externalUrl":null,"permalink":"/posts/2021-05-26-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"","title":"复习编译原理笔记","type":"posts"},{"content":" 重抓CPP \u0026amp; 新抓GO \u0026amp; 新抓 RUST # 0 GOOGLE的CPP规范 # 具体的链接看这里https://zh-google-styleguide.readthedocs.io/en/latest/google-cpp-styleguide/contents/这个是中文的链接，下面贴上原本的链接https://google.github.io/styleguide/cppguide.html。下面给出来OCEANUS项目当中和编程规范匹配或者差别的地方。\n0.1 头文件 # 【define保护】所有头文件定义宏来保护.h文件，基本的定义格式为：\n___H_\n基本就是ifndef \u0026amp; define \u0026amp; endif的结构\n【include顺序】#include的顺序按照项目源代码目录树顺序进行排列，避免使用./../\n【前置声明】尽量不要前置声明\n【内联函数】行数小于10行时，使用内联函数\n0.2 作用域 # 总的思考：目前看起来，面向对象的代码实际上是一种理解方式和组织方式的区别，换言之用可以理解的方式组织数据和方法。但是其基本的初始化和调用的方式还是没有破坏原本的规则，比方说数据结构的对齐，每次内存申请RBP和RSP申请时候挪动的指针大小等方面。\n【命名空间】鼓励使用匿名命名空间或者static声明。禁止使用using声明，禁止使用内联命名空间\n【匿名命名空间和静态变量】在 .cc 文件中定义一个不需要被外部引用的变量时，可以将它们放在匿名命名空间或声明为 static 。但是不要在 .h 文件中这么做。\n【非成员函数、静态成员函数和全局函数】使用静态成员函数或命名空间内的非成员函数, 尽量不要用裸的全局函数. 将一系列函数直接置于命名空间中，不要用类的静态方法模拟出命名空间的效果，类的静态方法应当和类的实例或静态数据紧密相关.//这个的代码没太明白，什么意思，难道是说类的的静态方法应当只针对具体的静态成员吗？\n【局部变量】将函数变量尽可能置于最小作用域内, 并在变量声明时进行初始化.//这个倒是没什么好说的，从来都是如此\n【静态和全局变量】禁止定义静态储存周期非原生数据类型变量，禁止使用含有副作用的函数初始化原生数据类型全局变量，因为多编译单元中的静态变量执行时的构造和析构顺序是未明确的，这将导致代码的不可移植。//除了int等基本数据类型，其他的都不可以定义为基本的数据结构，实际上是为了避免静态变量的初始化和析构时候导致的不确定性问题，这要求将大量的静态变量隐藏在类的内部，也是为了方便具体的管理和认识\n【初始化顺序】同一个编译单元内是明确的，静态初始化优先于动态初始化，初始化顺序按照声明顺序进行，销毁则逆序。不同的编译单元之间初始化和销毁顺序属于未明确行为 (unspecified behaviour)。3\n0.3 类 # 【隐式类型转换】不要定义隐式类型转换. 对于转换运算符和单参数构造函数, 请使用 explicit 关键字。//explicit需要具体查询一下，这个存在一点问题，现在记得不是很清楚。cpp primer 7.5.4节，第256页\n【结构体与类】仅当只有数据成员时使用 struct, 其它一概使用 class。//Nmmm，struct和class的区别，也需要查\n【继承】使用组合常常比使用继承更合理. 如果使用继承的话, 定义为 public 继承。//组合更灵活一些，具体见于headfirst设计模式的鸭子设计流程\n【多重继承】真正需要用到多重实现继承的情况少之又少. 只在以下情况我们才允许多重继承: 最多只有一个基类是非抽象类; 其它基类都是以 Interface 为后缀的纯接口类。//好极了，我倒是想看看项目有几个用了多重继承\n【接口类】\n【运算符重载】除少数特定环境外, 不要重载运算符，也不要创建用户定义字面量。\n【数据成员】将 所有 数据成员声明为 private, 除非是 static const 类型成员。\n【声明顺序】类定义一般应以 public: 开始，后跟 protected:，最后是 private:。\n0.4 函数 # 【函数体】我们承认长函数有时是合理的, 因此并不硬性限制函数的长度。如果函数超过 40 行, 可以思索一下能不能在不影响程序结构的前提下对其进行分割。//40行的长度实际上还是有点短，一会看一下OCEANUS的函数限制长度是多少\n【参数顺序】函数的参数顺序为：输入参数在先, 后跟输出参数。输入参数通常是值参或 const 引用, 输出参数或输入/输出参数则一般为非 const 指针。\n【引用参数】所有按引用传递的参数必须加上 const。\n【缺省参数】在使用缺省参数时，优先考虑使用函数重载，并且对于虚函数不允许使用缺省参数。\n【函数重载】若要使用函数重载，则必须能让读者一看调用点就胸有成竹，而不用花心思猜测调用的重载函数到底是哪一种。这一规则也适用于构造函数。\n0.5 其他 # 【异常】不推荐使用 C++ 异常。\n【运行时类型识别】禁止使用运行时类型识别。\n【类型转换】使用 C++ 的类型转换，如 static_cast\u0026lt;\u0026gt;()。不要使用 int y = (int)x 或 int y = int(x) 等转换方式。\n【流】原则上使用 printf 等函数代替流，除非接口必须使用流。//哈哈哈哈哈，笑死我了，C++失败的流设计\n【自增与自减】对于迭代器和其他模板对象使用前缀形式 (++i) 的自增/自减运算符。\n【初始化】初始化时，整数用 0，实数用 0.0，指针用 NULL（C++03）或nullptr（C++11）。\n【auto】用 auto 绕过烦琐的类型名，只要可读性好就继续用，别用在局部变量之外的地方。//只有局部变量能用，这个倒是挺不错的\n0.6 注释 # 【注释风格】注释风格使用 // 或 /* */，需要保持风格统一。\n【文件注释】在每一个文件开头加入版权公告。\n【类注释】每个类的定义都要附带一份注释, 描述类的功能和用法, 除非它的功能相当明显。\n【函数注释】函数声明处的注释描述函数功能；定义处的注释描述函数实现。\n【成员变量注释】每个类数据成员 (也叫实例变量或成员变量) 都应该用注释说明用途\n【全局变量注释】和数据成员一样，所有全局变量也要注释说明含义及用途，以及作为全局变量的原因。\n【代码前注释】对于代码中巧妙的，晦涩的，有趣的，重要的地方加以注释。\n【不允许的注释】不要描述显而易见的现象，永远不要用自然语言翻译代码作为注释，要假设读代码的人 C++ 水平比你高，即便他可能不知道你的用意。\n【TODO注释】对那些临时的，短期的解决方案，或已经够好但仍不完美的代码使用 TODO 注释。\n0.7 命名 # 【通用约定】函数命名、变量命名、文件命名要有描述性，少用缩写。\n【文件命名】文件名要全部小写，可以包含下划线 (_) 或连字符 (-)，依照项目的约定。如果没有约定，那么 “_” 更好。例如 my_useful_class.cc。\n【类型命名】类型名称的每个单词首字母均大写，不包含下划线：MyExcitingClass，MyExcitingEnum。\n【变量命名】变量 (包括函数参数) 和数据成员名一律小写，单词之间用下划线连接。类的成员变量以下划线结尾，但结构体的就不用，如：a_local_variable、a_struct_data_member、a_class_data_member_。\n【常量命名】声明为 constexpr 或 const 的变量，或在程序运行期间其值始终保持不变的，命名时以 “k” 开头，大小写混合。例如：const int kDaysInAWeek = 7;\n【函数命名】常规函数使用大小写混合，取值和设值函数则要求与变量名匹配：MyExcitingFunction()、MyExcitingMethod()、my_exciting_member_variable()、set_my_exciting_member_variable()。\n【命名空间命名】命名空间以小写字母命名，例如：websearch::index。最高级命名空间的名字取决于项目名称。要注意避免嵌套命名空间的名字之间和常见的顶级命名空间的名字之间发生冲突。\n【宏命名】除头文件保护外，原则上不使用宏，如果一定要使用，像这样命名：MY_MACRO_THAT_SCARES_SMALL_CHILDREN。\n【枚举命名】枚举的命名应当和 常量 或 宏 一致：kEnumName 或是 ENUM_NAME，例如：\n下面复习一些CPP的基本知识\n先复习一些CPP的基本知识：\n几种构造函数： 引用：或者说左值引用。和初始化不同，初始化时初始值会拷贝到新建的对象里，而定义引用时直接将引用和它的初始值绑定到一起。引用的生命周期实际上和原先变量的生命周期是一致的。我们需要关注CONST 引用：允许将一个const int \u0026amp;绑定到一个普通int对象上。实际上还是一个临时量生命周期的问题，生成一个了临时量，然后进行绑定，本身是常量的临时量，还是只能绑定到常量。不过这里暗藏一个问题，就是const int \u0026amp;的绑定到一个非const的对象时候，只是代表不能通过这个const引用进行修改，直接对非const变量或者非const引用进行修改是可行的。 参数传递：参数传递实际上值得说道说道，好多地方看起来都是引用传递。传值参数没啥注意，指针形参也没啥注意，传引用参数实际上就是一个别名，相当于直接操作传入的对象，然后还能避免拷贝操作，对于不支持拷贝操作的类型必须使用引用形参进行传递，对于长度过于长，拷贝操作很花时间的操作还能节省很多时间，还有一点要注意，当函数无需修改引用形参的值的时候最好使用常量引用。 智能指针：目前直接看到的是shared_ptr，允许多指针共享同一个对象，但是只是引用计数增减是原子操作，具体的读写操作都不一定保证原子。智能指针实际上减少了程序员操作的难度。但是有一种情况会造成内存泄露，比方说智能指针放到了容器里，然后智能指针用完以后没有erase才导致一直没释放。一般来说，如果我们需要在多个对象之间共享内存才需要使用智能指针，这样子智能指针指向的对象的生命周期和类对象的生命周期才能相互独立。智能指针和new的混用，可以使用new返回的指针初始化智能指针。 智能指针的注意事项：使用shared_ptr作为参数时，不要将智能指针和普通指针混用，所谓的智能指针管理自己的析构也只是智能指针之间才能这样子操作，这也是推荐使用make_shared而不是new的原因。这个地方实际上隐藏着一个智能指针和普通指针混用的问题，普通指针指向的内存可能已经被智能指针释放掉了，这就导致了问题。 智能指针的初始化：初始化实际上有好几个方面， 类static成员： 构造函数后面接一个=default，具体见7.1.4节（第237页） 虚函数后面接一个=0来纯虚函数 0.8 单元测试 # 单元测试应该覆盖什么东西？\n功能测试，保证功能正确 多线程并发测试，包括并发的读写和并发的初始化等 错误测试，如果有多个错误码最好都能够测试一遍。 0.9 代码设计原则 # 写的东西越多，对于一些代码的设计准则就觉得越要保持一致性：\n做一个产品，内部的组建的错误码可以对外暴露，这样子能迅速清楚问题来源。但是分层，代码设计的原则应当保持 扁平化代码，层次化代码是看功能需要标定的。 代码的设计应该是无隐喻的，但是产品往往是有隐喻的。该不该将隐喻嵌入到代码内部呢？这个就得看情况咯。 1 范型编程相关和一些兼容性事宜 # 1.1 继承，多态，虚继承 # 【动态绑定】在CPP中，当使用基类的引用或者指针的时候会发生动态绑定，换言之使用具体的结构体的时候是不发生动态绑定的。动态绑定又被称为运行时绑定。但是这种动态绑定实际上是暗藏了一个从派生类到基类的类型转换，也是隐式转换。在派生类对象中含有与其基类对应的组成部分，这一事实是继承的关键所在。但还有一点要注意，从派生类转换成基类可以，从基类转换成派生类不行！\n【基类】基类一般定义一个虚析构函数。基类的private是不能被派生类的成员访问的，换言之只有基类的函数能够访问自己的private成员。对于希望派生类访问的成员，需要使用protected类型。final防止继承，\n【派生类】派生类需要对virtual的函数进行override 来覆盖其旧的定义。需要注意的是，派生类不能直接初始化基类的数据成员，必须使用基类的构造函数初始化基类部分。换言之，每个类控制它自己的成员初始化的过程。实际上虚函数的动态绑定就是具体的地址，但是目前看起来似乎service的很多地方都不是虚函数的\n【派生类列别】目前看到的都是public\n1.2 范型 # 两种模板，一种是函数模板，另一种是类模板。以下的第一章，第二章都是《C++ TEMPLATE》的章节\n第二章【函数模板】function template的每个参数必须严格符合定义的形式，不能隐式转换，此外最好两个参数都是const引用，否则会触发局部临时对象，返回的时候就不能以引用的方式传递了。两个重要原则：\n模板中的函数参数是const的引用 函数体中的条件判断需要是传入的类型的对象锁支持的操作/运算 第一条保证了函数可以用于不能拷贝的类型，第二条是为了实现可移植性。一般来说模板的instantiate为两次，一次是基础的语法检查，另一个是带入具体的种类到模板里，看支不支持模板的运算。这就带来了一个问题，编译器需要知道template的实现。\n由于template只会实例化用到的函数和类型。\n第三章【类模板】类模板的名字并不是一个类型名，只有实例化的类模版，或者说包含模板参数的类模板才是类型。类模板的类型参数必须满足真正调用到的函数里面的操作必须支持，这句话也可以说成class template中，只有被实际调用的成员函数，才会被实例化。类模板支持特化，特化就和实例化很类似。类模板也支持偏特化，也就是部分特化Specializations，但是一旦偏特化，那么所有的成言函数都得特化了。同时，类模板也支持预设模板自变量，就可以只输入一部分参数而不输入带有预设模板自变量的值。关于类模板可能还有一点要注意Vector\u0026lt;Vector\u0026lt;int\u0026gt; \u0026gt;最后的那个\u0026gt;要和前面的\u0026gt;有一个空格，不要变成\u0026raquo;符号。\n第四章【非类型模板参数】非类型模板参数也有两种，一种是非类型类别模板参数，另一种是非类型函数模板参数。这种模版参数实际上就是值，或者是常量。具体的非类型模板参数的种类是什么还得确定，很难说具体结果。\n第五章【tricky points】【typename】用于指明类型，不会引起和内部static的错误使用。当使用类内部的类型成员时候，最好加上这个typename。【template template parameters】双重模版参数，具体的template参数可以是class template，模板类型参数里面必须用class。function template不允许有template template parameters。【字符串常量的引用出错】以by reference传递字符串常量时，会出现意想不到的错误，因为会以const char[x]的方式传递参数\n第六章【using template】【置入式模型】如果讲template的定义和声明分离，那么链接器就很难找到具体的定义，因此最好直接在模板的声明文件里面把定义给出，换言之在.h文件里面就把具体的定义给出来，另外还有两种不太好的做法：1在声明文件.h里面最后#include \u0026ldquo;myfirst.cpp\u0026rdquo;。2 另一种稍微差一些的方法就是在具体的调用文件里面，把.cpp文件也引入。这种最好的方法，被称为“置入式模型”，一般都推荐使用置入式模型。【显式实例化】尽量不要使用显式实例化，会大大增加复杂程度。显式实例化和特例化有什么区别呢？显式实例化是指你使用特定的template parameter去代替模版的参数，而特例化是指对某个类型的逻辑需要特殊考虑，从而进行了重写。\n第七章【术语规范】【ODR】One-Definition Rule【Template ID】template name + template arguments。注意区分template arguments和template parameter的区别。\n第八章【基础技术更深入】\n第十四章【template的多型威力】静态多型与动态多型，【动态多型】虚函数，引用，指针之类的东西【静态多型】不同模板的实例化是静态多型，但是静态多型带来的问题就是不能再处理异质群集了：所有的类型必须在编译的时候就确定。【动态多型和静态多型的比较】继承实现的多型是bounded和dynamic的，我们称之为侵入式的。【为什么选择静态多型】静态多型的能够检查异质对象检查，就是具有类型检查功能。\n第十五章【特征萃取和策略类别】\n1.3 兼容性事宜 # 今天遇到这个事情，就是编译一个CPP的LIB给C用，然后就引出来这么两个问题：\nC98的程序或者C11的程序能不能链接其他版本的LIB呢？可以参看这个链接https://stackoverflow.com/questions/46746878/is-it-safe-to-link-c17-c14-and-c11-objects。分析起来只要编译器移植，兼容性一致就可以。 如何编译一个C++ LIB支持给C使用呢？具体的例子可以参看这个网页https://www.teddy.ch/c++_library_in_c/，使用cmake生成具体的lib的流程看这个网页https://www.cnblogs.com/52php/p/5681755.html 1.4 部分使用事宜 # 由于CPP的莫名其妙的编译，nm的时候看到的名字会有一大堆的数字和ascii字符，不能直接对照，因此需要使用命令nm \u0026ndash;demangle\n2 GOOGLE TEST笔记 # 需要添加具体的测试case来做单元测试，因此需要学习一下google test的使用。\n入门部分内容https://google.github.io/googletest/primer.html。\n高级部分内容https://google.github.io/googletest/advanced.html\n具体样例https://google.github.io/googletest/samples.html\n3 侯捷 # 两种容器，关联容器，顺序容器。C11新引入unordered containers容器，实际上也是关联容器。中文翻译为不定序容器，实际上就是hashtable\n今天看到一个人提问，*ptr到底是这个ptr指向的对象本身还是个引用，按照c++11的page，是一个左值表达式，这个左值表达式的result是个对象的引用。\n然后又有个问题，左值右值啥区别？\nAn lvalue (locator value) represents an object that occupies some identifiable location in memory (i.e. has an address).\nrvalues are defined by exclusion, by saying that every expression is either an lvalue or an rvalue. Therefore, from the above definition of lvalue, an rvalue is an expression that does not represent an object occupying some identifiable location in memory.\n简单来说就是\nL-Values are locations, R-Values are actual values.\n4 线程安全（linux多线程服务器编程：使用muduo库） # 4.1 构造函数线程安全 # 三个要求：\n不在构造函数中注册回调 不在构造函数当中把this传递给夸线程的对象 即便是构造函数最后一行也不行（这个之所以不行是因为如果改对象是基类，那么派生类可能还在继续构造） 4.2 析构函数的线程安全 # 作为数据成员的mutex并不能保证析构时，别的线程不使用该对象。换言之作为数据成员的mutex并不能保证析构时线程安全。因此需要使用智能指针。实际上这个问题的根源就在于判断指针是否存活是困难的。为此才引入了智能指针：shared_ptr \u0026amp; unique_ptr。为了避免循环引用的问题，往往还需要引入weak_ptr。通常做法是owner拥有指向child的shared_ptr，而child持有指向owner的weak_ptr。\n实际上，大部分的生命周期的问题都是析构函数和调用同时发生的。对于observer模式，建议使用《linux多线程服务器编程：使用muduo库》的例子\n4.3 C++常见内存问题 # 缓冲区溢出 空悬指针/野指针 重复释放 内存泄露 内存碎片 4.4 RAII好 # RAII好啊，mutex使用RAII好极了啊\n4.5 任务队列 # 对对象而言，使用bind 函数指针+对象指针就可以调用具体对象的函数，即可跨线程post任务\n5 程序员的自我修养，链接，装载和库 # 编译和链接的基础知识 # The linker operates on a small number of basic data types: symbols, relocations, and contents. These are defined in the input object files. Here is an overview of each of these. A symbol is basically a name and a value. value is address During the linking process, the linker will assign an address to each defined symbol, and will resolve each undefined symbol by finding a defined symbol with the same name. 链接过程包括：\n地址和空间分配 符号决议（符号绑定，名称绑定） 重定位 程序的区域划分：\n最开始的部分是elf文件头，用来告诉程序自己是个啥：动态库/静态库/可执行文件\n代码段，.text/.code\n数据段，存储全局变量/局部静态变量，已经初始化的放在.data，未初始化的放在.bss段。为啥区分数据段和代码段：1 代码是只读的，数据可以变化 2 现代CPU基于缓存，因此需要区分指令和代码。3 代码是可以共享的，因此拆分。\n可以使用size命令查看每个段大小，可以使用objdump -s -d main.o查看反汇编和具体段里面放的内容。\n每个elf文件里面都有符号，而每个定义的符号对应一个符号表，符号表是文件里面的一个段，段名字为.symtab。分为以下几个种类：\n定义在目标文件的全局符号，可以被其它文件引用 在本目标文件内引用的全局符号，一般叫做外部引用 除了上面两种之外的符号，可以使用nm来查看elf的符号表 函数修饰和函数签名 # C++为了面对函数重名的问题发明了符号修饰和符号改编，函数签名包含了一个函数的信息：比方说函数名，参数类型，返回值等信息。\n比方说，gcc里面C++所有的符号都以_Z开头，后面紧跟N，然后是命名空间和类的名字，有个程序叫做c++file可以分析名字,\n而C只是简单的在名字前面加个_\n弱符号和强符号 # 弱符号和强符号：强符号，C/C++默认函数和初始化的全局变量为强符号，两个同名的强符号会重名。注意强弱符号针对定义而言，extern的符号是外部定义，和强弱符号就没关系 弱引用和强引用：对于弱引用，如果没有该符号不定义，链接器不会报错。 静态链接的基础知识 # 静态链接，现在的静态链接一般都是两步链接，先计算空间，再合并。这里要明白一点，静态库实际上就是把代码合并到了执行文件里面，即使这回引入很多不需要的代码，而且你还得解决这些依赖的不需要的代码所引入的undefined reference\nCOMMON块，现代程序处理链接时候和COMMON块一样的处理方式，直接空间非配为最大的块。\n静态链接\n所以符号的地址不确定，对静态库而言，发生的是连接时重定位，而动态加载是装载时重定位\n静态链接的问题，静态链接不会per函数把名字印进去，它只会per文件，也就是说把所有的都丢进去.\n动态链接 # 全局符号表\n共享对象全局符号介入，即如果一个符号要被加入全局符号表，如果相同的符号名存在，那么后面加入的被忽略，所以要注意这个问题\n但是这个结果往往是和其它的链接的选项相关的，如果后面还有其它符号同时链接进入，那么很可能会被当作静态符号链进来。\n这里还有个东西plt，使用plt执行间接跳转，动态链接的间接跳转。disass的结果里面就有一个plt段，专门做跳转。\n6 EFFECTIVE C++ # 建议2:尽量使用const，这里提供一个注意的点，两个函数同名但是一个是const，另一个不是，实际上就是发生了重载。这里面还有个争议，也就是bitwise测试的const，即bit检测不变。但是这导致我可以转移为另一个相等的对象\n建议8:避让异常逃离析构函数，绝对不要在析构函数抛出异常，这会导致可能的内存泄露等问题。\n建议9:绝对不要在构造和析构函数中掉用virtual函数。由于还没初始化完成，因此这个行为会引发未定义的问题，换言之，尽量初始化/析构只做已经OK的函数，\n建议10:注意自己给自己赋值的情况，\n建议14:小心赋值，对于RAII对象，要么禁止拷贝，要么引用计数，要么复制底层资源，要么转移底层资源的拥有权\n建议18:让接口容易使用，不容易出错。因此最好使用：1 用类型系统来构造接口。2 类隐藏一个函数，使用函数来替代对象，因此使用const等限制接口是可行的3 使得你的type和内置type一样的行为 4 尽量让客户不再面对资源管理的问题\n建议30:inline。inline是一种对编译器说的申请，具体实现是不是inline展开的完全看编译起。在类的函数定义在类的内部，默认就是inline实现的。但是，template是和inline没有必然联系的。那么问题来了，什么时候用inline？答案是当你确定这东西不会被调试的时候。\n建议32:public继承塑模出is-a关系。简单来说A public 继承自B，那么每个A对象也是B对象，因此B起作用的地方A也可以起作用。这句话的意思，就是A的每个函数都可以在B上实现，但如果需要A对象，那么B对象未必可行。但是有个问题，比方说基类鸟类型，派生类企鹅类型。鸟会飞的话，企鹅就会飞，但是实际上企鹅不会飞，因此这是错误的继承体系导致的问题。\n建议34:区分接口继承和实现继承。声明非纯虚函数的目的是为了让派生类继承该函数的接口和缺省实现；纯虚函数提供接口；非虚函数负责提供接口和强制性实现\n建议38:通过复合塑模出has-a或“根据某物实现出”，\n建议39:明智而审慎的使用private继承。private继承是纯粹的实现继承，换言之认为只有实现部分被继承，而接口部分应该被略去。\n建议40:明智而审慎的使用多重继承。什么时候用多重继承比较合适？如果同时： 1 public继承某个基类的接口 2 private某个协助实现的class\n7 C++的一些题目整理 # 自己整理：\nC程序有几个区：堆，栈，代码段，全局/静态存储区，常量区。但这个说法严格来说是错误的，应该是：堆，栈，只读区：代码段，常量区，可读可写区：全局/静态存储区， bigo：\nshared_ptr的底层:shared_ptr是异常安全的，这里讲的很清楚：https://heleifz.github.io/14696398760857.html 右值引用 大端小端的概念，写个程序验证大端小端 树的后序遍历，不使用递归的模式，使用循环的模式 bigo二面：\n进程切换发生了什么 拓扑排序 一亿对kv对，怎么管理排序，value的范围为uint64 蚂蚁图数据库：\n怎么设计一个安全门限系统 多线程对连续的10个uint64_t进行写操作，MESI协议怎么变化。 随机数产生算法有哪些 青州支行：\n一个有依赖的调度，怎么去找到最少的运算时间。 8 深度探索C++ 对象模型 # 8.1 第一章 关于对象 笔记 # C当中，数据和函数是分离的。而C++中，一些自定义的数据类型往往使用ADT来实现，C++和C的区别并不单纯是语言层面的差别，更多是软件工程的差别，从软件工程角度来看“一个ADT或者数据类型的封装“能比”C程序中使用全局数据“更好。但是这种更好并不代表使用更容易。\n那么C++如何实现对象模型呢？\n简单对象模型：简单来说，每个对象（无论是数据成员，还是函数成员）都拥有一个自己的slot，每个slot指向具体的对象 表格驱动对象模型：class对象本身有两个指向表格的指针，这两个表格分别存储数据乘员和函数成员即data member table和member function table。member function table是一堆slot，每个slot指向具体的函数对象。而data member table则包含具体的成员 c++对象模型：非static数据对象放置在每个类对象里面，静态数据成员放在所有的类对象之外。静态函数成员和非静态函数成员放在所有的class object之外，而虚函数使用虚表支持。每个class产生一堆指向虚函数的指针，放在虚表里，每个类对象添加一个指针指向虚表，称为vptr。vptr的设定，重置由构造函数/拷贝构造函数指定。每个类别的type_info object也由虚表指出，通常放在虚表的第一个slot里面。 C++对象模型的另一个问题：继承怎么办？ 有一个东西要注意，C程序员的巧计会变成C++的陷阱，比方说C struct末尾的零长数组，一般C可以动态申请长度，然后放置在后面。而C++里面的排列次序不同的section，比方说public/protected/private是不保证一定在末尾的。同样基类和派生类的内存布局也不一定，因此并不能保证一定有效\nC++支持三种程序设计典范：\n程序模型： 8.2 构造函数语义学 笔记 # implict :暗中的，隐含的（通常指非程序代码当中出现的）\nExplicit:明确的，指代码里出现的\nTrivial:没有用处的\nNontrivial:有用的\nmemberwise：对每个member施以。。。\nbitwise：对每个bit施以\nsemantics：语义学\n一般情况下，编译器是不会生成默认构造函数的，换言之，是程序需要生成，而不是编译器需要的情况下，就不会有默认构造函数。那么何时编译器需要呢？\n如果一个类别有一个member object，这个member object有默认构造函数，那么编译器会生成一个default constructor。但是书里面说的不会初始化诸如指针等其它内存成员是不一定正确的。如果有多个带有默认构造函数的member object，那么以member object的声明顺序进行初始化 如果class object的基类有默认构造函数 带有virtual function的class 带有virtual base class的class 总之，不要有以下两个误区：\n如果class 没定义default constructor，就会合成出来一个 编译器合成出来的default constructor 会明确设定每个data member的默认值 那么拷贝构造函数呢？如果没有提供一个具体的拷贝构造函数，C++会调用default memberwise initializztion手法完成，但是这里有一个bitwise copy setantics\nmemberwise copy：访问每个成员，然后具体的执行拷贝 bitwise copy :浅拷贝的一种 实际上c11里面的std::is_trivially_copyable就是能不能直接memcpy拷贝，也就是\nObjects of trivially-copyable types that are not potentially-overlapping subobjects are the only C++ objects that may be safely copied with std::memcpy or serialized to/from binary files with std::ofstream::write()/std::ifstream::read().\n8.3 第四章 函数语义学 # 9 malloc相关的代码 # 9.1 malloc的理解和流程 # 这几天在查log4cplus coredump的问题的时候，出现的问题就是破坏了malloc的结构导致coredump，因此需要对malloc管理的结构有个直观认识。malloc实际上是在堆上管理内存，因此其地址是分配是从低地址向高地址分配的，因此用户数据的起始地址实际上是低地址在前的。具体malloc分配出来的结构实际上是下面这个东西\nstruct malloc_chunk { //如果前一块被释放，该处存储前一块的大小 INTERNAL_SIZE_T mchunk_prev_size; /* Size of previous chunk (if free). 如果当前块在使用，那么虚拟地址相邻的块的mchunk_prev_size也可以存储数据*/ //本块的大小，包含堆头 INTERNAL_SIZE_T mchunk_size; /* Size in bytes, including overhead. */ //双链表结构，只有当堆块被释放时使用 struct malloc_chunk *fd; /* double links -- used only if free. */ struct malloc_chunk *bk; //只有在本堆块为large chunk时，且被释放才会使用 //指向前一个large chunk 和 后一个 large chunk 的大小 /* Only used for large blocks: pointer to next larger size. */ struct malloc_chunk *fd_nextsize; /* double links -- used only if free. */ struct malloc_chunk *bk_nextsize; }; /* 这里的previos chunk表示的是虚拟地址相邻的上一块，或者说低地址的上一块*/ chunk-\u0026gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ /* P PREV_INUSE记录上个块是否被分配*/ | Size of previous chunk, if unallocated (P clear) | /* M 表示属于heap/mmap获取的*/ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ /* A表示当前chunk是否属于祝线程*/ | Size of chunk, in bytes |A|M|P| /* 低地址，这个chunk真正的大小*/ mem-\u0026gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | User data starts here... . /* 这里面放的是真正的数据*/ . . /* 起始地址在低地址*/ . (malloc_usable_size() bytes) . . | /* 也就是说这张图里下面是高地址*/ nextchunk-\u0026gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | (size of chunk, but used for application data) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of next chunk, in bytes |A|0|1| +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 也就是说具体这个mem地址是真正返回给客户的地址，然后真正分配给用户内存chunk的大小存储在起始地址前面(也就是在更低的地址)，换言之真正存储的数据会把size之后的结构都覆盖掉，也就是说fd/bk都被用户数据覆盖了。那么具体每个到malloc当中，内存分配是怎么管理的？换言之chunk怎么管理的呢？\nArena是每个线程管理堆区的单位，每个线程有自己的Arena。主线程的为main arena，其它线程的为thread arena。 bins是具体的管理chunk的结构，chunk挂起来连接到bin上，具体获取bin需要使用宏bin_at(m,i)和next_bin(b) 如下图bins包含small bins，large bins，unsorted bins unsorted bins 存储chunk拆分出来以后的剩余部分和最近被free掉的chunk（如果这个chunk不被fastbin回收） fastbin存储最近free的chunk，数据大小为一般为16～64B。那么最近从small bin和large bin，free掉的大的chunk，也丢到unsorted bins里面 具体的管理结构为malloc_state\n实际分配的时候看arena当中是否内存充足，有空余的chunk那么拆分/不拆分直接给出，要不使用sbrk/mmap申请。\n顺序是优先fastbin再small /large bins中查找，还不行就unsorted bins查找，不成功再恢复到bins里面。具体的流程为：\n优先fastbins分配 如果分配内存\u0026lt;512字节，则通过内存大小定位到smallbins对应的index上(floor(size/8)) 如果smallbins[index]为空，进入步骤4 如果smallbins[index]非空，直接返回第一个chunk 如果分配内存\u0026gt;512字节，则定位到largebins对应的index上 如果largebins[index]为空，进入步骤4 如果largebins[index]非空，扫描链表，找到第一个大小最合适的chunk，如size=12.5K，则使用chunk B，剩下的0.5k放入unsorted_list中 遍历unsorted_list，查找合适size的chunk，如果找到则返回；否则，将这些chunk都归类放到smallbins和largebins里面 index++从更大的链表中查找，直到找到合适大小的chunk为止，找到后将chunk拆分，并将剩余的加入到unsorted_list中 如果还没有找到，那么使用top chunk 或者，内存\u0026lt;128k，使用brk；内存\u0026gt;128k，使用mmap获取新内存 相关资料看这几个链接：\nhttps://zhuanlan.zhihu.com/p/163401620 https://jacktang816.github.io/post/mallocandfree/ 感觉说的有些前后矛盾，到底是先找sammbins还是找unsorted bins呢？ https://a1ex.online/2020/09/28/glibc-malloc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/ https://niebelungen-d.top/2021/03/07/Glibc-2-20-malloc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/#int-malloc 9.2 从类对象到malloc的调用 # 上面是malloc的操作，那么使用构造函数构造对象的时候new怎么和malloc建立关系的呢？以string为目标看下，依赖的代码是gcc4.8.5的代码\n10 C++设计新思维笔记 # 结尾 # 结尾记录一点和c++关系不大，但是和thrift关系比较大的东西，因为我一边写着cpp的程序练手，一边在学习怎么使用thrift进行通信。\nthrift常见错误异常和几个小问题 # 0 编译成功thrift程序之后，运行会爆出错误：\ndyld: Symbol not found: _GENERAL_NAME_free*\r* Referenced from: /usr/local/lib/libthrift-0.9.3-dev.dylib* 查询这个问题的时候搜索百度和google会有两个搜索结果，百度的结果上说是什么mac的编译环境是clang而不是gcc导致的（什么小白装thrift的链接），这个回答是错误的，也没给出解决方案。另一个是google上运行python的时候报这个错，参考那个解决方法，解决thrift的依赖问题即可：在cmake文件中指明openssl的lib库在哪里。\n1 如果server没有打开，那么client端进行连接的时候，每一次都会爆出Thrift: TSocket::open() error on socket (after THRIFT_POLL) \u0026lt;Host: 127.0.0.1 Port: 9000\u0026gt;Connection refused的错误提示，换言之Connection refused就是server端服务没打开。\n2 如果server打开了，但是client选择的Ttransport的类型和server端的Ttransport类型不一致（比方说，一边是TBufferedTransport，另一边是TBinaryTransport）那么client端会成功的连接，不会爆出所谓的Connection refused 的错误（三次握手成功了？），但是client端会长期的等待直到到了Tsocket所设定的超时时间，然后报错THRIFT_EAGAIN (timed out)，而server端则会给出提示Thrift: Sat May 15 00:32:15 2021 received invalid message type 0 from client即消息的类型错误。\n3 和上面的问题非常相似，只不过反过来了，就是服务端是TFramedTransport，客户端是TBufferedTransport，连接的时候会成功连接，不会爆出Connection refused的错误，但是client端一调用具体的函数就会触发异常No more data to read.的问题，服务端的报警信息我没有看到，不太确定。\n4 和上面的问题类似，如果server打开了，客户端执行两次Ttransport-\u0026gt;open()会发生什么呢？实际上不会发生什么事情，不会出现报错和异常。\n5 Ttransport-\u0026gt;open()成功之后，使用Tprotocol初始化两个不同的生成的client对象，并调用相对应的servcie函数会发生什么？不会发生什么问题，不会出现报错。\n6 一个transport-\u0026gt;open()之后，再次声明新的Tsocket,Ttransport,Tprotocol和新的对象，并调用对应的service函数，会卡住，服务端会报错：\n7 server端正在正常工作，client端transport-\u0026gt;open()成功，之后服务端offline/关闭了，client端报错No more data to read.\n8 thrfit到底是个单向的，还是双向的服务？实际上thrift是可以实现双向连接的，服务端可以拿到客户端的连接并且进行消息的发送，但是似乎没有进行这种服务的？答案是thrift并没有双向的服务，所谓的双向知识提供接口更新的时候让对端（也就是原先的服务端）通知一下消息。\n9 thrift多线程环境下能不能正确的支持消息发送？还是说需要拆分开？很明显不支持多线程，不可能把多线程都给你做了，下一个问题的里面的链接也说的很清楚了。为了维持多线程的安全，最好再重新启一个连接去获取对应的数据。\n10 thrift的连接是长链接吗？比方说我trnasport-\u0026gt;open()之后，那么我是三次握手完成了吗？从thrift的文档来看，就是完成了一个三次握手过程。如果有连接的话，我是应该再开一个还是再利用现在已经存在的东西呢？有这么一个回答https://stackoverflow.com/questions/42510657/is-a-singleton-apache-thrift-client-better-than-multiple-client-instances/42516397\n11 undefined reference to `std::__throw_out_of_range_fmt(char const*, \u0026hellip;)\u0026lsquo;问题：这几天发现一个很奇怪的问题，cmake是3.12.2，如果先在g++ 4.8的版本下编译了一遍代码，以后无论source改变环境变量使得g++为4.9/5.3.1的新版本，总会导致一直有下面的错误提示。解决方法是删除掉旧文件，重新使用新的g++/gcc版本编译。\n/usr/local/lib64/libbenchmark.a(benchmark_runner.cc.o): In function `benchmark::internal::BenchmarkRunner::DoNIterations()\u0026#39;:\rbenchmark_runner.cc:(.text+0x1bd1): undefined reference to `std::thread::_M_start_thread(std::shared_ptr\u0026lt;std::thread::_Impl_base\u0026gt;, void (*)())\u0026#39;\r/usr/local/lib64/libbenchmark.a(string_util.cc.o): In function `benchmark::StrSplit(std::string const\u0026amp;, char)\u0026#39;:\rstring_util.cc:(.text+0x1e27): undefined reference to `std::__throw_out_of_range_fmt(char const*, ...)\u0026#39; 12 今天测试了一下boost::any和unique_ptr与void*存储数据时候存储数据拷贝的性能差异等数据，给个简单的对比\n对象 Time CPU Iterations 备注 Boost::any 112 ns 112 ns 5603362 std::unique_ptr 69.5 ns 69.4 ns 9993861 void* 67.4 ns 67.4 ns 10328140 测试程序很简单，综合而言，使用unique_ptr的效率不比void*低多少，而且还避免了内存泄露。因此更推荐使用unique_ptr\n#include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;boost/any.hpp\u0026gt; #include \u0026lt;benchmark/benchmark.h\u0026gt; std::string res(\u0026#34;hellosdfasdfasdfasdfasdfasdfasdfasf\u0026#34;); boost::any tmp = res; void* tmp_void = static_cast\u0026lt;void*\u0026gt;(new std::string(res)); std::unique_ptr\u0026lt;std::string\u0026gt; tmp_uniqre_ptr(new std::string(res)); static void BM_SomeFunction(benchmark::State\u0026amp; state) { // Perform setup here for (auto _ : state) { std::string final = *tmp_uniqre_ptr; } } // Register the function as a benchmark BENCHMARK(BM_SomeFunction); // Run the benchmark BENCHMARK_MAIN(); 13 编译的一个静态库，然后被人用来生成静态库了，提示\nrelocation R_X86_64_32 against .bss' can not be used when making a shared object; recompile with -fPIC\n出现问题的原因是因为编译静态库的时候，没加fPIC标记换言之：\nIs the side-effect of not using -fPIC when compiling a static library which goes into a shared object platform-dependent 。\n这个回答可以说是讲的非常清楚了:\nIn brief, the term position independent code (PIC) refers to the generated machine code which is memory address agnostic, i.e. does not make any assumptions about where it was loaded into RAM. Only position independent code is supposed to be included into shared objects (SO) as they should have an ability to dynamically change their location in RAM.\nhttps://stackoverflow.com/questions/19364969/compilation-fails-with-relocation-r-x86-64-32-against-rodata-str1-8-can-not\n下面给出gcc的定义\n-fpic Generate position-independent code (PIC) suitable for use in a shared library, if supported for the target machine. Such code accesses all constant addresses through a global offset table (GOT). The dynamic loader resolves the GOT entries when the program starts (the dynamic loader is not part of GCC; it is part of the operating system). If the GOT size for the linked executable exceeds a machine-specific maximum size, you get an error message from the linker indicating that -fpic does not work; in that case, recompile with -fPIC instead. (These maximums are 8k on the SPARC, 28k on AArch64 and 32k on the m68k and RS/6000. The x86 has no such limit.)\nPosition-independent code requires special support, and therefore works only on certain machines. For the x86, GCC supports PIC for System V but not for the Sun 386i. Code generated for the IBM RS/6000 is always position-independent.\nWhen this flag is set, the macros __pic__ and __PIC__ are defined to 1.\n-fPIC If supported for the target machine, emit position-independent code, suitable for dynamic linking and avoiding any limit on the size of the global offset table. This option makes a difference on AArch64, m68k, PowerPC and SPARC.\nPosition-independent code requires special support, and therefore works only on certain machines.\nWhen this flag is set, the macros __pic__ and __PIC__ are defined to 2\n14 今天遇到一个非常有趣的问题：我写了一个静态库libauth.a，里面使用ar -M \u0026lt; authlib.mri打包了boringssl库，然后squirrel在调用的时候自己又引了一个libcrypto.so文件。然后问题来了，libcrypto.so里面和boringssl库（静态库）有函数重名了，然后每次一跑程序就coredump在一个openssl函数上。那么\n为什么程序能编译通过？没啥问题，自己试过了一个动态库，一个静态库，和两个都是动态库是一样的，编译的选项哪个在前面用哪个。但这个前提是main程序只掉用了重名函数，如果main程序还调用了别的程序，那么最后掉用的会被其它掉用的程序所影响。 如何解决这个问题呢？最直接的就是切换编译选项里面的先后顺序，恐怕还是-fvisibility=hidden 如果采用第二个问题的解决方法，那么我写的libauth.a里面使用的函数究竟是libcrypto.so也就是openssl动态库里面的，还是boringssl静态库里面的？这个是时候就出现好玩的东西了，如果真正的函数除了两个lib中同名的函数，还调用了别的函数，而别的函数调用了自己库里面的重名函数，那么会导致最终都掉用对应的库里面的函数。如果没掉用，那么无所谓了。 换个问题，如果两个都是静态库，那么能够编译通过吗？如果两个都是静态库，而且只是一个重名，那么采用默认的编译方式的时候是先找到一个满足的就ok，不会报错。但是如果main程序调用了两个库里面的其它的符号，那么问题就来了，就会报重复定义！ /* a.c */ 1 #include \u0026lt;stdio.h\u0026gt; 2 3 void out() { 4 printf(\u0026#34;hello from a \\n\u0026#34;); 5 return; 6 } /* b.c */ 1 #include \u0026lt;stdio.h\u0026gt; 2 3 void out() { 4 printf(\u0026#34;hello from b \\n\u0026#34;); 5 return; 6 } 7 8 void call_out() { 9 out(); 10 } /* main.c */ 1 extern void test(); 2 extern void call_out(); 3 int main() { 4 out(); 5 call_out(); 6 return 0; 7 } /* gcc main.c ./liba.a ./libb.a ====分隔==== 会报错，提示重复定义，为什么呢？先把a中的定义引入，然后发现b里面的call_out定义，由于静态链接不是按照需求引入链接，而是直接把文件里面所有的符号链接都丢到elf文件里，因此在之后引入call_out定义的时候会把b的out定义引入，然后就重名了，就会报错 */ /* gcc main.c ./libb.a ./liba.a ====分隔==== 不会报错，为什么呢？依赖是引入的时候就会是引入b的定义，整个过程就不会引入a的定义 */ /* gcc main.c ./libb.so ./liba.so ====分隔==== 不会报错，为什么呢？依赖是引入的时候就会是引入b的定义，整个过程就不会引入a的定义，输出都是hello from b */ /* gcc main.c ./liba.so ./libb.so ====分隔==== 不会报错，为什么呢？依赖是先找liba.so，再找libb.so，但是会都输出hello from a */ /* gcc main.c ./libb.a ./liba.so ====分隔==== 不会报错，为什么呢？由于必须引入call_out静态符号，会同时引入b的out静态符号，因此必然是输出hello from b */ /* gcc main.c ./liba.so ./libb.a ====分隔==== 不会报错，为什么呢？先找到a里面out的动态符号，由于必须引入call_out静态符号，会同时引入b的out静态符号，因此必然是输出hello from b */ 添加了--whole-archive那么，就会报错说是有重复定义。但是也有说是直接就报错，说是有多重定义的。\n换个问题，如果两个都是动态库，能编译通过吗？可以的，动态库运行的时候才会动态加载，加载的顺序由编译时候链接的顺序决定，符号表以第一个查到的为准。但是这个时候，即使main里面调用必然是b里面的call_out，那么call_out执行的out也会是和顺序强相关，也就是说，如果结果如下：\n[root@set-zf-kms-test-c-dev01 lib_test]# gcc main.c ./libb.so ./liba.so\r[root@set-zf-kms-test-c-dev01 lib_test]# ./a.out //动态链接只会调用第一个被链接进来的，也就是b的out符号\rhello from b\rhello from b\r[root@set-zf-kms-test-c-dev01 lib_test]# gcc main.c ./liba.so ./libb.so\r[root@set-zf-kms-test-c-dev01 lib_test]# ./a.out //动态链接还是只调用第一个的out动态符号，也就是a的out符号\rhello from a\rhello from a 15 前几天在写无锁环的遇上一个问题，就是什么是is_trivially_copyable，简单来说trivially_copyable类型的存储地址是连续的，也就是说trivially_copyable类型需要满足三个条件：\nuses the implicitly defined copy and move constructors, copy and move assignments, and destructor. has no virtual members. its base class and non-static data members (if any) are themselves also trivially copyable types. 16 今天写cmakelist即使写了link_list也不能正确的执行连接到grpc的库根本原因是因为link_directories写到了add_executable的后面，最后改完了成了\ncmake_minimum_required(VERSION 2.8.9) project(health_test) #Bring the headers, such as Student.h into the project include_directories(/home/qcraft/code_test/grpc-cpp/include) link_directories(/home/qcraft/code_test/grpc-cpp/grpc/cmake/build) add_executable(health_test_client health_client.cc health.grpc.pb.cc health.pb.cc) #Generate the shared library from the sources target_link_libraries(health_test_client -lgrpc++ -lgrpc++_reflection -lpthread) C/C++常见问题总结 # 在公司开发AuthSDK/KmsSDK时遇到很多问题，简单总结并给出解决方法。前四种为兼容性问题，最后一个为编译问题：\n依赖GCC版本错误导致各种问题：GCC兼容性的问题容易导致缺乏定义和结构体大小变化问题：遇见过编译爆出undefined reference to `std::__throw_out_of_range_fmt，数据体结构变化导致coredump等。\n依赖软件库版本不同导致各种问题：依赖库的版本变化可能导致多种问题：遇见过BOOST库版本错误导致COREDUMP，LCRYPTO库版本错误导致计算错误，静态库缺乏fPIC标记无法被动态库包含。\n依赖头文件错误导致UB：不同版本头文件混用导致各种UB：遇见过使用log4cplus 1.1.3和log4cplus1.2.2的库混用导致初始化日志配置就coredump问题。\n库重名问题：动态库混编，静态库混编，动/静态库混编导致重名/缺乏定义问题。\n常见其它问题：\n1 GCC版本错误问题 # 公司内部gcc环境很多：4.8.5/4.9.2/5.3.1/8.3.1/\u0026hellip;，gcc环境的变化最容易导致的问题是undefined reference，尤其以4.8.5老版本和4.8.5以上的版本混用导致为主。遇到的未定义错误可能包括：\nundefined reference to `std::__throw_out_of_range_fmt(char const*, \u0026hellip;)\u0026rsquo;，该问题出现的原因是因为gcc4.8.5缺乏该函数的定义，解决方法只能使用新版本的gcc（实质为使用新版本stdc++库），如果不能更换gcc版本建议联系导致出现上述undefined reference的具体函数提供方寻求解决方案。在开发KMS 时选择公司内部clogV2作为日志库的时候遇到这个问题，最终的解决方案是弃用clogV2选择log4cplus，但导致了另外一个严重问题。提示的错误信息见下：\n/usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../lib64/libclogV2.a(configurator.cxx.o): In function `log4cplus::(anonymous namespace)::substVars(std::string\u0026amp;, std::string const\u0026amp;, log4cplus::helpers::Properties const\u0026amp;, log4cplus::helpers::LogLog\u0026amp;, unsigned int)\u0026#39;: (.text+0x1683): undefined reference to `std::__throw_out_of_range_fmt(char const*, ...)\u0026#39; /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../lib64/libclogV2.a(property.cxx.o): In function `log4cplus::helpers::Properties::init(std::istream\u0026amp;)\u0026#39;: (.text+0x107d): undefined reference to `std::__throw_out_of_range_fmt(char const*, ...)\u0026#39; /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../lib64/libclogV2.a(property.cxx.o): In function `log4cplus::helpers::Properties::getPropertySubset(std::string const\u0026amp;) const\u0026#39;: (.text+0x169f): undefined reference to `std::__throw_out_of_range_fmt(char const*, ...)\u0026#39; /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../lib64/libclogV2.a(fileappender.cxx.o): In function `log4cplus::preprocessFilenamePattern(std::string const\u0026amp;, log4cplus::DailyRollingFileSchedule\u0026amp;)\u0026#39;: (.text+0x9988): undefined reference to `std::__throw_out_of_range_fmt(char const*, ...)\u0026#39; /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../lib64/libclogV2.a(patternlayout.cxx.o): In function `log4cplus::pattern::LoggerPatternConverter::convert(std::string\u0026amp;, log4cplus::spi::InternalLoggingEvent const\u0026amp;)\u0026#39;: (.text+0x304): undefined reference to `std::__throw_out_of_range_fmt(char const*, ...)\u0026#39; /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../lib64/libclogV2.a(patternlayout.cxx.o):(.text+0xaac): more undefined references to `std::__throw_out_of_range_fmt(char const*, ...)\u0026#39; follow collect2: error: ld returned 1 exit status make[2]: *** [sts_decode] Error 1 make[1]: *** [CMakeFiles/sts_decode.dir/all] Error 2 make: *** [all] Error 2 undefined reference to `std::__cxx11::basic_string，该问题出现的原因是因为使用的string非C++11标准实现版本，4.8.5之前的版本不支持C++11，此外C++11的ABI和string实现变化都极容易导致对C++11支持不彻底的4.8.5及老版本GCC出现CORE问题。对该问题的解决方法为添加宏定义-D_GLIBCXX_USE_CXX11_ABI=0，或指定具体的库版本为C++11版本。如果使用Cmake参与编译，那么需要手动删除产生的文件，一部分cmake 重新时不会删除部分中间文件，导致依然报该undefine reference。\n遇到的例子是使用5.3.1编译出来的KMS库在给4.8.5使用时爆出的错误信息：\n如果使用muduo库参与库实现，需要注意是否为C98标准，C98标准muduo使用的string不是std::string，需要显式定义DMUDUO_STD_STRING，才能正确编译否则会报错undefined reference to string。开发KMS SDK时，多线程同步最早选择的库为MUDUO C98分支，当时链接报错这个错误会报错：\n除了版本混用导致的undefined reference问题，还极易出现莫名其妙的CORE问题：\ngcc4.8.5多线程操作字符串COREDUMP问题，该问题不多赘述，网上资料很多。\n不同版本数据结构变化导致COREDUMP问题，举个简单例子：Kms Pangolin SDK的代码基于4.8.5编译，使用5.3.1编译器引用库时会core。原因：Kms Pangolin SDK SDK的数据结构为unordered_map后面紧跟一个mutex，加锁时会从unordered_map偏移48字节位置加锁，这个位置是mutex的位置。\n但是GCC5.0和GCC4.8的unordered_map大小不一样，GCC5.0的unordered_map为56字节，因此锁的位置有偏移，但是代码依然对偏移位置为48的地方加锁，因此GCC5之后版本修改锁会错误的修改unordered_map的_M_buckets。两种解决方法：1不使用发生变化的数据结构，增加代码开发的难度 2 和使用者的gcc版本对齐，增加维护难度，不建议，且难度较大。\n当时CORE文件的异常栈为：\n(gdb) bt\r#0 0x00007f0a03a64110 in std::_Hashtable\u0026lt;std::string, std::pair\u0026lt;std::string const, meituan::kms::Crypto*\u0026gt;, std::allocator\u0026lt;std::pair\u0026lt;std::string const, meituan::kms::Crypto*\u0026gt; \u0026gt;, std::__detail::_Select1st, std::equal_to\u0026lt;std::string\u0026gt;, std::hash\u0026lt;std::string\u0026gt;, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits\u0026lt;true, false, true\u0026gt; \u0026gt;::_M_find_before_node(unsigned long, std::string const\u0026amp;, unsigned long) const ()\rfrom /opt/meituan/chenxinhua03/serving/faceservice-torch/cv-faceservice-torch/lib/kms_pangolin/libkms-crypto.so\r#1 0x00007f0a03a5de43 in meituan::kms::Cryptos::get(std::string const\u0026amp;, std::string const\u0026amp;, std::string const\u0026amp;, std::string\u0026amp;) () from /opt/meituan/chenxinhua03/serving/faceservice-torch/cv-faceservice-torch/lib/kms_pangolin/libkms-crypto.so\r#2 0x0000000000642f0e in FaceAuthServiceHandler::faceAuth (this=0x37872a0, _return=..., img1=..., img2=..., fpRate=faceauthservice::FaceBaseFPRate::FP_E_4) at /opt/meituan/tools/cv-faceservice-torch/src/face_service_server.cpp:414\r#3 0x0000000000556490 in faceauthservice::FaceAuthServiceProcessor::process_faceAuth (this=0x44cd7e0, seqid=0, iprot=0x7f0884001820, oprot=0x7f08840018b0, callContext=0x0) at /opt/meituan/tools/cv-faceservice-torch/thrift/FaceAuthService/FaceAuthService.cpp:327\r#4 0x0000000000555e50 in faceauthservice::FaceAuthServiceProcessor::process_fn (this=0x44cd7e0, iprot=0x7f0884001820, oprot=0x7f08840018b0, fname=\u0026#34;faceAuth\u0026#34;, seqid=0, callContext=0x0)\rat /opt/meituan/tools/cv-faceservice-torch/thrift/FaceAuthService/FaceAuthService.cpp:300\r#5 0x0000000000555772 in faceauthservice::FaceAuthServiceProcessor::process (this=0x44cd7e0, piprot=..., poprot=..., callContext=0x0) at /opt/meituan/tools/cv-faceservice-torch/thrift/FaceAuthService/FaceAuthService.cpp:282\r#6 0x00000000006a40e4 in cthrift::CthriftSvr::ProcessSync(apache::thrift::transport::CthriftUniformRequest\u0026amp;, int const\u0026amp;, unsigned char*, boost::weak_ptr\u0026lt;muduo::net::TcpConnection\u0026gt;, muduo::Timestamp) ()\r#7 0x00000000006a6a52 in cthrift::CthriftSvr::Process(apache::thrift::transport::CthriftUniformRequest\u0026amp;, int const\u0026amp;, unsigned char*, boost::weak_ptr\u0026lt;muduo::net::TcpConnection\u0026gt;, muduo::Timestamp) ()\r#8 0x00000000006a7ba3 in cthrift::CthriftSvr::ProcessUniformNormal(apache::thrift::transport::CthriftUniformRequest\u0026amp;, int const\u0026amp;, unsigned char const*, bool\u0026amp;, boost::weak_ptr\u0026lt;muduo::net::TcpConnection\u0026gt;, muduo::Timestamp) ()\r#9 0x00000000006acb9e in cthrift::CthriftSvr::ProcessUniform(boost::weak_ptr\u0026lt;muduo::net::Buffer\u0026gt;, int const\u0026amp;, unsigned char const*, bool\u0026amp;, boost::weak_ptr\u0026lt;muduo::net::TcpConnection\u0026gt;, muduo::Timestamp) ()\r#10 0x00000000006ad693 in cthrift::CthriftSvr::Process(boost::shared_ptr\u0026lt;muduo::net::Buffer\u0026gt; const\u0026amp;, boost::weak_ptr\u0026lt;cthrift::ConnContext\u0026gt;, boost::weak_ptr\u0026lt;muduo::net::TcpConnection\u0026gt;, muduo::Timestamp) ()\r#11 0x00000000006b3852 in boost::detail::function::void_function_obj_invoker0\u0026lt;boost::_bi::bind_t\u0026lt;void, boost::_mfi::mf4\u0026lt;void, cthrift::CthriftSvr, boost::shared_ptr\u0026lt;muduo::net::Buffer\u0026gt; const\u0026amp;, boost::weak_ptr\u0026lt;cthrift::ConnContext\u0026gt;, boost::weak_ptr\u0026lt;muduo::net::TcpConnection\u0026gt;, muduo::Timestamp\u0026gt;, boost::_bi::list5\u0026lt;boost::_bi::value\u0026lt;cthrift::CthriftSvr*\u0026gt;, boost::_bi::value\u0026lt;boost::shared_ptr\u0026lt;muduo::net::Buffer\u0026gt; \u0026gt;, boost::_bi::value\u0026lt;boost::weak_ptr\u0026lt;cthrift::ConnContext\u0026gt; \u0026gt;, boost::_bi::value\u0026lt;boost::weak_ptr\u0026lt;muduo::net::TcpConnection\u0026gt; \u0026gt;, boost::_bi::value\u0026lt;muduo::Timestamp\u0026gt; \u0026gt; \u0026gt;, void\u0026gt;::invoke(boost::detail::function::function_buffer\u0026amp;) ()\r#12 0x00000000007b90f1 in muduo::net::EventLoop::doPendingFunctors() ()\r#13 0x00000000007b92df in muduo::net::EventLoop::loop() ()\r#14 0x00000000007ba9a1 in muduo::net::EventLoopThread::threadFunc() ()\r#15 0x00000000007db585 in muduo::detail::startThread(void*) ()\r#16 0x00007f0a035c1ea5 in start_thread () from /lib64/libpthread.so.0\r#17 0x00007f09afac28dd in clone () from /lib64/libc.so.6} 2 依赖软件库版本不同问题 # 公司内部基础环境混乱，基于inf_cbom是比较通用的解决手段，但是inf_cbom和很多默认库版本不同会导致很多问题，目前inf_cbom已经废弃，对于版本的管理需要开发者自己维护。遇见的错误为：\nboost版本冲突，导致出现未知COREDUMP。两种解决方法：1强制客户使用新版本/inf_cbom版本boost，增加客户运行的难度 2 开发者回退为boost153版本，会增加一定的维护困难，不过由于153和169大部分代码对齐，因此难度较为简单。AUTHSDK开发时依赖boost69的实现，SQUIRREL使用了boost153版本代码。运行时出现COREDUMP，调用栈为：\n(gdb) thread apply all bt\rThread 12 (Thread 0x7fffd2ffd700 (LWP 4271))\r#0 Oxooo0000000000000 in ?？ ()\r#1 0x00007ffff68da14a in tls_destructor () from /lib64/libboost_thread-mt.so.1.53.0\r#2 0x00007ffff68da262 in thread_proxy () from /lib64/libboost_thread-mt.so.1.53.0\r#3 0x00007ffff7bc6ea5 in start_thread () from /lib64/libpthread.so.o\r#4 0x00007ffff54f496d in clone () from /lib64/libc.so.6 libcrypto错误版本功能支持不足，libcrypto.so/a是openssl编译出的加解密库，公司内部现在有三个加解密库:centos6的1.0.1f，centos7的1.0.2k，与boringssl编译出来的libcrypto。这三个混用有多种问题：centos的1.0.1f对pem支持有限，不能load一行多于80字符的pem，libcrypto和centos7的1.0.2k混用会导致coredump。这个问题的解决方法为：自己处理PEM格式，改为对1.0.1f兼容的格式，将对libcrypto的依赖放开由使用者决定哪个版本libcrypto。\nSquirrel使用openssl lcrypto加解密库，authsdk默认包含boringssl lcrypto库，squirrel使用下coredump。调用栈为：\nCore was generated by\rProgram terminated with signal 11, Segmentation fault\r#0 0x0000000005c5614c in SquirrelCpp: :Base64Encode (input=input@entry=0x1ffefff8d0 \u0026#34;\\362\\n\\213\\\u0026#34;f\\277\\177\\bE0\\302wI:_\\345\\234\\071\\364\\07 with _new_line-with_new_lineGentry=true) at /root/project/squirrel-cpp-client/src/Curler.cpp:7o\r#1 0x0000000005c562e7 in SquirrelCpp::_get_BA (url=url@entry=0x5ede929 \u0026#34;/config2/get\u0026#34;, method=method@entry=0x5ede925 \u0026#34;GET\u0026#34;,key=0xb7d068 at /root/project/squirrel-cpp-client/src/Curler.cpp:105\r#2 0x0000000005c5744f in SquirrelCpp::Curler::getValueByKey (url=\u0026#34;lion-api.inf.test.sankuai. com\u0026#34;, usr=\u0026#34;Squirrel-cpp-client\u0026#34;, key=\u0026#34;avatar passwd=\u0026#34;5XXRYR1QNG\u0026#34;, group=\u0026#34;\u0026#34;) at /root/project/squirrel-cpp-client/src/Curler.cpp:131 静态库缺乏fPIC导致不能被动态库包含，这个问题最常见的例子是thrift-0.9.3和thrift-0.8：0.8版本thrift静态库没有fPIC标记，因此依赖0.8版本的静态库必须得放弃包含0.8版本thrift依赖。三种解决方法：1使用thrift-0.9.3版本代码，完美支持fPIC，且对老版本thrift兼容。唯一麻烦的地方是需要手动重新生成thrift gen 文件，老版本的thrift idl的生成文件和新版本thrift idl的生成文件无法对齐。2 开放thrift给调用者，由使用者提供thrift依赖。3 自己手动从静态库.a文件使用ar x somelib.a获得中间.o文件，然后删除掉未添加fPIC标记的文推荐，重新打包。这种方法的问题是比较麻烦，且重名的.o会相互覆盖\nsquirrel使用authsdk的静态库打包动态库的时候遇上这个问题，报错内容为：\nBuilding CXX object CMakeFiles/squirrel-cpp-client.dir/src/ServerInfo.cpp.o\rLinking CXX static library libsquirrel-cpp-client.a\rLinking CXX shared Library libsquirrel-cpp-client.so\r[ 98%] Built target squirrel-cpp-client-static\r/usr/bin/ld:../deps/kms/libauth_service4c.a(thread.o): relocation R_X86_64_32 against、.text\u0026#39; can not be used when making a shared object; recompile with -fPIC\r/usr/bin/ld:../deps/kms/libauth_service4c.a(log4cplus.cpp.o):relocation R_X86_64_32 against 、.rodata\u0026#39; can not be used when making a shared object; recompile with -fPIC\r/usr/bin/ld:../deps/kms/libauth_service4c.a(once.o) : relocation R_X86_64_32 against 、.bss\u0026#39; can not be used when making a shared object; recompile with -fPIC\r/usr/bin/ld:../deps/kms/libauth_service4c.a(chrono.o):relocation R_X86_64_32 against hidden symbol 、_ZZN5boost6system15system_categoryEvE24system_category_instance\u0026#39; can not be used when making a shared object;recompile with -fPIC\r/usr/bin/ld:../deps/kms/libauth_service4c.a(thrift_client.cpp.o):relocation R_X86_64_32S against symbol ZTV15KmsAgentService\u0026#39; can not be used when making a shared object; recompile witr -fPIC\r/usr/bin/ld: /deps/kms/libauth_service4c.a(kms_aes.cpp.o):relocation R_X86_64_32 against 、.rodata\u0026#39; can not be used when making a shared object; recompile with -fPICo\rcan /usr/bin/ld:../deps/kms/libauth_service4c.a(key_format_convert.cpp.o):relocation R_X86_64_32 against 、.rodata\u0026#39; can not be used when making a shared object; recompile with -fPIC\r/usr/bin/ld:../deps/kms/libauth_service4c.a(KmsAgent.cpp.o):relocation R_X86_64_32S against symbol、_ZTV28KmsAgent_OnNotifyUpdate_args\u0026#39; can not be used when making a shared object; recompile with -fPIC /usr/bin/ld: /deps/kms/libauth_service4c.a(common_types.cpp.o):relocation R_X86_64_32S against symbol、_ZTV10TNameStore\u0026#39; can not be used when making a shared object; recompile with -fPIC\r\u0026#39;usr/bin/ld:../deps/kms/libauth_service4c.a(kms_global_config.cpp.o):relocation R_X86_64_32S against symbol 、_ZTV15KmsGLobalConfig\u0026#39; can not be used when making a shared object; recompile with -fPIC\rusr/bin/ld: /deps/kms/libauth_service4c.a(kms_key_map.cpp.o):relocation R_X86_64_32S against symbol、_ZTV9KmsKeyMap\u0026#39; can not be used when making a shared object; recompile with -fPIC 3 依赖错误头文件问题 # 一部分库，尤其以log4cplus为代表的库提供复杂的.h文件，这些复杂的.h文件隐藏内部复杂度的手段并不是隐藏数据结构，而是隐藏数据结构的调用。换言之这些数据结构用户可见，只不过不会显式调用。因此，如果引用这个版本的头文件和其它版本的库文件变成会导致奇特UB。这种问题对开发者往往是透明的，近乎无解。\nAuth SDK使用的log4cplus为1.1.3版本，头文件中包含了RollingFileAppender结构，大小为664字节。使用clogV2动/静态库链接的时候，发现clogV2用的log4cplus是基于1.2.2的，RollingFileAppender大小为680字节。导致分配内存时按照664字节分配，操作数据时按照680字节大小操作内部属性，从而导致各种UB。\n当时出现的CORE文件调用栈见下，具体出错的位置不在这里。\n(gdb) bt\r#0 0x00007ffff63cb3d7 in raise () from /lib64/libc.so.6\r#1 0x00007ffff63ccac8 in abort () from /lib64/libc.so.6\r#2 0x00007ffff640df67 in __libc_message () from /lib64/libc.so.6\r#3 0x00007ffff6417b36 in _int_malloc () from /lib64/libc.so.6\r#4 0x00007ffff641a78c in malloc () from /lib64/libc.so.6\r#5 0x00007ffff6cda18d in operator new(unsigned long) () from /lib64/libstdc++.so.6\r#6 0x00007ffff6d38cd9 in std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator\u0026lt;char\u0026gt; const\u0026amp;) ()\rfrom /lib64/libstdc++.so.6\r#7 0x00007ffff6d3a561 in char* std::string::_S_construct\u0026lt;char const*\u0026gt;(char const*, char const*, std::allocator\u0026lt;char\u0026gt; const\u0026amp;, std::forward_iterator_tag) () from /lib64/libstdc++.so.6\r#8 0x00007ffff6d3a998 in std::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;::basic_string(char const*, std::allocator\u0026lt;char\u0026gt; const\u0026amp;) () from /lib64/libstdc++.so.6\r#9 0x00007ffff7b9815b in log4cplus::helpers::Properties::exists(char const*) const () from /lib64/libclogV2.so\r#10 0x00007ffff7b4b895 in log4cplus::Appender::Appender(log4cplus::helpers::Properties const\u0026amp;) () from /lib64/libclogV2.so\r#11 0x00007ffff7b6714f in log4cplus::FileAppenderBase::FileAppenderBase(log4cplus::helpers::Properties const\u0026amp;, std::_Ios_Openmode) ()\rfrom /lib64/libclogV2.so\r#12 0x00007ffff7b71646 in log4cplus::FileAppender::FileAppender(log4cplus::helpers::Properties const\u0026amp;, std::_Ios_Openmode) ()\rfrom /lib64/libclogV2.so //已经出错了\r#13 0x00007ffff7b71959 in log4cplus::RollingFileAppender::RollingFileAppender(log4cplus::helpers::Properties const\u0026amp;) ()\rfrom /lib64/libclogV2.so\r#14 0x00007ffff77009f1 in log4cplus::spi::FactoryTempl\u0026lt;log4cplus::RollingFileAppender, log4cplus::spi::AppenderFactory\u0026gt;::createObject (\rthis=\u0026lt;optimized out\u0026gt;, props=...) at ../include/log4cplus/spi/factory.h:242\r#15 0x00007ffff7b50bb9 in log4cplus::PropertyConfigurator::configureAppenders() () from /lib64/libclogV2.so\r#16 0x00007ffff7b53d2e in log4cplus::PropertyConfigurator::configure() () from /lib64/libclogV2.so\r#17 0x00007ffff7b53f24 in log4cplus::PropertyConfigurator::doConfigure(std::string const\u0026amp;, log4cplus::Hierarchy\u0026amp;, unsigned int) ()\rfrom /lib64/libclogV2.so\r#18 0x00007ffff744ed07 in AuthService::Init (this=this@entry=0x6089c0)\rat /home/vgdog/code/sts/auth_sdk_cpp/source/auth_service_real.cpp:9\r#19 0x00007ffff744c6ac in kms::Singleton\u0026lt;AuthService\u0026gt;::instance ()\rat /home/vgdog/code/sts/auth_sdk_cpp/source/./utils/Singleton.h:54\r#20 inf::auth::AuthServiceSignInit (param=...) at /home/vgdog/code/sts/auth_sdk_cpp/source/auth_service.cpp:8\r#21 0x0000000000400dee in main () 4 库重名问题 # 库重名问题，库重名问题是很多隐式问题出现的根本问题，但这类问题很难暴露。而且出现问题的地方往往不具备规律。下面给出几种常见的库重名错误：\n静态库重名问题：提供静态库给其它使用者时，常常会提示multiple definition of xxxx，这种问题要么是写程序的时候在头文件里面给的是定义，要么是因为提供的静态库包裹了重名库函数。两种解决方法：1将所有内部函数使用命名空间保护，所有的使用必须指定命名空间。2 使用fvisibility控制符号可见性，避免出现不想暴露的符号最终暴露出去导致重名。\n动态库重名问题：动态库符号重名编译阶段不会报错，运行时也不会直接出错。具体调用时使用的符号看先扫描到哪个动态库，比方说g++ main.c ./liba.so ./libb.so，如果先在liba.so中找到符号，那么就使用liba.so的实现。这种重名问题是无解的，错误的动态库导致的行为属于UB，无法修复。因此建议实现动态库时第三方依赖尽量由使用者解决。\nsquirrel使用openssl lcrypto库\n静态库/动态库混编问题：动态库静态库混编的后果是不可预料的，正常情况下使用的符号也是先扫到的优先使用，但是如果有符号只存在于静态库中，那么会把静态库的所有符号一起链接到可执行程序中，从而极容易导致multiple definition of xxxx。这问题近乎无解，建议减少对静态库的使用。\n5 其它常见问题 # 其它常见问题往往具体编译环境有关：\n编译时即使添加了对应的基础库，也报undefined_reference错误。请检查是不是库依赖的关系和链接的顺序不相符，比方说A依赖B，编译的命令里面-lb在-la前面，链接时连接器只会在la后的-lx里面找依赖。\nkms/authsdk代码依赖两种加解密库：cryptopp \u0026amp; openssl crypto。由于两者的部分头文件重名，可能导致can\u0026rsquo;t find xxx.h的问题。目前kms使用crytpopp库，authsdk使用openssl crypto。建议不要混用两个库。\n第三方依赖库线程安全问题，以libcurl为代表的第三库超时使用信号实现，但信号不是线程安全的。建议检查相关函数线程安全保证，使用配置/其它第三方库绕过这些问题。出现libcrul超时coredump的栈见下\n#0 0x081eff2c in addbyter ()\r#1 0x081f05b8 in dprintf_formatf ()\r#2 0x081f15cf in curl_mvsnprintf ()\r#3 0x081f0079 in curl_msnprintf ()\r#4 0x081ef55c in Curl_failf ()\r#5 0x081fa1a3 in Curl_resolv_timeout ()\r#6 0xeb8fbdd4 in ?? ()\r#7 0x00000000 in ?? () 第三方加解密库建议使用borringssl crypto实现，目前已知openssl crypto库的base64解码存在bug，cryptopp的ecdsa签名格式非业内通用格式，cryptopp签名性能过差。但是考虑到库重名问题，建议开放具体库由使用者决定。\n加解密异常越界问题，开发authsdk流程中，由于cryptopp加解密库性能和兼容性问题转而使用openssl进行开发，使用rsa进行签名之后，将结果从char[]数组转换为string，之后显示string的内容会触发coredump。出现问题的原因为rsa签名的长度为700多字节，而作为缓冲区的数组长度为64，会移除。然后使用string进行赋值会coredump，从而导致问题。事后复现的coredump栈见下，单纯从栈很难看出来具体的错误是什么：\n(gdb) bt\r#0 0x00007ffff74af56d in ?? () from /lib64/libstdc++.so.6\r#1 0x00007ffff751307e in std::string::assign(std::string const\u0026amp;) () from /lib64/libstdc++.so.6\r#2 0x000000000041a962 in SignAlgorithm::rsa_sha256_sign_openssl (message=\u0026#34;to be or not to be , it is a problem\u0026#34;,\rpem_private_key=\u0026#34;MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCxlK9lRUIDDdH6NCGBEUoq5MChmKWdTlbE9gnc3ecLL9HJ+HKhixrNo513AbGo5IZLW1IM85qAJ9797TD9c8U/PoBflCU40Lo56KHUPMyYDhSsKCzLbWf06D1y6g7V+sjYSqjo1Hw2UkZZ+k/qyRhX\u0026#34;...,\rsignature=\u0026lt;error reading variable: Cannot access memory at address 0xe498b41ec53bedd9\u0026gt;)\rat /home/vgdog/code/code_test/sign_test/sign_algorithm.h:156\r#3 0xfcad1a4212b0fdcd in ?? ()\r#4 0xe498b41ec53bedf1 in ?? ()\r#5 0x12b4b1cd7e7fdd53 in ?? ()\r#6 0xeab48b2612c8e4da in ?? ()\r#7 0x1f9b145bcbba6d0e in ?? ()\r#8 0x0000000000674108 in ?? ()\r#9 0x00007ffff6ba7f49 in __internal_atexit (listp=0x7ffff6f356c8 \u0026lt;__exit_funcs\u0026gt;, d=0x34c77835045aaed0, arg=0x41a2ec \u0026lt;_start\u0026gt;,\rfunc=0xb9d78888ec6d3a3b) at cxa_atexit.c:34\r#10 __cxa_atexit (func=0xb9d78888ec6d3a3b, arg=0x41a2ec \u0026lt;_start\u0026gt;, d=0x34c77835045aaed0) at cxa_atexit.c:57\r#11 0x0000000000462abd in __libc_csu_init ()\r#12 0x00007ffff6b90555 in __libc_start_main (main=0x41a3e6 \u0026lt;main()\u0026gt;, argc=1, argv=0x7fffffffe468, init=\u0026lt;optimized out\u0026gt;,\rfini=\u0026lt;optimized out\u0026gt;, rtld_fini=\u0026lt;optimized out\u0026gt;, stack_end=0x7fffffffe458) at ../csu/libc-start.c:266\r#13 0x000000000041a315 in _start () 今天谢了一个泛型函数，遇到两个问题:1 泛型函数特化基类生成一个函数，然后派生类调用该泛型函数的时候回报undefined reference，简单的代码例子如下，这个是因为查找命名的空间不对，具体可以参考C++ primer。这里要注意，即使特化了。这个问题是怎么回事呢？具体可以参考这个问题：https://stackoverflow.com/questions/27988024/passing-a-derived-class-to-a-template-function-specialized-with-base-class\n这个解释就比较耐人寻味，认为会优先寻找派生类的特化，而不会去查找基类的特化，因为基类的特化需要一次类型转换。这里面涉及到了enable_if的使用，可以参考https://en.cppreference.com/w/cpp/types/enable_if \u0026amp; https://ouuan.github.io/post/c-11-enable-if-%E7%9A%84%E4%BD%BF%E7%94%A8/#enable_if-%E7%9A%84%E4%BD%BF%E7%94%A8。\n这里的解决方式有两种，一种是具体派生类使用的时候特化为调用父类的特化函数简单来说就是call_hello具体调用到基类，另一种就是像上面的回答的一样，我们使用enable_if来当派生类或者基类调用函数时，由于没有特化函数的声明，所以会优先去查找类型转换的函数。\n#include \u0026lt;iostream\u0026gt; class base { public: int hello() { std::cout \u0026lt;\u0026lt;\u0026#34; hello world\u0026#34; \u0026lt;\u0026lt; std::endl; } }; template\u0026lt;typename T\u0026gt; int call_hello(T \u0026amp;arg); template\u0026lt;\u0026gt; int call_hello\u0026lt;base\u0026gt;(base \u0026amp;arg) { arg.hello(); return 0; } class derive: public base { public: int hello_second() { std::cout \u0026lt;\u0026lt;\u0026#34; hello world second\u0026#34; \u0026lt;\u0026lt; std::endl; } }; int main() { derive test; call_hello(test); return 0; } /* 报错： /tmp/ccSSwO8U.o: In function `main\u0026#39;: main.cc:(.text+0x3e): undefined reference to `int call_hello\u0026lt;derive\u0026gt;(derive\u0026amp;)\u0026#39; collect2: error: ld returned 1 exit status 如果call_hello不是泛型，调用反而会成功。不出现问题 */ C++ 并发编程实战 # 第二章 std::stread # std::thread代表线程，其内部具有存储空间，参数会按照默认方式拷贝到该处，新创建的线程才能直接访问他们，然后这些副本被当成临时变量，以右值的形式传递给新线程上的函数或可调用对象\n而std::thread类型是不允许拷贝，只允许移动的，移动就是std::move，这里的move语义令人迷惑，比方说我写了个函数\nstd::thread f() { void some_function(); return std::thread(some_function); } 明明std::thread是一个局部变量，也就是说是在栈上，它没有拷贝构造函数，只有移动函数，这里返回的时候直接move了，相当于栈上的变量返回了，那么栈已经被销毁了，这里不是就不安全了吗？这里面有个错误的想法即move是移动，move实际上只是转换为右值，从而能够使用右值的拷贝构造函数。参考下面的thread实现代码\n00125 public: 00126 thread() = default; 00127 thread(const thread\u0026amp;) = delete; 00128 00129 thread(thread\u0026amp;\u0026amp; __t) \u0026lt;=== here 00130 { swap(__t); } 那么我们就可以给move一个清晰的定义了\n而std::move是什么意思呢？\nstd::move作用主要可以将一个左值转换成右值引用，从而可以调用C++11右值引用的拷贝构造函数，换句话说std::move()与std::forward()都仅仅做了**类型转换(可理解为static_cast转换)**而已。真正的移动操作是在移动构造函数或者移动赋值操作符中发生的 std::move应该是针对你的对象中有在堆上分配内存这种情况而设置的，这样子就可以很轻松地利用上一次分配出来的堆上的内存，而不需要再次拷贝浪费资源了 关于move，可以参考\nhttps://www.cnblogs.com/shadow-lr/p/Introduce_Std-move.html\n第三章 mutex # 一般来说，对于锁或者说互斥，都直接使用std::lock_guard\u0026lt;\u0026gt;来保证RAII，不过std::lock_guard一般只针对一个锁，那么可以使用std::scoped_lock\u0026lt;\u0026gt;去同时锁定多个锁\n防范死锁的思想简答来说就是：只有另一个线程有可能正在等待当前线程，那么当前线程千万不能反过来等待它，就可以有一些具体的准则来帮助我们进行研发\n避免嵌套锁，一个线程只持有一个锁\n尽量按照固定顺序获取锁\n按照层次加锁，这里实际上是说按照特定方式明确加锁次序，参考下面的代码。这里面有个问题https://stackoverflow.com/questions/14500495/thread-local-and-context-switch，很有趣，需要搞明白thread local是thread相关，不是cpu相关\nclass hierarchical_mutex\r{\rstd::mutext internal_mutex_;\runsigned long const hierachy_value_;\runsigned long const previous_hierachy_value_;\rstatic thread_local unsigned long this_thread_hierarchy_value; void check_for_hierarchy_violation()\r{\rif (this_thread_hierachy_value \u0026lt;= hierarchy_value_) {\rthrow std::logic_error(\u0026#34;mutex hierarchy violated\u0026#34;);\r}\r}\rvoid update_hierarchy_value()\r{\rprevious_hierarchy_value = this_thread_hierarchy_value;\rthis_thread_hierarchy_value=hierarchy_value_;\r}\rpublic:\rexplicit hierarchical_mutex(unsigned long value): hierarchy_value_(value), previous_hierarchy_value(0){}\rvoid lock(){\rcheck_for_hierarchy_violation();\rinternal_mutext.lock();\rupdate_hierarchy_value();\r}\r} 将准则推广到锁操作之外\n关于锁的移动，std::unique_lock不持有锁，所以可以用来移动unique_lock\n关于初始化单次的保护，标准库提供了std::call_once，而不是使用双检锁，为啥呢？参考https://www.drdobbs.com/cpp/c-and-the-perils-of-double-checked-locki/184405726，简单来说就是双检索对resource_ptr的写操作可能发生在初始化操作之前，因此可能会导致其他线程读取到已经赋值了，但是实际上还没初始化的resource_ptr\n新抓GO # 参考链接：\nhttps://golang.iswbm.com/ https://go.dev/doc/effective_go GO语言圣经 建议看英文版本，看中文版本很糟糕 函数定义\n一个函数的声明由一个函数名字、参数列表(由函数的调用者提供参数变量的具体值)、一个可选的返回值列表和包含函数定义的函数体组成\n简短变量声明左边的变量可能并不是全部都是刚刚声明的。如果有一些已经在相同的词法域声明过了(§2.7),那么简短变量声明语句对这些已经声明过的变量就只有赋值行为了。可以实现一个变量在多个环境再次使用，简短变量声明模式必须至少要声明一个新的变量。这里务必注意简短变量声明和普通的赋值的区别即:=和=的区别\n有一个很牛逼的语句，这个怎么理解呢？先右边求出来值，然后再统一更新左边变量的值。\nx, y = y, x 变量的生命周期指的是在程序运行期间变量有效存在的时间间隔。对于在包一级声明的变量来说,它们的生命周期和整个程序的运行周期是一致的。而相比之下,在局部变量的声明周期则是动态的:从每次创建一个新变量的声明语句开始,直到该变量不再被引用为止,然后变量的存储空间可能被回收。函数的参数变量和返回值变量都是局部变量。它们在函数每次被调用的时候创建。\n底层数据类型决定了内部结构和表达方式,也决定是否可以像底层类型一样对内置运算符的支持。\n一个声明语句将程序中的实体和一个名字关联,比如一个函数或一个变量。声明语句的作用域是指源代码中可以有效使用这个名字的范围。\n不要将作用域和生命周期混为一谈。声明语句的作用域对应的是一个源代码的文本区域;它是一个编译时的属性。一个变量的生命周期是指程序运行时变量存在的有效时间段,在此时间区域内它可以被程序的其他部分引用;是一个运行时的概念。\n当编译器遇到一个名字引用时,如果它看起来像一个声明,它首先从最内层的词法域向全局的作用域查找。如果查找失败,则报告“未声明的名字”这样的错误。如果该名字在内部和外部的块分别声明过,则内部块的声明首先被找到。在这种情况下,内部声明屏蔽了外部同名的声明,让外部的声明的名字无法被访问\nGo语言将数据类型分为四类:基础类型、复合类型、引用类型和接口类型\n递归，为什么下面的递归不需要出栈？\nfunc outline(stack []string, n *html.Node) { if n.Type == html.ElementNode { // push tag 主要问题出在这里，我们拷贝了stack，底层数据结构一致，这里修改的是内存拷贝的数据，可以对比shared_ptr的reset stack = append(stack, n.Data) fmt.Println(stack) } for c := n.FirstChild; c != nil; c = c.NextSibling { outline(stack, c) } } append函数并不确定原本的slice和append以后的slice是不是一个，所以往往是直接赋值将返回值赋值给过去的slice。这里面实际上就是还是那句话，拷贝和底层函数的传递。这种风格是GO语言风格的值。这里参考GO语言圣经128递归和SLICE里面的说法，一个是slice的拷贝，一个是底层数据的操作。\n实际上，这种slice的操作，无论是append等都是返回一个slice，从而能够直接修改变化，这里又有GC保底\n对这个有迷惑的看这个CSDN的链接 https://blog.csdn.net/liyunlong41/article/details/86767936\nGO语言圣经写的\n更新slice变量不仅对调用append函数是必要的,实际上对应任何可能导致长度、容量或底层数组变化的操作都是必要的。\n为什么下面的迭代是错误的？必须使用第二种方法？\n问题的原因在于循环变量的作用域。在上面的程序中,for循环语句引入了新的词法块,循环变量dir在这个词法块中被声明。在该循环中生成的所有函数值都共享相同的循环变量。需要注意,函数值中记录的是循环变量的内存地址,而不是循环变量某一时刻的值。\nvar rmdirs []func() for _, dir := range tempDirs() { os.MkdirAll(dir, 0755) rmdirs = append(rmdirs, func() { os.RemoveAll(dir) // NOTE: incorrect! }) } var rmdirs []func() for _, d := range tempDirs() { dir := d // NOTE: necessary! os.MkdirAll(dir, 0755) // creates parent directories too rmdirs = append(rmdirs, func() { os.RemoveAll(dir) }) } // ...do some work... for _, rmdir := range rmdirs { rmdir() // clean up } 不管你的method的receiver是指针类型还是非指针类型,都是可以通过指针/非指针类型进行调用的,编译器会帮你做类型转换。\n在声明一个method的receiver该是指针还是非指针类型时,你需要考虑两方面的内部,第一方面是这个对象本身是不是特别大,如果声明为非指针变量时,调用会产生一次拷贝;第二方面是如果你用指针类型作为receiver,那么你一定要注意,这种指针类型指向的始终是一块内存地址,就算你对其进行了拷贝。熟悉C或者C艹的人这里应该很快能明白。 实际上第一种，也就是不适用指针的话就是把对象拷贝一份找了一个临时对象，这个让人感觉很奇怪虽然 这里有一个问题，运算符重载，运算符是不是是一个函数\n这两天在用Golang写一个小工具，访问两个地址判断是否被block，需要将两个服务端的返回结果记录到不同的日志里面，glog经过调研可以拆分日志到不同文件，但是低等级日志会记录高等级的日志，这不符合我完全拆分的目的。因此只能使用logrus实现了，简单记录下代码。这里的代码大差不差，可能出现一些简单的编译错误，按照提示修改即可\nimport ( \u0026#34;os\u0026#34; log \u0026#34;github.com/sirupsen/logrus\u0026#34; ) // 自定义Hook结构 type FileHook struct { file *os.File LogLevels []log.Level } func (hook *FileHook) Fire(entry *log.Entry) error { line, err := entry.String() if err == nil { hook.file.WriteString(line) } return nil } // 实现Hook接口的Levels方法 func (hook *FileHook) Levels() []log.Level { return hook.LogLevels } func init_log() { // 创建不同级别的日志文件 infoLogFile, err := os.OpenFile(\u0026#34;common.log\u0026#34;, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666) if err != nil { log.Fatal(err) } // defer infoLogFile.Close() warningLogFile, err := os.OpenFile(\u0026#34;warning.log\u0026#34;, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666) if err != nil { log.Fatal(err) } // defer warningLogFile.Close() errorLogFile, err := os.OpenFile(\u0026#34;error.log\u0026#34;, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666) if err != nil { log.Fatal(err) } // defer errorLogFile.Close() // 设置日志格式为JSON格式 log.SetFormatter(\u0026amp;log.JSONFormatter{}) infoHook := \u0026amp;FileHook{ file: infoLogFile, LogLevels: []log.Level{ log.InfoLevel, }, } warningHook := \u0026amp;FileHook{ file: warningLogFile, LogLevels: []log.Level{ log.WarnLevel, }, } errorHook := \u0026amp;FileHook{ file: errorLogFile, LogLevels: []log.Level{ log.ErrorLevel, }, } // 添加Hook到logrus日志钩子 log.AddHook(infoHook) log.AddHook(warningHook) log.AddHook(errorHook) } func main() { init_log() log.Info(\u0026#34;info level\u0026#34;) log.Warn(\u0026#34;warning level\u0026#34;) log.Error(\u0026#34;Error level\u0026#34;) } 新抓RUST # 核心的理念\n所有权理念\nRust中的每个值都有一个被称为其所有者的变量(即：值的所有者是某个变量) 值在任一时刻有且只有一个所有者 当所有者(变量)离开作用域，这个值将被销毁 引用和所有权\n不可变借用：借用只读权，不允许修改其引用的数据 可变引用：借用可写权(包括可读权)，允许修改其引用的数据 多个不可变引用可共存(可同时读) 可变引用具有排他性，在有可变引用时，不允许存在该数据的其他可变和不可变引用 这样的说法不准确，短短几句话也无法描述清楚，因此留在后面再详细解释\n在当前作用域内，从第一次使用可变引用开始创建这把独占锁，之后无论使用原始变量(即所有权拥有者)、可变引用还是不可变引用都会抢占这把独占锁，以保证只有一方可以访问数据，每次抢得独占锁后，都会将之前所有引用变量给锁住，使它们变成不可用状态。当离开当前作用域时，当前作用域内的所有独占锁都被释放。\n因此，可变引用是抢占且排他的，将其称为抢占式独占锁更为合适。\n换个角度来理解，自从第一次使用可变引用导致独占锁出现后，可以随时使用原始变量、可变引用或不可变引用来抢独占锁，但抢锁后以前的引用变量就不能再用，且当前持有的锁也可以随时被抢走。一切都由程序员控制，程序员可以在任意代码位置通过原始变量或引用来抢锁。\n多线程（前置，宏和arc智能指针，clone，wrap，unwrap的含义）\n多线程 多线程屏障 线程的局部变量 Condition Variables Atomic原子锁与内存顺序 闭包和迭代器\n智能指针\nBox 特意的将数据分配在堆上\n数据较大时，又不想在转移所有权时进行数据拷贝\n类型的大小在编译期无法确定，但是我们又需要固定大小的类型时\n特征对象，用于说明对象实现了一个特征，而不是某个特定的类型\nrc \u0026amp; arc，两个都是只可读的，不能写 希望在堆上分配一个对象供程序的多个部分使用且无法确定哪个部分最后一个结束时，就可以使用 Rc 成为数据值的所有者。说起来RC 范型和特征\n范型：\n结构体范型 枚举范型 函数范型 范型特化 范型常数化 特征：特征看起来是一组呀\n特征定义与实现的位置（孤儿规则）。\n孤儿规则：如果你想要为类型 A 实现特征 T，那么 A 或者 T 至少有一个是在当前作用域中定义的！ 特征的默认实现： 特征可以作为函数参数：\n特征约束，实际上就是范型，它的语法糖为impl Summary，它的意思是 实现了Summary特征 的 item 参数。这样子一个函数就可以多种调用。多种约束同时存在，可以使用Where约束 函数返回时的impl Trait，用来返回使用了trait的某种类型，不过只能返回一种 derive派生列表 特征对象\n因为函数返回的impl Trait只能返回一种类型，那么如果有多种需要返回怎么办？使用特征对象指向实现了 特征的类型的实例，这种映射关系是存储在一张表中，可以在运行时通过特征对象找到具体调用的类型方法。 可以通过 \u0026amp; 引用或者 Box\u0026lt;T\u0026gt; 智能指针的方式来创建特征对象，即要么是\u0026amp; dyn Trait要么是 Box\u0026lt;dyn Trait\u0026gt;。这里有个dyn关键字：dyn 关键字只用在特征对象的类型声明上，在创建时无需使用 dyn 关联函数 +\n生命周期\n关于生命周期的详细分析，我个人觉得https://rust-book.junmajinlong.com/ch6/05_re_understand_move.html，这个更好理解一些 RUST的生命周期，生命周期语法用来将函数的多个引用参数和返回值的作用域关联到一起，一旦关联到一起后，Rust 就拥有充分的信息来确保我们的操作是内存安全的。标记的生命周期只是为了取悦编译器，让编译器不要难为我们，写程序的时候可能不会知道哪个生命周期比较久，编译器会报错。在通过函数签名指定生命周期参数时，我们并没有改变传入引用或者返回引用的真实生命周期，而是告诉编译器当不满足此约束条件时，就拒绝编译通过 函数的返回值如果是一个引用类型，那么它的生命周期只会来源于： 函数参数的生命周期 函数体中某个新建引用的生命周期 生命周期消除：函数或者方法中，参数的生命周期被称为 输入生命周期，返回值的生命周期被称为 输出生命周期 结构体的生命周期 三条消除规则 每一个引用参数都会获得独自的生命周期 若只有一个输入生命周期(函数参数中只有一个引用类型)，那么该生命周期会被赋给所有的输出生命周期，也就是所有返回值的生命周期都等于该输入生命周期 若存在多个输入生命周期，且其中一个是 \u0026amp;self 或 \u0026amp;mut self，则 \u0026amp;self 的生命周期被赋给所有的输出生命周期 RUST的引用\n同一时刻，你只能拥有要么一个可变引用, 要么任意多个不可变引用 引用必须总是有效的 数据结构\nRUST的字符串 rust的字符串分为两种， 一种是str，字符串的切片 另一种是string，这个实际上是真正的字符串 字符串字面量是切片，对于字符串而言，切片就是对 String 类型中某一部分的引用，可以理解为部分的字符串 字符串字面量是切片 元组： 结构体： 枚举 部分默认就会拷贝的类型 所有整数类型，比如 u32 布尔类型，bool，它的值是 true 和 false 所有浮点数类型，比如 f64 字符类型，char 元组，当且仅当其包含的类型也都是 Copy 的时候。比如，(i32, i32) 是 Copy 的，但 (i32, String) 就不是 不可变引用 \u0026amp;T ，例如转移所有权中的最后一个例子，但是注意: 可变引用 \u0026amp;mut T 是不可以 Copy的 模式匹配\n变量遮蔽无法理解 方法\n包和模块\n项目：Package 就是一个项目，因此它包含有独立的 Cargo.toml 文件，以及因为功能性被组织在一起的一个或多个包。一个 Package 只能包含一个库(library)类型的包，但是可以包含多个二进制可执行类型的包。 工作区间 包：对于 Rust 而言，包是一个独立的可编译单元，它编译后会生成一个可执行文件或者一个库。牢记 Package 是一个项目工程，而包只是一个编译单元 模块 僵硬的Centos7 # 说实在的，这都2024年了，还有一堆用Centos7的公司，天天稳定性如何如何，然后一堆基础库需要重新安装。。。。这里记录一下如何在Centos7安装基础库，包括Gcc，Openssl，Protobuf，Cmake，Git，Grpc，Zlog。\n安装Gcc 10\n说实在的，要是ubuntu我直接就推荐安装clang，直接clang 18一安装多省事。。。也就CentOS7有这种破事，接下来安装的是GCC10，因为GCC9的话安装Grpc的时候会有个编译器错误，这个错误在10做了修复，命令非常简单\nyum install -y http://mirror.centos.org/centos/7/extras/x86_64/Packages/centos-release-scl-rh-2-3.el7.centos.noarch.rpm\ryum install -y http://mirror.centos.org/centos/7/extras/x86_64/Packages/centos-release-scl-2-3.el7.centos.noarch.rpm\ryum install -y devtoolset-10-gcc-c++\recho \u0026#34;source /opt/rh/devtoolset-10/enable\u0026#34; \u0026gt;\u0026gt; /etc/bashrc\rsource /opt/rh/devtoolset-10/enable\r# 写入Dockerfile的内容\rRUN yum install -y http://mirror.centos.org/centos/7/extras/x86_64/Packages/centos-release-scl-rh-2-3.el7.centos.noarch.rpm\rRUN yum install -y http://mirror.centos.org/centos/7/extras/x86_64/Packages/centos-release-scl-2-3.el7.centos.noarch.rpm\rRUN yum install -y devtoolset-10-gcc-c++\rRUN echo \u0026#34;source /opt/rh/devtoolset-10/enable\u0026#34; \u0026gt;\u0026gt; /etc/bashrc\rSHELL [\u0026#34;/bin/bash\u0026#34;, \u0026#34;--login\u0026#34;, \u0026#34;-c\u0026#34;] 安装Openssl\ncd /root\rwget https://www.openssl.org/source/openssl-1.1.1t.tar.gz\rtar -xzvf openssl-1.1.1t.tar.gz\rcd openssl-1.1.1t\r./config\rmake -j 32\rmake install\rldconfig\r写入Dockerfile的内容\rRUN cd /root \u0026amp;\u0026amp; \\\rwget https://www.openssl.org/source/openssl-1.1.1t.tar.gz \u0026amp;\u0026amp; \\\rtar -xzvf openssl-1.1.1t.tar.gz \u0026amp;\u0026amp; \\\rcd openssl-1.1.1t \u0026amp;\u0026amp; \\\r./config \u0026amp;\u0026amp; \\\rmake -j 32 \u0026amp;\u0026amp; \\\rmake install \u0026amp;\u0026amp; \\\rldconfig 安装Cmake\ncd /root wget https://github.com/Kitware/CMake/releases/download/v3.29.3/cmake-3.29.3.tar.gz\rtar -xvf cmake-3.29.3.tar.gz\rcd cmake-3.29.3\r./bootstrap --prefix=/usr/ -- -DCMAKE_USE_OPENSSL=OFF\rmake -j 8\rmake install\rcmake --version\r# Dockerfile里面的内容\rRUN cd /root \u0026amp;\u0026amp; \\\rwget https://github.com/Kitware/CMake/releases/download/v3.29.3/cmake-3.29.3.tar.gz \u0026amp;\u0026amp; \\\rtar -xvf cmake-3.29.3.tar.gz \u0026amp;\u0026amp; \\\rcd cmake-3.29.3 \u0026amp;\u0026amp; \\\r./bootstrap --prefix=/usr/ -- -DCMAKE_USE_OPENSSL=OFF \u0026amp;\u0026amp; \\\rmake -j 8 \u0026amp;\u0026amp; \\\rmake install \u0026amp;\u0026amp; \\\rcmake --version 安装Git\ncd /root\rwget https://www.kernel.org/pub/software/scm/git/git-2.31.1.tar.gz\rtar xzf git-2.31.1.tar.gz\rcd git-2.31.1\rmake all\rmake prefix=/usr install\r# Dockerfile里面的内容\rRUN cd /root \u0026amp;\u0026amp; \\\rwget https://www.kernel.org/pub/software/scm/git/git-2.31.1.tar.gz \u0026amp;\u0026amp; \\\rtar xzf git-2.31.1.tar.gz \u0026amp;\u0026amp; \\\rcd git-2.31.1 \u0026amp;\u0026amp; \\\rmake all \u0026amp;\u0026amp; \\\rmake prefix=/usr install 安装Protobuf\ncd /root\rwget https://github.com/protocolbuffers/protobuf/releases/download/v3.19.4/protobuf-all-3.19.4.tar.gz\rtar -xzvf protobuf-all-3.19.4.tar.gz\rcd protobuf-3.19.4\r./configure -prefix=/usr/local/\rmake -j 32\rmake install\rRUN cd /root \u0026amp;\u0026amp; \\\rwget https://github.com/protocolbuffers/protobuf/releases/download/v3.19.4/protobuf-all-3.19.4.tar.gz \u0026amp;\u0026amp; \\\rtar -xzvf protobuf-all-3.19.4.tar.gz \u0026amp;\u0026amp; \\\rcd protobuf-3.19.4 \u0026amp;\u0026amp; \\\r./configure -prefix=/usr/local/ \u0026amp;\u0026amp; \\\rmake -j 32 \u0026amp;\u0026amp; \\\rmake install 安装Grpc，这里注意，如果安装了grpc就可以不安装protobuf了，库它都会安装\ncd /root\rgit clone --recurse-submodules -b v1.64.0 --depth 1 --shallow-submodules https://github.com/grpc/grpc\rcd grpc\rmkdir -p cmake/build\rpushd cmake/build\rcmake -DgRPC_INSTALL=ON -DgRPC_BUILD_TESTS=OFF -DCMAKE_INSTALL_PREFIX=/usr/local/ ../.. make -j 32\rmake install\r# Dockerfile\rRUN cd /root \u0026amp;\u0026amp; \\\rgit clone --recurse-submodules -b v1.64.0 --depth 1 --shallow-submodules https://github.com/grpc/grpc \u0026amp;\u0026amp; \\\rcd grpc \u0026amp;\u0026amp; \\\rmkdir -p cmake/build \u0026amp;\u0026amp; \\\rpushd cmake/build \u0026amp;\u0026amp; \\\rcmake -DgRPC_INSTALL=ON -DgRPC_BUILD_TESTS=OFF -DCMAKE_INSTALL_PREFIX=/usr/local/ ../.. \u0026amp;\u0026amp; \\\rmake -j 32 \u0026amp;\u0026amp; \\\rmake install 安装Zlog\ncd /root wget https://github.com/HardySimpson/zlog/archive/refs/tags/1.2.16.tar.gz\rtar -xvf 1.2.16.tar.gz\rcd zlog-1.2.16\rmake \u0026amp;\u0026amp; make install\rRUN cd /root \u0026amp;\u0026amp; \\\rwget https://github.com/HardySimpson/zlog/archive/refs/tags/1.2.16.tar.gz \u0026amp;\u0026amp; \\\rtar -xvf 1.2.16.tar.gz \u0026amp;\u0026amp; \\\rcd zlog-1.2.16 \u0026amp;\u0026amp; \\\rmake \u0026amp;\u0026amp; make install 结尾 # 唉，尴尬\n","date":"2021 年 5 月 11 日","externalUrl":null,"permalink":"/posts/2021-05-11-%E9%87%8D%E6%8A%93cpp/","section":"Posts","summary":"","title":"重抓CPP\u0026 新抓GO","type":"posts"},{"content":" 处世三书笔记 # 我个人将一个人的方面分为：\n理：事物运行的道理，这里不区分大的道理和小的道理。世界观，人生观也在内。方法论同样不外乎，不过我单独摘出来为法。 志（质）：品质，志向。这个和人的精气神息息相关，志和理是人与人相交往的基础。实际上志大大的影响一个人的其他四个方面。 趣：喜好的东西，放松的方式。骄奢淫逸这都算趣的范畴， 法：做事情的方法，具体做事情的道理，说白了就是方法论。这个东西分很多方面， 谋：考虑，谋划方案的深度和方法， 这五个方面并不是完全隔离，有的时候是你中有我，我中有你的。拿出来是为了能够更好的分析/理解人。\n读完了《菜根谭》其中有一些值得吸收的地方，主要是：\n从法的角度，菜根谭提出“解决问题应当下苦功夫，不要选择捷径，有具体的技能并不是什么值得骄傲的事情，但是肯下苦功夫研究，钻研才是一个人自我的超凡精神”。具体需要按照是不是需要接触人等角度，考虑“改变别人应当从容易出发，自己做事应当从难处触发。劝诫别人要从容易接受，理解的角度出发”等方面。 从谋的角度，菜根谭提出要“考虑全面，未胜时不可志骄。且多多思考，不要被现实场景所限制” 从趣的角度，菜根谭提出“趣不可过量，且不可过多沉溺其中，满足时考虑缺憾，自然心凉意冷” 1《菜根谭》笔记+书评 # 《菜根谭》这本书是掺杂了儒，道，佛三家的内容，可以说是五分道，四分儒，一分佛。道的想法主要集中在对于功名富贵，喜乐欢畅，淫邪欢爱都视为虚幻无偿的想法，认为本无荣辱之分，只是自身虚妄的想法；儒的想法主要集中在一些做事的方法，淡泊明志，待人以宽等等；佛的想法则诸如大千世界，一花一木，人心本无尘埃，如是有我等方面。当然宋代之后，儒释道融合，所以《菜根谭》可能看起来都各派观点都有融合。\n但是我并不喜欢这本书，因为书里面某些地方纯粹放屁，这不单纯是《菜根谭》的问题，中国很多古书都是两面皮，正面是大儒风采，宽厚淡然，使人如沐春风。背面则是恶人嘴脸，厚黑心辣，不但要人身死还要道消。毕竟孔子也干过这事情。再说就扯远了，接着说《菜根谭》。\n《菜根谭》这本书分为几个部分，分别是：修省，应酬，评议，闲适，概论。顾名思义分别是讲求怎么修省自身的道德；怎么和他人交往；怎么看待生活/富贵/权势/名望；如何自得其乐；以及对人生无常，时光流逝的些许感慨。总体来说，这本书重点关注道德层面和欲望层面的东西，劝人自省和通达的，我特别喜欢吃午饭的时候看，感觉像是吃的宫保鸡丁盖饭里面加了一颗小白菜，清新可口。\n我个人觉得菜根谭中这本书中值得学习的东西无非这么几个方面，都是做事情，解决问题的方法，缺乏看待世界的理和谋：\n慎独：这个就不多解释了，大家都明白是什么意思 谨慎为事：无论事情进展到何时，都要如履薄冰般小心，不要为山九仞，功亏一篑 解决问题应当下苦功夫，不要选择捷径，有具体的技能并不是什么值得骄傲的事情，但是肯下苦功夫研究，钻研才是一个人自我的超凡精神。 无论是与他人交往还是处事不宜过刚，方圆都有才是正道。但是在都阿谀奉承的场合适当地说些实话，也是必要的。 改变别人应当从容易出发，自己做事应当从难处触发。劝诫别人要从容易接受，理解的角度出发。 书中对于做事/谋事的角度值得学习，但是所谓道德的吹捧，修身养性就大可不必了，古代是万般皆下品惟有读书高，向着泥塑学习，终究成为他人摆布的木偶。而现代人应当以技为理，以科学的方法看待世界，实事求是地解决问题。再说了，古代还有举世皆浊我独清，不如隐居终南山，但毕竟现在哪有出世之地呢，更何况入世尚且没彻底，何谈出世呢？\n实际上《菜根谭》还是跳不出道德君子的范畴，一方面吹捧道德的重要，有了道德就名声自显，福气自来。但又贬弃追求口舌/富贵的方面。一方面提到了佛家的现我为假我，但转头又提现我不可放弃。此外，《菜根谭》事事以道德为先，其他均无视，体现了中国传统哲学修身不修技的观点。但是《菜根谭》只谈结果，不谈方法，空落了憾处。远不如《王阳明-心学》。这点是中国传统哲学的大特点：西方哲学重思辨和推理，中国哲学则尤抱琵琶半遮面，落成空中楼阁。\n此外，很搞笑的是，如果完整读下来，会觉得《菜根谭》的风格变化特别大，前面几章还在讲修身养性，到最后就一下子“千古风流，不过雨打风吹去了，从“有”一下子就去了“无”的范畴；前面还是名声不显、我独掌握真理，也淡然，后面倏忽就开始感叹，善于把握人生宇宙法则与真理的的高人又有多少人呢？从儒转道可以说是无缝衔接。当然书里面有一点我是赞同的：一个人如果本性清明纯真，饥来吃饭，困来入眠，生活自然朴素，根本就不需要参禅问道。而心地沉沦堕落之人，即使天天谈论佛经禅理，也只是在白白耗费自己的精力。这也是我看不起很多信佛之人的地方，无救人救世之宏愿，沉迷语言心灵的机锋，不为事，光为理。\n最后摘录一些写的不错的话语：\n优人傅粉调朱①，效妍丑于毫端②，俄而歌残场罢，妍丑何存？弈者争先竞后，较雌雄于指下③，俄而局散子收，雌雄安在？ 喜寂厌喧者，往往避人以求静，不知意在无人，便成我相①。心著于静②，便是动根，如何到得人我一空，动静两忘的境界？ 纷扰固溺志之场①，而枯寂亦槁心之地②。故学者当栖心玄默③，以宁吾真体④；亦当适志恬愉⑤，以养吾圆机⑥ 功夫自难处做去者，如逆风鼓棹①，才是一段真精神；学问自苦中得来者，似披沙获金②，才是一个真消息。 2 《鬼谷子》笔记+书评 # 鬼谷子是一本讲“法”，也就是具体如何做事情，揣摩人的书。我对这本书的评价比《菜根谭》要高，因为所谓讲“法”，比《菜根谭》讲“理”更透彻也更深刻，没有任何说教的意味。有的书籍比方说《鬼谷子七十二术》过于追求技法，导致术写死了，而鬼谷子原书只提到了具体的方针，因地制宜，因而《鬼谷子》原书更具备普适性和指导意义。\n综合来说，《鬼谷子》共分为下面的部分和内容：\n捭阖，实质上是一种看待方式，和他人交流的基本方法，共三个层面1捭阖的定义是什么2将事物的状态类比于“开合”3沟通的方法使用“开合”的手段。这章的内容是其他几章节的基础。 反应，本章主要谈的是如何获取事情的真相，方法不外乎三种：象比，使用比喻或者历史事件打探；反听，更换不同人的角度来审视；见微知著，从小事打探全局的真相 内 揵，本章讲解的实际上是交往之道，方法是：或结以道德， 或结以党友，或结以财货， 或结以采色。但无论何时都要力求自保，等待何时的时机。 飞 箝，本章讲解如何控制他人，方法是：夸赞别人使他得意忘形，从而抓住把柄一击致命。 揣 篇+摩 篇，两张讲解的是如何获得人内心真正的想法，明面为揣，暗面为摩，从明面获得内心想法的方法是：首先获取对方外在的些许实际情况，然后通过感情剧变时揣情”，“迂回揣情，即不通过他，通过他身旁的人”。从暗面获得内心想法的方法是：根据对象的不同，选择不同的方式：1以欲望相推动，有以平，有以正，有以喜，有以怒，有以名，有以行，有以廉，有以信，有以利，有以卑2以性格相推动，划分对方的性格种类。 权 篇，本章讲解的是游说劝服别人的手段，方法是分为两种：1根据对方的性格来劝诫，比方说德行高洁的人就应当以高洁事打动等等2 具体的语言类别：佞言、谀言、平言、戚言、静言，这五种言辞是特别需要使用的。佞言，揣度对方意欲而设置说辞，其目的是为了让对方觉得我们对他忠心耿耿，以缩短双方的心理距离；谀言，繁称文辞，为对方论点翻来覆去地寻找证据，从各方面加以论证，让对方觉得我们博学多识，为取得对方信任打下基础；平言，该讲则讲，该停则停，让对方觉得我们勇于决事，为对方听从我们的决策打下基础；戚言，以悲戚的言辞去说心中的话，博得对方同情，以取得信任；静言，自知自己不足，故意加以掩盖，反而责备他人的不足，以求得辩驳的胜利，让对方听从我们的决策。策士明白了这五种说辞的特征和目的，可以根据人主的情况，依据说辩的形势需要选择不同的种类，并依此特征去设置说辞，以达到不同的说辩目的。 谋 篇，本章的内容我非常喜欢，很有趣写的。方法为：1 根据参与者的关系和具体矛盾指定策略，如果想正名，就要让别人不正，放纵他。智慧要隐秘的使用，不能告知与人（听着是不是像阴谋诡计） 2 针对不同的人，使其发挥不同的作用，比方说仁人、勇士、智者、愚者、不肖者、贪者等不同的对象设计计谋，让计谋有明确的针对性和指向性。仁义的人看轻财物，不可以用物质利益来诱惑他，但是可使他献出财物；勇士看轻灾难，不可以用祸难使他感到恐惧，但是可使他到危险的地方解除祸患；智者通达事理，不可以用欺诈的手法来蒙骗他，但可以跟他讲道理，使他立功。这三种人才要各得其用。而愚蠢的人，容易受到蒙蔽，所以就蒙蔽他；不肖的人，容易使他感到害怕，就以可怕的结果威胁他；贪婪的人，容易受到引诱，就引诱他。 决 篇，这章主要是讲决断的，本指谋士替君主决断，但是可以拓展开谈，方法是：阳德、阴贼、信诚、蔽匿、平素。加之过去事情的参考，即可知道具体事情可不可为。 符 言，这章的内容一般人没用，所以我不写了。 中 经，这章的内容就不写解释了，很有趣，但是不是很光明正大：解仇斗郄、缀去术、却语术、摄心术、守义术 这本书最大的有点是不说教，就是一本工具书！但是方法又不是那种死方法，宽泛灵活，可以自由改变，埋下种子就可以自由应用了。任何想做事的人必须先知人，而所谓知人，不外乎通过手段，通过品质知人，因此每个人都是需要学习一些小“技巧”去探查他人的。实际上，你去看《战国策》，抗日战争，《三国演义》中简直处处是本书的体现，\n当然这本书最大的问题也是过于宽泛了，很多时候需要个人去揣摩，这本书建议和《孙子兵法》一起来看，会更加有趣。实际上这本书再结合“论迹不论心”等基本前提，就可以作为判定事物情况的指南了，妙啊。\n3 《像火箭科学家一样思考：将不可能变为可能》笔记+书评 # 第一章，拥抱不确定性：人们喜欢确定性，厌恶未知，人们在不确定性里面寻找确定性，在混乱搜寻秩序，我们尝试去控制，却不是理解。作为成年人，我们无法摆脱这种影响。我们相信（或假装相信）每个问题都有一个正确的答案，我们还相信这个正确答案已经被某个比我们聪明得多的人找到了。要承认我不懂，而不是我什么都懂\n你可以走过去，看看感觉如何，然后走回另一边，看看是否行不通。”你只要把门开着就行了。布兰森正是。寻找光明的最佳方式不是将不确定性拒之千里之外，而是直接落入它的怀抱之中。\n为了在高压力、高风险的情况下保持冷静，你真正需要的是知识……被迫直面失败的可能性，研究它，剖析它，梳理它的所有组成部分和后果，这种做法真的很管用。”\n知道风险是什么，采用“冗余”和“安全边际”\n第二章，第一性原理就是质疑一切：知识会扭曲我们的认识。流程是一种守旧的做法，它是为了应对过去的难题而制定出来的。如果我们把流程当作一份神圣的契约，不对其提出质疑，那它就会阻碍事物向前发展。随着时间的推移，过时的流程便阻塞了我们组织的大动脉。\n第一性原理是什么？系统性地怀疑你可能怀疑的一切事物，直到你获得无可置疑的真相”。避免类比，类比就是模仿\n时间质疑你心中的假设。针对每一个承诺、假设和预算项目，问问你自己：如果这不是真的，那又如何？我为什么要这样做？我能把它摒弃掉，或者用更好的事物取代它吗？\n反响思考：弗雷泽要求他们做以前从未做过的事：摧毁默克公司。弗雷泽让公司高管扮演默克主要竞争对手的角色，想一些能够让默克破产的点子。然后，他们又调换角色，重新做回默克公司的员工，制定出能够避免这些威胁的战略\n奥卡姆剃刀，指导原则：尽量简单。简单的事物也可以很强大，但不要把“简单”和“容易”混为一谈\n第三章，发挥想象力：依靠思想，构造思想实验，不一定非得实际做，先考虑合理性。\n保持好奇心，夺取考虑为什么，而不是被某种腐朽的官僚/管理限制。\n顽皮是一种故意暂时放宽规则的做法，以探索制定其他规则的可能性，只要假装自己是一个七岁的小孩，考虑一下问题就可以重拾好奇心。\n思想实验不是为了找到正确的答案，\n多做点无聊，无聊就会思考各种事情的联系。\n如果我们不花时间去思考，不停顿下来去理解和深思，就无法找到智慧或形成新的想法。最终，我们还是继续采用了首先进入脑海的解决方案或想法，而不是继续研究问题。但是，那些值得解决的问题是不会立即产生答案的。作家威廉·德雷谢维奇（WilliamDeresiewicz）说过：“首先进入脑海的想法永远不是最好的想法。最初的想法别人也能想到，它是我们经常听说的想法，往往属于传统思维。”\n多将不同的东西放在一起对比，即使是风马牛不相及的事情，也可以启发出更多的思路。\n不要做孤独天才，及时和不了解的人沟通，也能想到启发性的答案。\n第四章，挑战不可能：如果只看可以做的，那么永远也决定不了要做什么。需要发散思维，从一开始就采用发散思维之所以重要，还因为在创意形成的最初阶段，我们很难判断哪些东西有用，哪些东西无用。\n有一种方法可以激荡大脑并产生奇思妙想，即问自己一个问题：科幻小说是怎样解决这个难题的？科幻小说把我们\n反溯法要求我们心怀壮志，并采取可付诸实施的步骤。我们想象出自己的理想工作，并勾勒出一张实现目标的路线图。我们描绘出完美的产品，然后问自己：制造出这样的产品需要付出什么？\n亚马逊也对其产品采取了类似的反溯法。亚马逊员工为尚未问世的产品撰写内部新闻稿，每份新闻稿都起着思想实验的作用，这是关于突破性想法的初步设想\n围的世界不断变化，新闻稿中最初的产品细节可能有一个短暂的半衰期。这些过时的细节不应遮掩产品整体构思的光辉。换句话说，不要坚持死抠细节。\n第五章，重构问题，清晰定义问题，问题便解决了一半：每当我们熟悉一个难题，以为自己拥有正确答案时，就不再看到其他选项。这种倾向被称为“定势效应”（einstellungeffect）。学会质疑问题，但是怎么才能区分自己的问题是不是正确的问题呢？\n我们只是为了技术而追求技术，为了树木失去了森林，为了方法失去了目的，为了形式失去了功能。战略是实现某个目标的计划；相比之下，战术是为实施战略而采取的行动，要学会质疑自己是不是在做战术的东西，我的战略是什么？\n功能固着”指一种“反对以新方式解决问题的心理障碍”。怎么避免呢？1 组合游戏也能帮上忙。你可以观察物品在其他领域的用途，从中获取灵感 2 把功能与形式分离也是有帮助的，不要光看功能 3 反其道而行，德鲁里知道一个许多商业领袖都忽略了的秘密：容易摘的果子早就被人采摘完了。你无法通过抄袭来击败比你强大的竞争对手，但你可以做截然相反的事情来打败他们。\n第六章，反转的例子：在得到所有证据之前，千万不要推理，否则将会犯下严重错误。人们会在不知不觉中扭曲事实来适应理论，而不是用理论来适应事实。人们是固执的，事实不会扭转观点\n无论你有多聪明，费曼的格言都是适用的：“第一性原理是指你不能欺骗自己，而你恰恰是最容易被欺骗的人。”\n怎么解决呢？我改变自己遣词造句的方式，以反映出这种心理转变。在会议上，我不再说“我认为……”而是说“这篇论文假定……”。另一种方式就是为了确保你不会爱上单一假设，请多制造几个假设。当你拥有多个假设时，就会减少对它们的依赖感，且更难以迅速选定一种假设。\n初次之外，不要仅靠后视镜和侧视镜去观察那些肉眼可见的危险，你要问问自己：“我忽略了什么？”当你认为自己已经考虑过所有可能性时，要继续追问：“我还忽略了其他东西吗？”深思熟虑，反复转动脑袋，检查你的盲点。\n有了盲点和多种假设之后，需要做的事情是但是，每个否定的答案都能让我们更接近真理，它们比肯定的答案提供更多信息。只有尝试反驳而非确认我们最初的直觉，从而形成否定的结果，我们才能取得进步。只证明自己是正确的，毫无疑问让人快乐，但是离进步更远。我们的目标应该是找到正确的答案，而不是成为正确的答案。\n有了想法之后，驳斥别人的观点，不要采用“稻草人谬误”战术，而要采用“钢铁侠”战术。这种方法要求你找到并阐明对立观点的最强形式，而不是最弱形式。真理绝不会唾手可得，需要你付出勇气、谦卑的态度和决心，但这些努力都是非常值得的。\n第七章，实践与测试：我们进行测试的目的不是为了证明自己是错的，而是为了确认那些我们认为正确的事物。火箭科学用一个看似简单的原则给我们提供了一条向前推进的路线，那就是“即飞即测”原则。根据这条原则，地球上的实验必须尽可能模仿火箭的飞行环境。\n关于测试，客观往往是不一定真实的（有的时候只是测试的人觉得自己很真实，比方说iphone出世调研都觉得不会流行），模拟真实（不舒适的环境）\n第八章，失败比成功重要：我将揭示精英企业如何把失败融入其商业模式中，并营造一种环境，让员工们更愿意暴露自身错误，而不是掩藏过错。\n要快速学习，而不是快速失败\n你的目标应该是专注于自己能够控制的变量，即输入，而不是关注输出。你应该问自己：“什么问题导致了此次失败？”如果输入需要修正，那就修正它们。\n“失败由两部分组成。”皮克斯的前总裁艾德·卡特穆尔写道，“其中一部分是事件本身，随之而来的是失望、困惑和羞愧感；另一部分则是我们对事件的反应。”你可以奖励那些“聪明人的失败”行为，惩罚表现不佳的人。\n做到心理安全。\n失败是痛苦的，而自揭短处会加重痛苦。但若反其道而行之，用否认和回避的态度来面对失败，那事情会变得更糟。为了学习和成长，我们必须承认自己的失败，而不是庆祝失败。\n第九章，成功不一定是好的：成功就带来问题，将运气当作实力\n而保持谦逊态度的方法之一，就是关注那些未遂事故。\n有一种解决方法是在检验过程中，我们通过时间隧道到未来进行一场思想实验，假设项目已经失败，然后我们退后一步问自己：“哪里出了问题？”通过生动描绘灾难性的场面，我们找到潜在问题并决定如何避免问题发生。\n要知道，人们可能已经在小群体中说这些事情了。”泰勒说，“但他们可能不会大声、清晰或不经常说出来，通常是因为这些东西可能会给你贴上‘消极’或‘不忠心’的标签。”\n4 《学会提问》笔记+书评 # 《学会提问》这本书是我最近半年看过的最好的书\n如何进行强批判式思维，有一个常见的思考的框架\n首先找寻论题和结论是什么 论题是问题，就是引发论题就是引起对话或讨论的问题或争议，论题可以分为两种 描述性论题，描述现实世界，指关于各种对过去、现在或将来的描述准确与否的问题。常见形式音乐学习是不是有助于提高一个人的数学能力？导致家庭暴力的最常见的诱因是什么？服用帕罗西汀(Paxil)是不是治疗抑郁症的有效方法？ 规定性论题，规定性论题是指关于什么该做、什么不该做、什么是对、什么是错、什么是好、什么是坏的问题。 结论 寻找理由 所谓理由，就是用来支撑或证明结论的信念、隐喻和其他陈述。注意：理由是指我们相信某个结论的原因或原理。 找到无论是理由，证据还是结论里面模糊不清的词语 准确辨认出关键词或短语的确切含义，，是你在决定是否同意别人观点时的一个必要步骤。 批判性问题：哪些词语是模棱两可（有歧义）的？ 注意，这里模糊不单纯指形容词比方说大量，较少。还有名次，比方说税收是指什么税？ 要小心几点障碍 第一个障碍是你自认为理解的和写作者想表达的是同一个意思。 第二个障碍是认为词语只存在一个明显的定义。别忘了问自己：“这些词语或短语是否可能有不同的意思？” 识别并找到结论，论证，理由里面的描述性假设和价值观假设是什么 假设分为两种，价值观假设和描述性假设 价值观假设：价值观假设，是指一种想当然的看法，认为某些相互对立的价值观中的一个比另一个更重要。简单来说人们有自己的价值倾向(value priority)或者说价值偏好(value preference) 判定价值观假设的一个重要方法就是问一下这个问题：“为什么那个人如此看重他用作理由的特定后果或结果？” 描述性假设：所谓描述性假设，是指对这个世界过去、现在或未来是什么样的信念；而规定性假设或者说价值观假设，你应该还记得，是指对这个世界应该是什么样的信念。描述性假设就是一种关于世界过去、现在和将来是怎么样的没有明说的信念。 其一，在理由和结论之间，寻找理由要证明结论所必不可少的假设（连接假设）；其二，在理由中，寻找理由成立所必不可少的假设。 探寻上面找到的假设的合理性 不断思考结论和理由之间存在的鸿沟。不断思考：假设这些理由都成立，有没有可能这个结论仍然是错误的？比方说如果站在反对者角度思考，如果站在理论支持者角度是否可信 找寻论证的谬误（所谓谬误，就是论证中的欺骗手段，交流者有可能利用这个欺骗手段来说服你接受他的结论。），找到论证中的各种花招 人身攻击型谬误：指针对个人进行人身攻击，而不是直接反驳其提供的理由。比方说他是卖药的，那么肯定不会说是否靠谱 滑坡谬误：假设采取某种做法会引发一连串不可控的不利事件，而实际上有现成的程序可用来防止此类连锁事件的发生。 追求完美解决方案谬误：错误地认为如果尝试某种解决方案后还有遗留问题未解决，那么这种解决方案根本就不该采用。 诉诸公众谬误：试图通过引述很多人都持有这一观点，以证明某个断言有道理。错误地以为很多人支持的事就是可取的。比方说别人都这样子认为，那就可以这样子做，这是对的 诉诸可疑权威谬误：引用某一权威的话来证明结论，而该权威对这一论题并没有特别的专门知识。 诉诸感情谬误：使用带有强烈感情色彩的语言来分散读者或听众的注意力，让他们忽视相关的理由和证据。常被用来加以利用的情感有：恐惧、希望、爱国主义、怜悯和同情。 稻草人谬误：歪曲对方的观点，使其容易受到攻击，进而攻击事实上根本就不存在的观点。 虚假的两难选择谬误：在现实中存在两种以上的选择时，却假想只有两种选择 乱扣帽子谬误：错误地以为因为你给某个特定事件或行为起了个名字，所以你合理解释了这一事件。 粉饰谬误：使用模糊、引发人们强烈情感认同的描述品行的词语，使我们倾向于同意某件事而不去细查其理由。比方说“在即将到来的选举中，你迎来了为一位女性投票的良机，她代表了这个伟大国家的未来，她为实现民主长期奋斗，为捍卫国家利益不遗余力，她为追寻美国梦而当机立断、充满信心、勇往直前。这位女性充满爱心，为儿童福利出力，为环境保护奔走，为推动国家迈向和平、繁荣和自由而出谋划策。投古德哈特(Goodheart)一票就是投真理一票，投梦想一票，投常识一票。” 转移话题谬误：插入一个不相干的话题，以将人们的注意力从原来的论题上转移开，通过将注意力从当前的论证转移到另一个论题上以赢得论证。 循环论证谬误：在论证过程中假设自己的结论成立的论证。比方说：阅读传统教科书比阅读电子文本的学习效果要好得多，因为以教材的形式来展现各种材料非常有利于学习。 验证证据的有效性：验证个人经历、典型案例、当事人证言和专家陈述 个人经历：个人经历主要是以偏概全谬误：一个人仅根据群体中极小部分人的经历就得出有关整个群体的结论。 典型案例：典型案例常常很有说服力，因为它们如此具体生动而又情节感人，很容易在我们的脑海里产生画面。但典型案例也是以偏概全往往 当事人证言：当事人证言似乎可信，但是 选择的当事人是有选择的，那些没被选择的人怎么评价呢？ 是否有个人利益相关呢？或者说stakeholders？ 省略信息是什么？ 人的因素有哪些？ 专家陈述 验证证据的有效性：个人观察和调查数据是否有效 个人观察不可信，因为个人的观察视角往往是有限的 调查问卷是否可信也是存疑的：不要想当然认为调查问卷的回答能够真实地反映出回答者的态度。两个最重要的偏差是措辞偏差(biased wording)和语境偏差(biased context) 研究报告是否可信呢：科学研究是我们获得证据的一个优质的来源，因为科学研究强调可重复性、控制和精确性。后三者就是我们需要关注是否可信的。在一些结论中强求确定性，其实这些结论中虽然存在一定的不确定性，但并不足以否定这一结论。我们把这一论证错误称为“强求确定性谬误”(impossible certainty fallacy)。 考虑报告的资料来源的质量怎么样？通常情况下，最可靠的报告往往出自那些发表在由同行专家评定的期刊上的文章 除了资料来源的质量以外，报告中有没有其他线索显示这项研究完成得很出色 研究实施的时间距离现在有多久，有没有理由让人相信研究发现可能会随着时间的流逝而发生改变？很多研究发现会随着时间的流逝而发生改变 这项研究的发现有没有被其他研究重复过？ 立论者在选择研究的时候是否有选择性？ 有没有理由让人蓄意歪曲这项研究？我们要当心研究人员亟须找到特定结果的那些情况。 研究的条件是不是人工制造的并因此遭到扭曲 根据研究样本，我们概括的范围到底有多大？ 样本数量是否充足 样本广度是否充足 样本随机性是否充足 测试方法是否可信？比方说文字的调查问卷就可能不能真正反映被调查者的想法 验证证据的有效性：数据是否有欺骗性 因为数字让证据显得非常有科学性，非常精确，似乎它就代表了“事实”。但是，统计数据可能（而且经常会）撒谎！它们并不一定能证明它们想要证明的观点。 查询数据的来源和有效性，比方说40%好像很高，总共就10个人 小心平均值，是平均数？中数？还是众数？ 测量时候的方法是否可信？比方说在不同温度测量球的压力，自然不同 小心用实际上风马牛不相及的言论证明结论，一种例子是完全不相干，另一种常见例子是说增加很多，证据是当前很多 统筹思考：是不是有什么信息省略了 几乎每个你遇到的信息都有一个目的。换句话说，这个信息的组织结构是由别人精心挑选和呈现的，目的就是让它能影响你的思维方式。 要学会反面思考，思考 常见的反驳论证 有没有研究和所说的研究相冲突？ 反对的人会提供什么样的理由？ 有没有支持论证的对立面的例子、证词、备受尊敬的权威人士提供的观点或者类比被省略？ 当为特殊的预测技巧进行辩护时省略掉关于预测失败或者预测失误的信息 遗漏的或不完整的数字、图表、表格或者数据 用来获得事实的程序细节 论证中所说的“事实”的来源 省略的结果，不管是正面还是反面结果，是短期还是长期结果，是提倡的还是反对的结果 统筹思考，在论证的过程中，我们会发现有很多替代原因，从而得出结论是错误的 很多时候一个事情有很多原因，过于追求唯一原因是错误的。过度简化因果关系谬误：依赖并不足以解释整个事件的因果因素来解释一个事件，或者过分强调这些因素中的一个或多个因素的作用。 在你努力找到各种原因时，要警惕专家和你都具有的一个倾向——沉浸在“确认偏误”(confirmation bias)当中，只努力寻找并依赖和我们的信念相一致的证据。 混淆相关性和因果性。忽略共同原因谬误：未能认识到两件事之间之所以有联系，是因为第三种因素在起作用。实际上有四种解释可以使用 解释一：甲是乙的一个原因 解释二：乙是甲的一个原因 解释三：甲和乙有关系是因为第三种因素——丙 解释四：甲和乙相互影响 时间上发生了相后顺序，事后归因谬误：假设乙事件是由甲事件所引发的，仅仅因为乙在时间上紧随甲之后发生。 不要批评人，基本归因错误(fundamental attribution error)的影响，这种错误指我们在解释他人的行为时普遍高估了个人倾向的重要性而低估了环境因素的作用。 统筹思考，是否结论有可能有很多种？同一套理论可能推出很多理论 重大的问题很少能用简单的“是”或绝对的“不是”来回答。当人们习惯用非黑即白、非是即否、非对即错、非正即误式的方式来思考问题时，他们就是在使用二分式思维(dichotomous thinking)。这种情况下需要缩减为灰度思考方法 结论在什么时候是准确的？ 结论在什么地方是准确的？ 结论为什么或为了什么目的是准确的？ 5 《波士顿咨询工作法：精确发现问题》笔记+书评 # 结尾 # 唉，尴尬\n","date":"2021 年 4 月 14 日","externalUrl":null,"permalink":"/posts/2021-04-14-%E5%A4%84%E4%B8%96%E4%B8%89%E4%B9%A6%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"","title":"处世三书笔记.md","type":"posts"},{"content":" 2021-04-12-boringSSL研究笔记 # boringSSL是google处于方便目的自己实现的SSL库，和openssl的通配性相比，boringSSL主要是定制型比较好，这几天我就打算研究下boringSSL和openSSL的差别。先从基本的数据结构出发，一部分的数据结构不言自明，就不多赘述了。有一点需要注意，想学习源码必须熟悉RFC！很多基础知识不会过多赘述，就是RFC的内容。\nBORING SSL和OPENSSL相比较使用的参数，命令行的选项之类的东西都非常类似。\n我这片博客的第一部分是技术调研，用来确定企业内部TLS方面的部分信息，如果对你有帮助可以给我邮箱发个邮件说说是哪几点，这样子也算是起到了一些帮助。\n0 技术调研和总览 # 0.1 如何做技术调研 # 下面是记录的阅读的一部分技术调研的笔记。\n技术调研的目的是什么，需求是什么？泛需求？核心需求是什么 合理安排时间 调整心态 最终呈现的结果，可以分为以下几个方面：\n核心需求是什么？想做什么事情？（这一部分可以和具体TLS相关写代码的人聊聊） 从哪些渠道收集了哪些信息？ 做了哪些常识？ 如果找到了解决方案，那么此方案的前提条件，适用场景，会不会有潜在的问题。优缺点分析， 如何落地？如果使用具体的功能，需要注意哪些方面 具体到本次的调研，要考察\n具体技术的新不新，稳不稳定，容不容易维护 结果量化，从各个角度进行技术的量化 多搜集信息，类似的项目做了什么？它们的利弊有哪些？比较这些技术的相似和不同，他们的优缺点有哪些？ 具体的技术如何落地？ 具体到本次的调研，要关注：\n性能方面的优化手段，包括但不限于计算加速，复用优化 安全性方面的改进， 兼容性剪裁，我们需要做哪些操作才能提供兼容，并且提供灵活的使用方法 一些具体的手段：\nthroughtworks技术雷达 0.2 调研计划 # 0.2.1 调研对象和方法 # 调研对象：BoringSSL和OpenSSL，及部分使用BoringSSL的开源软件（gRPC，chromium)\n调研目的：调研BorringSSL基础库内做了哪些TLS的的功能性/安全性/性能方面的改造。\n期望的调研结果：给出适用场景/优缺点比较/实现难易程度比较/性能比较\n调研方法：1 调研BORGINSS L从2020年提交的PATCH，关注其中功能性方面的代码；2 BoringSSL文档中提供，而OpenSSL未提供的旧功能，尤其关注针对大规模环境下提交的功能；3 源代码剪裁，尤其是以gRPC为代表的软件所执行的代码剪裁。\n0.2.2 调研结果 # 调研结果从以下几个方面展示：\n安全方面：重点关注BorringSSL实现了哪些新的安全功能，改进了哪些曾经的部件（流程），对TLS的利用到哪种程度 标准化方面：即BorringSSL提取出哪些组件为标准模块参与到基本功能里 性能方面：性能方面主要为TLS握手性能的优化。需区分TLS1.3和TLS1.3之前的协议 兼容性方面：主要表现为功能剪裁，即BoringSSL相比较OpenSSL筛检了哪些基本功能。 0.2.2.1 安全方面 # 安全方面BoringSSL全力推进HPKE的使用\nHPKE，混合公钥加密方案，目前主要用于非对称环境下的一次一密通信方案。目前已有的使用方案为ECH，用于加密SNI信息，保证所有握手信息的安全性，绕过第三方监控等等。OpenSSL不支持该功能，而BoringSSL已经作为基本组件进入代码库。\nHPKE的解释和优缺点：混合公钥加密方案，目前主要用于非对称环境下的一次一密通信方案。目前已有的使用方案为ECH，用于加密SNI信息，保证所有握手信息的安全性，绕过第三方监控等等。HPKE的优点是，其安全性经过机构证明，和实施时编写的代码细节没有直接关系，且性能良好。其缺点在于客户端必须预先共享真正服务器（backend server)的证书/公钥等信息，增加了客户端负担。HPKE适用于大规模启用TLS握手环境。实现难度较大。\nAEAD取代过去的EncryptThenMac，使用AEAD替代过去加密和认证分离的储存机制。优点为安全和性能的兼顾，避免了程序员自己实现不安全的EThenC方案。缺点为目前已有的AEAD方案没有拆分开EThenC灵活，不能随意组合。OpenSSL提供了的AEAD接口，但是没有将AEAD作为一个通用模块参与到对敏感信息（如SESSION，Identity）的保护。\nAEAD的解释和优缺点：严格来说AEAD仍然是一种encrypt-then-authenticate的算法，但是AEAD的的认证过程和加密过程同时进行，而且无需特殊处理CBC加密块。因此AEAD需要较少的运算遍数，1遍（OCB，不常用），1.5遍（GCM，Poly1305），或2遍。这意味着AEAD比AES-CBC+HMAC的方案要快。单AEAD目前模式基本是固定的，没有拆分开的灵活。AEAD适用于任何敏感信息储存场景。实现难度较小。\nTrustToken/PMBToken，GOOGLE用于替代第三方COOKIE而提出的方案，除了提供者和提供者授权的对象能够鉴别Token携带者是否为用户（也可用于区分用户和robot），第三方均无法鉴别。该方案不属于标准方案，因此OpenSSL并不支持\nTrustToken的优缺点：GOOGLE用于替代第三方COOKIE而提出的方案，除了提供者和提供者授权的对象能够鉴别Token携带者是否为用户（也可用于区分用户和robot），第三方无法鉴别。优点为trusttoken提供了完全保密性，即使是redeemer认为token是可信的，也不能从token当中得出用户的具体身份。缺点是：trusttoken并不抗重放，不能确认用户是其声称的角色。（Trust Tokens are a way to convey trust in a user, not establish trust in a user.）且其具体的使用方法需要结合环境变化，实现难度较大。\nSSL_CTX_set_custom_verify证书校验异步操作，相比OpenSSL，BoringSSL单独将认证证书的流程拿出来从而提供更详细的认证控制。\nBoringSSL对于计算流程，身份验证流程，证书签名流程均留了开放接口方便用户进行自定义操作，方便用户将签名/验签等流程交付给自定义/异步的真实后端操作。由于是可选的操作，因此不存在明显的优缺点。\n0.2.2.2 标准化方面 # AEAD的标准化，目前已知覆盖了敏感信息存储（SESSION TICKET）。AEAD的优缺点已经阐述过，不再赘述。\nHKDF-EXPAND+HKDF-EXTRACT，逐渐替代过去的PRF。相比较而言BoringSSL内部已经开始大规模的使用HKDF替代过去的PRF流程，相比较而言，目前OPENSSL并没有使用HKDF替代过去的PRF。\nHKDF优缺点：HKDF是TLS1.3中特别提出的PRF，作为安全基本件参与到整个运算当中。优点为更安全：即先经过HKDF-EXTRACT从原始密钥材料中提取出来的部分信息，再HKDF-Expand为最终密钥材料，增加了利用原始密钥材料进行分析的难度。TLS1.2当中只使用了HKDF-Expand部分。缺点同样是不够灵活，其内部依赖HMAC。HKDF适用于任何密钥延生/产生场景，实现难度较小。\nSIPHASH，主要用于hash表的一种高速安全的伪随机码产生函数。BoringSSL，OpenSSL支持但是没有大规模使用\nSIPHASH的优缺点：SIPHASH于2012年设计，相比较传统的MAC算法，更高效且具备更高的理论安全（计算结果更为随机）。但SIPHASH本身并不是为MAC认证设计，因此用途相对单一，更适用于hashtable等使用场景。但由于hashtable一般内嵌于各种基础环境当中，因此使用SIPHASH改造底层代码会比较困难，实现难度较大。\nGREASE，是\u0026quot;Generate Random Extensions And Sustain Extensibility\u0026quot;的简称，目前依然处于DRAFT阶段。BoringSSL已经支持，但OpenSSL并未支持\nGREASE优缺点：GREASE用于测试服务器/客户端的TLS实现是否正确，并用于简单的测试。它之所以有效依赖一个简单的前提：TLS期望服务端/客户端会忽视它们不是别的选项（协议/CIPHER/拓展等等）。从本质来说，GREASE只是一种测试，不存在所谓优缺点的问题。\n0.2.2.3 性能方面 # 性能部分分为两个方面，一个是gRPC/GOOGLE开始大规模采用的性能优化方案，另一个是bssl和OpenSSL本身的性能对比，作为附录附加在最后。\n证书压缩，使用证书压缩功能降低长证书链下传输的数据长度。证书压缩主要针对长证书链，目前证书压缩的应用场景主要集中在QUIC协议，普通TLS并未大规模使用，因此未进行性能测试。\n证书压缩的优缺点：从理论来讲证书压缩只有优点没有缺点，但由于该标准刚刚成为正式RFC，尚未流行，支持的设备过少可能是该标准的缺点。实现难度较大。\nTLS1.3的大规模使用，使用TLS1.3降低时延消耗(一个RTT）。需要注意两点：1 tls的clienthello报文往往是跟随三次握手的末尾一同到达对端。2 cloudfire的服务器在国外，一个RTT的影响较大。\n协议版本号 被访问网站 共耗时（1000次） TLS1.2 www.cloudfire.com 435.7983s TLS1.3 www.cloudfire.com 231.5094s 使用复用模式降低握手性能消耗和时延，TLS1.3复用方案的选择，BorringSSL在TLS1.3才引入SESSION TICKET方案。通过[3]可知使用DH交换算法时，TLS1.3复用比TLS1.2复用快大约25%，使用ECDH-P-256, TLS 1.3复用快15%。\n理论上来说，复用减少至少一次签名，因此复用应当比完整握手的新建性能高30%以上。此外由于TLS1.3的SESSION TICKET免除了SESSION CACHE本地缓存争用的问题，服务端的新建性能会提高一部分，但这一部分耗时相比完整握手的两次非对称运算耗时，优化的力度难以衡量，需要测量确定。由于缺乏性能工具，所以使用估算手段计算性能。以下测量值均评估自我的主机，纯软算。\n复用方案 测试方法 新建性能（理论值） TLS1.3完整握手 Bssl speed测试结果估算(384) 173 TLS1.3复用握手 Bssl speed测试结果估算(384) 438 AEAD存储敏感信息时具备更好的性能。\n具体算法 操作对象 平均速度 AES256(CBC)+HMAC(SHA1) 16386字节数据 Did 32000 AES-256-CBC-SHA1 (16384 bytes) open operations in 1010359us (31671.9 ops/sec): 518.9 MB/s AEAD（AES256-GCM） 相同的16384字节数据 Did 253000 AES-256-GCM (16384 bytes) seal operations in 1000260us (252934.2 ops/sec): 4144.1 MB/s 前向安全，每次握手使用静态的公钥密钥对进行握手，降低计算非对称密钥的成本。有一点需要注意TLS1.3是必然提供前向安全的，该优化针对TLS1.3之前的协议。Google在ALTS中通过轮换密钥来保证过去的流量不会被破解。每次采用静态公私密钥对减少了椭圆曲线计算的性能消耗，理论上应该至少能有20%新建性能的提升。\n方案 操作对象 新建性能（理论值） 不提供前向安全 ECDH P384 286 前向安全 ECDH P384 173 ALPN，通信时延是性能消耗的主要来源，因此采用ALPN拓展协议能够在TLS协议协商过程当中直接确定上次协议的通信细节，避免再引入上层协议的通信延时。\nAPLN的优缺点：APLN从理论来讲不存在缺点，但是需要TLS和上层协议结合可能是其唯一缺点。\n0.2.2.4 兼容性方面 # 下表为具体的兼容性剪裁对比。\n功能剪裁 OPENSSL BORINGSSL（GRPC, CHROMIUM） TLS PROTOCOL TLS1.0-TLS1.3 TLS1_2, TLS1_3(GRPC和chromium都不支持TLS1.0/1.1，CHROME81即不再支持) 默认CIPHER TLS协议对应的所有协议 \u0026ldquo;TLS_AES_128_GCM_SHA256:\u0026rdquo; \u0026ldquo;TLS_AES_256_GCM_SHA384:\u0026quot; \u0026ldquo;TLS_CHACHA20_POLY1305_SHA256:\u0026quot; \u0026ldquo;ECDHE-ECDSA-AES128-GCM-SHA256:\u0026quot; \u0026ldquo;ECDHE-ECDSA-AES256-GCM-SHA384:\u0026quot; \u0026ldquo;ECDHE-RSA-AES128-GCM-SHA256:\u0026quot; \u0026ldquo;ECDHE-RSA-AES256-GCM-SHA384\u0026rdquo;, 签名算法 ecdsa_secp256r1_sha256 (0x0403)ecdsa_secp384r1_sha384 (0x0503)ecdsa_secp521r1_sha512 (0x0603)ed25519 (0x0807)ed448 (0x0808)rsa_pss_pss_sha256 (0x0809)rsa_pss_pss_sha384 (0x080a)rsa_pss_pss_sha512 (0x080b)rsa_pss_rsae_sha256 (0x0804)rsa_pss_rsae_sha384 (0x0805)rsa_pss_rsae_sha512 (0x0806)rsa_pkcs1_sha256 (0x0401)rsa_pkcs1_sha384 (0x0501)rsa_pkcs1_sha512 (0x0601)SHA224 ECDSA (0x0303)ecdsa_sha1 (0x0203)SHA224 RSA (0x0301)rsa_pkcs1_sha1 (0x0201)SHA224 DSA (0x0302)SHA1 DSA (0x0202)SHA256 DSA (0x0402)SHA384 DSA (0x0502)SHA512 DSA (0x0602) SSL_SIGN_ECDSA_SECP256R1_SHA256, SSL_SIGN_RSA_PSS_RSAE_SHA256, SSL_SIGN_RSA_PKCS1_SHA256, // Larger hashes are acceptable. SSL_SIGN_ECDSA_SECP384R1_SHA384, SSL_SIGN_RSA_PSS_RSAE_SHA384, SSL_SIGN_RSA_PKCS1_SHA384, SSL_SIGN_RSA_PSS_RSAE_SHA512, SSL_SIGN_RSA_PKCS1_SHA512, // For now, SHA-1 is still accepted but least preferable. SSL_SIGN_RSA_PKCS1_SHA1, 校验客户端证书支持的verify算法 和上面一致，都支持 SSL_SIGN_ED25519, SSL_SIGN_ECDSA_SECP256R1_SHA256, SSL_SIGN_RSA_PSS_RSAE_SHA256, SSL_SIGN_RSA_PKCS1_SHA256, // If needed, sign larger hashes. // // TODO(davidben): Determine which of these may be pruned. SSL_SIGN_ECDSA_SECP384R1_SHA384, SSL_SIGN_RSA_PSS_RSAE_SHA384, SSL_SIGN_RSA_PKCS1_SHA384, SSL_SIGN_ECDSA_SECP521R1_SHA512, SSL_SIGN_RSA_PSS_RSAE_SHA512, SSL_SIGN_RSA_PKCS1_SHA512, // If the peer supports nothing else, sign with SHA-1. SSL_SIGN_ECDSA_SHA1, SSL_SIGN_RSA_PKCS1_SHA1, 支持的曲线（groups） x25519 (0x001d)secp256r1 (0x0017)x448 (0x001e)secp521r1 (0x0019)secp384r1 (0x0018) {NID_secp224r1, \u0026ldquo;P-224\u0026rdquo;, \u0026ldquo;secp224r1\u0026rdquo;},{NID_X9_62_prime256v1, , \u0026ldquo;P-256\u0026rdquo;, \u0026ldquo;prime256v1\u0026rdquo;},{NID_secp384r1, \u0026ldquo;P-384\u0026rdquo;, \u0026ldquo;secp384r1\u0026rdquo;},{NID_secp521r1, \u0026ldquo;P-521\u0026rdquo;, \u0026ldquo;secp521r1\u0026rdquo;},{NID_X25519, \u0026ldquo;X25519\u0026rdquo;, \u0026ldquo;x25519\u0026rdquo;},{NID_CECPQ2, \u0026ldquo;CECPQ2\u0026rdquo;, \u0026ldquo;CECPQ2\u0026rdquo;}, SESSION TICKET复用 TLS1-TLS1.3都支持 仅TLS1.3支持 默认的证书校验方式 也是只校验服务端证书，不校验SNI GRPC_TLS_SERVER_VERIFICATION 校验证书和SNI必须匹配 1 连接相关的数据结构 # 1.1 cipher数据结构 # boringSSL取了cipher的通用name和具体的cipher id（和clienthello中保持一致），但是和openssl不一致的地方是boringSSL拆出来了通用属性，作为结构体里面的成员。可以看到，拆出来了秘钥交换算法，认证算法，对称加密算法，MAC算法，秘钥衍生算法。有一个很有趣的东西是SSLCipherPreferenceList，这个东西提供了prefertcert功能。头文件定义于internal.h文件，具体代码见下：\nstruct ssl_cipher_st { // name is the OpenSSL name for the cipher. const char *name; // standard_name is the IETF name for the cipher. const char *standard_name; // id is the cipher suite value bitwise OR-d with 0x03000000. uint32_t id; // algorithm_* determine the cipher suite. See constants below for the values. uint32_t algorithm_mkey; uint32_t algorithm_auth; uint32_t algorithm_enc; uint32_t algorithm_mac; uint32_t algorithm_prf; }; BSSL_NAMESPACE_BEGIN // Bits for |algorithm_mkey| (key exchange algorithm). #define SSL_kRSA 0x00000001u #define SSL_kECDHE 0x00000002u // SSL_kPSK is only set for plain PSK, not ECDHE_PSK. #define SSL_kPSK 0x00000004u #define SSL_kGENERIC 0x00000008u // Bits for |algorithm_auth| (server authentication). #define SSL_aRSA 0x00000001u #define SSL_aECDSA 0x00000002u // SSL_aPSK is set for both PSK and ECDHE_PSK. #define SSL_aPSK 0x00000004u #define SSL_aGENERIC 0x00000008u #define SSL_aCERT (SSL_aRSA | SSL_aECDSA) // Bits for |algorithm_enc| (symmetric encryption). #define SSL_3DES 0x00000001u #define SSL_AES128 0x00000002u #define SSL_AES256 0x00000004u #define SSL_AES128GCM 0x00000008u #define SSL_AES256GCM 0x00000010u #define SSL_eNULL 0x00000020u #define SSL_CHACHA20POLY1305 0x00000040u #define SSL_AES (SSL_AES128 | SSL_AES256 | SSL_AES128GCM | SSL_AES256GCM) // Bits for |algorithm_mac| (symmetric authentication). #define SSL_SHA1 0x00000001u // SSL_AEAD is set for all AEADs. #define SSL_AEAD 0x00000002u // Bits for |algorithm_prf| (handshake digest). #define SSL_HANDSHAKE_MAC_DEFAULT 0x1 #define SSL_HANDSHAKE_MAC_SHA256 0x2 #define SSL_HANDSHAKE_MAC_SHA384 0x4 // SSL_MAX_MD_SIZE is size of the largest hash function used in TLS, SHA-384. #define SSL_MAX_MD_SIZE 48 1.2 握手的基本数据结构 # 1.2.1 TLS连接结构 # 可以看出来SSL_HANDSHAKE结构和具体的握手状态是相关的，具体的握手状态在自动机里面才会用到，先不过于关注这几个东西。BoringSSL添加了一个SSL_CONFIG结构用于完成握手之后给后面连接保存必要的信息。 SSL并不是线程安全的，任何时刻只能有一个线程使用该数据结构。具体的配置可以直接对SSL_CTX结构或者世界对SSL结构配置。实际上这个东西就是我们关注的对象\nenum ssl_hs_wait_t { ssl_hs_error, ssl_hs_ok, ssl_hs_read_server_hello, ssl_hs_read_message, ssl_hs_flush, ssl_hs_certificate_selection_pending, ssl_hs_handoff, ssl_hs_handback, ssl_hs_x509_lookup, ssl_hs_channel_id_lookup, ssl_hs_private_key_operation, ssl_hs_pending_session, ssl_hs_pending_ticket, ssl_hs_early_return, ssl_hs_early_data_rejected, ssl_hs_read_end_of_early_data, ssl_hs_read_change_cipher_spec, ssl_hs_certificate_verify, }; enum ssl_grease_index_t { ssl_grease_cipher = 0, ssl_grease_group, ssl_grease_extension1, ssl_grease_extension2, ssl_grease_version, ssl_grease_ticket_extension, ssl_grease_last_index = ssl_grease_ticket_extension, }; enum tls12_server_hs_state_t { state12_start_accept = 0, state12_read_client_hello, state12_read_client_hello_after_ech, state12_select_certificate, state12_tls13, state12_select_parameters, state12_send_server_hello, state12_send_server_certificate, state12_send_server_key_exchange, state12_send_server_hello_done, state12_read_client_certificate, state12_verify_client_certificate, state12_read_client_key_exchange, state12_read_client_certificate_verify, state12_read_change_cipher_spec, state12_process_change_cipher_spec, state12_read_next_proto, state12_read_channel_id, state12_read_client_finished, state12_send_server_finished, state12_finish_server_handshake, state12_done, }; enum tls13_server_hs_state_t { state13_select_parameters = 0, state13_select_session, state13_send_hello_retry_request, state13_read_second_client_hello, state13_send_server_hello, state13_send_server_certificate_verify, state13_send_server_finished, state13_send_half_rtt_ticket, state13_read_second_client_flight, state13_process_end_of_early_data, state13_read_client_encrypted_extensions, state13_read_client_certificate, state13_read_client_certificate_verify, state13_read_channel_id, state13_read_client_finished, state13_send_new_session_ticket, state13_done, }; // handback_t lists the points in the state machine where a handback can occur. // These are the different points at which key material is no longer needed. enum handback_t { handback_after_session_resumption = 0, handback_after_ecdhe = 1, handback_after_handshake = 2, handback_tls13 = 3, handback_max_value = handback_tls13, }; struct SSL_HANDSHAKE { explicit SSL_HANDSHAKE(SSL *ssl); ~SSL_HANDSHAKE(); static constexpr bool kAllowUniquePtr = true; // ssl is a non-owning pointer to the parent |SSL| object. SSL *ssl; // config is a non-owning pointer to the handshake configuration. SSL_CONFIG *config; // wait contains the operation the handshake is currently blocking on or // |ssl_hs_ok| if none. enum ssl_hs_wait_t wait = ssl_hs_ok; // state is the internal state for the TLS 1.2 and below handshake. Its // values depend on |do_handshake| but the starting state is always zero. int state = 0; // tls13_state is the internal state for the TLS 1.3 handshake. Its values // depend on |do_handshake| but the starting state is always zero. int tls13_state = 0; // min_version is the minimum accepted protocol version, taking account both // |SSL_OP_NO_*| and |SSL_CTX_set_min_proto_version| APIs. uint16_t min_version = 0; // max_version is the maximum accepted protocol version, taking account both // |SSL_OP_NO_*| and |SSL_CTX_set_max_proto_version| APIs. uint16_t max_version = 0; private: size_t hash_len_ = 0; uint8_t secret_[SSL_MAX_MD_SIZE] = {0}; uint8_t early_traffic_secret_[SSL_MAX_MD_SIZE] = {0}; uint8_t client_handshake_secret_[SSL_MAX_MD_SIZE] = {0}; uint8_t server_handshake_secret_[SSL_MAX_MD_SIZE] = {0}; uint8_t client_traffic_secret_0_[SSL_MAX_MD_SIZE] = {0}; uint8_t server_traffic_secret_0_[SSL_MAX_MD_SIZE] = {0}; uint8_t expected_client_finished_[SSL_MAX_MD_SIZE] = {0}; public: void ResizeSecrets(size_t hash_len); // GetClientHello, on the server, returns either the normal ClientHello // message or the ClientHelloInner if it has been serialized to // |ech_client_hello_buf|. This function should only be called when the // current message is a ClientHello. It returns true on success and false on // error. // // Note that fields of the returned |out_msg| and |out_client_hello| point // into a handshake-owned buffer, so their lifetimes should not exceed this // SSL_HANDSHAKE. bool GetClientHello(SSLMessage *out_msg, SSL_CLIENT_HELLO *out_client_hello); Span\u0026lt;uint8_t\u0026gt; secret() { return MakeSpan(secret_, hash_len_); } Span\u0026lt;uint8_t\u0026gt; early_traffic_secret() { return MakeSpan(early_traffic_secret_, hash_len_); } Span\u0026lt;uint8_t\u0026gt; client_handshake_secret() { return MakeSpan(client_handshake_secret_, hash_len_); } Span\u0026lt;uint8_t\u0026gt; server_handshake_secret() { return MakeSpan(server_handshake_secret_, hash_len_); } Span\u0026lt;uint8_t\u0026gt; client_traffic_secret_0() { return MakeSpan(client_traffic_secret_0_, hash_len_); } Span\u0026lt;uint8_t\u0026gt; server_traffic_secret_0() { return MakeSpan(server_traffic_secret_0_, hash_len_); } Span\u0026lt;uint8_t\u0026gt; expected_client_finished() { return MakeSpan(expected_client_finished_, hash_len_); } union { // sent is a bitset where the bits correspond to elements of kExtensions // in t1_lib.c. Each bit is set if that extension was sent in a // ClientHello. It\u0026#39;s not used by servers. uint32_t sent = 0; // received is a bitset, like |sent|, but is used by servers to record // which extensions were received from a client. uint32_t received; } extensions; // retry_group is the group ID selected by the server in HelloRetryRequest in // TLS 1.3. uint16_t retry_group = 0; // error, if |wait| is |ssl_hs_error|, is the error the handshake failed on. UniquePtr\u0026lt;ERR_SAVE_STATE\u0026gt; error; // key_shares are the current key exchange instances. The second is only used // as a client if we believe that we should offer two key shares in a // ClientHello. UniquePtr\u0026lt;SSLKeyShare\u0026gt; key_shares[2]; // transcript is the current handshake transcript. SSLTranscript transcript; // cookie is the value of the cookie received from the server, if any. Array\u0026lt;uint8_t\u0026gt; cookie; // ech_grease contains the bytes of the GREASE ECH extension that was sent in // the first ClientHello. Array\u0026lt;uint8_t\u0026gt; ech_grease; // ech_client_hello_buf, on the server, contains the bytes of the // reconstructed ClientHelloInner message. Array\u0026lt;uint8_t\u0026gt; ech_client_hello_buf; // key_share_bytes is the value of the previously sent KeyShare extension by // the client in TLS 1.3. Array\u0026lt;uint8_t\u0026gt; key_share_bytes; // ecdh_public_key, for servers, is the key share to be sent to the client in // TLS 1.3. Array\u0026lt;uint8_t\u0026gt; ecdh_public_key; // peer_sigalgs are the signature algorithms that the peer supports. These are // taken from the contents of the signature algorithms extension for a server // or from the CertificateRequest for a client. Array\u0026lt;uint16_t\u0026gt; peer_sigalgs; // peer_supported_group_list contains the supported group IDs advertised by // the peer. This is only set on the server\u0026#39;s end. The server does not // advertise this extension to the client. Array\u0026lt;uint16_t\u0026gt; peer_supported_group_list; // peer_delegated_credential_sigalgs are the signature algorithms the peer // supports with delegated credentials. Array\u0026lt;uint16_t\u0026gt; peer_delegated_credential_sigalgs; // peer_key is the peer\u0026#39;s ECDH key for a TLS 1.2 client. Array\u0026lt;uint8_t\u0026gt; peer_key; // negotiated_token_binding_version is used by a server to store the // on-the-wire encoding of the Token Binding protocol version to advertise in // the ServerHello/EncryptedExtensions if the Token Binding extension is to be // sent. uint16_t negotiated_token_binding_version; // cert_compression_alg_id, for a server, contains the negotiated certificate // compression algorithm for this client. It is only valid if // |cert_compression_negotiated| is true. uint16_t cert_compression_alg_id; // ech_hpke_ctx, on the server, is the HPKE context used to decrypt the // client\u0026#39;s ECH payloads. ScopedEVP_HPKE_CTX ech_hpke_ctx; // server_params, in a TLS 1.2 server, stores the ServerKeyExchange // parameters. It has client and server randoms prepended for signing // convenience. Array\u0026lt;uint8_t\u0026gt; server_params; // peer_psk_identity_hint, on the client, is the psk_identity_hint sent by the // server when using a TLS 1.2 PSK key exchange. UniquePtr\u0026lt;char\u0026gt; peer_psk_identity_hint; // ca_names, on the client, contains the list of CAs received in a // CertificateRequest message. UniquePtr\u0026lt;STACK_OF(CRYPTO_BUFFER)\u0026gt; ca_names; // cached_x509_ca_names contains a cache of parsed versions of the elements of // |ca_names|. This pointer is left non-owning so only // |ssl_crypto_x509_method| needs to link against crypto/x509. STACK_OF(X509_NAME) *cached_x509_ca_names = nullptr; // certificate_types, on the client, contains the set of certificate types // received in a CertificateRequest message. Array\u0026lt;uint8_t\u0026gt; certificate_types; // local_pubkey is the public key we are authenticating as. UniquePtr\u0026lt;EVP_PKEY\u0026gt; local_pubkey; // peer_pubkey is the public key parsed from the peer\u0026#39;s leaf certificate. UniquePtr\u0026lt;EVP_PKEY\u0026gt; peer_pubkey; // new_session is the new mutable session being established by the current // handshake. It should not be cached. UniquePtr\u0026lt;SSL_SESSION\u0026gt; new_session; // early_session is the session corresponding to the current 0-RTT state on // the client if |in_early_data| is true. UniquePtr\u0026lt;SSL_SESSION\u0026gt; early_session; // ech_server_config_list, for servers, is the list of ECHConfig values that // were valid when the server received the first ClientHello. Its value will // not change when the config list on |SSL_CTX| is updated. UniquePtr\u0026lt;SSL_ECH_SERVER_CONFIG_LIST\u0026gt; ech_server_config_list; // new_cipher is the cipher being negotiated in this handshake. const SSL_CIPHER *new_cipher = nullptr; // key_block is the record-layer key block for TLS 1.2 and earlier. Array\u0026lt;uint8_t\u0026gt; key_block; // ech_accept, on the server, indicates whether the server should overwrite // part of ServerHello.random with the ECH accept_confirmation value. bool ech_accept : 1; // ech_present, on the server, indicates whether the ClientHello contained an // encrypted_client_hello extension. bool ech_present : 1; // ech_is_inner_present, on the server, indicates whether the ClientHello // contained an ech_is_inner extension. bool ech_is_inner_present : 1; // scts_requested is true if the SCT extension is in the ClientHello. bool scts_requested : 1; // needs_psk_binder is true if the ClientHello has a placeholder PSK binder to // be filled in. bool needs_psk_binder : 1; // handshake_finalized is true once the handshake has completed, at which // point accessors should use the established state. bool handshake_finalized : 1; // accept_psk_mode stores whether the client\u0026#39;s PSK mode is compatible with our // preferences. bool accept_psk_mode : 1; // cert_request is true if a client certificate was requested. bool cert_request : 1; // certificate_status_expected is true if OCSP stapling was negotiated and the // server is expected to send a CertificateStatus message. (This is used on // both the client and server sides.) bool certificate_status_expected : 1; // ocsp_stapling_requested is true if a client requested OCSP stapling. bool ocsp_stapling_requested : 1; // delegated_credential_requested is true if the peer indicated support for // the delegated credential extension. bool delegated_credential_requested : 1; // should_ack_sni is used by a server and indicates that the SNI extension // should be echoed in the ServerHello. bool should_ack_sni : 1; // in_false_start is true if there is a pending client handshake in False // Start. The client may write data at this point. bool in_false_start : 1; // in_early_data is true if there is a pending handshake that has progressed // enough to send and receive early data. bool in_early_data : 1; // early_data_offered is true if the client sent the early_data extension. bool early_data_offered : 1; // can_early_read is true if application data may be read at this point in the // handshake. bool can_early_read : 1; // can_early_write is true if application data may be written at this point in // the handshake. bool can_early_write : 1; // next_proto_neg_seen is one of NPN was negotiated. bool next_proto_neg_seen : 1; // ticket_expected is true if a TLS 1.2 NewSessionTicket message is to be sent // or received. bool ticket_expected : 1; // extended_master_secret is true if the extended master secret extension is // negotiated in this handshake. bool extended_master_secret : 1; // pending_private_key_op is true if there is a pending private key operation // in progress. bool pending_private_key_op : 1; // grease_seeded is true if |grease_seed| has been initialized. bool grease_seeded : 1; // handback indicates that a server should pause the handshake after // finishing operations that require private key material, in such a way that // |SSL_get_error| returns |SSL_ERROR_HANDBACK|. It is set by // |SSL_apply_handoff|. bool handback : 1; // cert_compression_negotiated is true iff |cert_compression_alg_id| is valid. bool cert_compression_negotiated : 1; // apply_jdk11_workaround is true if the peer is probably a JDK 11 client // which implemented TLS 1.3 incorrectly. bool apply_jdk11_workaround : 1; // client_version is the value sent or received in the ClientHello version. uint16_t client_version = 0; // early_data_read is the amount of early data that has been read by the // record layer. uint16_t early_data_read = 0; // early_data_written is the amount of early data that has been written by the // record layer. uint16_t early_data_written = 0; // session_id is the session ID in the ClientHello. uint8_t session_id[SSL_MAX_SSL_SESSION_ID_LENGTH] = {0}; uint8_t session_id_len = 0; // grease_seed is the entropy for GREASE values. It is valid if // |grease_seeded| is true. uint8_t grease_seed[ssl_grease_last_index + 1] = {0}; }; 1.2.2 SSL握手模板结构 # 握手模板结构是原始握手的模板，通过跟这个协商产生具体的握手协议。 SSL_CTX 结构是线程安全的。\nstruct ssl_ctx_st { explicit ssl_ctx_st(const SSL_METHOD *ssl_method); ssl_ctx_st(const ssl_ctx_st \u0026amp;) = delete; ssl_ctx_st \u0026amp;operator=(const ssl_ctx_st \u0026amp;) = delete; const bssl::SSL_PROTOCOL_METHOD *method = nullptr; const bssl::SSL_X509_METHOD *x509_method = nullptr; // lock is used to protect various operations on this object. CRYPTO_MUTEX lock; // conf_max_version is the maximum acceptable protocol version configured by // |SSL_CTX_set_max_proto_version|. Note this version is normalized in DTLS // and is further constrainted by |SSL_OP_NO_*|. uint16_t conf_max_version = 0; // conf_min_version is the minimum acceptable protocol version configured by // |SSL_CTX_set_min_proto_version|. Note this version is normalized in DTLS // and is further constrainted by |SSL_OP_NO_*|. uint16_t conf_min_version = 0; // quic_method is the method table corresponding to the QUIC hooks. const SSL_QUIC_METHOD *quic_method = nullptr; bssl::UniquePtr\u0026lt;bssl::SSLCipherPreferenceList\u0026gt; cipher_list; X509_STORE *cert_store = nullptr; LHASH_OF(SSL_SESSION) *sessions = nullptr; // Most session-ids that will be cached, default is // SSL_SESSION_CACHE_MAX_SIZE_DEFAULT. 0 is unlimited. unsigned long session_cache_size = SSL_SESSION_CACHE_MAX_SIZE_DEFAULT; SSL_SESSION *session_cache_head = nullptr; SSL_SESSION *session_cache_tail = nullptr; // handshakes_since_cache_flush is the number of successful handshakes since // the last cache flush. int handshakes_since_cache_flush = 0; // This can have one of 2 values, ored together, // SSL_SESS_CACHE_CLIENT, // SSL_SESS_CACHE_SERVER, // Default is SSL_SESSION_CACHE_SERVER, which means only // SSL_accept which cache SSL_SESSIONS. int session_cache_mode = SSL_SESS_CACHE_SERVER; // session_timeout is the default lifetime for new sessions in TLS 1.2 and // earlier, in seconds. uint32_t session_timeout = SSL_DEFAULT_SESSION_TIMEOUT; // session_psk_dhe_timeout is the default lifetime for new sessions in TLS // 1.3, in seconds. uint32_t session_psk_dhe_timeout = SSL_DEFAULT_SESSION_PSK_DHE_TIMEOUT; // If this callback is not null, it will be called each time a session id is // added to the cache. If this function returns 1, it means that the // callback will do a SSL_SESSION_free() when it has finished using it. // Otherwise, on 0, it means the callback has finished with it. If // remove_session_cb is not null, it will be called when a session-id is // removed from the cache. After the call, OpenSSL will SSL_SESSION_free() // it. int (*new_session_cb)(SSL *ssl, SSL_SESSION *sess) = nullptr; void (*remove_session_cb)(SSL_CTX *ctx, SSL_SESSION *sess) = nullptr; SSL_SESSION *(*get_session_cb)(SSL *ssl, const uint8_t *data, int len, int *copy) = nullptr; CRYPTO_refcount_t references = 1; // if defined, these override the X509_verify_cert() calls int (*app_verify_callback)(X509_STORE_CTX *store_ctx, void *arg) = nullptr; void *app_verify_arg = nullptr; ssl_verify_result_t (*custom_verify_callback)(SSL *ssl, uint8_t *out_alert) = nullptr; // Default password callback. pem_password_cb *default_passwd_callback = nullptr; // Default password callback user data. void *default_passwd_callback_userdata = nullptr; // get client cert callback int (*client_cert_cb)(SSL *ssl, X509 **out_x509, EVP_PKEY **out_pkey) = nullptr; // get channel id callback void (*channel_id_cb)(SSL *ssl, EVP_PKEY **out_pkey) = nullptr; CRYPTO_EX_DATA ex_data; // Default values used when no per-SSL value is defined follow void (*info_callback)(const SSL *ssl, int type, int value) = nullptr; // what we put in client cert requests bssl::UniquePtr\u0026lt;STACK_OF(CRYPTO_BUFFER)\u0026gt; client_CA; // cached_x509_client_CA is a cache of parsed versions of the elements of // |client_CA|. STACK_OF(X509_NAME) *cached_x509_client_CA = nullptr; // Default values to use in SSL structures follow (these are copied by // SSL_new) uint32_t options = 0; // Disable the auto-chaining feature by default. wpa_supplicant relies on this // feature, but require callers opt into it. uint32_t mode = SSL_MODE_NO_AUTO_CHAIN; uint32_t max_cert_list = SSL_MAX_CERT_LIST_DEFAULT; bssl::UniquePtr\u0026lt;bssl::CERT\u0026gt; cert; // callback that allows applications to peek at protocol messages void (*msg_callback)(int write_p, int version, int content_type, const void *buf, size_t len, SSL *ssl, void *arg) = nullptr; void *msg_callback_arg = nullptr; int verify_mode = SSL_VERIFY_NONE; int (*default_verify_callback)(int ok, X509_STORE_CTX *ctx) = nullptr; // called \u0026#39;verify_callback\u0026#39; in the SSL X509_VERIFY_PARAM *param = nullptr; // select_certificate_cb is called before most ClientHello processing and // before the decision whether to resume a session is made. See // |ssl_select_cert_result_t| for details of the return values. ssl_select_cert_result_t (*select_certificate_cb)(const SSL_CLIENT_HELLO *) = nullptr; // dos_protection_cb is called once the resumption decision for a ClientHello // has been made. It returns one to continue the handshake or zero to // abort. int (*dos_protection_cb)(const SSL_CLIENT_HELLO *) = nullptr; // Controls whether to verify certificates when resuming connections. They // were already verified when the connection was first made, so the default is // false. For now, this is only respected on clients, not servers. bool reverify_on_resume = false; // Maximum amount of data to send in one fragment. actual record size can be // more than this due to padding and MAC overheads. uint16_t max_send_fragment = SSL3_RT_MAX_PLAIN_LENGTH; // TLS extensions servername callback int (*servername_callback)(SSL *, int *, void *) = nullptr; void *servername_arg = nullptr; // RFC 4507 session ticket keys. |ticket_key_current| may be NULL before the // first handshake and |ticket_key_prev| may be NULL at any time. // Automatically generated ticket keys are rotated as needed at handshake // time. Hence, all access must be synchronized through |lock|. bssl::UniquePtr\u0026lt;bssl::TicketKey\u0026gt; ticket_key_current; bssl::UniquePtr\u0026lt;bssl::TicketKey\u0026gt; ticket_key_prev; // Callback to support customisation of ticket key setting int (*ticket_key_cb)(SSL *ssl, uint8_t *name, uint8_t *iv, EVP_CIPHER_CTX *ectx, HMAC_CTX *hctx, int enc) = nullptr; // Server-only: psk_identity_hint is the default identity hint to send in // PSK-based key exchanges. bssl::UniquePtr\u0026lt;char\u0026gt; psk_identity_hint; unsigned (*psk_client_callback)(SSL *ssl, const char *hint, char *identity, unsigned max_identity_len, uint8_t *psk, unsigned max_psk_len) = nullptr; unsigned (*psk_server_callback)(SSL *ssl, const char *identity, uint8_t *psk, unsigned max_psk_len) = nullptr; // Next protocol negotiation information // (for experimental NPN extension). // For a server, this contains a callback function by which the set of // advertised protocols can be provided. int (*next_protos_advertised_cb)(SSL *ssl, const uint8_t **out, unsigned *out_len, void *arg) = nullptr; void *next_protos_advertised_cb_arg = nullptr; // For a client, this contains a callback function that selects the // next protocol from the list provided by the server. int (*next_proto_select_cb)(SSL *ssl, uint8_t **out, uint8_t *out_len, const uint8_t *in, unsigned in_len, void *arg) = nullptr; void *next_proto_select_cb_arg = nullptr; // ALPN information // (we are in the process of transitioning from NPN to ALPN.) // For a server, this contains a callback function that allows the // server to select the protocol for the connection. // out: on successful return, this must point to the raw protocol // name (without the length prefix). // outlen: on successful return, this contains the length of |*out|. // in: points to the client\u0026#39;s list of supported protocols in // wire-format. // inlen: the length of |in|. int (*alpn_select_cb)(SSL *ssl, const uint8_t **out, uint8_t *out_len, const uint8_t *in, unsigned in_len, void *arg) = nullptr; void *alpn_select_cb_arg = nullptr; // For a client, this contains the list of supported protocols in wire // format. bssl::Array\u0026lt;uint8_t\u0026gt; alpn_client_proto_list; // SRTP profiles we are willing to do from RFC 5764 bssl::UniquePtr\u0026lt;STACK_OF(SRTP_PROTECTION_PROFILE)\u0026gt; srtp_profiles; // Defined compression algorithms for certificates. bssl::GrowableArray\u0026lt;bssl::CertCompressionAlg\u0026gt; cert_compression_algs; // Supported group values inherited by SSL structure bssl::Array\u0026lt;uint16_t\u0026gt; supported_group_list; // The client\u0026#39;s Channel ID private key. bssl::UniquePtr\u0026lt;EVP_PKEY\u0026gt; channel_id_private; // ech_server_config_list contains the server\u0026#39;s list of ECHConfig values and // associated private keys. This list may be swapped out at any time, so all // access must be synchronized through |lock|. bssl::UniquePtr\u0026lt;SSL_ECH_SERVER_CONFIG_LIST\u0026gt; ech_server_config_list; // keylog_callback, if not NULL, is the key logging callback. See // |SSL_CTX_set_keylog_callback|. void (*keylog_callback)(const SSL *ssl, const char *line) = nullptr; // current_time_cb, if not NULL, is the function to use to get the current // time. It sets |*out_clock| to the current time. The |ssl| argument is // always NULL. See |SSL_CTX_set_current_time_cb|. void (*current_time_cb)(const SSL *ssl, struct timeval *out_clock) = nullptr; // pool is used for all |CRYPTO_BUFFER|s in case we wish to share certificate // memory. CRYPTO_BUFFER_POOL *pool = nullptr; // ticket_aead_method contains function pointers for opening and sealing // session tickets. const SSL_TICKET_AEAD_METHOD *ticket_aead_method = nullptr; // legacy_ocsp_callback implements an OCSP-related callback for OpenSSL // compatibility. int (*legacy_ocsp_callback)(SSL *ssl, void *arg) = nullptr; void *legacy_ocsp_callback_arg = nullptr; // verify_sigalgs, if not empty, is the set of signature algorithms // accepted from the peer in decreasing order of preference. bssl::Array\u0026lt;uint16_t\u0026gt; verify_sigalgs; // retain_only_sha256_of_client_certs is true if we should compute the SHA256 // hash of the peer\u0026#39;s certificate and then discard it to save memory and // session space. Only effective on the server side. bool retain_only_sha256_of_client_certs : 1; // quiet_shutdown is true if the connection should not send a close_notify on // shutdown. bool quiet_shutdown : 1; // ocsp_stapling_enabled is only used by client connections and indicates // whether OCSP stapling will be requested. bool ocsp_stapling_enabled : 1; // If true, a client will request certificate timestamps. bool signed_cert_timestamps_enabled : 1; // channel_id_enabled is whether Channel ID is enabled. For a server, means // that we\u0026#39;ll accept Channel IDs from clients. For a client, means that we\u0026#39;ll // advertise support. bool channel_id_enabled : 1; // grease_enabled is whether draft-davidben-tls-grease-01 is enabled. bool grease_enabled : 1; // allow_unknown_alpn_protos is whether the client allows unsolicited ALPN // protocols from the peer. bool allow_unknown_alpn_protos : 1; // false_start_allowed_without_alpn is whether False Start (if // |SSL_MODE_ENABLE_FALSE_START| is enabled) is allowed without ALPN. bool false_start_allowed_without_alpn : 1; // handoff indicates that a server should stop after receiving the // ClientHello and pause the handshake in such a way that |SSL_get_error| // returns |SSL_ERROR_HANDOFF|. bool handoff : 1; // If enable_early_data is true, early data can be sent and accepted. bool enable_early_data : 1; private: ~ssl_ctx_st(); friend void SSL_CTX_free(SSL_CTX *); }; 1.3 握手/加解密过程当中涉及到的数据结构 # 1.3.1 transcript hash数据结构 # transcript实际上就是握手报文的完整结构，直接翻译为抄本，除了TLS1.3的HELLO RETRY REQUEST会加上一些特殊的地方，其他都是由报文拼接。可以看到，GOOGLE把所有的跟HASH相关的动作都包裹到SSLTranscript结构中。但是从功能的角度来看，我觉得这个就属于C++的强行面向对象了，我个人很厌烦这一点，不像C那么灵活和彻底。\n// SSLTranscript maintains the handshake transcript as a combination of a // buffer and running hash. class SSLTranscript { public: SSLTranscript(); ~SSLTranscript(); // Init initializes the handshake transcript. If called on an existing // transcript, it resets the transcript and hash. It returns true on success // and false on failure. bool Init(); // InitHash initializes the handshake hash based on the PRF and contents of // the handshake transcript. Subsequent calls to |Update| will update the // rolling hash. It returns one on success and zero on failure. It is an error // to call this function after the handshake buffer is released. bool InitHash(uint16_t version, const SSL_CIPHER *cipher); // UpdateForHelloRetryRequest resets the rolling hash with the // HelloRetryRequest construction. It returns true on success and false on // failure. It is an error to call this function before the handshake buffer // is released. bool UpdateForHelloRetryRequest(); // CopyToHashContext initializes |ctx| with |digest| and the data thus far in // the transcript. It returns true on success and false on failure. If the // handshake buffer is still present, |digest| may be any supported digest. // Otherwise, |digest| must match the transcript hash. bool CopyToHashContext(EVP_MD_CTX *ctx, const EVP_MD *digest); Span\u0026lt;const uint8_t\u0026gt; buffer() { return MakeConstSpan(reinterpret_cast\u0026lt;const uint8_t *\u0026gt;(buffer_-\u0026gt;data), buffer_-\u0026gt;length); } // FreeBuffer releases the handshake buffer. Subsequent calls to // |Update| will not update the handshake buffer. void FreeBuffer(); // DigestLen returns the length of the PRF hash. size_t DigestLen() const; // Digest returns the PRF hash. For TLS 1.1 and below, this is // |EVP_md5_sha1|. const EVP_MD *Digest() const; // Update adds |in| to the handshake buffer and handshake hash, whichever is // enabled. It returns true on success and false on failure. bool Update(Span\u0026lt;const uint8_t\u0026gt; in); // GetHash writes the handshake hash to |out| which must have room for at // least |DigestLen| bytes. On success, it returns true and sets |*out_len| to // the number of bytes written. Otherwise, it returns false. bool GetHash(uint8_t *out, size_t *out_len); // GetFinishedMAC computes the MAC for the Finished message into the bytes // pointed by |out| and writes the number of bytes to |*out_len|. |out| must // have room for |EVP_MAX_MD_SIZE| bytes. It returns true on success and false // on failure. bool GetFinishedMAC(uint8_t *out, size_t *out_len, const SSL_SESSION *session, bool from_server); private: // buffer_, if non-null, contains the handshake transcript. UniquePtr\u0026lt;BUF_MEM\u0026gt; buffer_; // hash, if initialized with an |EVP_MD|, maintains the handshake hash. ScopedEVP_MD_CTX hash_; }; 1.3.2 AEAD context # 严格来说TLS1.2就有AEAD，不过在TLS1.3中正式大规模使用，具体的\nclass SSLAEADContext { public: SSLAEADContext(uint16_t version, bool is_dtls, const SSL_CIPHER *cipher); ~SSLAEADContext(); static constexpr bool kAllowUniquePtr = true; SSLAEADContext(const SSLAEADContext \u0026amp;\u0026amp;) = delete; SSLAEADContext \u0026amp;operator=(const SSLAEADContext \u0026amp;\u0026amp;) = delete; // CreateNullCipher creates an |SSLAEADContext| for the null cipher. static UniquePtr\u0026lt;SSLAEADContext\u0026gt; CreateNullCipher(bool is_dtls); // Create creates an |SSLAEADContext| using the supplied key material. It // returns nullptr on error. Only one of |Open| or |Seal| may be used with the // resulting object, depending on |direction|. |version| is the normalized // protocol version, so DTLS 1.0 is represented as 0x0301, not 0xffef. static UniquePtr\u0026lt;SSLAEADContext\u0026gt; Create(enum evp_aead_direction_t direction, uint16_t version, bool is_dtls, const SSL_CIPHER *cipher, Span\u0026lt;const uint8_t\u0026gt; enc_key, Span\u0026lt;const uint8_t\u0026gt; mac_key, Span\u0026lt;const uint8_t\u0026gt; fixed_iv); // CreatePlaceholderForQUIC creates a placeholder |SSLAEADContext| for the // given cipher and version. The resulting object can be queried for various // properties but cannot encrypt or decrypt data. static UniquePtr\u0026lt;SSLAEADContext\u0026gt; CreatePlaceholderForQUIC( uint16_t version, const SSL_CIPHER *cipher); // SetVersionIfNullCipher sets the version the SSLAEADContext for the null // cipher, to make version-specific determinations in the record layer prior // to a cipher being selected. void SetVersionIfNullCipher(uint16_t version); // ProtocolVersion returns the protocol version associated with this // SSLAEADContext. It can only be called once |version_| has been set to a // valid value. uint16_t ProtocolVersion() const; // RecordVersion returns the record version that should be used with this // SSLAEADContext for record construction and crypto. uint16_t RecordVersion() const; const SSL_CIPHER *cipher() const { return cipher_; } // is_null_cipher returns true if this is the null cipher. bool is_null_cipher() const { return !cipher_; } // ExplicitNonceLen returns the length of the explicit nonce. size_t ExplicitNonceLen() const; // MaxOverhead returns the maximum overhead of calling |Seal|. size_t MaxOverhead() const; // SuffixLen calculates the suffix length written by |SealScatter| and writes // it to |*out_suffix_len|. It returns true on success and false on error. // |in_len| and |extra_in_len| should equal the argument of the same names // passed to |SealScatter|. bool SuffixLen(size_t *out_suffix_len, size_t in_len, size_t extra_in_len) const; // CiphertextLen calculates the total ciphertext length written by // |SealScatter| and writes it to |*out_len|. It returns true on success and // false on error. |in_len| and |extra_in_len| should equal the argument of // the same names passed to |SealScatter|. bool CiphertextLen(size_t *out_len, size_t in_len, size_t extra_in_len) const; // Open authenticates and decrypts |in| in-place. On success, it sets |*out| // to the plaintext in |in| and returns true. Otherwise, it returns // false. The output will always be |ExplicitNonceLen| bytes ahead of |in|. bool Open(Span\u0026lt;uint8_t\u0026gt; *out, uint8_t type, uint16_t record_version, const uint8_t seqnum[8], Span\u0026lt;const uint8_t\u0026gt; header, Span\u0026lt;uint8_t\u0026gt; in); // Seal encrypts and authenticates |in_len| bytes from |in| and writes the // result to |out|. It returns true on success and false on error. // // If |in| and |out| alias then |out| + |ExplicitNonceLen| must be == |in|. bool Seal(uint8_t *out, size_t *out_len, size_t max_out, uint8_t type, uint16_t record_version, const uint8_t seqnum[8], Span\u0026lt;const uint8_t\u0026gt; header, const uint8_t *in, size_t in_len); // SealScatter encrypts and authenticates |in_len| bytes from |in| and splits // the result between |out_prefix|, |out| and |out_suffix|. It returns one on // success and zero on error. // // On successful return, exactly |ExplicitNonceLen| bytes are written to // |out_prefix|, |in_len| bytes to |out|, and |SuffixLen| bytes to // |out_suffix|. // // |extra_in| may point to an additional plaintext buffer. If present, // |extra_in_len| additional bytes are encrypted and authenticated, and the // ciphertext is written to the beginning of |out_suffix|. |SuffixLen| should // be used to size |out_suffix| accordingly. // // If |in| and |out| alias then |out| must be == |in|. Other arguments may not // alias anything. bool SealScatter(uint8_t *out_prefix, uint8_t *out, uint8_t *out_suffix, uint8_t type, uint16_t record_version, const uint8_t seqnum[8], Span\u0026lt;const uint8_t\u0026gt; header, const uint8_t *in, size_t in_len, const uint8_t *extra_in, size_t extra_in_len); bool GetIV(const uint8_t **out_iv, size_t *out_iv_len) const; private: // GetAdditionalData returns the additional data, writing into |storage| if // necessary. Span\u0026lt;const uint8_t\u0026gt; GetAdditionalData(uint8_t storage[13], uint8_t type, uint16_t record_version, const uint8_t seqnum[8], size_t plaintext_len, Span\u0026lt;const uint8_t\u0026gt; header); const SSL_CIPHER *cipher_; ScopedEVP_AEAD_CTX ctx_; // fixed_nonce_ contains any bytes of the nonce that are fixed for all // records. uint8_t fixed_nonce_[12]; uint8_t fixed_nonce_len_ = 0, variable_nonce_len_ = 0; // version_ is the wire version that should be used with this AEAD. uint16_t version_; // is_dtls_ is whether DTLS is being used with this AEAD. bool is_dtls_; // variable_nonce_included_in_record_ is true if the variable nonce // for a record is included as a prefix before the ciphertext. bool variable_nonce_included_in_record_ : 1; // random_variable_nonce_ is true if the variable nonce is // randomly generated, rather than derived from the sequence // number. bool random_variable_nonce_ : 1; // xor_fixed_nonce_ is true if the fixed nonce should be XOR\u0026#39;d into the // variable nonce rather than prepended. bool xor_fixed_nonce_ : 1; // omit_length_in_ad_ is true if the length should be omitted in the // AEAD\u0026#39;s ad parameter. bool omit_length_in_ad_ : 1; // ad_is_header_ is true if the AEAD\u0026#39;s ad parameter is the record header. bool ad_is_header_ : 1; }; 1.3.3 Key Share结构 # class SSLKeyShare { public: virtual ~SSLKeyShare() {} static constexpr bool kAllowUniquePtr = true; HAS_VIRTUAL_DESTRUCTOR // Create returns a SSLKeyShare instance for use with group |group_id| or // nullptr on error. static UniquePtr\u0026lt;SSLKeyShare\u0026gt; Create(uint16_t group_id); // Create deserializes an SSLKeyShare instance previously serialized by // |Serialize|. static UniquePtr\u0026lt;SSLKeyShare\u0026gt; Create(CBS *in); // Serializes writes the group ID and private key, in a format that can be // read by |Create|. bool Serialize(CBB *out); // GroupID returns the group ID. virtual uint16_t GroupID() const PURE_VIRTUAL; // Offer generates a keypair and writes the public value to // |out_public_key|. It returns true on success and false on error. virtual bool Offer(CBB *out_public_key) PURE_VIRTUAL; // Accept performs a key exchange against the |peer_key| generated by |Offer|. // On success, it returns true, writes the public value to |out_public_key|, // and sets |*out_secret| to the shared secret. On failure, it returns false // and sets |*out_alert| to an alert to send to the peer. // // The default implementation calls |Offer| and then |Finish|, assuming a key // exchange protocol where the peers are symmetric. virtual bool Accept(CBB *out_public_key, Array\u0026lt;uint8_t\u0026gt; *out_secret, uint8_t *out_alert, Span\u0026lt;const uint8_t\u0026gt; peer_key); // Finish performs a key exchange against the |peer_key| generated by // |Accept|. On success, it returns true and sets |*out_secret| to the shared // secret. On failure, it returns false and sets |*out_alert| to an alert to // send to the peer. virtual bool Finish(Array\u0026lt;uint8_t\u0026gt; *out_secret, uint8_t *out_alert, Span\u0026lt;const uint8_t\u0026gt; peer_key) PURE_VIRTUAL; // SerializePrivateKey writes the private key to |out|, returning true if // successful and false otherwise. It should be called after |Offer|. virtual bool SerializePrivateKey(CBB *out) { return false; } // DeserializePrivateKey initializes the state of the key exchange from |in|, // returning true if successful and false otherwise. virtual bool DeserializePrivateKey(CBS *in) { return false; } }; 1.3.4 ECH 拓展 # 没想到BoringSSL已经支持ECH了，\nclass ECHServerConfig { public: ECHServerConfig() : is_retry_config_(false), initialized_(false) {} ECHServerConfig(ECHServerConfig \u0026amp;\u0026amp;other) = default; ~ECHServerConfig() = default; ECHServerConfig \u0026amp;operator=(ECHServerConfig \u0026amp;\u0026amp;) = default; // Init parses |ech_config| as an ECHConfig and saves a copy of |private_key|. // It returns true on success and false on error. It will also error if // |private_key| is not a valid X25519 private key or it does not correspond // to the parsed public key. bool Init(Span\u0026lt;const uint8_t\u0026gt; ech_config, Span\u0026lt;const uint8_t\u0026gt; private_key, bool is_retry_config); // SupportsCipherSuite returns true when this ECHConfig supports the HPKE // ciphersuite composed of |kdf_id| and |aead_id|. This function must only be // called on an initialized object. bool SupportsCipherSuite(uint16_t kdf_id, uint16_t aead_id) const; Span\u0026lt;const uint8_t\u0026gt; raw() const { assert(initialized_); return raw_; } Span\u0026lt;const uint8_t\u0026gt; public_key() const { assert(initialized_); return public_key_; } Span\u0026lt;const uint8_t\u0026gt; private_key() const { assert(initialized_); return MakeConstSpan(private_key_, sizeof(private_key_)); } Span\u0026lt;const uint8_t\u0026gt; config_id_sha256() const { assert(initialized_); return MakeConstSpan(config_id_sha256_, sizeof(config_id_sha256_)); } bool is_retry_config() const { assert(initialized_); return is_retry_config_; } private: Array\u0026lt;uint8_t\u0026gt; raw_; Span\u0026lt;const uint8_t\u0026gt; public_key_; Span\u0026lt;const uint8_t\u0026gt; cipher_suites_; // private_key_ is the key corresponding to |public_key|. For clients, it must // be empty (|private_key_present_ == false|). For servers, it must be a valid // X25519 private key. uint8_t private_key_[X25519_PRIVATE_KEY_LEN]; // config_id_ stores the precomputed result of |ConfigID| for // |EVP_HPKE_HKDF_SHA256|. uint8_t config_id_sha256_[8]; bool is_retry_config_ : 1; bool initialized_ : 1; }; 1.3.5 SSL_CONFIG结构 # SSL_CONFIG用于存储一些握手完成之后需要的数据结构，\nstruct SSL_CONFIG { static constexpr bool kAllowUniquePtr = true; explicit SSL_CONFIG(SSL *ssl_arg); ~SSL_CONFIG(); // ssl is a non-owning pointer to the parent |SSL| object. SSL *const ssl = nullptr; // conf_max_version is the maximum acceptable version configured by // |SSL_set_max_proto_version|. Note this version is not normalized in DTLS // and is further constrained by |SSL_OP_NO_*|. uint16_t conf_max_version = 0; // conf_min_version is the minimum acceptable version configured by // |SSL_set_min_proto_version|. Note this version is not normalized in DTLS // and is further constrained by |SSL_OP_NO_*|. uint16_t conf_min_version = 0; X509_VERIFY_PARAM *param = nullptr; // crypto UniquePtr\u0026lt;SSLCipherPreferenceList\u0026gt; cipher_list; // This is used to hold the local certificate used (i.e. the server // certificate for a server or the client certificate for a client). UniquePtr\u0026lt;CERT\u0026gt; cert; int (*verify_callback)(int ok, X509_STORE_CTX *ctx) = nullptr; // fail if callback returns 0 enum ssl_verify_result_t (*custom_verify_callback)( SSL *ssl, uint8_t *out_alert) = nullptr; // Server-only: psk_identity_hint is the identity hint to send in // PSK-based key exchanges. UniquePtr\u0026lt;char\u0026gt; psk_identity_hint; unsigned (*psk_client_callback)(SSL *ssl, const char *hint, char *identity, unsigned max_identity_len, uint8_t *psk, unsigned max_psk_len) = nullptr; unsigned (*psk_server_callback)(SSL *ssl, const char *identity, uint8_t *psk, unsigned max_psk_len) = nullptr; // for server side, keep the list of CA_dn we can use UniquePtr\u0026lt;STACK_OF(CRYPTO_BUFFER)\u0026gt; client_CA; // cached_x509_client_CA is a cache of parsed versions of the elements of // |client_CA|. STACK_OF(X509_NAME) *cached_x509_client_CA = nullptr; Array\u0026lt;uint16_t\u0026gt; supported_group_list; // our list // The client\u0026#39;s Channel ID private key. UniquePtr\u0026lt;EVP_PKEY\u0026gt; channel_id_private; // For a client, this contains the list of supported protocols in wire // format. Array\u0026lt;uint8_t\u0026gt; alpn_client_proto_list; // alps_configs contains the list of supported protocols to use with ALPS, // along with their corresponding ALPS values. GrowableArray\u0026lt;ALPSConfig\u0026gt; alps_configs; // Contains a list of supported Token Binding key parameters. Array\u0026lt;uint8_t\u0026gt; token_binding_params; // Contains the QUIC transport params that this endpoint will send. Array\u0026lt;uint8_t\u0026gt; quic_transport_params; // Contains the context used to decide whether to accept early data in QUIC. Array\u0026lt;uint8_t\u0026gt; quic_early_data_context; // verify_sigalgs, if not empty, is the set of signature algorithms // accepted from the peer in decreasing order of preference. Array\u0026lt;uint16_t\u0026gt; verify_sigalgs; // srtp_profiles is the list of configured SRTP protection profiles for // DTLS-SRTP. UniquePtr\u0026lt;STACK_OF(SRTP_PROTECTION_PROFILE)\u0026gt; srtp_profiles; // verify_mode is a bitmask of |SSL_VERIFY_*| values. uint8_t verify_mode = SSL_VERIFY_NONE; // ech_grease_enabled controls whether ECH GREASE may be sent in the // ClientHello. bool ech_grease_enabled : 1; // Enable signed certificate time stamps. Currently client only. bool signed_cert_timestamps_enabled : 1; // ocsp_stapling_enabled is only used by client connections and indicates // whether OCSP stapling will be requested. bool ocsp_stapling_enabled : 1; // channel_id_enabled is copied from the |SSL_CTX|. For a server, means that // we\u0026#39;ll accept Channel IDs from clients. For a client, means that we\u0026#39;ll // advertise support. bool channel_id_enabled : 1; // If enforce_rsa_key_usage is true, the handshake will fail if the // keyUsage extension is present and incompatible with the TLS usage. // This field is not read until after certificate verification. bool enforce_rsa_key_usage : 1; // retain_only_sha256_of_client_certs is true if we should compute the SHA256 // hash of the peer\u0026#39;s certificate and then discard it to save memory and // session space. Only effective on the server side. bool retain_only_sha256_of_client_certs : 1; // handoff indicates that a server should stop after receiving the // ClientHello and pause the handshake in such a way that |SSL_get_error| // returns |SSL_ERROR_HANDOFF|. This is copied in |SSL_new| from the |SSL_CTX| // element of the same name and may be cleared if the handoff is declined. bool handoff : 1; // shed_handshake_config indicates that the handshake config (this object!) // should be freed after the handshake completes. bool shed_handshake_config : 1; // jdk11_workaround is whether to disable TLS 1.3 for JDK 11 clients, as a // workaround for https://bugs.openjdk.java.net/browse/JDK-8211806. bool jdk11_workaround : 1; // QUIC drafts up to and including 32 used a different TLS extension // codepoint to convey QUIC\u0026#39;s transport parameters. bool quic_use_legacy_codepoint : 1; }; 2 握手函数 # 2.1 握手相关函数 # 函数SSL_do_handshake负责继续当前连接的握手状态，有个很有趣的地方实际上要注意，需要先绑定fd或bio才能继续让SSL_do_handshake继续。很类似的SSL__connect和SSL_accept分别用来给client和server端使用，SSL_read函数和openssl代码里还是一致的，返回读取到的明文。和SSL_read类似的函数SSL_peak用来获得明文，但是不会真正的读取报文。这东西也就特定情况下需要。\n诸如KEY_UPDATE_UPDATE_REQUESTED和KEY_UPDATE_UPDATE_NOT_REQUESTED倒是和我写的代码完全一致。\nSSL_get_error函数很有趣，最近的操作失败时，使用这个函数获取失败原因，统一的处理\n3 基本的属性和值 # 3.1 protocol version和函数 # 和openssl一样，还是两个函数。但是有单独的函数去设定对应的SSL版本号。最后的函数负责获得握手时确定的版本号\n#define DTLS1_VERSION_MAJOR 0xfe #define SSL3_VERSION_MAJOR 0x03 #define SSL3_VERSION 0x0300 #define TLS1_VERSION 0x0301 #define TLS1_1_VERSION 0x0302 #define TLS1_2_VERSION 0x0303 #define TLS1_3_VERSION 0x0304 #define DTLS1_VERSION 0xfeff #define DTLS1_2_VERSION 0xfefd OPENSSL_EXPORT int SSL_CTX_set_min_proto_version(SSL_CTX *ctx, uint16_t version); OPENSSL_EXPORT int SSL_CTX_set_max_proto_version(SSL_CTX *ctx, uint16_t version); OPENSSL_EXPORT int SSL_version(const SSL *ssl); 3.2 CTX的属性和函数 # 属性这一块坦白讲我觉得没啥意思，\nSSL_MODE_ENABLE_PARTIAL_WRITE //允许往一个record里面写部分的报文 3.3 证书和私钥相关函数 # OPENSSL_EXPORT int SSL_CTX_use_certificate(SSL_CTX *ctx, X509 *x509); OPENSSL_EXPORT int SSL_use_certificate(SSL *ssl, X509 *x509); OPENSSL_EXPORT int SSL_CTX_set0_chain(SSL_CTX *ctx, STACK_OF(X509) *chain); OPENSSL_EXPORT int SSL_CTX_set1_chain(SSL_CTX *ctx, STACK_OF(X509) *chain); OPENSSL_EXPORT void SSL_CTX_set_cert_cb(SSL_CTX *ctx, int (*cb)(SSL *ssl, void *arg), void *arg); //这个函数就很有趣了，设置回调来选择具体的证书 OPENSSL_EXPORT size_t SSL_get0_peer_verify_algorithms(const SSL *ssl, const uint16_t **out_sigalgs);//这个函数就负责选择对端识别的sig算法，从而能够影响本端证书的选择 OPENSSL_EXPORT int SSL_CTX_check_private_key(const SSL_CTX *ctx); //检测私钥证书是否匹配 4 复用相关数据结构 # 复用最基础的数据结构就三个，这三个就是我们主要的研究对象。\n4.1 SESSION # SESSION基本的数据结构，但是是关联SESSION ID还是SESSION CACHE是需要看SESSION里面的数据结构。实际上这意味着我们可以自由自在地往里面存储数据。\nOPENSSL_EXPORT SSL_SESSION *SSL_SESSION_new(const SSL_CTX *ctx); OPENSSL_EXPORT int SSL_SESSION_up_ref(SSL_SESSION *session); OPENSSL_EXPORT void SSL_SESSION_free(SSL_SESSION *session); //减少引用计数，引用计数为0就触发free OPENSSL_EXPORT uint64_t SSL_SESSION_get_time(const SSL_SESSION *session);//获取SESSION的颁发时间 OPENSSL_EXPORT size_t SSL_SESSION_get_master_key(const SSL_SESSION *session, uint8_t *out, size_t max_out);//获取具体的衍生秘钥 OPENSSL_EXPORT int SSL_SESSION_should_be_single_use(const SSL_SESSION *session);//这个就很牛逼了，只能使用一次的SESSION 4.2 SESSION CACHE # 和SESSION有什么区别？这个问题自然而然出现了，看注释应该是一样的，都是SSL_session结构。boringg ssl自己内置了一种SESSION CACHE的代码实现，使用的数据结构是内置的hashTable，原文引用于下\nFor a server, the library implements a built-in internal session cache as an in-memory hash table. Servers may also use SSL_CTX_sess_set_get_cb and SSL_CTX_sess_set_new_cb to implement a custom external session cache. In particular, this may be used to share a session cache between multiple servers in a large deployment. An external cache may be used in addition to or instead of the internal one. Use SSL_CTX_set_session_cache_mode to toggle the internal cache.\n#define SSL_SESS_CACHE_OFF 0x0000 //用来关停SESSION CACHE功能 struct ssl_session_st { explicit ssl_session_st(const bssl::SSL_X509_METHOD *method); ssl_session_st(const ssl_session_st \u0026amp;) = delete; ssl_session_st \u0026amp;operator=(const ssl_session_st \u0026amp;) = delete; CRYPTO_refcount_t references = 1; // ssl_version is the (D)TLS version that established the session. uint16_t ssl_version = 0; // group_id is the ID of the ECDH group used to establish this session or zero // if not applicable or unknown. uint16_t group_id = 0; // peer_signature_algorithm is the signature algorithm used to authenticate // the peer, or zero if not applicable or unknown. uint16_t peer_signature_algorithm = 0; // secret, in TLS 1.2 and below, is the master secret associated with the // session. In TLS 1.3 and up, it is the resumption PSK for sessions handed to // the caller, but it stores the resumption secret when stored on |SSL| // objects. int secret_length = 0; uint8_t secret[SSL_MAX_MASTER_KEY_LENGTH] = {0}; // session_id - valid? unsigned session_id_length = 0; uint8_t session_id[SSL_MAX_SSL_SESSION_ID_LENGTH] = {0}; // this is used to determine whether the session is being reused in // the appropriate context. It is up to the application to set this, // via SSL_new uint8_t sid_ctx_length = 0; uint8_t sid_ctx[SSL_MAX_SID_CTX_LENGTH] = {0}; bssl::UniquePtr\u0026lt;char\u0026gt; psk_identity; // certs contains the certificate chain from the peer, starting with the leaf // certificate. bssl::UniquePtr\u0026lt;STACK_OF(CRYPTO_BUFFER)\u0026gt; certs; const bssl::SSL_X509_METHOD *x509_method = nullptr; // x509_peer is the peer\u0026#39;s certificate. X509 *x509_peer = nullptr; // x509_chain is the certificate chain sent by the peer. NOTE: for historical // reasons, when a client (so the peer is a server), the chain includes // |peer|, but when a server it does not. STACK_OF(X509) *x509_chain = nullptr; // x509_chain_without_leaf is a lazily constructed copy of |x509_chain| that // omits the leaf certificate. This exists because OpenSSL, historically, // didn\u0026#39;t include the leaf certificate in the chain for a server, but did for // a client. The |x509_chain| always includes it and, if an API call requires // a chain without, it is stored here. STACK_OF(X509) *x509_chain_without_leaf = nullptr; // verify_result is the result of certificate verification in the case of // non-fatal certificate errors. long verify_result = X509_V_ERR_INVALID_CALL; // timeout is the lifetime of the session in seconds, measured from |time|. // This is renewable up to |auth_timeout|. uint32_t timeout = SSL_DEFAULT_SESSION_TIMEOUT; // auth_timeout is the non-renewable lifetime of the session in seconds, // measured from |time|. uint32_t auth_timeout = SSL_DEFAULT_SESSION_TIMEOUT; // time is the time the session was issued, measured in seconds from the UNIX // epoch. uint64_t time = 0; const SSL_CIPHER *cipher = nullptr; CRYPTO_EX_DATA ex_data; // application specific data // These are used to make removal of session-ids more efficient and to // implement a maximum cache size. SSL_SESSION *prev = nullptr, *next = nullptr; bssl::Array\u0026lt;uint8_t\u0026gt; ticket; bssl::UniquePtr\u0026lt;CRYPTO_BUFFER\u0026gt; signed_cert_timestamp_list; // The OCSP response that came with the session. bssl::UniquePtr\u0026lt;CRYPTO_BUFFER\u0026gt; ocsp_response; // peer_sha256 contains the SHA-256 hash of the peer\u0026#39;s certificate if // |peer_sha256_valid| is true. uint8_t peer_sha256[SHA256_DIGEST_LENGTH] = {0}; // original_handshake_hash contains the handshake hash (either SHA-1+MD5 or // SHA-2, depending on TLS version) for the original, full handshake that // created a session. This is used by Channel IDs during resumption. uint8_t original_handshake_hash[EVP_MAX_MD_SIZE] = {0}; uint8_t original_handshake_hash_len = 0; uint32_t ticket_lifetime_hint = 0; // Session lifetime hint in seconds uint32_t ticket_age_add = 0; // ticket_max_early_data is the maximum amount of data allowed to be sent as // early data. If zero, 0-RTT is disallowed. uint32_t ticket_max_early_data = 0; // early_alpn is the ALPN protocol from the initial handshake. This is only // stored for TLS 1.3 and above in order to enforce ALPN matching for 0-RTT // resumptions. For the current connection\u0026#39;s ALPN protocol, see // |alpn_selected| on |SSL3_STATE|. bssl::Array\u0026lt;uint8_t\u0026gt; early_alpn; // local_application_settings, if |has_application_settings| is true, is the // local ALPS value for this connection. bssl::Array\u0026lt;uint8_t\u0026gt; local_application_settings; // peer_application_settings, if |has_application_settings| is true, is the // peer ALPS value for this connection. bssl::Array\u0026lt;uint8_t\u0026gt; peer_application_settings; // extended_master_secret is whether the master secret in this session was // generated using EMS and thus isn\u0026#39;t vulnerable to the Triple Handshake // attack. bool extended_master_secret : 1; // peer_sha256_valid is whether |peer_sha256| is valid. bool peer_sha256_valid : 1; // Non-zero if peer_sha256 is valid // not_resumable is used to indicate that session resumption is disallowed. bool not_resumable : 1; // ticket_age_add_valid is whether |ticket_age_add| is valid. bool ticket_age_add_valid : 1; // is_server is whether this session was created by a server. bool is_server : 1; // is_quic indicates whether this session was created using QUIC. bool is_quic : 1; // has_application_settings indicates whether ALPS was negotiated in this // session. bool has_application_settings : 1; // quic_early_data_context is used to determine whether early data must be // rejected when performing a QUIC handshake. bssl::Array\u0026lt;uint8_t\u0026gt; quic_early_data_context; private: ~ssl_session_st(); friend void SSL_SESSION_free(SSL_SESSION *); }; 数据结构看完了，看看SESSION CACHE的管理是怎么做的，几个关键函数如下，其中：\n从session_id拓展到hash实际上使用了session_id的前四字节\nuint32_t ssl_hash_session_id(Span\u0026lt;const uint8_t\u0026gt; session_id) { // Take the first four bytes of |session_id|. Session IDs are generated by the // server randomly, so we can assume even using the first four bytes results // in a good distribution. uint8_t tmp_storage[sizeof(uint32_t)]; if (session_id.size() \u0026lt; sizeof(tmp_storage)) { OPENSSL_memset(tmp_storage, 0, sizeof(tmp_storage)); OPENSSL_memcpy(tmp_storage, session_id.data(), session_id.size()); session_id = tmp_storage; } uint32_t hash = ((uint32_t)session_id[0]) | ((uint32_t)session_id[1] \u0026lt;\u0026lt; 8) | ((uint32_t)session_id[2] \u0026lt;\u0026lt; 16) | ((uint32_t)session_id[3] \u0026lt;\u0026lt; 24); return hash; } 有了hash+session_id+session_ctx-\u0026gt;sessions最后实际上是个比较函数，BORING SSL最后使用的比较函数是个宏，展开来这个宏如下。所以我们得看看LHASH到底是个什么数据结构，因为ssl-\u0026gt;session_ctx-\u0026gt;sessions的数据结构是LHASH_OF(SSL_SESSION) *sessions = nullptr;。这个东西在OPENSSL里面也有，说白了就是hash表，但是一个大锁对应一个HASH表可太狠了，所以我们得看看ssl_lookup_session的时候发生了什么\n// ssl_lookup_session looks up |session_id| in the session cache and sets // |*out_session| to an |SSL_SESSION| object if found. static enum ssl_hs_wait_t ssl_lookup_session( SSL_HANDSHAKE *hs, UniquePtr\u0026lt;SSL_SESSION\u0026gt; *out_session, Span\u0026lt;const uint8_t\u0026gt; session_id) { SSL *const ssl = hs-\u0026gt;ssl; out_session-\u0026gt;reset(); if (session_id.empty() || session_id.size() \u0026gt; SSL_MAX_SSL_SESSION_ID_LENGTH) { return ssl_hs_ok;//session id不合法，不是合理的session id就直接放弃 } UniquePtr\u0026lt;SSL_SESSION\u0026gt; session; // Try the internal cache, if it exists. if (!(ssl-\u0026gt;session_ctx-\u0026gt;session_cache_mode \u0026amp; SSL_SESS_CACHE_NO_INTERNAL_LOOKUP)) { uint32_t hash = ssl_hash_session_id(session_id);//先通过session_id计算出来hash auto cmp = [](const void *key, const SSL_SESSION *sess) -\u0026gt; int { Span\u0026lt;const uint8_t\u0026gt; key_id = *reinterpret_cast\u0026lt;const Span\u0026lt;const uint8_t\u0026gt; *\u0026gt;(key); Span\u0026lt;const uint8_t\u0026gt; sess_id = MakeConstSpan(sess-\u0026gt;session_id, sess-\u0026gt;session_id_length); return key_id == sess_id ? 0 : 1; }; MutexReadLock lock(\u0026amp;ssl-\u0026gt;session_ctx-\u0026gt;lock); //读锁开始锁SSL连接相关的session-ctx的锁了，然后升高ssl-\u0026gt;session-ctx-\u0026gt;session的reference count。但是这个锁太大了！去找一下这个锁的初始化的位置，这个锁太狠了 // |lh_SSL_SESSION_retrieve_key| returns a non-owning pointer. session = UpRef(lh_SSL_SESSION_retrieve_key(ssl-\u0026gt;session_ctx-\u0026gt;sessions, \u0026amp;session_id, hash, cmp)); // TODO(davidben): This should probably move it to the front of the list. } // Fall back to the external cache, if it exists. if (!session \u0026amp;\u0026amp; ssl-\u0026gt;session_ctx-\u0026gt;get_session_cb != nullptr) { int copy = 1; session.reset(ssl-\u0026gt;session_ctx-\u0026gt;get_session_cb(ssl, session_id.data(), session_id.size(), \u0026amp;copy)); if (!session) { return ssl_hs_ok; } if (session.get() == SSL_magic_pending_session_ptr()) { session.release(); // This pointer is not actually owned. return ssl_hs_pending_session; } // Increment reference count now if the session callback asks us to do so // (note that if the session structures returned by the callback are shared // between threads, it must handle the reference count itself [i.e. copy == // 0], or things won\u0026#39;t be thread-safe). if (copy) { SSL_SESSION_up_ref(session.get()); } // Add the externally cached session to the internal cache if necessary. if (!(ssl-\u0026gt;session_ctx-\u0026gt;session_cache_mode \u0026amp; SSL_SESS_CACHE_NO_INTERNAL_STORE)) { SSL_CTX_add_session(ssl-\u0026gt;session_ctx.get(), session.get()); } } if (session \u0026amp;\u0026amp; !ssl_session_is_time_valid(ssl, session.get())) { // The session was from the cache, so remove it. SSL_CTX_remove_session(ssl-\u0026gt;session_ctx.get(), session.get()); session.reset(); } *out_session = std::move(session); return ssl_hs_ok; } 上面看完了LOOKUP我们看看new SESSION的时候，也就是添加SESSION的时候发生了什么？一个ssl的session最多存储多少个？\nint SSL_CTX_add_session(SSL_CTX *ctx, SSL_SESSION *session) { // Although |session| is inserted into two structures (a doubly-linked list // and the hash table), |ctx| only takes one reference. UniquePtr\u0026lt;SSL_SESSION\u0026gt; owned_session = UpRef(session); SSL_SESSION *old_session; MutexWriteLock lock(\u0026amp;ctx-\u0026gt;lock);//还是一把大写锁啊，蛋疼 if (!lh_SSL_SESSION_insert(ctx-\u0026gt;sessions, \u0026amp;old_session, session)) { return 0; } // |ctx-\u0026gt;sessions| took ownership of |session| and gave us back a reference to // |old_session|. (|old_session| may be the same as |session|, in which case // we traded identical references with |ctx-\u0026gt;sessions|.) owned_session.release(); owned_session.reset(old_session); if (old_session != NULL) { if (old_session == session) { // |session| was already in the cache. There are no linked list pointers // to update. return 0; } // There was a session ID collision. |old_session| was replaced with // |session| in the hash table, so |old_session| must be removed from the // linked list to match. SSL_SESSION_list_remove(ctx, old_session); } SSL_SESSION_list_add(ctx, session); // Enforce any cache size limits. if (SSL_CTX_sess_get_cache_size(ctx) \u0026gt; 0) { while (lh_SSL_SESSION_num_items(ctx-\u0026gt;sessions) \u0026gt; SSL_CTX_sess_get_cache_size(ctx)) { if (!remove_session_lock(ctx, ctx-\u0026gt;session_cache_tail, 0)) { break; } } } return 1; } 上面看完了NEW我们看看删除SESSION的时候发生了什么\nstatic int remove_session_lock(SSL_CTX *ctx, SSL_SESSION *session, int lock) { int ret = 0; if (session != NULL \u0026amp;\u0026amp; session-\u0026gt;session_id_length != 0) { if (lock) { CRYPTO_MUTEX_lock_write(\u0026amp;ctx-\u0026gt;lock); //先加锁，先把锁给锁上避免争用 } SSL_SESSION *found_session = lh_SSL_SESSION_retrieve(ctx-\u0026gt;sessions, session); //好了，获取对应的SESSION看是不是还存在，不存在就说明已经被其他的线程给删除了，那我们就没啥事情了，但是需要释放锁。 if (found_session == session) { ret = 1; found_session = lh_SSL_SESSION_delete(ctx-\u0026gt;sessions, session);//从OPENSSL的hash表里面删除掉这个session SSL_SESSION_list_remove(ctx, session);//hash表删除掉可没玩，还需要从链表上把session删除掉 } if (lock) { CRYPTO_MUTEX_unlock_write(\u0026amp;ctx-\u0026gt;lock); } if (ret) { //ret为1，说明是当前线程执行的删除操作，因此需要释放内存 if (ctx-\u0026gt;remove_session_cb != NULL) { ctx-\u0026gt;remove_session_cb(ctx, found_session); } SSL_SESSION_free(found_session);//释放掉内存 } } return ret; } static void SSL_SESSION_list_remove(SSL_CTX *ctx, SSL_SESSION *session) { //一个基础的链表，直接删除就成了 if (session-\u0026gt;next == NULL || session-\u0026gt;prev == NULL) { return; } if (session-\u0026gt;next == (SSL_SESSION *)\u0026amp;ctx-\u0026gt;session_cache_tail) { // last element in list if (session-\u0026gt;prev == (SSL_SESSION *)\u0026amp;ctx-\u0026gt;session_cache_head) { // only one element in list ctx-\u0026gt;session_cache_head = NULL; ctx-\u0026gt;session_cache_tail = NULL; } else { ctx-\u0026gt;session_cache_tail = session-\u0026gt;prev; session-\u0026gt;prev-\u0026gt;next = (SSL_SESSION *)\u0026amp;(ctx-\u0026gt;session_cache_tail); } } else { if (session-\u0026gt;prev == (SSL_SESSION *)\u0026amp;ctx-\u0026gt;session_cache_head) { // first element in list ctx-\u0026gt;session_cache_head = session-\u0026gt;next; session-\u0026gt;next-\u0026gt;prev = (SSL_SESSION *)\u0026amp;(ctx-\u0026gt;session_cache_head); } else { // middle of list session-\u0026gt;next-\u0026gt;prev = session-\u0026gt;prev; session-\u0026gt;prev-\u0026gt;next = session-\u0026gt;next; } } session-\u0026gt;prev = session-\u0026gt;next = NULL;//看看这一步操作，还是把当前要去掉的session的前和后置空了，对一部分人，教科书级别的打脸啊。 } 所以可以总结session_ctx-\u0026gt;lock的管辖范围，一个大锁管了一堆，虽然有lazy delete但是，没蛋用。能够看出来，实际上BORING SSL和OPENSSL都一样，都是一把大锁加个链表存储\n4.3 SESSION TICKET # 和SESSION CACHE不同，RFC5077里面给出了SESSION TICKET的实现。对于BORING SSL而言，SESSION TICKET也是支持的。\nOn the server, tickets are encrypted and authenticated with a secret key. By default, an SSL_CTX will manage session ticket encryption keys by generating them internally and rotating every 48 hours. Tickets are minted and processed transparently. The following functions may be used to configure a persistent key or implement more custom behavior, including key rotation and sharing keys between multiple servers in a large deployment. There are three levels of customisation possible:\nOne can simply set the keys with SSL_CTX_set_tlsext_ticket_keys. 2) One can configure an EVP_CIPHER_CTX and HMAC_CTX directly for encryption and authentication. 3) One can configure an SSL_TICKET_AEAD_METHOD to have more control and the option of asynchronous decryption. 相比较而言，我更喜欢session ticket，因为这东西完全不在本地存储软件，省大了去的事啦！而且只要逻辑确定了，避开锁争用的消耗就太棒啦！看一下具体的创建session_tickets的函数\nstatic bool add_new_session_tickets(SSL_HANDSHAKE *hs, bool *out_sent_tickets) { SSL *const ssl = hs-\u0026gt;ssl; if (// If the client doesn\u0026#39;t accept resumption with PSK_DHE_KE, don\u0026#39;t send a // session ticket. !hs-\u0026gt;accept_psk_mode || // We only implement stateless resumption in TLS 1.3, so skip sending // tickets if disabled. (SSL_get_options(ssl) \u0026amp; SSL_OP_NO_TICKET)) { //判断能不能颁发session，看来boring ssl在老版本根本没做这工作 *out_sent_tickets = false; return true; } // TLS 1.3 recommends single-use tickets, so issue multiple tickets in case // the client makes several connections before getting a renewal. static const int kNumTickets = 2; //每次颁发两个single-use ticket，来保证能够多次复用，不过我很好奇这个single-use怎么做的 // Rebase the session timestamp so that it is measured from ticket // issuance. ssl_session_rebase_time(ssl, hs-\u0026gt;new_session.get()); //校定时间 for (int i = 0; i \u0026lt; kNumTickets; i++) { UniquePtr\u0026lt;SSL_SESSION\u0026gt; session( SSL_SESSION_dup(hs-\u0026gt;new_session.get(), SSL_SESSION_INCLUDE_NONAUTH)); if (!session) { return false; } if (!RAND_bytes((uint8_t *)\u0026amp;session-\u0026gt;ticket_age_add, 4)) { //随机生成ticket_age_add return false; } session-\u0026gt;ticket_age_add_valid = true; bool enable_early_data = ssl-\u0026gt;enable_early_data \u0026amp;\u0026amp; (!ssl-\u0026gt;quic_method || !ssl-\u0026gt;config-\u0026gt;quic_early_data_context.empty()); if (enable_early_data) { //校定是不是需要EARLYDATA拓展 // QUIC does not use the max_early_data_size parameter and always sets it // to a fixed value. See draft-ietf-quic-tls-22, section 4.5. session-\u0026gt;ticket_max_early_data = ssl-\u0026gt;quic_method != nullptr ? 0xffffffff : kMaxEarlyDataAccepted; } static_assert(kNumTickets \u0026lt; 256, \u0026#34;Too many tickets\u0026#34;); uint8_t nonce[] = {static_cast\u0026lt;uint8_t\u0026gt;(i)}; ScopedCBB cbb; CBB body, nonce_cbb, ticket, extensions; if (!ssl-\u0026gt;method-\u0026gt;init_message(ssl, cbb.get(), \u0026amp;body, SSL3_MT_NEW_SESSION_TICKET) || !CBB_add_u32(\u0026amp;body, session-\u0026gt;timeout) || !CBB_add_u32(\u0026amp;body, session-\u0026gt;ticket_age_add) || !CBB_add_u8_length_prefixed(\u0026amp;body, \u0026amp;nonce_cbb) || !CBB_add_bytes(\u0026amp;nonce_cbb, nonce, sizeof(nonce)) || !CBB_add_u16_length_prefixed(\u0026amp;body, \u0026amp;ticket) || !tls13_derive_session_psk(session.get(), nonce) || !ssl_encrypt_ticket(hs, \u0026amp;ticket, session.get()) || !CBB_add_u16_length_prefixed(\u0026amp;body, \u0026amp;extensions)) { return false; } if (enable_early_data) { //根据是否需要加入early_data来确定是不是加拓展 CBB early_data; if (!CBB_add_u16(\u0026amp;extensions, TLSEXT_TYPE_early_data) || !CBB_add_u16_length_prefixed(\u0026amp;extensions, \u0026amp;early_data) || !CBB_add_u32(\u0026amp;early_data, session-\u0026gt;ticket_max_early_data) || !CBB_flush(\u0026amp;extensions)) { return false; } } // Add a fake extension. See draft-davidben-tls-grease-01. if (!CBB_add_u16(\u0026amp;extensions, ssl_get_grease_value(hs, ssl_grease_ticket_extension)) || !CBB_add_u16(\u0026amp;extensions, 0 /* empty */)) { return false; } if (!ssl_add_message_cbb(ssl, cbb.get())) { return false; } } *out_sent_tickets = true; return true; } 最后我们提一句single-use这个事情，TLS1.3 RFC对于SINGLE-USE是维持一个SESSION TICKET数据库，如果用到了就直接删除，保证不会再出现复用。那么BORING SSL怎么做的呢？我们就看看BORING SSL处理SESSION TICKET的逻辑，换言之，只要是TLS1.3之后，包括TLS1.3的版本，必然是SINGLE-USE的，这个假设可以说是相当错误，实际上没必须如此的设定。\nint SSL_SESSION_should_be_single_use(const SSL_SESSION *session) { return ssl_session_protocol_version(session) \u0026gt;= TLS1_3_VERSION; } 那么如何实现SINGLE-USE的呢？遗憾的是，这个东西BORING SSL和OPENSSL SSL都没实现：\nNote also, in TLS 1.2 and earlier, offering sessions allows passive observers to correlate different client connections. TLS 1.3 and later fix this, provided clients use sessions at most once. Session caches are managed by the caller in BoringSSL, so this must be implemented externally. See SSL_SESSION_should_be_single_use for details.\n5 拓展相关数据结构 # 5.1 ALPN # 5.2 NPN # 结尾 # 唉，尴尬\n","date":"2021 年 4 月 12 日","externalUrl":null,"permalink":"/posts/2021-04-12-boringssl%E7%A0%94%E7%A9%B6%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"","title":"boringSSL研究笔记","type":"posts"},{"content":" TLS1.3 8446 RFC翻译 # 先说点东西，RFC8446里面过于基础的东西，和术语等东西我是不会翻译的，没什么价值，安全从业者都懂。不翻译的东西我会留着原文，翻译的地方只会为中文。如果想看英文版本直接看这个网址：https://tools.ietf.org/html/rfc8446\n0 前言和目录 # 0.1 摘要 # 这篇文档定义了1.3版本的传输层安全协议 （以下简称为TLS协议）。TLS协议允许客户端和服务端在互联网上通信，并免受偷听，篡改和伪造消息的风险。\n这篇文章更新了RFC5705与RFC6066，废除了RFC5077，RFC5246和RFC6961。这篇文档同样给TLS1.2的实现提了新要求。\n0.2 本备忘录的状况 # 这是一份互联网标准跟踪文件。\n本文件是互联网工程任务组 (IETF)的产品。它代表了IETF界（IETF社区）的共识。该文档已收到公开审查意见，并已被互联网工程指导小组（IESG）批准发布。更多互联网标准的相关信息可在RFC 7841的第2节中找到。\n关于本文档当前状态的信息，任何勘误以及如何提供反馈意见的信息，可通过以下途径获得：https://www.rfc-editor.org/info/rfc8446。\n0.3 目录 # 1 引论 # TLS的主要目标是在两个通信段之间提供一个安全信道，对底层的唯一要求是下层协议提供可靠的、有序的数据流。 具体而言，该安全信道应该提供以下属性：\n可认证: 通讯讯道的服务端必须可认证，客户端可选择性的被认证。认证的方式可以使用非对称算法（即RSA/ECDSA/EdDSA/PSK方式） 保密性: 通讯讯道建立后，传输数据只能终端可见。TLS并不隐藏传输数据的长度，尽管中断可以添加padding来混淆数据长度并对抗讯道分析技术 一致性: 讯道建立后，传输的数据，不可以在不被察觉下篡改 即使攻击者可以完整控制通讯网络，如同[RFC3552]，以上特性也必须被提供。附录Appendix E提供了更纤细的信息。\nTLS主要由两部分组成。\n握手协议(第4节)，用于验证通讯对端的身份。协商密码模式和参数，建立共享的秘钥信息。 握手协议的设计应当能够抵御篡改；主动攻击者不能强迫对端协商其未选择的握手参数。 记录协议（第5节），使用握手协议中协商的参数，保护通信方之间的流量。记录协议将流量拆分为一系列记录，每个记录都使用traffic key独立地保护。 TLS独立于应用协议，TLS协议透明地为高层协议提供服务 但是，TLS标准并没有规定协议如何用TLS增加安全性；如何启动TLS握手，如何实现证书交换流程，都是由运行在TLS之上的协议的设计者和实现者来判断。\n本文档定义了TLS 1.3版本标准行为。 虽然TLS 1.3与以前的版本并不直接兼容，但所有版本的TLS都包含了版本（回退）机制，允许客户和服务器在双方共享某一支持版本的情况下下协商一个可用的TLS版本。\n本文档取代并废除了之前的TLS版本，包括1.2版本[RFC5246]。 它还删除了[RFC5077]中定义的TLS票据机制，并用第2.2节中定义的机制代替。 由于 TLS 1.3 改变了密钥的推导方式，它更新了第 7.5 节中描述的 [RFC5705]，同时也改变了在线证书状态协议 [RFC5077] 中定义的机制。 它还改变了在线证书状态协议(OCSP)消息的传输方式，因此更新了[RFC6066]，取消了[RFC6961]，详见第4.4.2.1节。\n1.1 公约和术语 # 1.2 与TLS1.2的差别 # 下面是TLS1.2和TLS1.3主要的功能差异，尽管并没有巨大的变化，但是细节的变动很多。\nTLS1.3支持的对称加密算法列表中，移除了过去版本合法的加密算法。 剩下的都是带有关联数据的认证加密（AEAD）算法。 密码套件（ciphersuite）的概念已经改变，拆分认证，密钥交换机制与记录保护算法（包括秘钥长度）和哈希算法。哈希算法用于密钥派生功能和握手信息认证码（MAC）一起使用。 增加了零往返时间(0-RTT)模式，在握手阶段就发送应用数据，节省了一个往返时间，但代价是牺牲了一定的安全性能。 静态RSA和静态Diffie-Hellman密码套件已被删除；所有基于公钥的密钥交换机制现在都提供前向保密功能。（实际上就是使用随机产生的临时私钥） TLS1.3中ServerHello之后的所有握手消息都是加密的。新引入的EncryptedExtensions消息允许曾经在ServerHello中以明文方式发送的各种扩展也被秘钥保护。 秘钥衍生算法重新设计。因为降低了新秘钥和旧秘钥内容和统计上面的关联， 新的设计使密码学家更容易分析密码强度。 基于HMAC的提取和扩展密钥衍生函数(HKDF)是该功能的基本单元（就是得用HKDF来做秘钥衍生）。 握手状态机进行了重大调整，使其设计原则更加一致，并删除了ChangeCipherSpec等多余的消息（除非网络上中间设备由于兼容性需要）。 椭圆曲线算法现在已经被列入基本规范，并且包含了新的签名算法，如EdDSA。 TLS 1.3 取消了基点协商功能，每条曲线采用固定的基点。 其他密码学方面的改进，包括将RSA填充改为使用RSA概率签名方案(RSASSA-PSS)，以及去除压缩、数字签名算法(DSA)和自定义的Ephemeral Diffie-Hellman(DHE)组。 TLS 1.2版本协商机制已经被废止，改为在扩展标记可使用版本得列表。 这增加了与现有服务器的兼容性，因为这些服务器的版本协商实现是不正确的。 基于服务器端状态的会话恢复，以及早期TLS版本中基于PSK的密码套件都由单独的PSK所取代。 参考文献跟随RFC同步更新，请酌情参考RFCs的更新版本（例如，RFC 5280而不是RFC 3280）。 1.3 影响TLS 1.2的更新 # 本文档定义了一些行为标准，这些标准影响TLS 1.2实现的变化，即使那些不支持TLS 1.3的机器也需要遵守这些行为。\n版本降级保护机制在4.1.3节中描述。 RSASSA-PSS签名方案在4.2.3节中定义。 ClientHello中的\u0026quot;supported_versions \u0026ldquo;扩展用来协商使用的TLS的版本，在TLS1.2和之前的版本使用ClientHello的legacy_version字段。 \u0026ldquo;signature_algorithms_cert \u0026ldquo;扩展允许客户端指明它可以使用哪些签名算法验证服务端的X.509证书。 此外，本文档还澄清了早期版本的TLS的一些合规性要求；见第9.3节。\n2 协议总览 # 安全通道使用的加密参数是由TLS握手协议产生的，该TLS子协议在客户端和服务器第一次相互通信时使用的。 握手协议允许对通信端协商协议版本，选择加密算法，认证对方（可选），并建立共享的秘密密钥材料。 一旦握手完成，对等体使用已协商的密钥来保护应用层的流量。\n握手失败或其他协议错误会触发连接的终止，可以在连接终止前发出警报消息（第6节）。\nTLS支持三种基本的密钥交换模式：\n(EC)DHE(有限域或椭圆曲线上的Diffie-Hellman算法) PSK-only（仅PSK） PSK with (EC)DHE（PSK+(EC)DHE） 图1展示了一个基础的完整TLS握手流程：\nClient Server Key ^ ClientHello Exch | + key_share* | + signature_algorithms* | + psk_key_exchange_modes* v + pre_shared_key* --------\u0026gt; ServerHello ^ Key + key_share* | Exch + pre_shared_key* v {EncryptedExtensions} ^ Server {CertificateRequest*} v Params {Certificate*} ^ {CertificateVerify*} | Auth {Finished} v \u0026lt;-------- [Application Data*] ^ {Certificate*} Auth | {CertificateVerify*} v {Finished} --------\u0026gt; [Application Data] \u0026lt;-------\u0026gt; [Application Data] + 表示在上方发送的消息（报文）中值得留意的关键拓展 * 表示不总是发送的消息/拓展，一般取决于具体的已经发送过的信息/扩展。 {} 代表该消息（报文）由[sender]_handshake_traffic_secret衍生的秘钥保护 [] 代表该消息（报文）由[sender]_application_traffic_secret_N衍生的秘钥保护 Figure 1: Message Flow for Full TLS Handshake 握手可以认为有三个阶段（如上图所示）。\n密钥交换阶段。建立共享的密钥材料，选择加密参数。 此阶段之后的一切消息都会被加密。 服务器参数。建立其他握手参数（根据客户端是否需要认证、应用层协议支持等情况变化）。 认证。验证服务器（以及客户端），并确认秘钥正确，并保证握手完整性。 在密钥交换阶段，客户端发送ClientHello(4.1.2节)消息，其包含：一个随机数nonce(ClientHello.random)；支持的协议版本；对称密码/HKDF散列对的列表；一组Diffie-Hellman key_shares(在 \u0026ldquo;key_share\u0026rdquo;(4. 2.8节)扩展中)，一组psk标签(在 \u0026ldquo;pre_shared_key\u0026rdquo;(4.2.11节)扩展中)，或者两者兼而有之；以及一些可能出现的的附加扩展，处于中间设备的兼容性考虑，还可能存在额外的字段和/或信息。\n然后，服务器会发送两条消息来建立服务器参数：\nEncryptedExtensions：该消息回复上面的ClientHello中和确定加密参数无关扩展的响应，但个别证书所特有的参数除外。[第4.3.1节] CertificateRequest：如果需要使用证书认证客户端，则需要该证书的相关信息。 如果不需要客户端认证，则省略该消息。(第4.3.2节) 最后，客户端和服务器交换认证消息。 TLS每次需要基于证书的认证时，都会使用同一组消息。 (基于PSK的认证是作为密钥交换的补充发生的)，这些消息，具体来说是下面几种：\nCertificate。 通讯终端的证书和证书相关扩展。 如果无需使用证书认证，那么，服务器会省略这条消息。如果服务端没法送CertificateRequest消息，客户端同样省略此消息。 请注意，如果原始公钥[RFC7250]或缓存信息扩展部分[RFC7924]也在生效，那么这个消息将不包含一个证书，而是其他一些对应于服务器的长期密钥。 [第4.4.2节] CertificateVerify。 使用与证书信息中的公钥相对应的私钥对整个握手报文计算一个签名。 如果通信终端不使用证书进行认证，则省略该消息。 第 4.4.3 节）。 Finished。 对整个握手过程中计算MAC（消息认证码）。 该消息提供密钥确认，将终端的身份与交换的密钥绑定，在PSK模式下还对握手进行认证等功能。 [第4.4.4节] 在收到服务器的消息后，客户端会响应其认证消息，即证书和CertificateVerify（如果需要的话），以及Finished。\n此时，握手完成，客户端和服务器衍生出记录层所需的密钥材料，使用该衍生秘钥材料来加解密应用层数据。除第2.3节规定的情况外，在发送Finished消息之前，不得发送应用数据。 请注意，虽然服务器可以在收到客户端的认证消息之前发送应用数据，但在这一点上发送的任何数据当然都是发送给未经认证的对等体。\n2.1 不正确的DHE交换流程 # 如果客户端没有 在\u0026quot;key_share \u0026ldquo;扩展中没有提供足够的秘钥信息（例如，它只包括服务器不能接受或不支持的DHE或ECDHE组），服务器用HelloRetryRequest纠正该秘钥的不匹配，客户端需要用适当的 \u0026ldquo;key_share \u0026ldquo;扩展重新开始握手，如图2所示。 如果不能协商出共同的加密参数，服务器必须发送正确的alert报文中止握手。\nClient Server ClientHello + key_share --------\u0026gt; HelloRetryRequest \u0026lt;-------- + key_share ClientHello + key_share --------\u0026gt; ServerHello + key_share {EncryptedExtensions} {CertificateRequest*} {Certificate*} {CertificateVerify*} {Finished} \u0026lt;-------- [Application Data*] {Certificate*} {CertificateVerify*} {Finished} --------\u0026gt; [Application Data] \u0026lt;-------\u0026gt; [Application Data] Figure 2: Message Flow for a Full Handshake with Mismatched Parameters 注意：握手抄本（transcript）包含了最初的ClientHello/HelloRetryRequest交换；它不会随着新的ClientHello而重置。\nTLS也允许多种基本握手的优化方案，如下描述：\n2.2 复用和Pre-Shared Key(PSK) # 尽管TLS PSK可以通过带外数据建立，但PSK也可以在先前的连接中建立，然后用来建立新的连接（\u0026ldquo;会话恢复 \u0026ldquo;或 \u0026ldquo;使用PSK恢复\u0026rdquo;）。 一旦握手完成，服务器可以向客户端发送一个PSK身份，该身份对应于从初始握手流程中导出的唯一密钥（见4.6.1节）。 然后，客户端可以在未来的握手中使用该PSK身份来协商相关PSK的使用。 如果服务器接受了PSK，那么新连接的安全上下文就会与原始连接进行加密绑定，并且从初始握手中得到的密钥会被用来加速加密的计算过程，从而免于完全握手。 在TLS 1.2及早期版本中，这个功能由 \u0026ldquo;会话ID \u0026ldquo;和 \u0026ldquo;会话票据\u0026rdquo;[RFC5077]提供。 在TLS 1.3中，这两种机制都被淘汰了。\nPSK可以与(EC)DHE密钥交换一起使用，以便与shared keys拓展提供的共享秘钥相结合提供前向保密，也可以单独使用，但代价是失去应用数据的前向保密性。\n图三展示了PSK的颁发和PSK的使用。\nClient Server Initial Handshake: ClientHello + key_share --------\u0026gt; ServerHello + key_share {EncryptedExtensions} {CertificateRequest*} {Certificate*} {CertificateVerify*} {Finished} \u0026lt;-------- [Application Data*] {Certificate*} {CertificateVerify*} {Finished} --------\u0026gt; \u0026lt;-------- [NewSessionTicket] [Application Data] \u0026lt;-------\u0026gt; [Application Data] Subsequent Handshake: ClientHello + key_share* + pre_shared_key --------\u0026gt; ServerHello + pre_shared_key + key_share* {EncryptedExtensions} {Finished} \u0026lt;-------- [Application Data*] {Finished} --------\u0026gt; [Application Data] \u0026lt;-------\u0026gt; [Application Data] Figure 3: Message Flow for Resumption and PSK 由于服务器是通过PSK进行认证的，所以它不会发送证书或证书验证消息。 当客户机通过PSK尝试复用连接时，它还应该向服务器提供一个 \u0026ldquo;key_share \u0026ldquo;扩展，以允许服务器拒绝复用，从而能够在需要时回退到完整握手。 服务器用回复\u0026quot;pre_shared_key \u0026ldquo;扩展来协商使用PSK机制，并可以（如这上所示）用 \u0026ldquo;key_share \u0026ldquo;扩展来响应，从而结合（EC）DHE密钥协商，提供前向保密。\n当使用带外数据分发PSK时，PSK的身份和秘钥衍生算法必须兼容。\n注意：当使用带外提供的预共享秘密时，一个重要的考虑因素是在密钥生成过程中使用足够的熵，如[RFC4086]中所讨论的那样。 从密码或其他低熵来源导出共享秘密是不安全的。 低熵秘密或密码会受到基于PSK binder的字典攻击。 指定的PSK认证即使与Diffie-Hellman密钥建立一起使用，也不是一种基于密码的强认证密钥交换。 具体来说，它不能阻止能够观察到握手的攻击者对密码/预共享密钥进行蛮力攻击。\n2.3 0-RTT数据 # 当客户端和服务器通过共享一个PSK（从外部获得或通过之前的握手）建立连接时，TLS 1.3允许客户端在第一次飞行时发送数据（\u0026ldquo;early data\u0026rdquo;）。 客户端使用PSK对服务器进行认证，并对early data进行加密。\n如图4所示，0-RTT数据直接附加到第一趟发送的1-RTT握手中。 握手的其余部分与PSK复用的1-RTT握手相同的消息。\nClient Server ClientHello + early_data + key_share* + psk_key_exchange_modes + pre_shared_key (Application Data*) --------\u0026gt; ServerHello + pre_shared_key + key_share* {EncryptedExtensions} + early_data* {Finished} \u0026lt;-------- [Application Data*] (EndOfEarlyData) {Finished} --------\u0026gt; [Application Data] \u0026lt;-------\u0026gt; [Application Data] + Indicates noteworthy extensions sent in the previously noted message. * Indicates optional or situation-dependent messages/extensions that are not always sent. () Indicates messages protected using keys derived from a client_early_traffic_secret. {} Indicates messages protected using keys derived from a [sender]_handshake_traffic_secret. [] Indicates messages protected using keys derived from [sender]_application_traffic_secret_N. Figure 4: Message Flow for a 0-RTT Handshake 重要提示：0-RTT数据的安全属性比其他类型的TLS数据要弱。 具体来说，0-RTT数据的安全属性要弱于其他类型的TLS数据：\n这些数据不提供前向安全的保障，因为它只使用所提供的PSK衍生的秘钥进行加密。 0-RTT并不抗虫方。对于普通的TLS 1.3 1-RTT数据的重放保护是通过服务器发送的Random值提供的，但是0-RTT数据不依赖于ServerHello，因此无法抗重放。如果数据是和TLS客户端认证或在应用协议内部认证相关，这一点就变得至关重要。 同样的警告适用于任何使用early_exporter_master_secret的情况。 0-RTT数据不能在一个连接内重放（即服务器不会对同一个连接处理两次相同的数据），攻击者也无法使0-RTT数据看起来是1-RTT数据（因为它受到不同密钥的保护）。 附录E.5包含了对潜在攻击的描述，第8节描述了服务器可以用来限制重放影响的机制。\n3 # 这部分我推荐不要看了，我没好好翻译，随便找了一个工具机器翻译的，没做校对，我把第四章翻译完了再回来改\n该部分重点介绍如何组织（格式化）数据，组织数据的过程可以视为一些基本的关键名词，讲解协议的时候会使用这些基本的关键名词。（可以视为函数）\n3.1 基本数据块大小 # 所有数据项的表示形式都是明确指定的。基本的数据块大小为一个字节（即8位）。多字节数据项是从左到右、从上到下的字节串联。从字节流中，多字节项（以下示例中的数字）通过以下方式形成（使用C语言表示法）：\nvalue = (byte[0] \u0026lt;\u0026lt; 8*(n-1)) | (byte[1] \u0026lt;\u0026lt; 8*(n-2)) | ... | byte[n-1]; 这种多字节值的字节顺序是通常的网络字节顺序或大端序列。\n3.2 杂项 # 这里给出一些相关的解释，\n注释以“/*”开始并以“*/”结束，这个和C语言是一样的。 可选组件用“[[ ]]”（双括号）括起来表示。 单字节实体的类型为opaque。 3.3. 数字 # 最基本的数字数据类型是无符号字节（uint8）。\n所有更大的数字数据类型都是无符号类型，且都由uint8拼接构成的，如3.1节所述。预定义以下数字类型：\nuint8 uint16[2]; uint8 uint24[3]; uint8 uint32[4]; uint8 uint64[8]; RFC里面所有的数字都以网络字节（大端）顺序传输；例如由十六进制字节01 02 03 04表示的uint32等于十进制值16909060。\n3.4. 向量 # 向量（或者说单维数组）是一串同类数据元素。向量的大小可以在文档编写时指定，或在运行时才确定。请注意，无论哪种情况，生命的长度都是向量的长度，而不是向量里面存储的元素数。指定一个新的类型T\u0026rsquo;作为固定长度的类型T的向量的语法是：\nT T\u0026#39;[n]; 这里，T\u0026rsquo;在数据流中占用n个字节，其中n是T的大小的倍数。向量的长度不包括在编码流中。\n在以下示例中，Datum被定义为协议不解释的三个连续字节，而Data是三个连续的Datum，总共消耗九个字节。\nopaque Datum[3]; /* 三个未解释的字节 */ Datum Data[9]; /* 三个连续的3字节向量 */ 变长向量通过指定一个合法长度的子范围（包括两端），使用\u0026lt;floor..ceiling\u0026gt;符号来定义。在编码时，实际长度位于向量内容之前。长度将采用一个数字形式，消耗所需的字节数，以容纳向量的指定最大（上限）长度。实际长度字段为零的变长向量称为空向量。\nT T\u0026#39;\u0026lt;floor..ceiling\u0026gt;; 在以下示例中，“mandatory”是一个必须包含300到400字节的类型为opaque的向量。它永远不能为空。实际长度字段占用两个字节，即uint16，这足以表示400值（见3.3节）。同样，“longer”最多可以表示800字节的数据，或400个uint16元素，它可以为空。其编码将包括一个前置于向量的两个字节实际长度字段。编码的向量长度必须是单个元素长度的整数倍（例如，17字节的uint16向量是非法的）。\nopaque mandatory\u0026lt;300..400\u0026gt;; /* 长度字段是两个字节，不能为空 */ uint16 longer\u0026lt;0..800\u0026gt;; /* 零到400个16位无符号整数 */ 3.5. 枚举\n一种额外的稀疏数据类型称为“枚举”或“enumerated”。每个定义都是一个不同的类型。只有相同类型的枚举才能分配或比较。枚举的每个元素必须赋予一个值，如以下示例所示。由于枚举的元素没有顺序，可以按任何顺序分配任何唯一值。\nenum { e1(v1), e2(v2), ... , en(vn) [[, (n)]] } Te; 协议的未来扩展或补充可以定义新的值。实现需要能够解析和忽略未知的值，除非字段的定义另有说明。\n一个枚举在字节流中占据的空间与其最大定义的序数值相同。以下定义将导致使用一个字节来承载类型Color的字段。\nenum { red(3), blue(5), white(7) } Color; 可以选择指定一个没有关联标签的值，以在不定义多余元素的情况下强制宽度定义。\n在以下示例中，Taste将在数据流中占用两个字节，但在当前版本的协议中只能取值1、2或4。\nenum { sweet(1), sour(2), bitter(4), (32000) } Taste; 枚举元素的名称在定义的类型内限定。在第一个示例中，对枚举第二个元素的完全限定引用将是Color.blue。如果赋值目标明确，则不需要这种限定。\nColor color = Color.blue; /* 过度指定，合法 */ Color color = blue; /* 正确，类型隐式 */ 分配给枚举的名称不需要是唯一的。数值可以描述同一名称适用的范围。值包括该范围的最小和最大包含值，由两个句点字符分隔。这主要用于保留空间区域。\nenum { sad(0), meh(1..254), happy(255) } Mood; 3.6. 结构类型\n结构类型可以从基本类型构造，以方便使用。每个规范声明一种新的、唯一的类型。定义所用的语法类似于C语言。\nstruct { T1 f1; T2 f2; ... Tn fn; } T; 使用标准向量语法允许固定和变长向量字段。变体示例中（3.8节）的结构V1和V2示范了这一点。\n结构中的字段可以使用类型名称限定，其语法类似于枚举。例如，T.f2指的是前述声明中的第二个字段。\n3.7. 常量\n字段和变量可以用“=”分配一个固定值，如：\nstruct { T1 f1 = 8; /* T.f1必须始终为8 */ T2 f2; } T; 3.8. 变体\n定义的结构可以基于环境中可用的某些知识具有变体。选择器必须是一个枚举类型，定义结构所定义的可能变体。选择的每个分支（如下）指定该变体字段的类型和一个可选的字段标签。变体在运行时的选择机制不由表示语言规定。\nstruct { T1 f1; T2 f2; .... Tn fn; select (E) { case e1: Te1 [[fe1]]; case e2: Te2 [[fe2]]; .... case en: Ten [[fen]]; }; } Tv; 例如：\nenum { apple(0), orange(1) } VariantTag; struct { uint16 number; opaque string\u0026lt;0..10\u0026gt;; /* 变长 */ } V1; struct { uint32 number; opaque string[10]; /* 固定长度 */ } V2; struct { VariantTag type; select (VariantRecord.type) { case apple: V1; case orange: V2; }; } VariantRecord; 4 握手协议 # 握手协议用于协商连接的安全参数。握手消息基于TLS Recordlayer，Record Layer将握手协议封装为一个或多个TLS明文或TLS秘文报文（结构）。这些报文（结构）如何处理，传输需要根据当前握手协议的状态确定\nenum { client_hello(1), server_hello(2), new_session_ticket(4), end_of_early_data(5), encrypted_extensions(8), certificate(11), certificate_request(13), certificate_verify(15), finished(20), key_update(24), message_hash(254), (255) } HandshakeType; struct { HandshakeType msg_type; /* handshake type */ uint24 length; /* remaining bytes in message */ select (Handshake.msg_type) { case client_hello: ClientHello; case server_hello: ServerHello; case end_of_early_data: EndOfEarlyData; case encrypted_extensions: EncryptedExtensions; case certificate_request: CertificateRequest; case certificate: Certificate; case certificate_verify: CertificateVerify; case finished: Finished; case new_session_ticket: NewSessionTicket; case key_update: KeyUpdate; }; } Handshake; 协议消息必须按照特定顺序发送，可参考4.4.1节中定义的顺序发送或参考第2节中的图所示。如果接受到不符合顺序的握手消息，对端需要发送“unexpected_message”警报中止握手。\n新的握手消息类型由IANA根据第11节中描述的分配。\n4.1 密钥交换消息 # 密钥交换消息用于确定客户端和服务端的安全能力，从而建立共享的密钥信息，这里包括用于保护握手过程和数据通信的通信密钥。（除了这个密钥还有复用密钥啥的）\n4.1.1. 密码协商 # 在TLS中，密码协商的过程需要客户端在其ClientHello消息中提供以下四组信息（选项）：\n一系列密码套件组成的列表，指示客户端支持的AEAD算法/HKDF密钥延生算法。 一个“supported_groups”（第4.2.7节）扩展，指示客户端支持的（EC）DHE组，以及一个“key_share”（第4.2.8节）扩展，包含这些组中一些或全部的计算得出的（EC）DHE共享密钥信息（对ECDHE可以理解为公钥乘以极点，就是大质数乘以基点）。 一个“signature_algorithms”（第4.2.3节）扩展，指示客户端可以接受的签名算法（用于certificate verify消息）。还可以添加一个“signature_algorithms_cert”扩展（第4.2.3节），指示特定支持的证书的签名算法。 一个“pre_shared_key”（第4.2.11节）扩展，包含客户端已知的对称密钥标识列表，以及一个“psk_key_exchange_modes”（第4.2.9节）扩展，指示可与PSK一起使用的密钥交换模式。 如果服务器不选择PSK，那么这前三个选项是完全独立的：服务器独立地选择一个密码套件、一个（EC）DHE组和用于密钥协商的共享密钥（key share），以及一个签名算法/证书对用于向客户端验证其身份。如果接收到的“supported_groups”和服务器支持的组之间没有重叠，服务器必须用“handshake_failure”或“insufficient_security”警报中止握手。\n如果服务器选择了PSK，则它还必须从客户端的“psk_key_exchange_modes”扩展中指示的集合中选择一个密钥建立模式（目前仅支持只使用PSK或将PSK与（EC）DHE一起使用）。请注意，如果PSK可以在没有（EC）DHE的情况下使用，那么服务端“supported_groups”参数中和客户端不重叠并不致命，这与前一段讨论的非PSK情况即（EC）DHE握手的情况不同。\n如果服务器选择了一个（EC）DHE组，而客户端在初始的ClientHello中没有提供兼容的“key_share”扩展，服务器必须响应一个HelloRetryRequest（第4.1.4节）消息。如果服务器成功选择参数并且不需要HelloRetryRequest，它将在ServerHello中指示所选参数如下：\n如果使用了PSK，服务器将发送一个“pre_shared_key”扩展，指示所选的密钥。 当使用（EC）DHE时，服务器还将提供一个“key_share”扩展。如果未使用PSK，则（EC）DHE和基于证书的身份验证就会被采用。 在通过证书进行身份验证时，服务器将发送Certificate（第4.4.2节）和CertificateVerify（第4.4.3节）消息。在本文档定义的TLS 1.3中，要么使用PSK或证书来进行认证，但两者不同时使用。将来的文档可能会定义如何同时使用它们。 如果服务器无法协商一组支持的参数（比方说，客户端和服务器参数之间没有重叠），它必须用“handshake_failure”或“insufficient_security”的致命警报中止握手（见第6节）。\n4.1.2 Client Hello # 当客户端首次连接到服务器时，必须将 ClientHello 作为其第一条 TLS 消息发送。当服务器对其 ClientHello 响应为 HelloRetryRequest 时，客户端也会发送 ClientHello。在这种情况下，客户端必须发送相同的未修改的 ClientHello，除非出现如下情况：\n如果在 HelloRetryRequest 中提供了“key_share”扩展，则应使用指定组的单个 KeyShareEntry 来替换原本的共享列表。 如果存在“early_data”扩展（第 4.2.10 节），则将其删除。在收到HelloRetryRequest 之后不允许发送early data。 倘若HelloRetryRequest里存在cookie拓展 如果存在“pre_shared_key”扩展，则需要重新计算“obfuscated_ticket_age”和binder的值来更新它，并（可选）删除与服务器指示的密码套件不兼容的任何 PSK。 （可选）添加、删除或更改“padding”扩展的长度[RFC7685]。 在 HelloRetryRequest 中定义且存在的扩展可能允许的其他修改。 因为 TLS 1.3 禁止重新协商，如果服务器已协商 TLS 1.3 并在任何其他时间收到 ClientHello，必须使用“意外消息”警报终止连接。\n如果服务器使用之前版本的 TLS 建立了 TLS 连接，并在重新协商中收到 TLS 1.3 的 ClientHello，它必须保留之前的协议版本。千万，不能协商 TLS 1.3\n该消息的结构如下：\nuint16 ProtocolVersion; opaque Random[32]; uint8 CipherSuite[2]; /* Cryptographic suite selector */ struct { ProtocolVersion legacy_version = 0x0303; /* TLS v1.2 */ Random random; opaque legacy_session_id\u0026lt;0..32\u0026gt;; CipherSuite cipher_suites\u0026lt;2..2^16-2\u0026gt;; opaque legacy_compression_methods\u0026lt;1..2^8-1\u0026gt;; Extension extensions\u0026lt;8..2^16-1\u0026gt;; } ClientHello; 字段的含义：\n遗留版本（legacy_version）：在之前的 TLS 版本中，此字段用于版本协商，并表示客户端支持的最高版本号。经验表明，许多服务器并不能正确实现版本协商，导致“版本零容忍”BUG，即服务器拒绝版本号比它高的 ClientHello。在 TLS 1.3 中，客户端在“supported_versions”扩展（第 4.2.1 节）中表明其版本偏好，并且遗留版本字段必须设置为 0x0303，这是 TLS 1.2 的版本号。TLS 1.3 的 ClientHellos 必须具有 0x0303 的遗留版本字段，且携带 supported_versions 扩展，拓展里指示的最高版本为 0x0304。（有关向后兼容性的详细信息，请参阅附录 D）\n随机数：由安全随机数生成器生成的 32 字节。 有关其他信息，请参阅附录 C。\n遗留会话 ID：TLS 1.3 之前的版本支持“会话恢复”功能，此功能在该版本中已与预共享密钥机制（PSK）合并（见第 2.2 节）。由 TLS 1.3 之前的服务器设置了缓存会话 ID 的客户端应将此字段设置为该值。在兼容模式下（见附录 D.4），此字段不能为空，因此不提供 TLS 1.3 之前会话的客户端必须生成一个新的 32 字节值。此值不必是随机的，但应是不可预测的，以避免实现固定在特定值上（也称为僵化）。否则，它必须设置为零长度向量（即，零值的单字节长度字段）。 密码套件：客户端支持的对称密码选项列表，特别是record layer保护算法（包括密钥长度）和用于 HKDF 的哈希算法，按照客户端偏好降序排列。值在附录 B.4 中定义。如果列表包含服务器不识别、不支持或不想使用的密码套件，服务器必须忽略这些密码套件，并像往常一样处理其余的套件。如果客户端正在尝试 PSK 密钥建立，它应至少提供一个包含可以与 PSK 可以关联使用哈希算法的密码套件。\n遗留压缩方法：TLS 1.3 之前的版本支持压缩，支持的压缩方法列表在此字段中发送。对于每个 TLS 1.3 的 ClientHello，此向量必须恰好包含一个设置为零的字节，对应于之前版本 TLS 中的“空”压缩方法，或者说不压缩。如果收到的 TLS 1.3 的 ClientHello 在此字段中有任何其他值，服务器必须使用“非法参数”警报中止握手。请注意，TLS 1.3 服务器可能会收到包含其他压缩方法的 TLS 1.2 或之前的 ClientHellos，并且（如果协商这样的先前版本）必须遵循相应的先前版本 TLS 的程序。\n扩展：客户端通过在扩展字段中发送数据向服务器请求扩展功能。实际的“扩展”格式在第 4.2 节中定义。在 TLS 1.3 中，某些扩展的使用是强制性的，一些功能通过移至扩展来使得ClientHello可以与历史版本 TLS 兼容性（从而老版本的TLS服务器也可以正确协商出老版本TLS）。服务器必须忽略无法识别的扩展。\nTLS 的所有版本都允许扩展字段可选地跟随压缩方法字段。TLS 1.3 的 ClientHello 消息始终包含扩展（起码包括“支持的版本supported_versions”，否则，它们将被解释为 TLS 1.2 的 ClientHello 消息）。然而，TLS 1.3 服务器可能会收到来自之前版本 TLS 的没有扩展字段的 ClientHello 消息。扩展的存在可以通过确定在 ClientHello 末尾的压缩方法字段之后检查是否还有字节来检测。请注意，这种检测可选数据的方法不同于具有可变长度字段的正常 TLS 方法，但它用于在定义扩展之前与 TLS 兼容。TLS 1.3 服务器首先需要执行此检查，并且只有在“supported_versions”扩展存在时才尝试协商 TLS 1.3。如果协商的是 TLS 1.3 之前的版本，服务器必须检查消息在legacy_compression_methods字段之后要么不包含数据，要么只包含一个有效的扩展块且之后没有数据。如果不是，则必须使用“解码错误”警报中止握手。\n如果客户端使用扩展请求额外的功能，而服务器未提供此功能，客户端可以中止握手。\n发送 ClientHello 消息后，客户端等待 ServerHello 或 HelloRetryRequest 消息。如果客户端选用early data功能，客户端在等待下一个握手消息时可以传输early data（第 2.3 节）。\n4.1.3 Server Hello # 如果可以和客户端的ClientHello协商出一组可接受的握手参数，服务器将发送ServerHello消息以响应ClientHello，继续进行握手。该消息的结构如下\nstruct { ProtocolVersion legacy_version = 0x0303; /* TLS v1.2 */ Random random; opaque legacy_session_id_echo\u0026lt;0..32\u0026gt;; CipherSuite cipher_suite; uint8 legacy_compression_method = 0; Extension extensions\u0026lt;6..2^16-1\u0026gt;; } ServerHello; 遗留版本字段：在早期的 TLS 版本中，此字段用于版本协商：表示服务端接受客户端ClientHello之后所选的版本号。不幸的是，在TLS1.3之后，某些网络中间设备（路由器啦，交换机啦）并不支持新的Value值。在 TLS 1.3 中，TLS 服务器使用“supported_versions”扩展（第 4.2.1 节）指示其版本，遗留版本字段不在真正生效，但是必须设置为 0x0303，这是 TLS 1.2 的版本号。（有关向后兼容性的详细信息，请参阅附录 D）\n随机数字段：由安全随机数生成器生成的 32 字节随机数。 请参阅附录 C获取更多信息。 如果协商 TLS 1.2 或 TLS 1.1，最后 8 字节必须按下面所述的内容进行覆盖，但其余字节必须是随机的。 这部分数据由服务器生成，并且必须独立于 ClientHello.random 生成。\n遗留session_id回显字段：兼容性角度出发，用于兼容客户端遗留session_id 字段。请注意，即使服务器选择不恢复的 TLS 1.3 之前的会话，客户端的值也应该被回显。如果客户端收到与在 ClientHello 中发送的不匹配的session_id，客户端必须使用“非法参数”警报中止握手。\n密码套件：服务器从 ClientHello.cipher_suites 列表中选择的单个密码套件。收到未提供的密码套件的客户端必须使用“非法参数”警报中止握手。\n遗留压缩方法字段：单个字节，内容为0x00\n扩展：扩展列表。ServerHello必须仅包含建立加密上下文和协商协议版本所需的扩展。所有 TLS 1.3 服务器问候消息必须包含“supported_versions”（支持的版本）扩展。当前ServerHello消息可以另外包含“pre_shared_key”（预共享密钥）扩展或“key_share”（密钥共享）扩展，或者两者都有（当使用带有 (EC)DHE 密钥建立的 PSK 时）。其他扩展（见第 4.2 节）在EncryptedExtensions消息中单独发送。\n出于与网络中间设备的后向兼容性原因（见附录 D.4），HelloRetryRequest 的结构和 ServerHello 一致，唯一不同点是必须将 Random 设置为“HelloRetryRequest”的 SHA-256 哈希值，就是：\nCF 21 AD 74 E5 9A 61 11 BE 1D 8C 02 1E 65 B8 91\nC2 A2 11 16 7A BB 8C 5E 07 9E 09 E2 C8 A8 33 9C\n客户端收到类型为 server_hello 的消息后，必须先检查 Random 值，如果它与此值匹配，则按照第 4.1.4 节中的描述进行处理。\nTLS 1.3 在服务器的随机值中嵌入了降级保护机制。TLS1.3服务器，如果和客户端协商 TLS 1.2 或更低版本的 TLS 1.3 服务器必须在其 ServerHello 中特别设置其 Random 值的最后 8 个字节为特定的内容：\n如果协商 TLS 1.2，TLS 1.3 服务器必须将其 Random 值的最后 8 个字节设置为：\n44 4F 57 4E 47 52 44 01\n如果协商 TLS 1.1 或更低版本，TLS 1.3 服务器必须将其 ServerHello.Random 值的最后 8 个字节设置为：\n44 4F 57 4E 47 52 44 00\nTLS 1.3 客户端和TLS1.3服务器协商时，必须检查最后 8 个字节不等于这两个值中的任何一个。如果 ServerHello 指示 TLS 1.1 或更低版本，TLS 1.2 客户端也应该检查最后 8 个字节不等于第二个值。如果发现匹配，客户端必须使用“illegal_parameter”警报中止握手。\n此机制提供了针对降级攻击的些许保护能力：因为在 TLS 1.2 及更低版本中存在的 ServerKeyExchange 消息包含对两个随机值的签名，只要使用临时密钥协商的技术（就是（EC）DHE每次交换不用固定密钥，用随机生成的），主动攻击者就不可能在未被检测到的情况下修改随机值。但在使用静态 RSA 时，它不提供降级保护。\n注意：这与[RFC5246]并不完全一致，因此实际上许多 TLS 1.2 客户端和服务器不会按照上述规定行事。\n使用 TLS 1.2 或更早版本进行重新协商的TLS 客户端，如果在重新协商期间收到 TLS 1.3 ServerHello，则必须使用“protocol_version”警报中止握手。这里之所以没提TLS1.3，是因为协商了 TLS 1.3 时，重新协商是不可能的。\n4.1.4. Hello Retry Request\n如果服务器在客户端的ClientHello能够找到双方共享的通信算法和密钥之类的数据，但 ClientHello 不包含足够的信息来继续握手，则服务器将响应 Hello Retry Request 消息发送此消息。如第 4.1.3 节所述，HelloRetryRequest 具有与 ServerHello 消息相同的格式，并且 legacy_version、legacy_session_id_echo、cipher_suite 和 legacy_compression_method 字段具有相同的含义。但是，为了方便起见，在本RFC中我们将“HelloRetryRequest”视为一个不同的消息进行讨论。\n\u0026hellip; （未完成，感觉不是特别重要，先省略）\n4.2 拓展 # (这部分是个大头)一系列的TLS消息包含拓展，拓展的结构和类型如下。这里注意：\n“extension_type”（扩展类型）标识特定的扩展类型。 “extension_data”（扩展数据）包含特定于该特定扩展类型的信息。 struct { ExtensionType extension_type; opaque extension_data\u0026lt;0..2^16-1\u0026gt;; } Extension; enum { server_name(0), /* RFC 6066 */ max_fragment_length(1), /* RFC 6066 */ status_request(5), /* RFC 6066 */ supported_groups(10), /* RFC 8422, 7919 */ signature_algorithms(13), /* RFC 8446 */ use_srtp(14), /* RFC 5764 */ heartbeat(15), /* RFC 6520 */ application_layer_protocol_negotiation(16), /* RFC 7301 */ signed_certificate_timestamp(18), /* RFC 6962 */ client_certificate_type(19), /* RFC 7250 */ server_certificate_type(20), /* RFC 7250 */ padding(21), /* RFC 7685 */ pre_shared_key(41), /* RFC 8446 */ early_data(42), /* RFC 8446 */ supported_versions(43), /* RFC 8446 */ cookie(44), /* RFC 8446 */ psk_key_exchange_modes(45), /* RFC 8446 */ certificate_authorities(47), /* RFC 8446 */ oid_filters(48), /* RFC 8446 */ post_handshake_auth(49), /* RFC 8446 */ signature_algorithms_cert(50), /* RFC 8446 */ key_share(51), /* RFC 8446 */ (65535) } ExtensionType; 尽管有些扩展只是指示，并不需要相应的响应，扩展扔通常以请求/响应的方式构建。客户端在 ClientHello 消息中发送其扩展请求，服务器在ServerHello、EncryptedExtensions、HelloRetryRequest 和 Certificate消息中发送这些扩展的响应。服务器在CertificateRequest 消息中发送扩展请求，客户端可能会回复Certificate 消息。服务器也可能发送NewSessionTicket报文，报文里面的拓展是一个“无头”拓展，客户端也不会对此给出任何响应。\n如果对端未发送相应扩展请求，本端绝不能发送扩展响应，HelloRetryRequest 中的“cookie”扩展除外。遇到这种情况时，必须以“unsupported_extension”警报中止握手。\n下表使用以下符号指示给定扩展可能出现在消息：CH（ClientHello）、SH（ServerHello）、EE（EncryptedExtensions）、CT（Certificate）、CR（CertificateRequest）、NST（NewSessionTicket）和HRR（HelloRetryRequest）。如果实现收到其识别但未在其出现的消息中指定的扩展，则必须以“illegal_parameter”警报中止握手。\n+--------------------------------------------------+-------------+ | Extension | TLS 1.3 | +--------------------------------------------------+-------------+ | server_name [RFC6066] | CH, EE | | | | | max_fragment_length [RFC6066] | CH, EE | | | | | status_request [RFC6066] | CH, CR, CT | | | | | supported_groups [RFC7919] | CH, EE | | | | | signature_algorithms (RFC 8446) | CH, CR | | | | | use_srtp [RFC5764] | CH, EE | | | | | heartbeat [RFC6520] | CH, EE | | | | | application_layer_protocol_negotiation [RFC7301] | CH, EE | | | | | signed_certificate_timestamp [RFC6962] | CH, CR, CT | | | | | client_certificate_type [RFC7250] | CH, EE | | | | | server_certificate_type [RFC7250] | CH, EE | | | | | padding [RFC7685] | CH | | | | | key_share (RFC 8446) | CH, SH, HRR | | | | | pre_shared_key (RFC 8446) | CH, SH | | | | | psk_key_exchange_modes (RFC 8446) | CH | | | | | early_data (RFC 8446) | CH, EE, NST | | | | | cookie (RFC 8446) | CH, HRR | | | | | supported_versions (RFC 8446) | CH, SH, HRR | | | | | certificate_authorities (RFC 8446) | CH, CR | | | | | oid_filters (RFC 8446) | CR | | | | | post_handshake_auth (RFC 8446) | CH | | | | | signature_algorithms_cert (RFC 8446) | CH, CR | +--------------------------------------------------+-------------+ 当存在多种不同类型的扩展时，这些扩展可以以任意顺序排列，但“pre_shared_key”（第 4.2.11 节）除外，它必须是 ClientHello 中的最后一个扩展（但可以出现在 ServerHello 扩展块中的任何位置）。在给定的扩展块中，同一类型的扩展绝不能出现多次\n和TLS 1.2 不同，在 TLS 1.3 中，即使在复用PSK 模式下，每次握手都会重新协商扩展。当然，0-RTT 参数是在上一次握手中协商的；如果发现本次握手的信息和上次0-RTT不匹配，服务端可能会拒绝 0-RTT（见第 4.2.10 节）。\n在TLS1.3中，新特性和已有特性之间可能会发生微妙（当然影响可能是巨大的，也不是多么微妙）的相互作用，这可能会导致整体安全性显著降低。所以在设计新扩展时，应考虑以下设计原则：\n有时，服务器不同意某个扩展的某些情况（比方说导致握手无法继续）应当视为出现错误，另外一些时候，服务端应该只是简单地拒绝支持特定功能。一般来说，对于前者应使用错误警报终止连接，对于后者应使用服务器扩展响应中的字段。 扩展应尽可能设计为不能通过操纵握手消息来强制使用（或不使用）特定功能的任何攻击。无论该功能是否被认为会导致安全问题，新拓展的设计者都应遵循这一原则。通常，只要计算Finished 报文哈希的时候会将扩展字段包含在输入里就够了，但当扩展改变握手阶段发送的消息的含义时，需要格外小心。设计者和实现者应意识到，在握手经过严格的认证之前（这里可不只是身份认证），主动攻击者可以修改消息、插入、删除或替换扩展。 （我理解最后这两个是针对协议实现者和设计者，避免出现中间件兼容性问题考虑的）\n4.2.1 Supported Versions 拓展 # struct { select (Handshake.msg_type) { case client_hello: ProtocolVersion versions\u0026lt;2..254\u0026gt;; case server_hello: /* and HelloRetryRequest */ ProtocolVersion selected_version; }; } SupportedVersions; 客户端发送“supported_versions”扩展用于指示其支持的 TLS 版本，服务器发送“supported_versions”扩展用于指示本次会话要使用的TLS版本。该扩展内容为按优先顺序排列的支持版本列表，最优先的版本排在首位。任何实现本RFC的TLS协议栈必须在“ClientHello”中发送包含它准备协商的所有 TLS 版本信息（这意味着至少提供版本号为0x0304，但如果客户端支持协商之前的 TLS 版本，它们也必须一并发送在该拓展的内容里）。\n如果该拓展没发送，即使客户端的ClientHello在遗留历史字段里面指明它想协商TLS1.3（0x0304)，如果服务器支持TLS1.3标准同时支持TLS1.2协议，那么该服务器必须参考RFC5246协商版本为TLS1.2或者之前的版本。\n如果 ClientHello 中携带supported_versions扩展，则服务器不得使用ClientHello.legacy_version（历史遗留版本字段）值用于版本协商，而必须仅参考“supported_versions”扩展来确定客户端对版本的偏好设置。服务器必须仅选择supported_versions”里包含的 TLS 版本，并且忽略任何服务器不认识的版本。请注意，此机制使得如果双方支持多版本的TLS的话，则有可能会协商 TLS 1.2或之前的版本，服务器必须准备好接收客户端的ClientHello包含supported_versions，但版本列表中不包括 0x0304。\n如果服务器选择 TLS 1.3 之前的 TLS 版本握手，那么服务器必须设置其ServerHello.version，并且绝不能发送“supported_versions”扩展。服务器如果协商 TLS 1.3则必须通过发送包含所选版本值（0x0304）的“supported_versions”扩展来响应CLientHello，且必须将 ServerHello.legacy_version 字段设置为 0x0303（TLS 1.2）。客户端在处理 ServerHello 的其余部分之前必须检查此扩展（尽管他们将不得不解析 ServerHello 以读取扩展）。如果此扩展存在，客户端必须忽略 ServerHello.legacy_version 值，并且必须仅使用“supported_versions”扩展来确定所选版本。如果 ServerHello 中的“supported_versions”扩展包含客户端未提供的版本或包含 TLS 1.3 之前的版本，客户端必须使用“illegal_parameter”警报中止握手。\n4.2.2 Cookie # struct { opaque cookie\u0026lt;1..2^16-1\u0026gt;; } Cookie; Cookie 有两个主要用途：\n允许服务器强制客户端在其明显的网络地址上证明可达性（从而提供一定程度的拒绝服务保护）。对于非面向连接的传输起作用（有关此示例，请参见[RFC6347]）。 允许服务器将状态卸载到客户端，从而允许其在不存储任何状态的情况下发送 HelloRetryRequest（这样子服务端完全可以啥都不存储了）。服务器可以通过在 HelloRetryRequest Cookie 中存储 ClientHello 的哈希值（使用某些完整性保护算法进行保护）来实现此目的。 当发送 HelloRetryRequest 时，服务器可以向客户端提供“cookie”扩展（注意哈，通常是只有在 ClientHello 中出现的扩展才服务端回应时才可以发送，这是个例外，）。客户端发送新的 ClientHello 时，必须将在 HelloRetryRequest 中接收到的cookie扩展内容复制到新的 ClientHello 中的“cookie”扩展中。后面如果还有握手，客户端发送的新握手的 ClientHello 中不得包含 cookie。\n当服务器以无状态方式运行时，它可能会在第一个和第二个 ClientHello 之间收到未受保护的 change_cipher_spec 类型的记录（见第 5 节）。由于服务器未存储任何状态，这将看起来像是收到的第一条消息。以无状态方式运行的服务器必须忽略这些记录。\n4.2.3 Signature Algorithms # TLS 1.3 提供了两个扩展来指示涉及到签名验签中可以使用的签名算法。“signature_algorithms_cert”扩展指明适用于证书中的签名算法，而最初出现在 TLS 1.2 中的“signature_algorithms”扩展适用于 CertificateVerify 消息中的签名算法。证书中的密钥还必须与它们所使用的签名算法的类型相匹配。对于 RSA 密钥和 PSS 签名，有个特殊事项要注意，下面会描述。如果不存在“signature_algorithms_cert”扩展，则“signature_algorithms”扩展里面的算法同时指代适用于证书中出现的签名算法。希望服务器通过证书进行身份验证的客户端必须发送“signature_algorithms”扩展。如果服务器通过证书进行身份验证而客户端未发送“signature_algorithms”扩展，则服务器必须使用“missing_extension”警报中止握手（见第 9.2 节）。\n添加“signature_algorithms_cert”扩展是为了两个目的：1 TLS协议本身清晰地表明其能力 2 允许证书支持和signature_algorithms不同的算法集。TLS 1.2 实现也应该处理此扩展。两个拓展内容一致的话，可以省略“signature_algorithms_cert”发送\n两种扩展的“extension_data”字段包含这些SignatureSchemeList 里面的值：\nenum { /* RSASSA-PKCS1-v1_5 algorithms */ rsa_pkcs1_sha256(0x0401), rsa_pkcs1_sha384(0x0501), rsa_pkcs1_sha512(0x0601), /* ECDSA algorithms */ ecdsa_secp256r1_sha256(0x0403), ecdsa_secp384r1_sha384(0x0503), ecdsa_secp521r1_sha512(0x0603), /* RSASSA-PSS algorithms with public key OID rsaEncryption */ rsa_pss_rsae_sha256(0x0804), rsa_pss_rsae_sha384(0x0805), rsa_pss_rsae_sha512(0x0806), /* EdDSA algorithms */ ed25519(0x0807), ed448(0x0808), /* RSASSA-PSS algorithms with public key OID RSASSA-PSS */ rsa_pss_pss_sha256(0x0809), rsa_pss_pss_sha384(0x080a), rsa_pss_pss_sha512(0x080b), /* Legacy algorithms */ rsa_pkcs1_sha1(0x0201), ecdsa_sha1(0x0203), /* Reserved Code Points */ private_use(0xFE00..0xFFFF), (0xFFFF) } SignatureScheme; struct { SignatureScheme supported_signature_algorithms\u0026lt;2..2^16-2\u0026gt;; } SignatureSchemeList; 注意：此枚举名为“SignatureScheme”，是因为在 TLS 1.2 中已经有一个“SignatureAlgorithm”类型，此类型会将其替换。在整个文本中术语“签名算法”，就是SignatureScheme\n每个 SignatureScheme 值列出了客户端支持验证的单个签名算法。这些值按偏好降序排列。请注意，签名算法接收的输入是任意长度的消息，而不是摘要。传统上对摘要起作用的算法应在 TLS 先使用指定的哈希算法对输入进行哈希处理，然后再输入到对摘要做签名的算法里。具体的签名算法参考下面的内容：\nRSASSA-PKCS1-v1_5 算法：表示使用 RSASSA-PKCS1-v1_5 [RFC8017] 的签名算法，其对应的哈希算法如 [SHS] 中所定义。仅适用于证书中的签名（见 4.4.2.2 节），无法用于签名的 TLS 握手消息，即使它们可能出于兼容 TLS 1.2 而出现在“signature_algorithms”和“signature_algorithms_cert”中。\nECDSA 算法：表示使用 ECDSA [ECDSA] 的签名算法，签名用到的曲线参考如 ANSI X9.62 [ECDSA] 和 FIPS 186-4 [DSS] 中所定义的相应曲线，哈希算法参考以及如 [SHS] 。签名编码为 DER 编码的 [X690] ECDSA-Sig-Value 结构。\nRSASSA-PSS RSAE 算法：（省略，过于琐碎，后面再翻译）\n遗留算法字段：具有已知弱点的算法（尤其是 RSASSA-PKCS1-v1_5 的 RSA算法或和ECDSA 一起使用的 SHA-1），所以被弃用。尽管它们可能出于 兼容TLS 1.2 的目的出现在“signature_algorithms”和“signature_algorithms_cert”中，但只能将这些算法用于证书里中的签名（见 4.4.2.2 节），而不能用来做TLS握手签名。简单来说就不要协商这些算法，客户端仅出于兼容性可以发送这些算法，但必须将它们列为最低优先级（在 SignatureSchemeList 中的所有其他算法之后列出）。除非不使用这些弱算法，就无法生成有效证书链，TLS 1.3 服务器绝不能提供 SHA-1 签名的证书（见 4.4.2.2 节）。\n自签名证书或作为信任锚点的证书上的签名无法验证，因为它们自己是一个全新信任链（certification path）（见 [RFC5280]，3.2 节）。全新信任链的证书可以使用未在“signature_algorithms”扩展中公开定义的算法，作为验证的签名算法。\n请注意，TLS 1.2 对该扩展的定义和TLS1.3不同。如果协商 TLS 1.2 的话，该过站实现必须按照 [RFC5246] 的要求行事。特别是：\nTLS 1.2 的 ClientHellos 可能省略此扩展 在 TLS 1.2 中，该扩展包含哈希/签名对。长度为两个字节编码，因此TLS1.3的SignatureScheme内容可以与 TLS 1.2 的编码一致（兼容）。一些遗留算法对不再保留，这些算法自 TLS 1.3 起被弃用。任何实现都不得提供或协商它们，尤其是MD5 [SLOTH]、SHA-224 和 DSA。 ECDSA 签名方案与 TLS 1.2 的 ECDSA 哈希/签名对对齐。然而，旧的语义并不包含签名曲线信息。如果协商 TLS 1.2，实现方必须接受使用“supported_groups”扩展涉及到的任何曲线的签名 宣称支持 RSASSA-PSS（这在 TLS 1.3 中是强制的）的实现方，必须可以接受协商的是 TLS 1.2版本。在 TLS 1.2 中，RSASSA-PSS 与 RSA 密码套件一起使用。 4.2.4 Certificate Authorities # “证书颁发机构”扩展用于指示端点支持的证书颁发机构（CAs），接收端应参考这些机构来证书选择。\n“证书颁发机构”扩展的主体由 CertificateAuthoritiesExtension 结构组成。\nopaque DistinguishedName\u0026lt;1..2^16-1\u0026gt;; struct { DistinguishedName authorities\u0026lt;3..2^16-1\u0026gt;; } CertificateAuthoritiesExtension; authorities：一堆可明确分辨（是谁的）CA名称[X501]，以 DER 编码[X690]格式表示。这些可分辨名称指定了信任锚或CA的具体名称；因此，此消息可用于描述已知的信任锚以及所需的授权空间。\n客户端可以在 ClientHello 消息中发送“Certificate Authorities”扩展。服务器可以在 CertificateRequest 消息中发送它。\n“可信 CA 密钥”（trusted_ca_keys）扩展[RFC6066]，有相同的目的但更复杂，在 TLS 1.3 中未使用（尽管它可能出现在提供TLS1.3之前版本的客户端ClientHello 消息中出现）。\n4.2.5 OID Filters # 感觉意义不大，先跳\n4.2.6 Post-Handshake Client Authentication # “post_handshake_auth”扩展用于表明客户端愿意执行握手后认证（第 4.6.2 节）（举个简单例子单向认证变双向认证）。服务器不得向未提供此扩展的客户端发送握手后证书请求（post-handshake CertificateRequest）。服务器不得发送此扩展。该拓展结果为\nstruct {} PostHandshakeAuth; 该扩展的“extension_data”字段长度为零，实际上这就是个没内容的标识\n4.2.7 Supported Groups # 客户端发送“supported_groups”扩展时，该拓展表明客户端支持的key share拓展里面的密钥协商方法（实际上也可能包含椭圆曲线类型），按照从最优先到最不优先的顺序排列。\n注意：在 TLS 1.3 之前的版本中，此扩展名为“elliptic_curves”，并且仅包含椭圆曲线组。 请参阅[RFC8422]和[RFC7919]。 此扩展过去还用于协商 ECDSA 曲线，但现在签名算法是独立协商的（请参阅 4.2.3 节）。\n此扩展的“extension_data”字段包含一些“NamedGroupList”值:\nenum { /* Elliptic Curve Groups (ECDHE) */ secp256r1(0x0017), secp384r1(0x0018), secp521r1(0x0019), x25519(0x001D), x448(0x001E), /* Finite Field Groups (DHE) */ ffdhe2048(0x0100), ffdhe3072(0x0101), ffdhe4096(0x0102), ffdhe6144(0x0103), ffdhe8192(0x0104), /* Reserved Code Points */ ffdhe_private_use(0x01FC..0x01FF), ecdhe_private_use(0xFE00..0xFEFF), (0xFFFF) } NamedGroup; struct { NamedGroup named_group_list\u0026lt;2..2^16-1\u0026gt;; } NamedGroupList; 椭圆曲线组（ECDHE）：表示支持相应命名曲线（命名曲线可以理解为基点确定，且明确名字的曲线），在 FIPS 186-4 [DSS] 或 [RFC7748]明确定义。曲线的值如果在0xFE00 至 0xFEFF之间则被保留为供个人使用 [RFC8126]。\n有限域组（DHE）：表示支持相应有限域组，参考 [RFC7919] 。值 0x01FC 至 0x01FF 被保留供个人使用。\nnamed_group_list中的项目按照发送方的偏好排序（最优先的选择在前）。\n自 TLS 1.3 起，服务器被允许向客户端发送“supported_groups”扩展。客户端在成功完成握手之前，服务端“supported_groups”的内容不该对本次握手有任何影响，但客户端参考来更改其后续新连接中的“key_share”扩展中使用的组。如果服务器有一个比客户端“key_share”扩展中的组更偏好的组，但仍然愿意接受 ClientHello，就应该发送“supported_groups”以更新客户端对其偏好的看法；服务端发送的supported_groups扩展应包含服务器支持的所有组，不用考虑论客户端是否支持。\n4.2.8 Key Share # “key_share”扩展包含端点的加密参数。\n客户端可以发送一个空的客户端共享向量，以便向服务器请求组选择，但会导致多个RTT（见第 4.1.4 节）。该拓展结构为\nstruct { NamedGroup group; opaque key_exchange\u0026lt;1..2^16-1\u0026gt;; } KeyShareEntry; group：密钥对应的命名组。\nkey_exchange：密钥交换信息。该字段的内容由命名组及计算方法确定。有限域Diffie-Hellman[DH76]参数在第 4.2.8.1 节中描述；椭圆曲线Diffie-Hellman参数在第 4.2.8.2 节中描述。\n在 ClientHello 消息中，此扩展的“extension_data”字段包含一个“KeyShareClientHello”值：\nstruct { KeyShareEntry client_shares\u0026lt;0..2^16-1\u0026gt;; } KeyShareClientHello; client_shares: 按客户端偏好降序排列的KeyShareEntry 值列表。\n如果客户端期望收到HelloRetryRequest，则此拓展可能为空。每个 KeyShareEntry 值必须对应于“supported_groups”扩展中提供的一个gourp，并且必须保持相同的顺序。然而，这些值可以是“supported_groups”扩展里group们的非连续子集，并且可能省略最优先握手的组的key。这种情况一般出现在，客户端支持的最高优先group比较新，好多地方（中间设备）还不支持\n客户端可以提供与supported groups数量相同的 KeyShareEntry 值，每个值代表一组单独的密钥交换参数。例如，客户端可能为多个椭圆曲线或多个有限域Diffie-Hellman组提供keyshare。每个 KeyShareEntry 的 key_exchange 值必须独立生成。客户端不得为同一组提供多个 KeyShareEntry 值。客户端不得为“supported_groups”扩展中未列出的组提供KeyShareEntry 值。服务器可以检查是否违反这些规则，如果违反，则使用“illegal_parameter”警报中止握手。\n在 HelloRetryRequest 消息中，此扩展的“extension_data”字段包含一个 KeyShareHelloRetryRequest 值：\nstruct { NamedGroup selected_group; } KeyShareHelloRetryRequest; selected_group：服务器打算协商的selected_group。\n收到 HelloRetryRequest 中的此扩展后，客户端必须验证（1）selected_group 字段对应于原始 ClientHello 中的“supported_groups”扩展中提供的一个组，并且（2）selected_group 字段不对应于原始 ClientHello 中的“key_share”扩展中提供的组（这个是确保是真的需要发送selected_group，而不是瞎发）。如果这两个检查中的任何一个失败，则客户端必须使用“illegal_parameter”警报中止握手。要是没出现刚才的错误，在发送新的 ClientHello 时，客户端必须用仅包含HelloRetryRequest 的 selected_group指示的group的新 KeyShareEntry 的扩展来替换原始的“key_share”扩展\n在 ServerHello 消息中，此扩展的“extension_data”字段包含一个 KeyShareServerHello 值：\nstruct { KeyShareEntry server_share; } KeyShareServerHello; server_share：服务端从客户端的key share里面挑选出来的单个 KeyShareEntry 值。\n如果使用（EC）DHE 密钥建立，服务器在 ServerHello 中只选一个 KeyShareEntry。此值必须和客户端提供的 KeyShareEntry 值处于同一命名组（named group）。服务器不得用客户端的“supported_groups”扩展中未指示的任何组发送 KeyShareEntry，并且在使用“psk_ke” PskKeyExchangeMode 时不得发送 KeyShareEntry。如果使用（EC）DHE 密钥建立并且客户端收到包含“key_share”扩展的 HelloRetryRequest，则客户端必须验证 ServerHello 中选择的 NamedGroup 与 HelloRetryRequest 中的相同。如果此检查失败，客户端必须使用“illegal_parameter”警报中止握手。\n4.2.8.1 Diffie-Hellman Parameters # 客户端和服务器的Diffie-Hellman[DH76]参数在KeyShare拓展的KeyShareEntry的key_exchange字段编码。内容为Diffie-Hellman group的公开传递的内容（Y = g^X mod p）（Diffie-Hellman group定义，请参见[RFC7919]）。将公开的整数编码为大端或者说网络字节序，左侧补零至 p （就是那个被mod的质数）的字节大小。\n注意：对于给定的Diffie-Hellman group，填充导致所有公共密钥具有相同的长度。\n接收端必须通过确保 1 \u0026lt; Y \u0026lt; p - 1。此检查确保远程对等方行为正常，别最后group是一个很容易碰撞的group。\n4.2.8.2 ECDHE Parameters # 客户端和服务器的 ECDHE 参数都在 KeyShare 结构中 KeyShareEntry 的不透明 key_exchange 字段中进行编码。\n对于 secp256r1、secp384r1 和 secp521r1，其内容是以下结构体的序列化值：\nstruct { uint8 legacy_form = 4; opaque X[coordinate_length]; opaque Y[coordinate_length]; } UncompressedPointRepresentation; X 和 Y 分别是网络字节序中 x 和 y 值的二进制表示（x,y是点的坐标）。由于没有长度标记，因此每个数字表示占用的字节数量由曲线参数决定。对于 P-256曲线，这意味着 X 和 Y 各自使用 32 个字节，必要时在左侧用零填充。对于 P-384，它们各自占用 48 个字节。对于 P-521，它们各自占用 66 个字节。\n对于 secp256r1、secp384r1 和 secp521r1 曲线，对端必须验证公共密钥点Q再椭圆曲线上。验证程序在 [ECDSA RFC] 的 4.3.7 节和 [KEYAGREEMENT] 的 5.6.2.3 节中有定义。此过程包括三个步骤：（1）验证 Q 不是无穷远点（0），（2）验证对于 Q = (x, y)，整数 x 和 y 都在正确的区间内，（3）确保 (x, y) 是椭圆曲线方程的正确解。对于这些曲线，实现者不需要验证其在正确的子群中。\n对于 X25519 和 X448曲线，公共密钥点Q的内容是在 [RFC7748] 中定义的字节串输入和输出：X25519 为 32 个字节，X448 为 56 个字节。 注意：TLS 1.3 之前的版本允许协商椭圆曲线的基点；TLS 1.3 取消了此功能，改为每个曲线采用固定的基点。\n4.2.9 Pre-Shared Key Exchange Modes # 为了使用预共享密钥（PSKs），客户端还必须发送一个“psk_key_exchange_modes”扩展。这个扩展的语义是客户端仅支持PSKs使用这些模式，这限制了在此 ClientHello 中提供的 PSKs 的如何使用，同时限制了服务器可能通过 NewSessionTicket 提供的 PSKs 如何使用。\n如果客户端提供“预共享密钥(PSK)”扩展，则必须提供“PSK 密钥交换模式(Pre-Shared Key Exchange Modes)”扩展。如果客户端提供“预共享密钥”但没有“PSK 密钥交换模式”扩展，服务器必须中止握手。服务器不得选择客户端未列出的密钥交换模式。此扩展还限制了用于 PSK 会话复用的模式。服务器不应发送与所宣传的模式不兼容的 NewSessionTicket；但是，如果服务器这样做，倒也没啥事，其影响仅仅是客户端的恢复尝试失败。\nenum { psk_ke(0), psk_dhe_ke(1), (255) } PskKeyExchangeMode; struct { PskKeyExchangeMode ke_modes\u0026lt;1..255\u0026gt;; } PskKeyExchangeModes; psk_ke：仅 PSK 密钥建立。在此模式下，服务器不得提供“key_share”值（因为key share涉及到了（EC）DHE的握手流程，客户端不支持）\npsk_dhe_ke：带有（EC）DHE 的 PSK 密钥建立。在此模式下，客户端和服务器必须按照第 4.2.8 节中的描述提供“key_share”值。\n任何未来新添加的PSK模式都必须明确标识服务器选择的模式；目前，这通过 ServerHello 中“key_share”的存在来表明。\n4.2.10 Early Data Indication # 当使用预共享密钥（PSK）并且该 PSK 允许发送early data时，客户端可以在第一趟发送数据的时候中发送应用数据（这句话是指发送ClientHello了，就发送earlydata）。如果客户端选择这样做，则必须同时提供“pre_shared_key”和“early_data”扩展。\n此扩展的“扩展数据（extension_data）”字段包含一个“EarlyDataIndication”值。\nstruct {} Empty; struct { select (Handshake.msg_type) { case new_session_ticket: uint32 max_early_data_size; case client_hello: Empty; case encrypted_extensions: Empty; }; } EarlyDataIndication; 0-RTT 数据的参数（版本、对称密码套件、应用层协议协商 (ALPN) [RFC7301] 协议等）和PSK是相关的。对于外部提供的 PSK，这些参数与PSK一起提供。对于通过 NewSessionTicket 消息建立的 PSK，这些参数是在建立 PSK 的连接中协商得出的。用于加密eayly data的 PSK 必须是客户端“pre_shared_key”扩展中列出的第一个 PSK。\n对于通过 NewSessionTicket 提供的 PSK，服务器必须验证所选 PSK 标识的ticket age（通过从 PskIdentity.obfuscated_ticket_age 减去 ticket_age_add 并对 2^32 取模计算）和ticket颁发的时间的只有小范围的差值（见第 8 节）。如果不在，服务器应该继续握手但拒绝 0-RTT报文，因为这可能意味着此 ClientHello 是一个历史重放报文。\n在0-RTT 消息同其他握手消息，使用相同类型的加密算法，但使用不同的密钥保护。在收到服务器的 Finished 消息后，如果服务器接受early data，将发送 EndOfEarlyData 消息以指示密钥更改。这条消息将使用 0-RTT 流量密钥进行加密。\n收到“early_data”扩展的服务器必须以以下三种方式之一行事：\n忽略该扩展并返回常规的 1-RTT 响应。然后，服务器通过尝试使用握手流量密钥对接收的记录进行解密来跳过early data，丢弃解密失败的记录（最多丢弃max_early_data_size的报文）。一旦记录成功解密，它将被视为客户端传达的第二个报文，服务器按照普通的 1-RTT 握手进行处理。 通过发送HelloRetryRequest 要求客户端发送新的ClientHello。客户端在后续的 ClientHello 中不得包含“early data”扩展。然后，服务器通过跳过所有外部内容类型为“application_data”（表示它们已加密，这个类型在record layer里面显示）的记录来忽略early data，最多达到配置的 max_early_data_size。 在 EncryptedExtensions 中返回其自身的“early_data”扩展，表示它打算处理early data。稍微注意，服务器需要接受early data全部数据消息的一部分。即使服务器发送接受early data的消息，实际的early data在服务器生成此回应时可能已经在网路上传递。 为了接受early data，服务器必须接受 PSK 密码套件，并选择客户端“pre_shared_key”扩展中提供的第一个密钥。此外，它必须验证以下新与所选 PSK 相关的信息相同：\nTLS 版本号 所选的密码套件 所选的 ALPN [RFC7301] 协议（如果有的话） 这些限制是使用相关 PSK 执行 1-RTT 握手所需要求的超集。对于外部建立的 PSK，这些信息与PSK一起提供。对于通过 NewSessionTicket 消息建立的 PSK，这些信息是在颁发ticket的连接中协商得出的。\n未来的扩展必须定义它们与 0-RTT 如何交互。\n如果这些检查中的任何一项失败，服务器不得使用该扩展进行响应，并且必须使用上述前两种机制之一丢弃所有第一次传来的数据（从而回退到 1-RTT 或 2-RTT）。如果客户端尝试进行 0-RTT 握手但服务器拒绝，服务器通常不会产生 0-RTT record layer加密密钥，而必须使用握手密钥（使用 1-RTT 握手密钥或在 HelloRetryRequest 的情况下查找明文 ClientHello）来查找第一个非 0-RTT 消息。\n如果服务器选择接受“early data”扩展，那么在处理early data记录时，如果无法解密 0-RTT 记录，它必须按照第 5.2 节的规定以“bad_record_mac”警报终止连接。\n如果服务器拒绝“early data”扩展，客户端应用程序可以选择在握手完成后重新传输之前在early data中发送的应用数据。请注意，自动重新传输early data可能导致关于连接协议自动机状态转换错误。例如，当协商的连接选择与early data使用的不同的 ALPN 协议时，应用程序可能需要构建不同的消息。同样，如果early data假设了任何关于连接状态的内容，握手完成后再次发送，状态就可能发生了变化。\nTLS 实现不应自动重新发送early data；交给应用程序决定决定何时重新传输更为合适。TLS实现者绝不能自动重新发送early data，除非协商连接时依然选择相同的 ALPN 协议。\n4.2.11 Pre-Shared Key Extension # “预共享密钥”扩展用于协商与PSK的身份标识。\n此扩展的“extension_data”字段包含一些“PreSharedKeyExtension”值：\nstruct { opaque identity\u0026lt;1..2^16-1\u0026gt;; uint32 obfuscated_ticket_age; } PskIdentity; opaque PskBinderEntry\u0026lt;32..255\u0026gt;; struct { PskIdentity identities\u0026lt;7..2^16-1\u0026gt;; PskBinderEntry binders\u0026lt;33..2^16-1\u0026gt;; } OfferedPsks; struct { select (Handshake.msg_type) { case client_hello: OfferedPsks; case server_hello: uint16 selected_identity; }; } PreSharedKeyExtension; identity：psk的标识。例如，tieckt（如在附录 B.3.4中所定义）或外部建立的PSK的标签。 obfuscated_ticket_age：混淆后的ticket age。第 4.2.11.1 节描述了如何通过 NewSessionTicket 消息声称此值。对于外部提供的SPK，应使用 0 的混淆票龄，服务器必须忽略该值。 identities：客户端愿意与服务器协商的SPK列表。如果与“early_data”扩展一起发送（见第 4.2.10 节），第一个PSK用于 0-RTT 传输。 binders：一系列 HMAC 值，与PSK列表中的每个PSK一一对应且顺序相同，计算方式下面会描述。 selected_identity：服务器选择的身份，表示为客户端列表中PSK的（基于 0 的）索引（就是个数字）\n每个预共享密钥（PSK）都和一个哈希算法相关联。对于通过NST报文建立的 PSK（第 4.6.1 节），算法就是颁发Ticket时候用的 KDF 哈希算法。对于外部建立的 PSK，哈希算法是颁发PSK的时候建立的\n如果未提供HASH算法，则 PSK默认用SHA-256。服务器必须确保选择兼容的 PSK（如果有）和密码套件。\n在 TLS 1.3 之前的版本中，服务器名称标识（SNI）值旨在与会话相关联（[RFC6066]的第 3 节），要求服务器检查SNI 值与复用会话Session中中指定的SNI值匹配。然而，实际实现的时候，对于提供的两个 SNI 值是否一致，到底用哪一个并不一致，导致一致性检查实际上由客户端自己。在 TLS 1.3 中，SNI 值始终在恢复握手的报文中明确指定，服务器无需将 SNI 值与PSK的内容强关联。但是，客户端应将 SNI 与 PSK 一起存储以满足第 4.6.1 节的要求。\n协议实现方需注意：当恢复会话是 PSK 的主要目的时，最简单实现 PSK/密码套件匹配要求的方法是首先协商密码套件，然后排除任何不兼容的 PSK。任何未知的 PSK（例如，不在 PSK 数据库中或使用未知密钥加密的 PSK）应直接忽略。如果未找到可接受的 PSK，服务器应在可能的情况下执行非 PSK 握手（就是完整握手）。如果后向兼容性很重要，客户端提供的、外部建立的 PSK 应影响密码套件的选择。\n在接受 PSK 密钥建立之前，服务器必须验证相应的binder 值（见下面的第 4.2.11.2 节）。如果此值不存在或未通过验证，服务器必须中止握手。服务器不应尝试验证多个绑定器；相反，它们应选择单个 PSK 并仅验证与该 PSK 对应的绑定器。有关此要求的安全原理，请参见第 8.2 节和附录 E.6。为了向客户端表示接受 PSK 密钥，服务器需要发送一个“pre_shared_key”扩展，指示所选的标识。\n客户端必须验证服务器的所选标识在客户端提供的范围内，服务器选择的密码套件的HASH算法也与 PSK 的HASH算法匹配。此外，如果 ClientHello 的“psk_key_exchange_modes”扩展要求提供非仅PSK模式的握手，则服务器的“key_share”扩展也必须存在。如果这些值不一致，客户端必须使用“illegal_parameter”警报中止握手。\n如果服务器提供“early_data”扩展，客户端必须验证服务器的所选标识为 0。如果返回任何其他值，客户端必须使用“illegal_parameter”警报中止握手。\n“pre_shared_key”扩展必须是 ClientHello 中的最后一个扩展（这有助于如下所述的实现）。服务器必须检查它是否是最后一个扩展，否则使用“illegal_parameter”警报中止握手。\n4.2.11.1. Ticket 年龄 # 客户端的Ticket Age的看法是自收到 NewSessionTicket 消息以来的duration。客户端不得尝试使用ticket age大于随ticket提供的“ticket_lifetime”值的ticket。每个 Psk Identity 的“obfuscated_ticket_age”字段都是混淆后的版本，计算方法为，以毫秒为单位的ticket age加上ticket包含的“ticket_age_add”值（见第 4.6.1 节），取模 2^32 形成。除非在不同连接重复使用PSK，此加法可防止监听者将Ticket和连接关联。请注意，NewSessionTicket 消息中的“ticket_lifetime”字段以秒为单位，而“obfuscated_ticket_age”以毫秒为单位。由于票证的有效期限制为一周，即使以毫秒为单位，32 位也足以表示任何合理的年龄。\n4.2.11.2. PSK Binder # PSK Binder将PSK 与当本次握手关联起来，当然也关联了颁发PSK的时候（就是上次握手）。binder列表中的每个entry都采用一种方法计算得出，对从头到包含PreSharedKeyExtension.identities 字段的部分 ClientHello 做transcript hash，再（见第 4.4.1 节）进行 HMAC 计算得出。所以会除了Binders部分，包括本次所有的ClientHello。消息的长度字段（包括总长度、扩展块的长度和“pre_shared_key”扩展的长度）都设置为好像存在binder。\nPskBinderEntry 的计算方式与 Finished 消息（第 4.4.4 节）相同，只不过把BaseKey换为binder_key，binder_key从PSK 派生得出（见第 7.1 节）。\n如果握手时发送了HelloRetryRequest，计算transcript hash是，第一个ClientHello 和 HelloRetryRequest 会与新的 ClientHello 一起包含在计算中。例如，如果客户端发送 ClientHello1，其绑定器将通过以下方式计算：\nTranscript-Hash(Truncate(ClientHello1)) 其中，Truncate() 会从 ClientHello 中删除binders列表。 如果服务器用 HelloRetryRequest 响应，然后客户端发送 ClientHello2，其binders将通过以下方式计算：\nTranscript-Hash(ClientHello1, HelloRetryRequest, Truncate(ClientHello2)) 完整的 ClientHello1/ClientHello2 包含在所有其他握手哈希计算中。请注意，在第一次传输中，Truncate(ClientHello1) 直接进行哈希处理，但在第二次传输中，ClientHello1 先进行哈希处理，然后作为“message_hash”消息重新注入，如[第 4.4.1 节][0]所述。\n4.2.11.3 Processing Order # 客户端在收到服务器的“Finished”之前可以一致“流式传输” 0-RTT 数据，然后在发送“EndOfEarlyData”消息，和其他握手报文。为了避免死锁，当接受“early_data”时，服务器必须尽快处理客户端的“ClientHello”，然后立即发送其消息序列，而不是在发送其“ServerHello”之前等待客户端的“EndOfEarlyData”消息。\n结尾 # 唉，尴尬\n","date":"2021 年 4 月 2 日","externalUrl":null,"permalink":"/posts/2021-04-02-tls1.3_8446_rfc%E7%BF%BB%E8%AF%91/","section":"Posts","summary":"","title":"TLS1.3 8446 RFC翻译","type":"posts"},{"content":" 2021-03-29-数论笔记 # 参考的基本资料为《数论讲义》上下册+《初等数论》，最后群环域的部分打算看《代数》(《Algebra》by Michael Artin).\n《数论讲义》上册笔记 # 第一章 整数的唯一分解定理 # 1 整除性 # 定理1：设a,b是两个整数，其中b\u0026gt;0，则存在两个唯一的整数q和r，使得$a=bq+r，0\u0026lt;= r\u0026lt;b$，我们一般称q为不完全商，r为a除b得到的余数，也叫作非负最小剩余，常记做$_b=r$，不过b常常省略掉。\n2 最大公因数和辗转相除法 # 定理1：设a,b,c是三个整数，其中b\u0026gt;0，则存在两个唯一的整数q和r，使得$a=bq+c$，q为整数，则$(a,b) = (b,c)$\n3 整数的唯一分解定理 # 先定义复数的定义，然后给出其他定理。\n引理1：设a是任一大于1的整数，则a的除1之外的最小正因数q是素数，而且$q\u0026lt;=\\sqrt{a}$\n引理2：设p是一个素数，a是任一整数，择有$p|a$或$(p,a)=1$\n引理3：设p是素数，则$p|ab$，则$p|a$或$p|b$\n定理1：任一大于1的整数能表示为素数的乘积，即对于任一整数a\u0026gt;1，有$a=p_1p_2\u0026hellip;p_n, p_1\u0026lt;= p_2 \u0026lt;= \u0026hellip; \u0026lt;= p_n$。其中p_1p_2\u0026hellip;p_n都是素数，并且若$a=q_1q_2\u0026hellip;q_m, q_1\u0026lt;= q_2 \u0026lt;= \u0026hellip; \u0026lt;= q_m$必然有$m=n,q_i==p_i,(i=1,2,\u0026hellip;n)$\n证明：定理1的证明是非常明显的使用数学归纳法的证明方式，将数字a拆成b*c，然后b和c都满足归纳。证明m=n只需要利用引理3，且素数互质即可。\n实际上之所以辗转相除方法是个优秀的方法，是因为效率高。将数字展开为唯一分解式是一种很麻烦再计算gcd很麻烦。\n此外还有一个要注意的地方是，如果素数定义变了那么唯一分解定理不再适用。\n5 素数 # 厄拉多塞筛法，利用第一章第三节的引理1，厄拉多塞筛法列出从2到$\\sqrt{n}$的素数，然后划去从$p_1$到$p_{\\sqrt{n}}$所有素数的倍数，剩下的就都是素数了。近代素数表都是由此得出的。\n定理1：素数的个数是无穷的\n定理2：存在无穷多个形如4n-1的素数\n证明：假设4n-1的素数是有限的，p是最大的。那么设$N=435\u0026hellip;*p -1$，N必然是合数，且所有的素数因子都大于p。首先N必然是奇数，其因子要么是4N+1/4N-1的形式(这两个数字都是奇数的表示法，换言之奇数要么是4N+1要么是4N-1），而两个4N+1乘法是得不到4N-1的，因此必然有个4N-1的因子是素数\n定理3：存在无穷多个形如kn+l的素数，其中(k,n)=1\n这个证明很麻烦，先略过。\n结尾 # 唉，尴尬\n","date":"2021 年 3 月 29 日","externalUrl":null,"permalink":"/posts/2021-03-29-%E6%95%B0%E8%AE%BA%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"","title":"数论笔记","type":"posts"},{"content":" 2021-02-23-基本的算法和数据结构(包含多线程) # 为什么写这个？通用的方法常常隐藏常见的方法。\n1 抽象，实现和STL # 1.1 STL 数据结构VECTOR # O(1)时间的快速访问 顺序存储，所以插入到非尾结点位置所需时间复杂度为O(n)，删除也一样 当我们新建一个vector的时候，会首先分配给他一片连续的内存空间，如std::vector\u0026lt;int\u0026gt; vec，当通过push_back向其中增加元素时，如果初始分配空间已满，就会引起vector扩容，其扩容规则在gcc下以2倍方式完成：首先重新申请一个2倍大的内存空间；然后将原空间的内容拷贝过来；最后将原空间内容进行释放，将内存交还给操作系统； 执行插入/删除后，所有执行点之后迭代器和指针引用失效，同理，扩容之后的所有迭代器指针和引用也失效。 常用的函数：push_back 在数组的最后添加一个数据，*pop_back 去掉数组的最后一个数据，*begin 得到数组头的指针 end 得到数组的最后一个单元+1的指针 capacity 当前vector分配的大小 size 当前使用数据的大小 erase 删除指针指向的数据项 clear 清空当前的vector empty 判断vector是否为空 1.2 map和multimap # 两个都是关联容器，也就是提供一对一key-value的数据处理能力。map与multimap的区别在于，multimap允许关键字重复，而map不允许重复。 这两个关联容器的底层数据结构均为红黑树。根据红黑树的原理，map与multimap可以实现**O(lgn)**的查找，插入和删除。 常用的函数：clear(） 删除所有元素，empty() 如果 map 为空则返回 true，find() 查找一个元素， insert() 插入元素，end() 返回指向 map 末尾的迭代器，insert(pair \u0026lt; int,string \u0026gt; (1,\u0026ldquo;Jim\u0026rdquo;)) 插入元素的时候要把元素的类型组织出来，size()返回map的大小，erase() 删除一个元素 1.3 unordered_map 与unordered_multimap # map与multimap为有序的 而unordered_map与unordered_multimap中key为无序排列，其底层实现为hash table，因此其查找时间复杂度理论上达到了O(1) 常用的函数为 1.4 set \u0026amp; multiset # set系列的数据结构是只有值，因此可以认为set是只保存关键字的容器。 set与multiset有序存储元素，这两种容器的底层实现与map一样都是红黑树，所以能实现O(lgn)的查找，插入，删除操作。 常用的函数为 1.5 优先队列priority_queue # 优先级队列相当于一个有权值的单向队列queue，在这个队列中，所有元素是按照优先级排列的。 priority_queue根据堆的处理规则来调整元素之间的位置，根据堆的特性，优先级队列实现了取出最大最小元素时间复杂度为O(1),对于插入和删除，其最坏情况为O(lgn)。 常用的函数为：priority_queue\u0026lt;Type, Container, Functional\u0026gt;Type数据类型，Container是容器类型，Functional是排序的函数,常，一般Functional默认是std::less\u0026lt;Type\u0026gt;小顶堆，不过我们可以穿进去std::greater\u0026lt;Type\u0026gt;来构建大顶堆，这个用于声明。push(const T\u0026amp; obj)：将obj的副本放到容器的适当位置，这通常会包含一个排序操作。push(T\u0026amp;\u0026amp; obj)：将obj放到容器的适当位置，这通常会包含一个排序操作。top()：返回优先级队列中第一个元素的引用。pop()：移除第一个元素。size()：返回队列中元素的个数。empty()：如果队列为空的话，返回true。 1.6 list # 底层一般是 1.7 stack # 底层一般是链表 常用的函数为：std::stack\u0026lt;std::string,std::liststd::string\u0026gt; fruit; 用于初始化。top()：返回一个栈顶元素的引用，类型为 T\u0026amp;。如果栈为空，返回值未定义。push(const T\u0026amp; obj)：可以将对象副本压入栈顶。这是通过调用底层容器的 push_back() 函数完成的。pop()：弹出栈顶元素。empty()：在栈中没有元素的情况下返回 true。size()：返回栈中元素的个数。 2 排序 # 基于比较的排序算法，其时间复杂度不可能低于 n∗lognn∗log**n，这是由排序过程中的决策树模型决定的\n决策树模型：\n节点表示比较： 决策树上的每个节点都代表一次元素比较操作（例如，比较数组中两个元素的大小）。 分支表示比较结果： 每个节点根据比较结果产生不同的分支，例如，大于、小于或等于。 叶子节点表示排序结果： 每一种可能的排序结果都对应着决策树上的一个叶子节点。 为什么最优时间复杂度是 n*logn：\n叶子节点数量： 对于 N 个元素，共有 N! (N 的阶乘) 种不同的排列方式，也就是 N! 种可能的排序结果。因此，决策树必须至少包含 N! 个叶子节点才能表示所有情况。 树的高度与比较次数： 决策树的高度（从根节点到最深叶子节点的路径长度）代表了排序算法在最坏情况下需要进行的最多比较次数。 树的高度限制： 对于一棵二叉树（大多数比较排序都是基于二叉比较），高度为 h 的树最多拥有 2h2h 个叶子节点。 推导出最优高度： 为了容纳 N! 个叶子节点，树的高度 h 必须满足 2h\u0026gt;=N!2h\u0026gt;=N! 。 使用斯特林公式近似计算阶乘：N!≈2πN(Ne)NN!≈2π**N(e**N)N，可以推导出 h\u0026gt;=log2(N!)≈N∗log2Nh\u0026gt;=log2(N!)≈N∗log2N。 结论：\n由于决策树的高度决定了比较次数，而为了表示所有可能的排序结果，树的高度至少为 N∗log2NN∗log2N，所以任何基于比较的排序算法，其时间复杂度都不可能低于 n∗lognn∗log**n。 这被称为比较排序算法的时间复杂度下限。\n2.1 最简单的排序 # 常见的排序算法就不多赘述了：\n选择排序：每次选择出来最小的元素然后交换到检查数组的首部，因此对于长度为N的数组选择排序需要大约N^2/2次比较和N次交换。问题是这个算法运行时间和输入无关（这不是个好消息）。但是数据移动最少。 插入排序：我更喜欢叫做插扑克排序，每次将当前元素插入到已经拍好的合适的位置。这个算法的时间和原本数组的排序有关。但是插入排序最惨情况也需要N^2/2的比较和N^2/2的交换，最好情况只需要N-1比较和0次交换。 2.2 归并排序 # 比较方法做的排序上限是多少？答案是：没有任何基于比较的算法能保证使用少于lg(N!)~NlgN的比较次数，将长度为N的数组排序。\n归并排序，一种思考的方法\n归并排序依托的原理是：两个有序的数组（长度都为N/2)，在整体重排的时候最多只需要比较N次。由于每次都是一半次数的缩减，因此这种复杂度直接减少到了N*log(N)。\n实际上归并排序就是典型的分治思想，将问题拆解为两份（如果拆解相等，一般是最优的），两个部分都做处理。整体的有序处理会简单很多。\n归并排序有两种实现，一种从上向下，一种从下向上。\n2.3 快速排序 # 快速排序大概是最著名的排序了，基本所有人都知道快排，实际上快排也是基于分治法。由于快排的特殊性，所以将伪码写上。\n快排平均需要2N*lnN次比较，以及1/6次交换。 快排最惨需要N^2/2次比较，但打乱数组会避免这种算法 public class quick { public static void sort(Comparele[] a) { Random.shuffle(a); sort(a,0,a.length-1); } private static void sort(Comparable[] a, int lo, int hi) { if (hi \u0026lt; lo) return; int j = partition(a,lo,hi); sort(a,lo,j-1); sort(a,j+1,hi); } private static int partition(Comparable[] a, int lo, int hi) { int i = lo, j = hi + 1; Comparable v = a[lo]; while(1) { while(less(a[++i],v)) if(i==hi) break; while(less(v,a[--j])) if(j==lo) break; if (i \u0026gt;= j) break; exchange(a, i, j); } exchange(a,lo,j); return j; } } 2.4 堆排序 # 简单来说我觉得堆排序是一个非常好玩的问题，实际上对常见问题的考虑都是一致的。堆大多都是大顶堆/小顶堆\n代码如下:\nprivate void sink(int k) { while(2*k \u0026lt;= N) { int j = 2*k; if (j \u0026lt; N \u0026amp;\u0026amp; less(j,j+1)) j++; if(!less(k,j)) break; exchange(k,j); k = j; } } 2.5 从排序向外发散 # 一个很常见的问题实际上是，最小的第K个数，这个问题的答案就是两种堆排序和快排思路\n3 查找 # 3.1 二叉树（二叉查找树） # 常见的先序遍历，中序遍历和后序遍历都是递归，下面给个迭代版本的实现。实际上还是利用非常常见的思想，也就是模拟计算机的栈而已。具体流程不明白的，就看下知乎上画的那个遍历的图片。\n先序遍历\nclass Solution { public List\u0026lt;Integer\u0026gt; preorderTraversal(TreeNode root) { List\u0026lt;Integer\u0026gt; preOrderList = new ArrayList\u0026lt;\u0026gt;(); //存放访问顺序 Stack\u0026lt;TreeNode\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); //存放结点，用于回溯 while(root != null || !stack.empty()) { //迭代遍历二叉树 while(root != null) { //使root指向当前子二叉树的最左结点 stack.push(root); preOrderList.add(root.val); //将当前子二叉树的根节点入栈，并访问 root = root.left; } while(root == null \u0026amp;\u0026amp; !stack.empty()) { root = stack.pop().right; //自底向上找到栈中跟结点第一个非空右孩子，第一个未访问过的右孩子！ } } return preOrderList; } } 中序遍历\nclass Solution { public List\u0026lt;Integer\u0026gt; inorderTraversal(TreeNode root) { List\u0026lt;Integer\u0026gt; inOrderList = new ArrayList\u0026lt;\u0026gt;(); //存放访问顺序 Stack\u0026lt;TreeNode\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); //存放结点，用于回溯 while(root != null || !stack.empty()) { //迭代遍历二叉树 while(root != null) { //使root指向当前子二叉树的最左结点 stack.push(root); root = root.left; } root = stack.pop(); inOrderList.add(root.val); //出栈当前子二叉树的根结点，并访问 root = root.right; //更新root结点：当前子二叉树的右孩子 or 树的父结点 } return inOrderList; } } 后序遍历\nclass Solution { public List\u0026lt;Integer\u0026gt; postorderTraversal(TreeNode root) { List\u0026lt;Integer\u0026gt; postOrderList = new ArrayList\u0026lt;\u0026gt;(); //用于存放访问顺序 Stack\u0026lt;TreeNode\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); //存放结点，用于回溯 TreeNode pre = null; //记录之前访问过的结点 while(root != null || !stack.empty()) { //迭代访问二叉树 while(root != null) { //使root指向当前子二叉树的最左结点 stack.push(root); root = root.left; } root = stack.peek(); if(root.right == null || root.right == pre) { //当前结点为叶子结点 或者 当前结点的右孩子是上个访问结点 pre = root; //更新上一次访问的结点 postOrderList.add(stack.pop().val); //出栈，表示访问了当前结点 root = null; //让root到下一次循环再更新，避免发生空栈错误 }else { root = root.right; //访问当前结点的右孩子 } } return postOrderList; } } linux内核的基础知识 # 1 进程调度 # 时间片，分配给每个可运行进程的处理器时间段。linux为抢占式系统。\n调度算法有基于优先级，linux为动态优先级\n2 缺页中断 # 结尾 # 唉，尴尬\n","date":"2021 年 2 月 23 日","externalUrl":null,"permalink":"/posts/2021-02-23-%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8C%85%E5%90%AB%E5%A4%9A%E7%BA%BF%E7%A8%8B/","section":"Posts","summary":"","title":"2021-02-23-基本的算法和数据结构(包含多线程)","type":"posts"},{"content":" 2021-02-22-安全方面的基础知识（数学篇+协议篇） # 1 分组密码 # 1.1 分组密码是啥？ # 从本质来说，分组密码实际上是将明文分组后，和秘钥做X乘，得到的密文分组的流程。需要注意，加密前的分组数量n和加密后的分组数量m不一定相等（但一般实现都是相等的）。总之这种加密实际上就是数字序列的代换。这种加密方式要满足以下几个方面：\n分组长度n要足够大，从而保证分组代换字母表里的元素个数2^n足够大，防止明文穷举攻击。 秘钥量要足够大，消减弱密钥的使用 置换算法要复杂，别简单整个移位代换就完了。总之要能对抗：差分攻击和线性攻击。 实现简单，出错恢复容易 1.2 安全的分组流程 # 因为分组密码本质是代换，因此就是要求实现从n==\u0026gt;2^n的拓展。但是问题来啦，n太大不好设计实现，n太小又太容易攻破。怎么办？所以分组密码设计小的加密单元，然后将内部拆成这些小单元做加密。为了对抗统计分析，常见的方法两种：\n扩散，扩散是隐藏明文的统计特性，从本质来说就是讲多个明文的统计特性转换为密文 混淆，混淆是因为明文和密文之间的统计关系 1.3 基本的加密流程 # 基本的加密流程就是Feistel密码结构，实质是香农提出的乘积密码方法。\n从本质来说就是这个流程，分组越大，轮数越多，秘钥越大，轮函数，子秘钥产生方法越夸张越安全。当然相对应的是实现的时候性能越低。 $$ L_{i}=R_{i-1}\\ R_{i}=L_{(i-1)}xorF(R_{(i-1)},K_{i}) $$\nL(i)=R(i-1) R(i)=L(i-1)异或F(R(i-1),K(i)) 1.4 常见的分组密码 # 1.4.1 DES算法 # DES算法本质就是Feistel算法的多重应用，具体流程不多写，找本书一看就明白，很直接。无非就是Ri-1和Ki的计算过程稍微复杂些。\n1.4.2 AES算法 # 1.4.3 商密SM4 # 1.4.4 祖冲之密码 # 1.5 差分分析与线性密码分析 # 对于分组密码攻击的方式很多，不过下面两种最有效\n差分攻击：通过分析明文对的差值对密文对的差值的影响来回复某些秘钥比特 线性攻击：利用密码算法的“不平衡的线性逼近” 1.6 分组密码的运行模式 # ECB,电子密码本,ECB的理想应用场景是短资料（如加密金钥）的加密。\n优点：构造简单、容易实做 缺点：时间下，容易被侦测。影像资料的差异性不大，很容易被辨识到重复性，相较于文字很容易受前后文的影响。 CBC,密码分组连结,引入了IV（初始化向量：Initialization Vector）的概念。IV是长度为分组大小的一组随机，通常情况下不用保密，不过在大多数情况下，针对同一金钥不应多次使用同一组IV。CBC要求第一个分组的明文在加密运算前先与IV进行异或；从第二组开始，所有的明文先与前一分组加密后的密文进行异或。\n优点：相同明文，会因为前一个的密文不同造就出不同的密文，也就是加密器多一个新的状态。\n缺点：\n一个密文Ci 的错误，会导致两个明文解析错误(Pi \u0026amp; Pi+1)。 第一次加密很容易被抽换bitwise，因为每次驱动的Initial Vector 都相同。 CFB,密文反馈,CFB模式先生成密码流字典，然后用密码字典与明文进行异或操作并最终生成密文。后一分组的密码字典的生成需要前一分组的密文参与运算。\n优点\n支持即时(real-time) 通讯 只需要加密器，加密做两次相当于解密。 支持自同步(self-synchronization)，即使中断连线、讯息错误，可以在数个周期后再次同步运作。 藉由自同步的概念，可以舍弃掉Initial Vector。 后半部的明文，可以透过周期性的部分密文建立解密状态，支持random access。 缺点：\nerror propagation 错误增长，当一个讯息错误时，需要好几个周期后才能修正回来，这导致中间的解密讯息都不能用。 OFB,输出反馈,生成字典的时候会采用明文参与运算，CFB采用的是密文。\n优点：\n支持即时(real-time) 通讯 只需要加密器，加密做两次相当于解密。 相较于CFB，没有错误增长的情况。 依序使用的key，可以事先算出来，然后依次使用。 杂讯下支持的能力好。 缺点：\n必须一直保持同步 讯息被修改时，不易被发现，只单纯影响单一明文(没有错误增长)。 起始状态的Initial Vector，不能重复使用，否则很容易被攻击者抓到。 加设没有预先算key，没办法解密出后半部的明文。 CTR：每次使用递增的计数器参与加密运算，保证相同的数据不会产生相同的密文。但是实际上也没有完整性。\n优点：\n加解密可以平行化处理，如果加解密速度耗时，可以选择这一种。 支持random access。 缺点：\n必须一直保持同步 讯息被修改时，不易被发现，只单纯影响单一明文(没有错误增长)。 起始状态的Initial Vector，不能重复使用，否则很容易被攻击者抓到。 CCM,全称是Counter with Cipher Block Chaining-Message Authentication Code，是CTR工作模式和CMAC认证演算法的组合体，可以同时资料加密和鉴别服务。\nGCM模式是CTR和GHASH的组合，GHASH操作定义为密文结果与金钥以及讯息长度在GF（2^128）域上相乘。GCM比CCM的优势是在于更高并行度及更好的效能。\n总结\n特点 加密模式 区块加密： ECB、CBC、CTR 串流加密： CFB、OFB 传递误差(资料不能有缺失)： CBC、CFB 不传递误差(资料允许缺失)： ECB、OFB、CTR 可并行： ECB、CTR 不可并行： CBC、OFB、CFB 2 公钥密码 # 2.1 公钥密码体质的基本数学原理 # 抽象代数如果实在是不能理解，建议看这个http://sparkandshine.net/algebraic-structure-primer-group-ring-field-vector-space/\n基本的数学原理建议跟着《Introduction to Modern Cryptography，Second Edition》学习，当然，看完这本入门之后看《信息安全数学基础》也是足够的。\n2.1.1 群 环 域 # 群的定义和一部分性质\n半群：设$\u0026lt;G, \u0026gt;$是一个代数系统，如果 $$ 满足：（1）封闭性 （2）结合律，则称$\u0026lt;G, *\u0026gt;$是半群。 群：设$\u0026lt;G, \u0026gt;$是一个代数系统，如果 $$ 满足：（1）封闭性 （2）结合律（3）存在元素e，对$∀a∈G$，有$ae=ea=a$；$e$称为$\u0026lt;G,\u0026gt;$的单位元（4）对$∀a∈G$，有$a^{-1}$，使得$aa^{-1}=a^{-1} * a=e$;称$a^{-1}$为元素$a$的逆元，则称$\u0026lt;G, *\u0026gt;$是群。也将$\u0026lt;G, *\u0026gt;$简称为G。这里加一条，如果群的元素是有限的，那么群元素的个数m，就是群的阶且： Let G be a finite group with m = |G|, the order of the group. Then for any element g ∈ G, $g^m = 1$.\n证明方式，是只针对阿贝尔群的，但是所有的有限群都通用。是利用:$g_1 · g_2 · · · g_m = (gg_1) · (gg_2) · · · (gg_m). $，因为$gg_i=gg_j$意味着$g_i=g_j$，所以右侧的元素都不相同，因此右边元素各不相同且也是这个群的元素。从而得出$g_1 · g_2 · · · g_m = (gg_1) · (gg_2) · · · (gg_m) = g^m · (g_1 · g_2 · · · g_m). $。所以$g^m=1$.这个东西的推论(corollary )是:\nLet G be a finite group with m = |G| \u0026gt; 1. Then for any g ∈ G and any integer x, we have gx = g[x mod m].\n这个东西是降低复杂度的有效方法。\nAbel群：如果群G的$$满足交换律，即对$∀a,b∈G$，有 $a * b=ba$,则称$\u0026lt;G, *\u0026gt;$是Abel（阿贝尔）群。阿贝尔群使得很多证书操作都可以交换降低计算难度。\n$\u0026lt;A,+\u0026gt;$是Abel群，其中$I$是整数集合\n$\u0026lt;Q,*\u0026gt;$是Abel群，其中$Q$是有理数集合\n$\u0026lt;Z_n,+_n\u0026gt;$是Abel群，其中$Z_n={{0,1,..,n-1}}$,$+_n$是模加，$a+_n b$等于$(a+b) mod n$，$x^{-1} = n-x$。$\u0026lt;Z_n,_n\u0026gt;$不是群，因为$0$没有逆元，这里$_n$是模乘，$a*_n b$等于$(a*b) mod n$。这里要注意，$Z_n={{0,1,..,n-1}}$这是一个常识。\n对于有限阿贝尔群的另一个推论\nLet G be a finite group with m = |G| \u0026gt; 1. Lete \u0026gt; 0 be an integer, and define the function fe : G → G by $f_e(g) = g^e$. If $gcd(e, m) = 1$, then fe is a permutation (i.e., a bijection). Moreover,if $d = e^{-1} mod m$ then $f^d$ is the inverse of $f^e$. (Note by Proposition 8.7, gcd(e, m) = 1 implies e is invertible modulo m.)\n证明比较简单，证明两者为逆很容易，这里加一个单词bijective双射，一一对应且每个都有映射，叫做双射。\n若$\u0026lt;G, \u0026gt;$是群，$I$是整数集合。如果$∃g∈G$，$∀a∈G$，都有$i∈I$，$a=g^i$，则称$\u0026lt;G,\u0026gt;$为循环群，$g$称为G的生成元，记$G=={{g^i|i∈I}}$。称$a^m=e$的最小正整数$m$为$a$的阶，记为$|a|$。注意：在密码学上，使用的群多为循环群，要注意循环群的性质！写在后面了 环的定义\n环：设$\u0026lt;G,+， \u0026gt;$是一个代数系统，如果 $$与 $+$ 满足：（1）$\u0026lt;G,+\u0026gt;$是Abel群 （2）$\u0026lt;G,\u0026gt;$是半群（3）乘法$$在加法$+$上可分配，即对$∀a,b,c∈G$，有$a*(b+c)=ab+ac$，和$(b+c)a=ba+c*a$。则称$\u0026lt;G,+， *\u0026gt;$是一个环。 域的定义\n域：设$\u0026lt;G,+， \u0026gt;$是一个代数系统，如果 $$与 $+$ 满足：（1）$\u0026lt;G,+\u0026gt;$是Abel群 （2）$\u0026lt;G,\u0026gt;$是Abel群（3）乘法$$在加法$+$上可分配，即对$∀a,b,c∈G$，有$a*(b+c)=ab+ac$，和$(b+c)a=ba+c*a$。则称$\u0026lt;G,+， *\u0026gt;$是一个域。\n有限域是指域中元素个数有限的域，元素的个数为域的阶。弱$q$是素数的幂，即$q=p^r$，其中$p$是素数，$r$是自然数，则称阶为$q$的域为Galois域，记为GF(q)或$F_q$\n2.1.2 素数和互素数 # 素数，除了正负1和正负自己没有其他因子的数字就是素数。相应的正整数可以由非0指数列表示，比方说$11011=711^213$，因此11011可以表示为${a_7=1,a_{11}=2,a_{13}=1}$。可知，两数字相乘就是对应的系数相加。 公因子，称c是a,b的最大公因子，如果：（1）c是a的因子，也是b的因子（2）a \u0026amp; b的任一公因子，也是c的因子。即$c=gcd(a,b)$ 公倍数，称c是a,b的最小公倍数，如果：（1）c是a的倍数，也是b的倍数（2）a \u0026amp; b的任一公倍数，也是c的倍数。即$c=lcm(a,b)$ 实际上，我们相关联的点一般是：\nIf c | ab and gcd(a, c) = 1, then c | b. Thus, if p is prime and p | ab then either p | a or p | b. If a | N, b | N, and gcd(a, b) = 1, then ab | N. 2.1.3 模运算 与 模指数运算 # 模运算是指对整数取余，如果从映射的角度来考虑，模运算实际上是We refer to the process of mapping a to [a mod N] as reduction modulo N. 即一种映射关系。这里有个属于叫做congruent module，即全等取余We say that a and b are congruent modulo N, written a = b mod N, if [a mod N] = [b mod N] 。模运算或者说取余关系是一种很有趣的关系：\nCongruence modulo N is an equivalence relation: i.e., it is reflexive (a =a mod N for all a), symmetric (a = b mod N implies b = a mod N), and transitive (if a = b mod N and b = c mod N, then a = c mod N). Congruencemodulo N also obeys the standard rules of arithmetic with respect to addition, subtraction, and multiplication; so, for example, if a = a′ mod N and b = b′ mod N then (a + b) = (a′ + b′) mod N and ab = a′b′ mod N. A consequence is that we can “reduce and then add/multiply” instead of having to “add/multiply and then reduce,” which can often simplify calculations.\n比方说计算$[1093028 · 190301 mod 100] $ ，可以先计算$1093028 · 190301 = [1093028 mod 100] · [190301 mod 100] mod 100 = 28 · 1 = 28 mod 100.$ 但是module操作并不能约去共同的约数。\n设$Z_8={{0,1,..,7}}$，可通过运算得到不是每个Z_8中的元素都有逆元，经过仔细观察可以发现，实际上只有和8互素的元素$1,3,5,7$才有乘法逆元。因此我们可以轻易的得到一条模运算的定理，赘述一条，计算时间为多想时间。\nLet b, N be integers, with b ≥ 1 and N \u0026gt; 1. Then b is invertible modulo N if and only if gcd(b, N) = 1\n记$Z_{n}^{}={{a|0\u0026lt;a\u0026lt;n,gcd(a,n)=1}}$，必然有$Z_{n}^{}$中的每个元素都有乘法逆元，这里的$Z_{n}^{}$也是一个通用符号，需要记住。$Z_{n}^{}$实际上是个乘法操作下的阿贝尔群。从$|Z_{n}^{*}|$拓展就得到了欧拉函数也就是$φ(N)$\n模指数是指对给定的正整数$m,n$，计算$a^m mod n $。下面给个简单的例子\n$a=7,n=19$则容易求出$7^1=7mod19,7^2=11mod 19,7^3=1mod19$，容易知道计算的周期为3，称满足$a^m=1modn$的最小正整数m为模n下a的阶，记为$ord_{n}(a)$、易知如果$a^m=1modn$，则$a^k=1modn$必然有k为m的倍数。\n2.1.4 费马定理，欧拉定理，卡米歇尔定理 # 费马定理：若p是素数，a是正整数，且$gcd(a,p)=1$，则$a^{p-1}=1mod { p}$\n欧拉函数：设n是一个正整数，小于n且与n互素的正整数的个数为n的欧拉函数，记为$φ(n)$，有以下结论：\n(1) 若$n$为素数，则$φ(n)=n-1$\n(2) 若$n$是素数$p$与$q$的乘积，则$φ(n)=（p-1)(q-1)$\n(3) 若$n$有标准分解式，$n=p_{1}^{α_1}p_{2}^{α_2}\u0026hellip;p_{t}^{α_t}$，则$φ(n)=n(1-1/p_{1})(1-1/p_{2})\u0026hellip;(1-1/p_{t})$\n相对应地，我们给出每一条的证明：\n(1) $n$为素数，则$φ(n)=n-1$不需要复杂证明\n(2) 若$n$是素数$p$与$q$的乘积，那么a ∈ {1, . . . , N - 1} is not relatively prime to N, then either p | a or q | a (a cannot be divisible by both p and q since this would imply pq | a but a \u0026lt; N = pq). 所以 $φ(n)=(N - 1) - (q - 1) - (p - 1) = pq - p - q + 1 = (p - 1)(q - 1). $\n(3)\n欧拉函数：若$a$和$n$互素，则$a^{φ(n)}=1modn$。证明很简单，因为$gcd(a,n)=1$，且$a\u0026lt;n$所以$a∈Z_{N}^{}$。$φ(n)$又是$Z_{N}^{}$的阶，参照2.2.1里群环域的第一个推论。除此之外，可知，$ord(a)|φ(n)$，如果$ord(a)=φ(n)$，则a是n的本原根，即$a^{1},a^{2},a^{3}\u0026hellip;a^{φ(n)}$在mod n下互不相同且都与n互素。\n卡米歇尔定理：\n2.1.5 素性检验 # Miller–Rabin 算法， 基于概率的算法，如果N是素数，必然有每个$a^{N-1}$对N取余都为1，一个不符合就说明条件不成立。之所以用这个算法是因为这个算法的效率比较高，而且尝试的次数越多，出错的概率越低。\nInput: Integer N and parameter 1t\nOutput: A decision as to whether N is prime or composite\nfor i = 1 to t:\n​\ta ← {1, . . . , N - 1}\n​\tif $a^{N-1} ̸= 1 mod N$ return “composite”\nreturn “prime”\n证明需要两个引理：\n1 Let G be a finite group, and H ⊆ G. Assume H is nonempty, and for all a, b ∈ H we have ab ∈ H. Then H is a subgroup of G.\n2 Let H be a strict subgroup of a finite group G (i.e., H ̸= G). Then |H| ≤ |G|/2.\n使用这两个引理退出来第三个引理，这第三个引理是使得初始的Miller-Rabin貌似正确的途径，但是问题就在于引理3的这个条件，如果不存在一个witness就完蛋了：\n3 Fix N. Say there exists a witness that N is composite. Then at least half the elements of $Z^∗_N$ are witnesses that N is composite.\n引理3里面的假设是必然存在witness，这个假设是证明流程里面的一个非常重要的前提。这个证明的流程可以说是非常奇特了：假设存在winess，然后证明非witness的集合的是（真）子群，其个数小于$\\frac{|G|}{2}$。那么必然有witness的个数大于$\\frac{|G|}{2}$，问题就在于不一定存在一个witness。\n我们重点关注的数是$Z^∗_N$里面的数字，因为$Z^*_N$里面的数字少，简单，好计算。\n但是初始的Miller-Rabin算法对于Carmichael number无效。Carmichael number是个很蛋疼的东西，Carmichael number是指，该数字n是个合数，但是所有和该数字互素的数b都满足，$b^{n-1}=1 (mod n)$，举一个最简单的例子，最小的carmichael Number，$561=31117$。因此需要执行对Miller-Rabin素性检验的改进。\nMiller-Rabin的改进依赖于以下引理：\nSay $x ∈ Z^∗_N$ is a square root of 1 modulo N if x2 = 1 mod N. If N is an odd prime then the only square roots of 1 modulo N are [±1 mod N].\n换言之，初始的素性检验先拿到$N - 1 = 2^ru $，然后只需要计算$a^{2r}u = 1 mod N $。修正过的素性检验，分别计算$a^{2^r}u = 1 mod N $，另r=0,1,\u0026hellip;n-1不断变化。我们称Say that $a ∈ Z^∗_N$ is a strong witness that N is composite (or simply a strong witness) if (1) $a^u≠ ±1 mod N$ and (2) $a^{2^i}u≠ -1 mod N$ for all $i ∈ {1, . . . , r - 1}. $ 换言之，这个strong witness比初始的Miller-Rabin更宽泛：\na如果不是strong witness，那么a必然不是witness。 如果a是witness，那么a必然是strong witness。 a是strong witness，但是a不一定是witness。 strong witness比witness的概率要高，出现的数字的可能性更大。 利用上面的引论，给出来两个结论：\n1对素数而言是不存在strong witness的， We conclude that when N is an odd prime there is no strong witness that N is composite.\n2 Let N be an odd number that is not a prime power. Then at least half the elements of$ Z^∗_N$ are strong witnesses that N is composite.\n第二个结论的推导稍微花一些时间，Let $Bad ⊆ Z^∗_N$ denote the set of elements that are not strong witnesses. We define a set $Bad^′ $and show that: (1) Bad is a subset of Bad′, and (2) $Bad^′$ is a strict subgroup of $Z^∗_N$. This suffices because by combining (2) and Lemma 8.37 we have that $ |Bad^′| ≤ |Z^∗_N|/2$. Furthermore, by (1) it holds that $Bad ⊆ Bad^′$, and so $|Bad| ≤ |Bad^′| ≤ |Z^∗_N|/2$ as in Theorem 8.38. Thus, at least half the elements of $Z^∗_N$ are strong witnesses. (We stress that we do not claim that Bad is a subgroup of $Z^∗_N$.) 前面的证明结束了，就需要证明$Bad^,$存在即可。这里可以令Let $i ∈ {0, . . . , r −1}$ be the largest integer for which there exists an a ∈ Bad with $a^{2^iu} = ±1 mod N$，然后证明$Bad ⊆ Bad′ $;$Bad′$ is a subgroup of $Z^∗_N$ . ;$Bad′$ is a strict subgroup of $Z^∗_N.$\n$$ Bad′ = {a | a^{2^iu} = ±1 mod N}.\\ $$\n最终改进的 Miller-Rabin算法为：\nInput: Integer N \u0026gt; 2 and parameter 1^t\nOutput: A decision as to whether N is prime or composite\nif N is even, return “composite”\nif N is a perfect power, return “composite”\ncompute r ≥ 1 and u odd such that $N - 1 = 2^ru$\nfor j = 1 to t:\n​\ta ← {1, . . . , N - 1}\n​\tif $a^u ≠ ±1 mod N$ and $a^{2^i}u ≠ -1 mod N$ for i ∈ {1, . . . , r - 1}\n​\treturn “composite”\nreturn “prime”\n2.1.6 欧几里得算法 # 欧几里得算法不但可以用来算公因子，也可以算乘法逆元？\n欧几里得算法的正向使用，换言之，有了欧几里得算法，可以再多项式复杂度下求出$gcd(a,b)$\n设$a,b$是任意的正整数，将$gcd(a,b)$记为$(a,b)$。必然有$(a,b)=(b,a mod b)$ 如果$(a,b)=1$，则$b$在$mod a$下有乘法逆元，即存在一个x，使得$bx=1mod a$。 欧几里得算法的逆向使用，求乘法逆元可用，具体看（《Introduction To Moder Cryptography, Second Edition》的Appendix B.1.2。）有两个定义：\n如果$(a,b)=1$,则$b$在$moda$下有乘法逆元，即存在一个$x$使得$bx=1moda$。推广的欧几里得算法先求出$(a,b)$。如果$(a,b)=1$时，返回b的逆元。 若$a$和$b$为正整数，则存在整数$x,y$使得$gcd(a,b)=ax+by$。实际上如果$gcd(a,b)=1$，那么第二个模式对a取余就得到$by=1moda$，y就是乘法逆元。此外还有一点要注意，$gcd(a,b)=ax+by$同时意味着，$gcd(a,b)$是可以表示为$ax+by$的最小整数，且$gcd(a,b)$被$ax+by$里面的每个元素整除。 第二点的证明：\nTo see this, take an arbitrary $c ∈ I$ and write $c = X′a + Y ′b$ with $X′, Y ′ ∈ Z.$ Using division with remainder (Proposition 8.1) we have that $c = qd + r$ with q, r integers and $0 ≤ r \u0026lt; d.$ Then $r = c - qd = X′a + Y ′b - q(Xa + Y b) = (X′ - qX)a + (Y ′ - qY )b ∈ I$. If r ̸= 0, this contradicts our choice of d as the smallest positive integer in I (because r \u0026lt; d). So, r = 0 and hence d | c. This shows that d divides every element of I.\n又因为$a,b∈I$，所以d是最大公约数，\n具体的伪代码我明天更新\n2.1.7 中国剩余定理 # 数论中最有用的一个工具，它有两个用途：\n已知某个数关于一些两两互素的树的同余类集 将大数用小数表示，大数的运算通过小数来实现。 用markdown公式来表示，就是已知下面的条件：\n设$m_1m_2m_3\u0026hellip;m_k$是两两互素的正整数，$M=\\prod_{i=1}^{k}{m_i}$，则一次同余方程\n$a_1(mod m_1)=x$ $a_2(mod m_2)=x$ \u0026hellip; $a_k(mod m_k)=x$ 对模M有唯一解：\n$x= (\\frac{M}{m_1}e_1a_1+\\frac{M}{m_2}e_2a_2+\u0026hellip;+\\frac{M}{m_k}e_ka_k)(modM)$，其中$\\frac{M}{m_i}e_i=1(modm_i)$ 中国剩余定理是可以用群的问题来说明的，首先给出同构的定义和运算的方式：\nLet G, H be groups with respect to the operations $◦G, ◦H$, respectively. A function$ f : G → H$ is an isomorphism from G to H if: 1 $f $ is a bijection, and 2 For all $g_1, g_2 ∈ G$ we have $f(g_1 ◦_G g_2) = f(g_1) ◦_H f(g_2)$. If there exists an isomorphism from G to H then we say that these groups are isomorphic and write $G ≃ H$.\n同构的运算方式： $$ (g, h)◦(g^′, h^′) = (g ◦_G g^′, h ◦_H h^′).// 这里的=是定义为 $$\n中国剩余定理的群定义方式：\nLet $N = pq$ where $p, q \u0026gt; 1$ are relatively prime. Then $ Z_N ≃ Z_p × Z_q$ and $Z^∗_ N ≃ Z^∗ p × Z^∗ q$. Moreover, let f be the function mapping elements $x ∈ {0, . . . , N − 1}$ to pairs $(x_p, x_q) $with $x_p ∈ {0, . . . , p − 1}$ and $x_q ∈ {0, . . . , q − 1}$ defined by $$ f(x) = ([x mod p], [x mod q]) $$ Then f is an isomorphism from $Z_N$ to $Z_p × Z_q$, and the restriction of f to $Z^∗N$ is an isomorphism from $Z^∗ N$ to $Z^∗_ p × Z^∗_ q$。这里实际上不一定是$N=pq$，可以是$N=p_1p_2p_3\u0026hellip;p_n$。换言之$ Z_N ≃ Z_{p_1} × Z_{p_2}\u0026hellip;× Z_{p_l}$ and $Z^∗_ N ≃ Z^_{p_1} × Z^{p_2}\u0026hellip;× Z^*{p_l}$.\n中国剩余定理的证明（使用群的基础知识）：\n首先证明是双射，然后证明同构定义的第二点即可。\n常见的中国剩余定理的运用往往集中在求模上，比方说求$11^{53} mod 15 $ ，求解$29^{100} mod 35 $ 。这时主要的问题就变成了，how to convert back and forth between the representation of an element modulo N and its representation modulo p and q. 从N到对p、q取余很简单，如何反向运算呢即给出了$(x_p, x_q)$，怎么计算原来的数字呢？方法如下：\nan element with representation $(x_p, x_q)$ can be written as $(x_p, x_q) = x_p · (1, 0) + x_q · (0, 1)$. 由于$gcd(p,q)=1$，可以得到$Xp+Yq=1$ Set $1_p := [Yq mod N]$ and $1_q := [Xp mod N]$. Compute $x := [(x_p · 1_p + x_q · 1_q) mod N]$. 2.1.8 离散对数和平方剩余 # 2.1.8.1 离散对数discrete logarithm # 离散对数问题实际上就称为DLP问题，也就是discrete-logarithm problem，设p是一个素数，a是p的本原根，则$a,a^2,\u0026hellip;,a^{p-1}$产生了$1～p-1$之间的所有值，且每个值只出现一次。之所以关注离散对数，因为离散对数需要多项式时间（多项式时间就是计算的高速），好生成也容易管理/计算。这里需要注意的是discrete是离散的意思。很有趣的事情是，离散对数的计算同样符合数学的计算：\n$log_g 1 = 0$ (where 1 is the identity of G) for any integer r, we have $log_g h^r = [r · log_g h mod q];$ $log_g(h_1h_2) = [(log_g h_1 + log_g h_2) mod q]$. 离散对数问题实际上就是Diffle-Hellman的基本原理，第一个问题是怎么判断一个离散对数，步骤很简单，但是具体的复杂度会很多：\nRun G(1n) to obtain (G, q, g), where G is a cyclic group of order q (with ∥q∥ = n), and g is a generator of G. Choose a uniform h ∈ G $A$ is given G, q, g, h, and outputs $x ∈ Z_q$. The output of the experiment is defined to be 1 if $g^x = h$, and 0 otherwise. 要注意的一点是离散对数并不一定是困难的，如果每个算法$A$都是困难的，离散对数难以计算的假设是：\nWe say that the discrete-logarithm problem is hard relative to G if for all probabilistic polynomial-time algorithms A there exists a negligible function negl such that $Pr[DLog_{A,G}(n) = 1] ≤ negl(n)$.\n$Pohlig–Hellman \\space algorithm$算法证明如果阶为q的群有小素数银子，那么DLP变地简单一些，这并不代表一下子就成为简单问题了。\n现在我们考虑怎么生成一个有限群，\n名词解释：\nDLP：离散对数问题。例如在整数模11乘法群中容易计算5×5×5×5=9 mod 11，那么求几个5相乘的结果是9这个问题就是一个离散对数问题。当模数为很大的质数时，这个问题是困难的。 2.1.8.2 平方剩余 # 平方剩余：设n为正整数，a是整数，满足$gcd(a,b)=1$，称a是模n的平方剩余，如果下面的方程有解 $$ x^2=a(modn) $$ 设p是素数，a是一个整数，勒让德(Legendre)符号$(\\frac{a}{p})$的定义如下 $$ \\frac{a}{p}= \\begin{cases} 0 \u0026amp; \\text{如果a被p整除}\\ -1 \u0026amp; \\text{如果a是模p的平方剩余}\\ 1 \u0026amp; \\text{如果a是模p的非平方剩余} \\end{cases} $$ 下面是更一般的雅克比符号，设n是正整数，且$n=p{_1}^{a_1}p{_2}^{a_2}\u0026hellip;p{_k}^{a_k}$，则雅克比符号为：\n$(\\frac{a}{n})=(\\frac{a}{p_1})^{a_1}(\\frac{a}{p_2})^{a_2}\u0026hellip;(\\frac{a}{p_k})^{a_k}$\n可以看到，当n时素数的时候雅克符号退化为勒让德符号。\n2.1.9 循环群 及其性质和双线性映射 # 2.1.9.1 循环群性质 # Let G be a finite group and g ∈ G. The order of g is the smallest positive integer i with $g^i = 1$.\n自然就能得出下一个结论：\nLet G be a finite group of order m, and say g ∈ G has order i. Then $i | m$。可以轻易得出，一个元素如果是生成元，必然有该元素的阶等于优先群的阶，换言之可以生成每个元素。\n自然就有：\nIf G is a group of prime order p, then G is cyclic. Furthermore, all elements of G except the identity are generators of G.\n另一条循环群的性质，If p is prime then $Z^∗_p$ is a cyclic group of order p - 1.\n很有趣的一点，优先循环群同构于加群$Z/nZ$，使用标准的语言来表示：\nLet G be a cyclic group of order n, and let g be a generator of G. Then the mapping $f : Z_n → G$ given by $f(a) = g^a$ is an isomorphism between Zn and G. Indeed, for $a, a^′ ∈ Z_n$ we have $$ f(a + a^′) = g^{[a+a^′ mod n]} = g^{a+a^′} = g^a · g^{a^′} = f(a) · f(a′). $$\nBijectivity of f can be proved using the fact that n is the order of g.\n书上最后给出了一段似是而非的解释，这个等到第九章再联系。\n2.1.9.3 双线性映射 # 双线性映射早期是一种对椭圆曲线的攻击方式：利用双线性对将ECDLP问题规约到DLP问题的MOV攻击。但这种攻击方式是有限的，只能对参数满足一定条件的曲线进行攻击。2000年双线性对开始在密码学领域得到重视，成果有基于身份的密码体制（IBE）、三方一轮密钥协商、BLS签名算法等。三方一轮的流程如下：\n设q是一个大素数，$G_1$，$G_2$和$G_T$是两个阶为q的群，三者其上的运算都包含加法和乘法。三者存在一个映射关系$e:G_1×G_2→G_T$，满足以下特性：\n双线性：有$∀g_1∈G_1,g_2∈G_2,a,b∈Z_p$，均有$e(g_1^a,g_2^b)=e(g_1,g_2)^{ab}$ 非退化性：$∃g_1∈G_1,g_2∈G_2$，满足$e(g_1,g_2)≠1_{G_T}$ 可计算性：存在有效的算法，对于$∀g_1∈G_1,g_2∈G_2$，均可计算$e(g_1,g_2)$ 下面给出一些名词解释：\nMOV攻击：又称MOV规约攻击，是Menezes、Okamoto和Vanstone三人的论文中提出的针对特殊椭圆曲线离散对数问题（ECDLP）的一种有效解法。通过双线性配对，将椭圆曲线上的离散对数问题规约成为某个乘法群上的离散对数问题，能够在亚指数步骤中计算ECDLP。 ECDLP:椭圆曲线离散对数问题。例如已知P、Q是两个椭圆曲线点，并且4个P相加得到Q，那么已知P和Q求解几个P相加得到Q的问题就是椭圆曲线离散对数问题。当选择的曲线满足一定要求时，该问题是困难的。 2.1.10 椭圆曲线的点乘运算方式 # 椭圆曲线怎么计算呢？密码学中使用的一般都是有限域上的椭圆曲线，其一般性定义为： $$ E(Z_p) = {H(x, y) | x, y ∈ Z_p\\space and\\space y^2 = x^3 + Ax + B \\space mod p}I ∪ {O}. $$ 最常见的形式都是： $$ y^2=x^3+ax+b /形式/\\ (a,b∈GF(p)， 4a^3+27b^2≠0) /条件/ $$ 那么如何进行椭圆曲线点乘的运算呢？使用曲线图理解会简单很多，椭圆曲线的加法实际上也是由此定义的\n设$P=(x_1,y_1),Q=(x_2,y_2),P≠-Q$，则$P+Q=(x_3,y_3)$由以下规矩确定： $$ x_3=λ^2-x_1-x_2(modp) \\ y_3=λ（x_1-x_3)-y_1(modp) $$ 其中，这里要注意这里的中间的横杆是“除法“，也就是说这里出现了有限域的离散取余 $$ λ= \\begin{cases} \\frac{y_2-y_1}{x_2-x_1} \u0026amp; \\text{P≠Q}\\ \\frac{3x_1^2+a}{2y_1} \u0026amp; \\text{P=Q} \\end{cases} $$ 举个简单的例子我们对椭圆曲线$E_{23}(1,1)$上的$P=(3,10),Q=(9,7)$求$P+Q$，有： $$ λ=\\frac{7-10}{9-3}=\\frac{-3}{-6}=\\frac{-1}{2}=-12^{-1}mod{23}=-112mod{23}=11mod23\\/2^{-1}也就是2的逆元是12，可使用上面的欧几里得求逆/\\ x_3=11^2-3-9=109=17mod23\\ y_3=11(3-17)-10=20mod23 $$\n有了上面的流程，一个新的问题就出现了，求解λ的时候，怎么求对应的乘法逆元呢？\nvoid exgcd(int a, int b, int\u0026amp; x, int\u0026amp; y) { if (b == 0) { x = 1, y = 0; return; } exgcd(b, a % b, y, x); y -= a / b * x; } 2.2 公钥密码体制的基本概念 # 2.3 常见的公钥密码体制 # 2.3.1 RSA加密 # RSA的安全性实际上和大数分解是相关的，没办法很简单地将n分解为两个大数。\n选取p和q，两个保密的大素数 $n=p*q$，$φ(n)=（p-1)(q-1）$，$φ(n)$是$n$的欧拉函数 选择$e$，有$1\u0026lt;e\u0026lt;φ(n)$，且$φ(n)$和$e$互素 计算$d*e=1 mod φ(n)$，因为$e$和$φ(n)$互素，所以$d$一定存在。 选择$（d,n）$为私钥，$（e,n）$为公钥 加密的时候$c=m^e mod n$，解密的时候$m = c^d mod n$。\n2.3.2 椭圆曲线密码体制 # 椭圆曲线的安全性利用的是对椭圆曲线构成的Abel群$E_p(a,b)$上考虑方程$Q=kP$，从k和P易得出Q，但是从Q难以计算P。\n首先需要选取一个大素数$p≈2^{180}$和两个参数a、b。可得椭圆曲线极其上面的点构成的Abel群$E_p(a,b)$。第二步选择$E_p(a,b)$的一个生成元$G(x_1,y_1)$，要求G的阶是一个非常大的素数，G的阶是满足$nG=o$的最小整数n。$E_p(a,b)$和G作为公开参数。\n用户A选择$d_A$为私钥，计算公钥$Q_A=d_A G$，此时A的密钥对为$（d_A,Q_A)$。用户B选择$d_B$为私钥，计算公钥$Q_B=d_B G$，此时B的密钥对为$（d_B,Q_B)$\nA和B分别选择各自的$Q_A$和$Q_B$发送到对端，然后A和B分别计算$(x_k,y_k)=d_A Q_B$和$(x_k,y_k)=d_B Q_A$。选择一部分作为共享的计算结果\n易知$d_A Q_B=d_A *d_B * G = d_B *d_A * G = d_B Q_A$，因此两边的数字一致。而攻击者只能拿到曲线，基点和两个公钥$Q_A,Q_B$。无法从公钥逆推私钥，因此提供保密性\n2.3.3 ElGamal密码体制 # 3 秘钥分配和管理 # 3.1 秘钥管理 # 常用的秘钥分配方式是有一个可信中心，挑选一个秘钥，然后在安全信道发送给用户。这种方法要求每个用户在该可信中心有一个主密钥，因此n个用户n个主密钥。为了保证n个用户相互通信的安全，回话秘钥为n(n-1)/2个。主密钥并不多，很方便。这里面还有几个问题。\n秘钥的分层。分层的KDC减少了主密钥的分布 秘钥的有效期。面向连接的协议由于回话可能很久，因此需要定期更新秘钥。无连接的协议必须每次都更新，这种最好周期利用同一秘钥。 纯无中心的秘钥控制。这种方式并不安全。 3.2 公钥加密体质的秘钥管理 # 这个实际上没啥好说的，公钥加密体质必须有个可信方。\n3.3 随机数安全 # 3.3.1 随机数产生算法，常规方法 # 一般来说怎么衡量随机数的随机性呢？考察两个方面：\n是不是均匀分布，也就是 是否满足独立性，也就是不能由其它的数字推导出来另一个数字。 目前常见的伪随机数产生器是线性同余算法，也就是 $$ X_{n+1}=(aX_n+c) mod {m} $$ 这里面a,c,m是产生高质量随机数的关键，为了让重复的周期扩大，一般是m取计算机能表示的最大整数。当然这里面需要一个X_0作为起始种子。除了上面的形式，还有 $$ X_{n+1}={X_n}^d mod m $$ 如果选择m是大素数乘积，d是RSA密钥，满足gcd(d,fai(m)) =1，那这就是RSA产生器。\n3.3.2 基于密码算法的随机数产生器 # 循环加密，主密钥保密，计数器循环加密并计算，可以用来产生随机数。 DES的OFB反馈， ANSI X9.17伪随机数产生器，3des+日期+种子 3.3.3 随机比特产生器 # BBS产生器：这个是目前已知强度最强两个大素数p和q，满足p=q=3(mod 4)，令n = p×q，再选择一个随机数s，使s与n互素。最后一位的目的是取最低有效位置。这个的难度是基于大整数分解难题。 $$ X_0 = (s^2)mod n\\ for{,}{,}{,}{,} i = {,}1{,}to{,} ∞ \\ X_i = (X_{i - 1} ^ 2 )mod {,}n\\ B_i = X_i mod 2 $$\nRabin产生器：k是一个大于等于2的整数，在$[2^k，2^{k+1}]$之间选取两个奇素数，p,q，有p=q=3(mod 4)，迭代公式为 $$ X_i=(X_{i-1}^2)mod n{,}{,}{,}{,}{,}{,}{,}{,}{,}{,}{,}{,}if (X_{i-1}^2)mod n \u0026lt; n/2\\ X_i = n -(X_{i-1}^2)mod n{,}{,}{,}{,}{,}{,}{,}{,}{,}{,}{,}{,}if (X_{i-1}^2)mod n \u0026gt; n/2 $$\n离散指数比特序列产生器\n3.3.4 crypto++的随机数实现 # crypto++的随机数同样需要先seed，而且不是线程安全的实现。\ncrypto++的随机数算法比较多：\nLC_RNG is a Linear Congruential Generator。也就是线性同余方法 RandomPool is a PGP style random pool，实际上是AES加密算法 AutoSeededX917RNG，就是上面的ANSI X9.17算法 NIST算法 3.3.5 openssl的随机数实现 # Openssl内部实现了足够安全的随机数产生器，使用的算法包括NIST, ANSI X9 committee (X9.17 and X9.31)等算法。\n默认情况下openssl使用md5作为随机数产生函数。一般情况下openssl使用/dev/urandom作为随机数产生器的种子源。设置好seed之后，可以通过软算方式获得产生的密钥。\n如果你是openssl1.0.1，使用的cpu是i5/i7三代cpu也可以使用硬件随机数产生器。\n3.4 秘密分割 # 门限这个东西有点类似分割的藏宝图，一个人份的藏宝图找不到东西，只有一定数量人份的藏宝图才能找到宝藏。完整的定义是：\n设秘密S被分成n个部分，每一部分信息称为一个子密钥/影子，由一个参与者持有，使得：\n由k个或多于k个参与者所持有的部分信息可重构s 由少于k个参与者所持有的部分信息则无法重构s 这种方案，被称为(k,n)-秘密分割门限方案，k称为方案的门限值\n3.4.1 Shamir门限 # 翻译为“沙米尔”门限，基于多项式的拉格朗日差值公式，插值是古典数值分析的一个基本问题：已知一个函数$φ(x)$在$k$个互不相同的点的函数值为$φ(x_i)(i=1,\u0026hellip;,k)$，寻求一个满足$f(x_i)=φ(x_i)(i=1,\u0026hellip;,k)$的函数$f(x)$，用来逼近$φ（x)$。$f(x)$被称为$φ(x)$的插值函数，$f(x)$可取自不同的函数类，即为代数多项式，也可为三角多项式或有理分式。若取$f(x)$为代数多项式，则称插值问题为代数插值。\n拉格朗日插值：已知一个函数$φ(x)$在$k$个互不相同的点的函数值为$φ(x_i)(i=1,\u0026hellip;,k)$，可构造k-1次插值多项式为 $$ f(x)=∑{j=1}^{k}{φ（x_j）}\\prod{l=1;l！=j}^{k}{((x-x_l)/(x_j-x_l))} $$ 利用的东西是$(k,n)$可知$f(0)$。\n实际上，如果有了足够的信息，不一定得先算出来f(x)，直接调用公式计算f(0)，也就是s即可 $$ f(0)=s=（-1）^{k-1}∑{j=1}^{k}{f（i_j）}\\prod{l=1;l！=j}^{k}{((i_l)/(i_j-i_l))} $$ 这种门限方法vault用了。\n举一个简单的例子，$k=3, n=5,q=19,s = 11$,随机选取$a_1 = 2, a_2 = 7$​得多项式为 $$ f(x)=(7x^2+2x+11)mod 19 $$ 分别计算f(1) = 1, f(2) = 5, f(3) = 4, f(4) = 17, f(5) = 6，所以如果知道三个子密钥f(2) = 5, f(3) = 4, f(5) = 6就可以得到下面的过程\n这里注意都是有限域上的计算，vault用的是GF(2^8)，乘法是正常取余数，除法是先转换为log，然后两者相减然后加255再对255取余数。+法是亦或\n理解除法/乘法看这个链接 https://mathoverflow.net/questions/223515/how-to-calculate-log-or-exp-of-a-value-in-gf2n-using-log-exp-table-of-gf2k\npackage shamir import ( \u0026#34;crypto/rand\u0026#34; \u0026#34;crypto/subtle\u0026#34; \u0026#34;fmt\u0026#34; mathrand \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) const ( // ShareOverhead is the byte size overhead of each share // when using Split on a secret. This is caused by appending // a one byte tag to the share. ShareOverhead = 1 ) // polynomial represents a polynomial of arbitrary degree type polynomial struct { coefficients []uint8 //uint8数组系数，构成一个多项式，每个系数都是uint8的值 } // makePolynomial constructs a random polynomial of the given // degree but with the provided intercept value. intercetpt value实际上就是解决值，就是x为0时的y值，也是我们的s func makePolynomial(intercept, degree uint8) (polynomial, error) { // Create a wrapper p := polynomial{ coefficients: make([]byte, degree+1), } // Ensure the intercept is set p.coefficients[0] = intercept // Assign random co-efficients to the polynomial if _, err := rand.Read(p.coefficients[1:]); err != nil { return p, err } return p, nil } // evaluate returns the value of the polynomial for the given x func (p *polynomial) evaluate(x uint8) uint8 { // Special case the origin if x == 0 { return p.coefficients[0] } // Compute the polynomial value using Horner\u0026#39;s method. degree := len(p.coefficients) - 1 out := p.coefficients[degree] for i := degree - 1; i \u0026gt;= 0; i-- { coeff := p.coefficients[i] out = add(mult(out, x), coeff) } return out } // interpolatePolynomial takes N sample points and returns // the value at a given x using a lagrange interpolation. func interpolatePolynomial(x_samples, y_samples []uint8, x uint8) uint8 { limit := len(x_samples) var result, basis uint8 for i := 0; i \u0026lt; limit; i++ { basis = 1 for j := 0; j \u0026lt; limit; j++ { if i == j { continue } num := add(x, x_samples[j]) denom := add(x_samples[i], x_samples[j]) term := div(num, denom) basis = mult(basis, term) } group := mult(y_samples[i], basis) result = add(result, group) } return result } // div divides two numbers in GF(2^8) func div(a, b uint8) uint8 { if b == 0 { // leaks some timing information but we don\u0026#39;t care anyways as this // should never happen, hence the panic panic(\u0026#34;divide by zero\u0026#34;) } log_a := logTable[a] log_b := logTable[b] diff := ((int(log_a) - int(log_b)) + 255) % 255 ret := int(expTable[diff]) // Ensure we return zero if a is zero but aren\u0026#39;t subject to timing attacks ret = subtle.ConstantTimeSelect(subtle.ConstantTimeByteEq(a, 0), 0, ret) return uint8(ret) } // mult multiplies two numbers in GF(2^8) func mult(a, b uint8) (out uint8) { log_a := logTable[a] log_b := logTable[b] sum := (int(log_a) + int(log_b)) % 255 ret := int(expTable[sum]) // Ensure we return zero if either a or b are zero but aren\u0026#39;t subject to // timing attacks ret = subtle.ConstantTimeSelect(subtle.ConstantTimeByteEq(a, 0), 0, ret) ret = subtle.ConstantTimeSelect(subtle.ConstantTimeByteEq(b, 0), 0, ret) return uint8(ret) } // add combines two numbers in GF(2^8) // This can also be used for subtraction since it is symmetric. func add(a, b uint8) uint8 { return a ^ b } // Split takes an arbitrarily long secret and generates a `parts` // number of shares, `threshold` of which are required to reconstruct // the secret. The parts and threshold must be at least 2, and less // than 256. The returned shares are each one byte longer than the secret // as they attach a tag used to reconstruct the secret. func Split(secret []byte, parts, threshold int) ([][]byte, error) { // Sanity check the input if parts \u0026lt; threshold { return nil, fmt.Errorf(\u0026#34;parts cannot be less than threshold\u0026#34;) } if parts \u0026gt; 255 { return nil, fmt.Errorf(\u0026#34;parts cannot exceed 255\u0026#34;) } if threshold \u0026lt; 2 { return nil, fmt.Errorf(\u0026#34;threshold must be at least 2\u0026#34;) } if threshold \u0026gt; 255 { return nil, fmt.Errorf(\u0026#34;threshold cannot exceed 255\u0026#34;) } if len(secret) == 0 { return nil, fmt.Errorf(\u0026#34;cannot split an empty secret\u0026#34;) } // Generate random list of x coordinates mathrand.Seed(time.Now().UnixNano()) xCoordinates := mathrand.Perm(255) // Allocate the output array, initialize the final byte // of the output with the offset. The representation of each // output is {y1, y2, .., yN, x}. out := make([][]byte, parts) for idx := range out { out[idx] = make([]byte, len(secret)+1) out[idx][len(secret)] = uint8(xCoordinates[idx]) + 1 } // Construct a random polynomial for each byte of the secret. // Because we are using a field of size 256, we can only represent // a single byte as the intercept of the polynomial, so we must // use a new polynomial for each byte. for idx, val := range secret { p, err := makePolynomial(val, uint8(threshold-1)) if err != nil { return nil, fmt.Errorf(\u0026#34;failed to generate polynomial: %w\u0026#34;, err) } // Generate a `parts` number of (x,y) pairs // We cheat by encoding the x value once as the final index, // so that it only needs to be stored once. for i := 0; i \u0026lt; parts; i++ { x := uint8(xCoordinates[i]) + 1 y := p.evaluate(x) out[i][idx] = y } } // Return the encoded secrets return out, nil } // Combine is used to reverse a Split and reconstruct a secret // once a `threshold` number of parts are available. func Combine(parts [][]byte) ([]byte, error) { // Verify enough parts provided if len(parts) \u0026lt; 2 { return nil, fmt.Errorf(\u0026#34;less than two parts cannot be used to reconstruct the secret\u0026#34;) } // Verify the parts are all the same length firstPartLen := len(parts[0]) if firstPartLen \u0026lt; 2 { return nil, fmt.Errorf(\u0026#34;parts must be at least two bytes\u0026#34;) } for i := 1; i \u0026lt; len(parts); i++ { if len(parts[i]) != firstPartLen { return nil, fmt.Errorf(\u0026#34;all parts must be the same length\u0026#34;) } } // Create a buffer to store the reconstructed secret secret := make([]byte, firstPartLen-1) // Buffer to store the samples x_samples := make([]uint8, len(parts)) y_samples := make([]uint8, len(parts)) // Set the x value for each sample and ensure no x_sample values are the same, // otherwise div() can be unhappy checkMap := map[byte]bool{} for i, part := range parts { samp := part[firstPartLen-1] if exists := checkMap[samp]; exists { return nil, fmt.Errorf(\u0026#34;duplicate part detected\u0026#34;) } checkMap[samp] = true x_samples[i] = samp } // Reconstruct each byte for idx := range secret { // Set the y value for each sample for i, part := range parts { y_samples[i] = part[idx] } // Interpolate the polynomial and compute the value at 0 val := interpolatePolynomial(x_samples, y_samples, 0) // Evaluate the 0th value to get the intercept secret[idx] = val } return secret, nil } vault选择的secret（S）是任意长度的byte数组，选取的x的坐标随机生成的是小于255的整数。对华耀内部可以使用诸如硬件指纹低位按照从小到大排列来产生，如果不够可以继续凑。\n看完了valut的实现，那么对普通用户怎么实现呢？实际上我们只是拆分，\n3.4.2 中国剩余定理门限 # 中国剩余定理讲解的实际上是数论里一元线性同余方程组的定理。\n设$m_1,m_2,\u0026hellip;,m_n$是n个大于1的证书，满足$m_1\\leq m_2 \\leq m_3\u0026hellip;.\\leq m_n，gcd(m_i,m_j)=1$，且$m_1 m_2 m_3 \u0026hellip; m_k \u0026gt;m_n m_n-1 m_n-2\u0026hellip; m_n-k+2$.设s为秘密数据，满足$m_1 m_2 m_3 \u0026hellip; m_k \u0026gt;s\u0026gt;m_n m_n-1 m_n-2\u0026hellip; m_n-k+2$.\n计算$M=m_1m_2 m_3\u0026hellip; m_n$，$s_i=s(mod m_i)$。以$(s_i, m_i, M)$作为一个子秘钥，集合${(s_i, m_i, M)}$即构成了一个$(k,n)$的门限.\n实际上是个方程解集的问题，即逻辑不完备不可解方程。\n4 消息认证和hash函数 # 4.1 生日攻击 # 生日攻击的描述非常简单，在n个人中随机选取k个人，当k为多大时能保证k个人中有两个人的生日是相同的？另一种说法是，在k个人中至少有两个人的生日相同的概率大于0.5，问k至少多大？\n计算很简单实际上，计算出来概率Q=k个人生日都不相同的选择/总共的选择，然后P=1-Q即为两个人相同的概率。\n对hash的攻击，实际上就是利用从多到少的映射来保证必然会撞见一个假冒的消息并保证hash值一致。\n4.2 HMAC # HASH一般是整个消息不断迭代，计算上一轮压缩函数结果（第一轮为IV）并和明文消息继续运算。\n而HMAC=HASH+MAC，快速，简单，可出口\n4.3 AEAD # 在这里说AEAD实际上稍微有点早，在TLS1.2和TLS1.3进行协商时，如果不使用AEAD算法，那么需要由主密钥计算出来MAC KEY（CLIENT \u0026amp; SERVER）和 ENC KEY(CLIENT \u0026amp; SERVER)。如果使用AEAD算法，那么就可以不计算MAC KEY，因为MAC KEY由NEC KEY衍生出来（就是需要产生一个IV）。\n，几种常见的MAC方法需要先提到链接https://zh.wikipedia.org/wiki/%E8%AE%A4%E8%AF%81%E5%8A%A0%E5%AF%86，然后才能看AEAD。\nAEAD 产生的原因很简单，单纯的对称加密算法，其解密步骤是无法确认密钥是否正确的。也就是说，加密后的数据可以用任何密钥执行解密运算，得到一组疑似原始数据，而不知道密钥是否是正确的，也不知道解密出来的原始数据是否正确。\n实际上就是同时提供认证，如下图同时产生MAC。\n5 数字签名和认证 # 6 密码协议 # 最好玩的一章，也是最蛋疼的一章。\n6.1 基本协议 # 6.1.1 智力扑克协议 # 提供四个特性，1\u0026gt;发牌是随机的2\u0026gt;牌不会重复3\u0026gt;每个人知道自己的牌，不知道对面的牌4\u0026gt;比赛后如果发生欺骗可被察觉。这个要求加密必须满足交换律。\nB先洗牌，使用Eb对52个消息做加密，把加密结果发给A A从52个加密消息里面随机选取5个发送给B，B再解密。这里面我感觉应该A把消息和自己加密过的消息发送给B，才能验证重复。 A另外选五个加密后的消息，使用自己的Ea加密后发给B B对收到的消息做解密再发给A 6.1.2 公平的扔硬币协议 # 扔硬币协议的问题要求双方在没有其他方面的协助下产生随机序列。本质还是利用凭证不可抵赖，不可由凭证逆推出原数据。\n利用平方根扔硬币 利用单向函数扔硬币。 利用二次剩余定理扔硬币 6.1.3 数字承诺协议 # 数字承诺协议本质是提供隐藏性和捆绑性\n6.2 零知识证明 # 所谓零知识证明就是在不透露你的机密信息情况下，证明你清楚这些机密信息。实际上PKI里面的使用签名证明拥有证书就是零知识证明的一种。一般零知识证明都是利用交互式证明系统，一步一步的证明有效性。\n交互式证明和数学证明的区别是，数学证明的证明者可以自己独立完成证明，而交互式证明需要一步一步证明。\n最简单的例子就是走迷宫流程，当然这个过程是基于概率的\n6.3 安全多方协议 # 简单来说就是常见的百万富翁问题，\n6.4 SGX intel的安全区相关知识和问题 # SGX的问题：\nSGX是一种对外的防护吗？那么比方说类似心脏滴血，本身实现不安全导致输出的缓冲区内部有不安全的数据能防备吗？ 回答：内存是直接隔离的，不会出现泄露，不存在任何泄露的可能。\nSGX负责保护关键数据，但是需要用户自己去划分哪些敏感数据需要保护，哪些不需要保护。有没有一般性的指导原则提供给开发者呢？没有\n一般来说，我们有PRF有原始密钥材料，有salt那么就可以拿到输出的密钥。因此，SGX可以作为安全的产生源头吗？还是说只是一个安全隔离的环境？我能不能用它来产生随机数等信息？可以生成随机数。\n在SGX环境下敏感数据如何传递呢？比方说我有个分布式环境：两台电脑A\u0026amp;B，其中A的enclave保存了密钥等敏感数据信息，我现在需要使用B这台机器做加密/解密操作，那么如何进行同步呢？只能采用A使用B的公钥加密然后丢到B的enclave中解密的手段吗？实际上这个手段同样要求enclave能够保护私钥，但是私钥的来源如何保护呢？没有\nSGX的资料里写了，会把数据写到内存并采用加密认证的方式存储，那么我的问题是，这个对内存做加密认证的密钥存储在哪里？是如何保存的呢？怎么避免被dump呢？固化在CPU里面，不对外暴露\n7 可证明安全 # 8 网络加密和认证 # 9 常见的TLS协议和认证协议 # 9.1 常见的安全协议 # 这个链接提供了标准的一些参考信息，https://www.secrss.com/articles/18154\n9.1.1 TLS1.3 和TLS1.2的区别 # 状态变化是前三条，小的细节变化在后面\n一种新的0-RTT模式添加，减少了一个RTT但是带来了一些安全性的问题，比方说不抗重放。 复用机制由PSK替代，复用使用PSK-ONLY/PSK-ECDHE 状态机重新设计，ServerHello之后的所有的消息都进行加密，从而提供保密性。移除无用state，比方说ChangeCipherSpec 静态RSA和DHE秘钥交换技术废除了 对称加密算法全都改成了AEAD也就是加密同时提供认证的cipher KDF重新设计，现在采用HKDF进行秘钥计算 TLS1.2的版本协商机制改为拓展支持 ECC曲线固定基点，新的签名算法给出。 使用random来抗降级攻击，TLS1.3协商出来TLS1.1的话必须修改serverhello.random里面的值。如果想提供抗重放的功能，需要记录ClientHello.random来进行保护。 9.1.2 RFC7296— Internet Key Exchange Protocol Version 2 (IKEv2) 与TLS的对比 # IKE协议主要是针对VPN中的密钥管理和交换方式\n9.2 TLS的秘钥交换协议 # 9.2.1 DHE密钥交换基础 # 从本质来说秘钥交换是在不可信的信道上保证秘钥的安全，利用的还是单向计算的不可达。下面就以Diffie-Hellman秘钥交换为例，Diffie-Hellman秘钥交换的安全性基于求离散对数的困难性：\n已知p是一个大素数 ,a是p的本原根，这两个是公开秘钥\n用户A选择X(A),计算Y(A)=a^X(A) mod p，用户A选择X(B),计算Y(B)=a^X(B) mod p\n用户A和用户B互相发送Y(A)和Y(B)到对端。A和B分别计算k=Y(B)^X(A) mod p和k=Y(A)^X(B) mod p\n易知$k=Y(B)^{X(A)} mod p=(a^{X(B)}mod p)^{X(A)} mod p=a^{X(B)X(A)}mod p$因此两边算出来的数字一致，另一方面攻击者只能拿到p、a、Y(A)、Y(B)。逆推Y到X是不可能的，因此提供保密性。\n基于椭圆曲线的离散对数难题实际上也是类似的方式。\n9.2.2 ECDHE密钥交换 # 和DHE比较类似，只不过计算的流程发生了改变：\n双方需要先协商好约定域参数，换言之确定椭圆曲线时那一条，基点是哪一个 用户A选择$d_A$为私钥，计算公钥$Q_A=d_A G$，此时A的密钥对为$（d_A,Q_A)$。用户B选择$d_B$为私钥，计算公钥$Q_B=d_B G$，此时B的密钥对为$（d_B,Q_B)$ A和B分别选择各自的$Q_A$和$Q_B$发送到对端，然后A和B分别计算$(x_k,y_k)=d_A Q_B$和$(x_k,y_k)=d_B Q_A$。选择一部分作为共享的计算结果 易知$d_A Q_B=d_A *d_B * G = d_B *d_A * G = d_B Q_A$，因此两边的数字一致。而攻击者只能拿到曲线，基点和两个公钥$Q_A,Q_B$。无法从公钥逆推私钥，因此提供保密性 9.2.3 PreMasterSecret \u0026amp; MasterSecret # 这个东西实际上主要是TLS1.2里面的东西，TLS1.3里面没进行大的改动。之所以单独拿出来也是为了解决一些概念上的混淆。PreMasterSecret我们简称为PMS，MasterSecret简称为MS。\nTLS1.2中，PMS是使用密钥交换协议直接获得的值，举个简单例子Diffie-Hellman中，就是直接计算出来的 $(g^a )^b(mod p)$。 该参数的长度和密钥交换协议使用的参数与算法直接相关。为了简化问题，MS是用来衍生其他密钥的固定长度的基础密钥。这就是为什么我们使用PMS生成MS的原因。除此之外还有一些其他参数参与运算，需要注意的是，TLS1.2当中，通过密钥协商直接计算出来的PMS是需要去掉。leading zeros 具体参看RFC的计算流程为：\nmaster_secret = PRF(pre_master_secret, \u0026#34;master secret\u0026#34;, ClientHello.random + ServerHello.random) [0..47]; 那么到了TLS1.3当中，出现了哪些变化呢？\nTLS1.3当中master_secret没变化，依然用来参与计算各种衍生密钥。但是PMS变了，被更名为(EC)DHE shared secret（章节7.4），无论是对于有限域的DHE交换，还是对于Elliptic Curve Diffie-Hellman，计算流程什么的都没改变，但是不需要再如同TLS1.2当中去掉leading zeros（务必不要去掉）。如何从PMS计算出来MS呢？具体参见RFC(底下的（EC)DHE就是原先的PMS：\nEarlySecret = HKDF_ETRACT(PSk, 0); DerivedEarlySecret = Derive-Secret(EarlySecret); HandshakeSecret = HKDF_EXTRACT((EC)DHE,DerivedEarlySecret); DeriveHandshakeSecret = Derive-Secret(HandshakeSecret); MasterSecret = HKDF_EXTRACT(DeriveHandshakeSecret); 9.3 常见的公钥加密方式的基本原理 # 这个还是看第二章公钥密码那里吧，就不多赘述了。\n9.4 常见的认证机制 # 9.4.0 常见的认证机制 # 认证的分类\n通信信道上的认证：你和我建立通信连接之前，要先证明你是谁。在网络传输（Network）场景中的典型是基于 SSL/TLS 传输安全层的认证。现在的很多微服务都是直接在通信信道上面的认证，基本认可了信道认证就够了。在TLS上面做操作还有一个很大的好处，就是可以直接对抗重放， 通信协议上的认证：你请求获取我的资源之前，要先证明你是谁。在互联网（Internet）场景中的典型是基于 HTTP 协议的认证。 通信内容上的认证：你使用我提供的服务之前，要先证明你是谁。在万维网（World Wide Web）场景中的典型是基于 Web 内容的认证。 我做的tls实际上是通信信道上的认证，通信协议参考，通信内容参考WebAuthn\nWebAuthn 规范涵盖了“注册”与“认证”两大流程，先来介绍注册流程，它大致可以分为以下步骤：\n用户进入系统的注册页面，这个页面的格式、内容和用户注册时需要填写的信息均不包含在 WebAuthn 标准的定义范围内。 当用户填写完信息，点击“提交注册信息”的按钮后，服务端先暂存用户提交的数据，生成一个随机字符串（规范中称为 Challenge）和用户的 UserID（在规范中称作凭证 ID），返回给客户端。 客户端的 WebAuthn API 接收到 Challenge 和 UserID，把这些信息发送给验证器（Authenticator），验证器可理解为用户设备上 TouchID、FaceID、实体密钥等认证设备的统一接口。 验证器提示用户进行验证，如果支持多种认证设备，还会提示用户选择一个想要使用的设备。验证的结果是生成一个密钥对（公钥和私钥），由验证器存储私钥、用户信息以及当前的域名。然后使用私钥对 Challenge 进行签名，并将签名结果、UserID 和公钥一起返回客户端。 浏览器将验证器返回的结果转发给服务器。 服务器核验信息，检查 UserID 与之前发送的是否一致，并用公钥解密后得到的结果与之前发送的 Challenge 相比较，一致即表明注册通过，由服务端存储该 UserID 对应的公钥。 参考 9.4.5 我们的国密认证 # 总结：使用用户名密码保护只能钥匙，而智能钥匙和身份绑定，时间戳对抗重放。每个实体网关的标识码不同，保证不会出现同一管理员可解锁所有设备的问题。\n流程如下：\nAPV应用安全网关设备启动后，管理员在设备上插入龙脉SJK1970智能密码钥匙，并在控制台上输入用户名和智能密码钥匙口令。\n上述校验通过后智能密码钥匙取得当前系统的时间戳Ta、B、Ta异或Array APV应用安全网关的标识符B的结果，做数字签名，计算TokenAB，附带智能密码钥匙存储的数字证书一起发给Array APV应用安全网关。公式为：\nTokenAB = Ta || B || Text2 || SSA(Ta || B || Text1) //B 为Array APV应用安全网关的实体标识码。每台APV应用安全网关的实体标识码不同。 //Text2为 用户输入的用户名。 //Text1为Ta异或B的结果。 Array APV应用安全网关用系统预置的智能密码钥匙证书的颁发者证书，验签智能密码钥匙发过来的证书。\nArray APV应用安全网关首先使用验签通过的证书中的公钥对签名值进行验签运算，验签通过，然后验证Ta和当前系统时间是否一致（误差在1分钟之内），然后验证B是否为APV应用安全网关设备的实体标识，然后验证Text2（用户输入的用户名）和验签通过证书的主题项中的名字是否一致的\n缺点有：\n内部秘钥没有管理可言，不存在任何的秘钥管理（更新，删除，吊销等等） 时钟同步要求比较严格。 不具备任何可拓展性。 9.4.1 授权 # RBAC # RBAC主要为了解决主题授权的问题，参考Kerberos\n总结：从本质来说，Kerberos需要每个用户拥有自己的秘钥（最早只有对称加密），TGT必须有每个客户的秘钥和TGT的秘钥，而每个TGT必须要每个客户的秘钥和SS的秘钥。使用时间戳来初步的抗重放和保证有效性。里面的基本概念的缩写如下：\nAS（Authentication Server）= 认证服务器 KDC（Key Distribution Center）= 密钥分发中心 TGT（Ticket Granting Ticket）= 票据授权票据，票据的票据 TGS（Ticket Granting Server）= 票据授权服务器 SS（Service Server）= 特定服务提供端 流程：\n首先，用户使用客户端（用户自己的机器）上的程序进行登录： 用户输入用户ID和密码到客户端。 客户端程序运行一个单向函数（大多数为杂凑）把密码转换成密钥，这个就是客户端（用户）的“用户密钥”(user\u0026rsquo;s secret key)。 随后 客户端认证（客户端(Client)从认证服务器(AS)获取票据的票据（TGT））： Client向AS发送1条明文消息，申请基于该用户所应享有的服务，例如“用户Sunny想请求服务”（Sunny是用户ID）。（注意：用户不向AS发送“用户密钥”(user\u0026rsquo;s secret key)，也不发送密码）该AS能够从本地数据库中查询到该申请用户的密码，并通过相同途径转换成相同的“用户密钥”(user\u0026rsquo;s secret key)。 AS检查该用户ID是否在于本地数据库中，如果用户存在则返回2条消息： 消息A：Client/TGS会话密钥(Client/TGS Session Key)（该Session Key用在将来Client与TGS的通信（会话）上），通过**用户密钥(user\u0026rsquo;s secret key)**进行加密 消息B：票据授权票据(TGT)（TGT包括：消息A中的“Client/TGS会话密钥”(Client/TGS Session Key)，用户ID，用户网址，TGT有效期），通过**TGS密钥(TGS\u0026rsquo;s secret key)**进行加密 一旦Client收到消息A和消息B，Client首先尝试用自己的“用户密钥”(user\u0026rsquo;s secret key)解密消息A，如果用户输入的密码与AS数据库中的密码不符，则不能成功解密消息A。输入正确的密码并通过随之生成的\u0026quot;user\u0026rsquo;s secret key\u0026quot;才能解密消息A，从而得到“Client/TGS会话密钥”(Client/TGS Session Key)。（注意：Client不能解密消息B，因为B是用TGS密钥(TGS\u0026rsquo;s secret key)加密的）。拥有了“Client/TGS会话密钥”(Client/TGS Session Key)，Client就足以通过TGS进行认证了。 然后，服务授权服务授权（client从TGS获取票据(client-to-server ticket)）： 当client需要申请特定服务时，其向TGS发送以下2条消息： 消息c：即消息B的内容（TGS\u0026rsquo;s secret key加密后的TGT），和想获取的服务的服务ID（注意：不是用户ID） 消息d：认证符(Authenticator)（Authenticator包括：用户ID，时间戳），通过**Client/TGS会话密钥(Client/TGS Session Key)**进行加密 收到消息c和消息d后，TGS首先检查KDC数据库中是否存在所需的服务，查找到之后，TGS用自己的“TGS密钥”(TGS\u0026rsquo;s secret key)解密消息c中的消息B（也就是TGT），从而得到之前生成的“Client/TGS会话密钥”(Client/TGS Session Key)。TGS再用这个Session Key解密消息d得到包含用户ID和时间戳的Authenticator，并对TGT和Authenticator进行验证，验证通过之后返回2条消息： 消息E：client-server票据(client-to-server ticket)（该ticket包括：Client/SS会话密钥 (Client/Server Session Key），用户ID，用户网址，有效期），通过提供该服务的**服务器密钥(service\u0026rsquo;s secret key)**进行加密 消息F：Client/SS会话密钥( Client/Server Session Key)（该Session Key用在将来Client与Server Service的通信（会话）上），通过**Client/TGS会话密钥(Client/TGS Session Key)**进行加密 Client收到这些消息后，用“Client/TGS会话密钥”(Client/TGS Session Key)解密消息F，得到“Client/SS会话密钥”(Client/Server Session Key)。（注意：Client不能解密消息E，因为E是用“服务器密钥”(service\u0026rsquo;s secret key)加密的）。 最后，服务请求（client从SS获取服务）： 当获得“Client/SS会话密钥”(Client/Server Session Key)之后，Client就能够使用服务器提供的服务了。Client向指定服务器SS发出2条消息： 消息e：即上一步中的消息E“client-server票据”(client-to-server ticket)，通过**服务器密钥(service\u0026rsquo;s secret key)**进行加密 消息g：新的Authenticator（包括：用户ID，时间戳），通过**Client/SS会话密钥(Client/Server Session Key)**进行加密 SS用自己的密钥(service\u0026rsquo;s secret key)解密消息e从而得到TGS提供的Client/SS会话密钥(Client/Server Session Key)。再用这个会话密钥解密消息g得到Authenticator，（同TGS一样）对Ticket和Authenticator进行验证，验证通过则返回1条消息（确认函：确证身份真实，乐于提供服务）： 消息H：新时间戳（新时间戳是：Client发送的时间戳加1，v5已经取消这一做法），通过**Client/SS会话密钥(Client/Server Session Key)**进行加密 Client通过Client/SS会话密钥(Client/Server Session Key)解密消息H，得到新时间戳并验证其是否正确。验证通过的话则客户端可以信赖服务器，并向服务器（SS）发送服务请求。 服务器（SS）向客户端提供相应的服务。 Kerberos 的缺点：\n失败于单点：它需要中心服务器的持续响应。当Kerberos服务宕机时，没有人可以连接到服务器。这个缺陷可以通过使用复合Kerberos服务器和缺陷认证机制弥补。 因为所有用户使用的密钥都存储于中心服务器中，危及服务器的安全的行为将危及所有用户的密钥。 Kerberos要求参与通信的主机的时钟同步。票据具有一定有效期，因此，如果主机的时钟与Kerberos服务器的时钟不同步，认证会失败。默认设置要求时钟的时间相差不超过10分钟。在实践中，通常用网络时间协议后台程序来保持主机时钟同步。 管理协议并没有标准化，在服务器实现工具中有一些差别。 OAUTH2 # OAUTH2主要解决对第三方应用授权的问题，\n四种授权方式：\n授权码模式：\n第三方应用将资源所有者（用户）导向授权服务器的授权页面，并向授权服务器提供 ClientID 及用户同意授权后的回调 URI，这是一次客户端页面转向。 授权服务器根据 ClientID 确认第三方应用的身份，用户在授权服务器中决定是否同意向该身份的应用进行授权，用户认证的过程未定义在此步骤中，在此之前应该已经完成。 如果用户同意授权，页面将从授权服务器的页面转向第三方应用在第 1 步调用中提供的回调 URI，并附带上一个授权码和获取令牌的地址作为参数（先从授权服务器发送到客户端，再从客户端发送到第三方），这是第二次客户端页面转向。这里的意思我理解就是实际上授权码和获取令牌的地址是从客户端那里重定位到第三方应用的，所以下面继续走 第三方应用通过回调地址收到授权码，然后将授权码与自己的 ClientSecret 一起作为参数，通过服务器向授权服务器提供的获取令牌的服务地址发起请求，换取令牌。该服务器的地址应与注册时提供的域名处于同一个域中。 授权服务器核对授权码和 ClientSecret，确认无误后，向第三方应用授予令牌。令牌可以是一个或者两个，其中必定要有的是访问令牌（Access Token），可选的是刷新令牌（Refresh Token）。访问令牌用于到资源服务器获取资源，有效期较短，刷新令牌用于在访问令牌失效后重新获取，有效期较长。 资源服务器根据访问令牌所允许的权限，向第三方应用提供资源。 这个过程设计，已经考虑到了几乎所有合理的意外情况，笔者再举几个最容易遇到的意外状况，以便你能够更好地理解为何要这样设计 OAuth2。\n会不会有其他应用冒充第三方应用骗取授权？ ClientID 代表一个第三方应用的“用户名”，这项信息是可以完全公开的。但 ClientSecret 应当只有应用自己才知道，这个代表了第三方应用的“密码”。在第 5 步发放令牌时，调用者必须能够提供 ClientSecret 才能成功完成。只要第三方应用妥善保管好 ClientSecret，就没有人能够冒充它。\n为什么要先发放授权码，再用授权码换令牌？ 这是因为客户端转向（通常就是一次 HTTP 302 重定向）对于用户是可见的，换而言之，授权码可能会暴露给用户以及用户机器上的其他程序，但由于用户并没有 ClientSecret，光有授权码也是无法换取到令牌的，所以避免了令牌在传输转向过程中被泄漏的风险。\n为什么要设计一个时限较长的刷新令牌和时限较短的访问令牌？不能直接把访问令牌的时间调长吗？ 这是为了缓解 OAuth2 在实际应用中的一个主要缺陷，通常访问令牌一旦发放，除非超过了令牌中的有效期，否则很难（需要付出较大代价）有其他方式让它失效，所以访问令牌的时效性一般设计的比较短，譬如几个小时，如果还需要继续用，那就定期用刷新令牌去更新，授权服务器就可以在更新过程中决定是否还要继续给予授权。\n简化模式，或者说隐式模式\n隐式模式与授权码模式的显著区别是授权服务器在得到用户授权后，直接返回了访问令牌，这显著地降低了安全性，但 OAuth2 仍然努力尽可能地做到相对安全，譬如在前面提到的隐式授权中，尽管不需要用到服务端，但仍然需要在注册时提供回调域名，此时会要求该域名与接受令牌的服务处于同一个域内。此外，同样基于安全考虑，在隐式模式中明确禁止发放刷新令牌。\n密码模式\n客户端模式\n9.4.2 凭证JWT # 分为三个部分，分别为header/payload/signature。header为声明的类型和使用的算法，payload是载荷，最后是加上hmac签名，有很多问题。\n其一般包含以下字段\niss（Issuer）：签发人。 exp（Expiration Time）：令牌过期时间。 sub（Subject）：主题。 aud （Audience）：令牌受众。 nbf （Not Before）：令牌生效时间。 iat （Issued At）：令牌签发时间。 jti （JWT ID）：令牌编号。 缺点是\n令牌难以主动失效：JWT 令牌一旦签发，理论上就和认证服务器再没有什么瓜葛了，在到期之前就会始终有效，除非服务器部署额外的逻辑去处理失效问题，这对某些管理功能的实现是很不利的。譬如一种颇为常见的需求是：要求一个用户只能在一台设备上登录，在 B 设备登录后，之前已经登录过的 A 设备就应该自动退出。如果采用 JWT，就必须设计一个“黑名单”的额外的逻辑，用来把要主动失效的令牌集中存储起来，而无论这个黑名单是实现在 Session、Redis 或者数据库中，都会让服务退化成有状态服务，降低了 JWT 本身的价值，但黑名单在使用 JWT 时依然是很常见的做法，需要维护的黑名单一般是很小的状态量，许多场景中还是有存在价值的。无状态到有状态都这样子 相对更容易遭受重放攻击：首先说明 Cookie-Session 也是有重放攻击问题的，只是因为 Session 中的数据控制在服务端手上，应对重放攻击会相对主动一些。要在 JWT 层面解决重放攻击需要付出比较大的代价，无论是加入全局序列号（HTTPS 协议的思路）、Nonce 字符串（HTTP Digest 验证的思路）、挑战应答码（当下网银动态令牌的思路）、还是缩短令牌有效期强制频繁刷新令牌，在真正应用起来时都很麻烦。真要处理重放攻击，建议的解决方案是在信道层次（譬如启用 HTTPS）上解决，而不提倡在服务层次（譬如在令牌或接口其他参数上增加额外逻辑）上解决。 只能携带相当有限的数据：HTTP 协议并没有强制约束 Header 的最大长度，但是，各种服务器、浏览器都会有自己的约束，譬如 Tomcat 就要求 Header 最大不超过 8KB，而在 Nginx 中则默认为 4KB，因此在令牌中存储过多的数据不仅耗费传输带宽，还有额外的出错风险。 必须考虑令牌在客户端如何存储：严谨地说，这个并不是 JWT 的问题而是系统设计的问题。如果授权之后，操作完关掉浏览器就结束了，那把令牌放到内存里面，压根不考虑持久化才是最理想的方案。但并不是谁都能忍受一个网站关闭之后下次就一定强制要重新登录的。这样的话，想想客户端该把令牌存放到哪里？Cookie？localStorage？Indexed DB？它们都有泄漏的可能，而令牌一旦泄漏，别人就可以冒充用户的身份做任何事情。 无状态也不总是好的：这个其实不也是 JWT 的问题。如果不能想像无状态会有什么不好的话，我给你提个需求：请基于无状态 JWT 的方案，做一个在线用户实时统计功能。兄弟，难搞哦。 9.5 访问控制 与 输入处理 # Web应用需要限制用户对应用程序的数据和功能的访问，以防止用户未经授权访问。访问控制的过程可以分为验证、会话管理和访问控制三个地方。\n验证机制验证机制在一个应用程序的用户访问处理中是一个最基本的部分，验证就是确定该用户的有效性。大多数的web应用都采用使用的验证模型，即用户提交一个用户名和密码，应用检查它的有效性。在银行等安全性很重要的应用程序中，基本的验证模型通常需要增加额外的证书和多级登录过程，比如客户端证书、硬件等。\n会话管理为了实施有效的访问控制，应用程序需要一个方法来识别和处理这一系列来自每个不同用户的请求。大部分程序会为每个会话创建一个唯一性的token来识别。\n对攻击者来说，会话管理机制高度地依赖于token的安全性。在部分情况下，一个攻击者可以伪装成受害的授权用户来使用Web应用程序。这种情况可能有几种原因，其一是token生成的算法的缺陷，使得攻击者能够猜测到其他用户的token；其二是token后续处理的方法的缺陷，使得攻击者能够获得其他用户的token。\n访问控制处理用户访问的最后一步是正确决定对于每个独立的请求是允许还是拒绝。如果前面的机制都工作正常，那么应用程序就知道每个被接受到的请求所来自的用户的id，并据此决定用户对所请求要执行的动作或要访问的数据是否得到了授权。\n由于访问控制本身的复杂性，这使得它成为攻击者的常用目标。开发者经常对用户会如何与应用程序交互作出有缺陷的假设，也经常省略了对某些应用程序功能的访问控制检查。\n输入处理常用的防护机制有如下几种：黑名单、白名单、过滤、处理。\n9.6 密钥管理 # 密钥管理（Key management）是一个密码系统中加密密钥的管理部分。它包括密钥的生成、交换、存储、使用、密钥销毁以及密钥更替的处理，涉及到密码学协议设计、密钥服务器、用户程序，以及其他相关协议。\n密钥是存储的核心，但是存储的内容和权限实际上是分离的，可以从三个层面来说：\n角色：拥有一部分权限的预定义身份。每个角色下面对应的是一系列策略 策略：策略分为三个方面：resource具体操作的对象/action什么行为/effect 授权：授权给具体的对象已经制造出来的角色 9.6.1 密钥的检索与分类 # 密钥的分类是密钥管理的第一步，这一步伴随着密钥的整个生命周期：\n根据对称加密/公钥加密体制进行检索和分类， 根据证书和私钥管理策略的起点（即所有凭证的位置和责任方）进行检索和分类，这个主要是应对某些攻击：比方说CA被攻陷时能够立刻检索到所有由该CA签发的证书。 密钥的管理者，这里的管理者不是私钥的拥有者，而是在密钥管理当中进行管理的人员。之所以考虑这个是因为密钥管理当中，人往往是最弱的一环。实际上这里也是根据密钥的功能进行分级的，比方说一级根密钥管理二级密钥，二级密钥管理三级密钥 9.6.2 管理流程 # 9.6.2.1 密钥交换 # 密钥交换面临的一个非常实际的问题，就是怎么找到可信的对端，怎么令对端认为自己可信，这往往是密钥交换的起点问题。\n9.6.2.2 密钥存储 # 如何实行密钥存储？明文？密文？怎么保证密钥对管理者是不可见的？这里面涉及到了一个同态加密的问题。这里需要注意抽象和具体的实现方法的剥离，这是一种具体的明智的管理方法。\n9.6.2.3 密钥使用 # 密钥的有效期限是一个重要问题，一个密钥应该在产生后多久被汰换呢？这是密钥使用的问题，另一方面，一个用户应该有多少对密钥？由公钥保护一堆对称密钥吗？这是主要的问题。\n9.6.3 密钥管理面临的问题 # 面临的问题实际上非常多\n如何高效，有组织的管理大量的加密密钥？ 抽象层面下层如何存储管理基本的介质，底层用的是数据库？文档？ 如何进行治理密钥，有效/无效/吊销如何进行？ 怎么保证保密性，如何提供完整性和认证性？ 实际上，很多时候看到的标准或者法规就是在规定如何进行管理，但是说实在的，很多人对于法规不是那么支持到底的。\n9.6.4 安全标准及法规 # GB/T 27909（ISO 11568） # 由于后者的标准（文档）是收费的，因此，参考了国内的国标来进行内容整理。27909标准里面的三块,1-一般原则，2-对称密钥管理，3-非对称密钥管理\n总则 # 对称密钥管理 # 对于不可重复密钥而言，密钥必须保证不可预测性及密钥在密钥空间中的等概率性。此外，需要利用外界信息进行密钥的迭代：比方说，利用ISO18031中的流程。 对于可重复密钥而言，密钥必须保证不可预测性及密钥在密钥空间中的等概率性。从原始密钥生成可重复密钥的流程应当是不可逆向的，即已泄露的初始密钥不能导致任何其他已生成密钥的泄露。\n密钥分级：密钥的机密性依靠其它密钥的机密性，密钥分级中某一级的泄露不应导致更高一级密钥的泄露。简单来说，具体的工作密钥由密钥加密密钥（KEK）进行保护。同样密钥生成密钥（KGK）也认为是比它所生成的密钥更高一级的密钥。\n密钥生命周期：\n密钥存储：密钥只应当以以下三种形式存在，明文密钥，由于泄露影响太大，因此只能存储于安全密码设备里/物理安全环境；密钥组件，以至少两个或多个分离的密钥组件形式密钥通过密钥分割和双重控制技术进行保护，授权一个密钥组件的人不能访问此密钥的其他组件；加密的密钥，这个没啥好说的；\n密钥完整性：数字签名，MAC，密钥分组绑定方法\n密钥使用：应当防止密钥的未授权访问，密钥只应在其预定的位置上用于其预定的功能。\n密钥更换：如果确认/怀疑密钥泄露，那么该密钥保护/导出的其它密钥也得替换。\n密钥归档：密钥归档只用于检验合法性，验证结束后销毁所有密钥实例，且归档的密钥不应再次投入使用。\n非对称密钥管理 # ISO 11770 # 分为三个部分，\n参考资料：https://docs.microsoft.com/en-us/sql/relational-databases/security/encryption/sql-server-and-database-encryption-keys-database-engine?view=sql-server-ver15\n9.6.5 （开源）密钥管理软件 # Barbican # 网址在这里：https://github.com/openstack/barbican\n优点在于：\n社区环境比较好，生态不错 有连续/明朗的管理策略 提供带外通信手段保护敏感信息/资产 缺点在于:\n单点故障比较严重， EPKS\nVault # 相关的资料很多，毕竟是开源产品。产品资料比较全面，\n产品的优点在于：\n相比其他产品，特意提出了吊销管理Revocation，作为自己的一个特色。 密钥的管理相对而言比较灵活，可以对密钥种类，密钥功能，密钥衍生等进行检索。 缺点在于：\n根据使用接口来说，使用方式不够灵活，细节不够具体。 提供的服务包括五个角度：\n安全存储：存储介质上的私钥是加密过的，获得存储介质上的文件并不会导致信息泄露。 动态密钥生成：根据需求生成不同的密钥， 数据加密： 租约和管理：voalt中所有的密钥都有租约关联，租约到期vault自动将之吊销。 吊销：吊销管理不单独针对具体的密钥，可以针对密钥种类/密钥树等类型。 这个文章似乎不错，可以用来学习vault的结构\nhttps://shuhari.dev/blog/2018/02/vault-introduction\n原理架构。\nGOOGLE的OPENSK\n腾讯云密钥管理系统产品文档 # 网址链接为https://main.qcloudimg.com/raw/document/intl/product/pdf/1030_31974_zh.pdf\n这个产品优点在于：\n它真正的提供了一款可用安全的服务，给出了客户SDK的可用接口的具体细节。 与hackeryeah的kms（下面的产品）相比多了合规和审计的部分， HSM符合国家标准，看上去比hackeryeah的更合规 缺点在于：\n对于密钥保护的层级力度不足，没有具体的层级安全，当然可能是产品文档里面给出的细节不多。 依然需要端到端加密来提供通信的安全性 信封解密过程使用DEK密文来保证正确归属性，非常糟糕的设计。且DEK的安全性是由待考证的。 RSA类型的密钥长度支持有限，只支持到2048 密钥分级：\n客户主密钥CMK保护敏感数据，CMK由HSM进行保护。主密钥CMK在HSM中进行加解密，腾讯云的管理是看不到具体CMK内容的。\nKMS # 粒度由namespace控制，控制也比较粗糙。\n[FREEBUF上的hackeryeah写的KMS] # 网址链接为https://www.freebuf.com/articles/es/229311.html\n这个产品优点在于：\n它基于实际的角度设计了一款KMS服务，并且提炼出通用KMS服务的基本点，诸如分级密钥，密钥管理 虽然是在抽象角度，但是很详细地给出了KMS中的具体模块及功能。 缺点在于：\n可以标准化的组件没有利用好，不能提炼成模块。 依然需要端到端加密来提供通信的安全性 密钥分级：\n数据加密密钥(DEK):将用于数据加密的密钥,也称三级密钥(DEK);一般公司里面一个应用对应一个DEK； 密钥加密密钥(KEK):保护三级的密钥,也称二级密钥(KEK 即对DEK进行加密);一般公司里面一个部门对应一个KEK，DEK在KEK管辖之内。 根密钥(RootKey):保护二级密钥的密钥，也称一级密钥(RootKey，即是对KEK进行加密)，根密钥构成了整个密钥管理系统的关键。 基本架构：\nSDK：主要提供给服务的使用者集成到自己开发的项目中,实现密钥的创建、导入、启用、禁用等相关密钥管理和加密以及解密等常见操作。SDK分为:Client模块、加解密模块，主要负责提供简单接口完成加密解密功能。 KMS服务：主要负责从硬件安全模块获取和保存根密钥,并且安全地保存在后台内存中,然后通过密钥的派生算法生成KEK进而生成DEK。分为，根密钥加载模块、密钥派生模块、Server模块。 HSM：提供根密钥生成和保管服务。 这里面存在一些技术细节：\n对于一级根密钥，推荐使用安全门限算法保证分割安全，既必须多个揭密者的密钥都获得的情况下，才能成功解密一级根密钥。\n防止根密钥被泄露，根密钥RootKey由密钥管理服务KMS从硬件安全模块即HSM中读取,按照一定的分散算法打散存储在内存中。\n创建密钥的流程：\n用户调用KMS提供的SDK中的创建用户数据密钥接 用户传入用户ID等必要信息(如果要创建KEK则传入部门信息，如果创建DEK则传入应用信息) KMS服务器验证请求 验证通过,KMS服务器在该用户名下创建新的密钥并返回密钥ID 密钥加密(解密同理)：\n服务调用方调用KMS提供的SDK中直接加密的接 服务调用方传入用户ID、密钥ID、待加密明文 KMS服务器验证密钥ID、用户ID以及是否为用户ID名下 验证通过,KMS服务器返回DEK到SDK中 SDK加密算法中对明文进行加密，并返回密文 [Self Design Kms] # 具体的客户机器，甚至包括操作数据库的机器，每台机器上存在一个KMS-Agent，每个KMS-Agent有私钥和公钥（证书），握手的时候使用证书私钥校验身份。证书当中包含该KMS-Agent的身份appkey，该KMS-Agent能够获取的秘钥必须都是对该appkey授权的秘钥。KMS-Agent获取的秘钥必须以加密方式存储，数据的结构如下，这里有一点要注意，Environment是环境变量，不会存储在数据结构里，对客户是透明的：\nnamespace name encrypted_key key_type srand timestamp version kms_secret_version namespace \u0026amp; name用来确定密钥，key_type确定key类型，比方说rsa/ecc/hmac等等，srand为随机数增加随机性，timestamp用来确定加密时间，一起参与到存储中。version用来存储秘钥的版本\nencrypted_key = Encrypted(plan_key)，秘钥为KMS-Agent Secret HKDF with srand \u0026amp; timestamp。kms_secret_version用来在迭代kms密钥时使用。\n这里面有一点要注意，encrypted_key需要使用base64编码，然后存入数据库\nHSM存储RootKey，可以用来生成二级密钥KEK，加密二级密钥KEK，RootKey从来不出HSM\n数据库密钥的存储\nKEK使用ROOTKEY+SRAND+TIMESTAMP存储于主数据库，\nnamespace encrytped_kek key_type srand timestamp environment version root_version owner 一个KEK对应一个namespace下的密钥，encrypted_kek = Encrypted(plan_kek)，加密操作为rootkey HKDF with srand \u0026amp; timestamp。timestamp为生成的日期，version用于轮转，轮转的频率可以设置，每次最多保留两个相邻版本的不同的encrypted_kek，当所有的由老版本的kek保护的具体应用秘钥ak都更新为使用新版本的key之后。老版本的key记录到日志更新操作里面。\n这里面有两点需要注意：\nencrypted_kek使用base64编码存入数据库，方便显示和查看。 namespace使用uniqueIndex AK，用户具体使用AK存储各种秘钥\nnamespace name encrypted_ak key_type srand timestamp environment version kek_version owner 每一个AK都有一个namespace，namespace由KEK保护，encrypted_ak= Encrypted(plan_ak)，加密操作为kek HKDF with srand \u0026amp; timestamp，每个timestamp,srand,都是秘钥自己的属性，和具体使用的kek的timestamp没关系，通过kek_version确定用的哪个kek做保护。\n这里面有三点要注意，encrypted_ak需要使用base64编码，然后存入数据库\nkms agent，即每个docker上面的kms 私钥也是需要存储在数据库当中的，所以还需要一个agent secret table。需不需要证书库呢？ encrypted_ak使用base64编码存入数据库，方便显示和查看。 namespace，name使用uniqueIndex AK授权关系，用来指定授权关系，根据指定具体的appkey来决定是不是授权\nnamespace name environment ownerappkey grantedappkey behavior namespace+name+environment用来指定秘钥是哪个，granted_appkey则指定该appkey可以获取该秘钥，behavior的权限为读和写。不过一帮都是只允许读\n用户信息\nName AppKey Cert KeyCipherText KeyType Srand TimeStamp Version KEKVersion 用户信息实际上和普通的Ak非常类似，只不过多了appkey和cert的存储，其中的keyciphertext是密文存储的用户私钥，需要事先创建名为”user“的production的KEK。\nKMS初始化的操作\n初始化数据库的连接和各种内部的数据表 初始化内存中的多线程并发读写mapserver.InitServerCmap\n初始化服务器的密钥\n输入服务器证书，私钥，CA证书和CA私钥 计算出固定的数据库rootkey，并且计算出本次启动cache到本地内存时加密数据使用的临时密钥\n判断user namepsace的kek是否存在，不存在则创建 初始化crl\n实际上就是创建crl证书吊销列表的内部保存map，然后从数据库当中读取出来这些吊销过的用户cert序列号。当用户访问的时候需要判断这些用户是否被吊销 初始化server的rbac信息\nrbac信息目前实现比较简单，除了root之外没有别的角色。自定角色的功能一直支持，但是没有启用的场景 数据库密钥的创建，更新与管理\n有HSM参与的情况下，RootKey存储于HSM中，当HSM不参与的情况下，以服务器的私钥使用HKDF手段生成的AES KEY作为ROOT KEY，参与KEK的生成和加密，将KEK存储于数据库中。 如果没有HSM，rootkey或者说纯私钥的原始密钥材料，那么使用P12格式存储在文件中，每次服务器启动读取rootkey的原始密钥材料，需要输入读取P12的密码来做解密 用户请求生成ak之前，应该先申请生成对应的kek，存储于数据库当中。 单独申请生成对应的kek（感觉这个没必要啊），但是这个可以一定程度简化设计。使用了gorm的FirstOrCreate函数 用户请求生成AK时 启动一个事务 检索当前的kek。这个时候使用行级别共享锁，锁住kek 在锁住kek的前提下，写入ak。总之务必保证，写入ak的时候kek是不变的，这两个是个原子操作。 用户申请读取ak时，先获取ak，然后拿这个ak对应的kek号读取kek，之后解秘kek再解密ak。过程当中都是行级别共享锁 用户申请更新ak时： 读取ak，先比较ak和用户用户希望更新ak的时候，旧版本的版本号是不是一样的，如果更新的时候发现版本号和请求的版本号不一样，那么就abort这个过程，返回错误。 如果ak的信息和用户给的信息是一致的，那么先拿到kek，然后生成新的ak。 生成新的ak后，启动事务。先用共享锁锁住kek，再更新ak，更新，然后释放事务。更新的时候务必保证ak的原始namespace，name，version，envirotment都是旧的数据。 自动更新kek： 检查当前的kek的旧的版本号是不是要更新的版本号-1，不是就放弃，否则 启动一个事务，使用独占锁，更新其内容和版本号，然后一条一条更新数据库内使用旧版本的kek加密的ak，整个都成功了，才算是成功。所以更新kek \u0026amp; ak 是原子操作。kek使用独占锁，使得旧版本的kek不会被其他连接读取或者更新，不允许其他连接读取是为了避免读取到旧的kek然后创建新的ak，对kek关联的ak使用独占 另一种更新秘钥的想法，数据库是纯无状态的，每次都需要存储历史版本的秘钥。比方说rootkey \u0026amp; kek都会记录历史版本，比方说当前是2，那么除了记录2，还会记录版本1。然后更新的时候只要找对应的下级秘钥还用旧的秘钥存储的，然后更新即可。 服务端程序的核心流程\n一个Server内部包含两个并发map，一个map存储kek，另一个密钥存储ak。 kek map存储明文kek，每次更新操作\nak map存储明文ak，每次检索不到就会\n启动server的命令\ngo run server/server.go --logtostderr=true 生成服务器使用的CA证书\n首先生成私钥\nopenssl req -new -x509 -extensions v3_ca -newkey rsa:4096 -keyout ca.key -out ca.pem -days 3650 -config ./ca.conf 补充一些openssl的操作命令，可以直接看https://www.jianshu.com/p/ea5bc56211ee这个文章。\n生成服务端rsa私钥：\nopenssl genrsa -out server/server.key 4096 生成服务端证书申请csr，这种方式使用默认的openssl.cnf文件，来生成csr文件\nopenssl req -new -key server/server.key -reqexts SAN -config \u0026lt;(cat /System/Library/OpenSSL/openssl.cnf \u0026lt;(printf \u0026#34;[SAN]\\nsubjectAltName=DNS:kms.qcraftai.com,DNS:security.qcraftai.com\u0026#34;)) -out server/server.csr 使用CA和CSR生成服务端证书文件。\nopenssl x509 -req -sha256 -CA ca.pem -CAkey ca.key -CAcreateserial -days 3650 -in server/server.csr -extensions SAN -extfile \u0026lt;(cat /System/Library/OpenSSL/openssl.cnf \u0026lt;(printf \u0026#34;[SAN]\\nsubjectAltName=DNS:kms.qcraftai.com,DNS:security.qcraftai.com\u0026#34;)) -out server/server.pem 生成客户端证书是同样的道理。举一个简单的例子\n生成客户端rsa私钥：\nopenssl genrsa -out client/client.key 2048 生成服务端证书申请csr，这种方式使用默认的openssl.cnf文件，来生成csr文件\nopenssl req -new -key client/client.key -reqexts SAN -config \u0026lt;(cat /System/Library/OpenSSL/openssl.cnf \u0026lt;(printf \u0026#34;[SAN]\\nsubjectAltName=AppKey:testclientkey\u0026#34;)) -out client/client.csr 使用CA和CSR生成服务端证书文件。\nopenssl x509 -req -sha256 -CA ca.pem -CAkey ca.key -CAcreateserial -days 3650 -in client/client.csr -extensions SAN -extfile \u0026lt;(cat /System/Library/OpenSSL/openssl.cnf \u0026lt;(printf \u0026#34;[SAN]\\nsubjectAltName=appkey:testclientkey\u0026#34;)) -out client/client.pem 那么现在如何进行编译和管理呢？关于postgresql参考下面的链接：\nhttps://hanggi.me/post/kubernetes/k8s-postgresql/\rhttps://gruchalski.com/posts/2021-07-12-postgres-in-docker-with-persistent-storage/ 我们是找了一台机器，执行命令\n//下面的命令映射出来port\rdocker run -d --name kms-storage -e POSTGRES_PASSWORD=xxxx -e PGDATA=/var/lib/postgresql/data/pgdata -v /postgres-data:/var/lib/postgresql/data -p 5432:5432 postgres 【Self Design Code Protect】\n参考资料：\nsyscall table：https://github.com/torvalds/linux/blob/master/arch/x86/entry/syscalls/syscall_64.tbl syscall reg reference:https://syscalls64.paolostivanin.com/ syscall header:https://github.com/torvalds/linux/blob/b07175dc41babfec057f494d22a750af755297d8/include/linux/syscalls.h#L468 一些细节：\n内核态访问用户态需要先strncpy_from_user，__user标识符意味着该地址指向用户态空间，没有在kernel映射的地址里面。因此kernel提供了copy_from_user(),strncpy_from_user(),copy_to_user()等函数做内存操作 内核跟踪点可以使用ftrace或者bpftrace进行追踪，那么这些就可以用来hook，从本质来说实际上就是拿ftrace做一次替代的hook git config personal\nalias.amd=commit --amend --no-edit alias.am=commit --amend alias.br=branch --sort=-committerdate alias.ci=commit alias.co=checkout alias.cp=cherry-pick alias.df=diff alias.drop=stash drop alias.fcp=!scripts/fcp.sh alias.pci=!git fetch origin master \u0026amp;\u0026amp; git rebase origin/master \u0026amp;\u0026amp; git push alias.la=log --oneline --decorate --graph --all alias.last=log -1 HEAD --stat alias.ls=log --graph --pretty=format:\u0026#39;%Cred%h%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset %C(yellow)%D%Creset\u0026#39; --abbrev-commit alias.lg=log --stat alias.pl=pull --rebase origin master alias.pop=stash pop alias.pr=pull --rebase --recurse-submodules alias.rc=rebase --continue alias.ri=rebase -i HEAD~10 alias.root=rev-parse --show-toplevel alias.save=stash save alias.sl=stash list alias.st=status alias.sup=submodule update --init --recursive alias.unstage=reset HEAD -- color.ui=auto filter.lfs.clean=git-lfs clean -- %f filter.lfs.smudge=git-lfs smudge -- %f filter.lfs.process=git-lfs filter-process filter.lfs.required=true 10 WEB安全的基础支持 # 10.1 安全开发与安全运营 # 10.1.1 安全开发的流程 # 阶段1：培训。开发团队的所有成员都必须接受适当的安全培训，了解相关的安全知识。培训对象包括开发人员、测试人员、项目经理、产品经理等。\n阶段2：在项目确立之前，需要提前确定安全方面的需求，确定项目的计划时间，尽可能避免安全引起的需求变更。\n阶段3：在设计阶段确定安全的最低可接受级别。考虑项目涉及到哪些攻击面、是否能减小攻击面。对项目进行威胁建模，明确可能来自的攻击有哪些方面，并考虑项目哪些部分需要进行渗透测试。\n阶段4：实现阶段主要涉及到工具、不安全的函数、静态分析等方面。实现阶段主要涉及到工具、不安全的函数、静态分析等方面。\n工具方面主要考虑到开发团队使用的编辑器、链接器等相关工具可能会涉及一些安全相关的问题，因此在使用工具的版本上，需要提前与安全团队进行沟通。\n函数方面主要考虑到许多常用函数可能存在安全隐患，应当禁用不安全的函数和API，使用安全团队推荐的函数。\n代码静态分析可以由相关工具辅助完成，其结果与人工分析相结合。\n阶段5：验证。验证阶段涉及到动态程序分析和攻击面再审计。动态分析对静态分析进行补充，常用的方式是模糊测试、渗透测试。模糊测试通过向应用程序引入特定格式或随机数据查找程序可能的问题。\n考虑到项目经常会因为需求变更等情况使得最终产品和初期目标不一致，因此需要在项目后期再次对威胁模型和攻击面进行分析和考虑，如果出现问题则进行纠正\n阶段6：发布。在程序发布后，需要对安全事件进行响应，需要预设好遇到安全问题时的处理方式。\n另外如果产品中包含第三方的代码，也需要考虑如何响应因为第三方依赖引入的问题。\n10.1.2 安全开发的团队建设 # 针对不同的角色有不同的分工：\n部门负责人：\n负责组织整体的信息安全规划 负责向高层沟通申请资源 负责与组织其他部门的协调沟通 共同推进信息安全工作 负责信息安全团队建设 负责安全事件应急工作处置 负责推动组织安全规划的落实 合规管理员：\n负责安全相关管理制度、管理流程的制定，监督实施情况，修改和改进相关的制度和流程 负责合规性迎检准备工作，包括联络、迎检工作推动，迎检结果汇报等所有相关工作 负责与外部安全相关单位联络 负责安全意识培训、宣传和推广 安全技术负责人：\n业务安全防护整体技术规划和计划 了解组织安全技术缺陷，并能找到方法进行防御 安全设备运维 服务器与网络基础设备的安全加固推进工作 安全事件排查与分析，配合定期编写安全分析报告 关注注业内安全事件， 跟踪最新漏洞信息，进行业务产品的安全检查 负责漏洞修复工作推进，跟踪解决情况，问题收集 了解最新安全技术趋势 渗透/代码审计人员：\n对组织业务网站、业务系统进行安全评估测试 对漏洞结果提供解决方案和修复建议 安全设备运维人员：\n负责设备配置和策略的修改 负责协助其他部门的变更导致的安全策略修改的实现 安全开发：\n根据组织安全的需要开发安全辅助工具或平台 参与安全系统的需求分析、设计、编码等开发工作 维护公司现有的安全程序与系统 10.1.3 安全运营 # 什么是安全运营，安全运营是一个比较复杂的东西，它平时感谢什么呢？：\n拥有安全知识背景，能够比较好的理解安全场景和需要解决的问题 拥有研发，运维相关背景知识，知道某一类问题的合理解决方案 有较好的沟通能力，可以在安全工程师、安全开发工程师、业务RD/SRE之间搭建沟通的桥梁； 拥有一定的项目管理能力，较好的责任心，确保已知问题能够得到闭环的解决，涉及到跨团队的沟通，还需要有一定的大公司跨团队协作的基本经验； 具备数据意识，可以提出数据埋点、统计诉求，并细心的将已发生的事件积累成数据素材，形成日常观测的指标（针对可用性、覆盖率、效果指标等） 安全运营的技巧：\n安全的责任划分，出了问题，怪谁？应该由哪里划分？ 自上而下还是自下而上？我们认为，安全无小事，安全无私事。也就是说，任何安全事件，都不是一个人的事情，至少普通事件你的Leader应当知情，抓大放小是节省精力的关键。 重视宣传 安全运营的问题\n1、量化指标：（1）当前资产监控覆盖率; （2）当前资产基线安全合格率; （3）当前系统安全已知风险漏洞解决率；（4）每周最多攻击事件/首次发现攻击分析，是否调整当前防御手段;（5）每周防火墙流量分析。\n2、安全运营一步步做到自动化，落实到系统，后期就是增加准确率，减少出错率，解放人力。\n3、安全运营看上去是打工人努力工作实现企业信息安全目标的体现，其实是出卖劳动力来反映对企业盈利的价值推动，所以一切安全运营工作目标的量化，尽可能的以货币体现，运营团队的价值输出要超出自身成本，这样就是为企业贡献了盈利，守住了安全基本目标。\n4、难以度量指标，例如终端安全运营需要知道基础的终端数量信息等；\n5、量化安全指标我觉得可以从这几个方面去考虑：（1）覆盖率：包括资产管理、流量管理、安全管理的覆盖情况，有没有未知资产或漏管资产；（2）准确率：主要是告警的准确率；（3）时效性：威胁处置启动的时间点等等\n6、安全汇报都是防火墙防护了多少攻击，内网处理了多少威胁，加固了多少台服务器，安全设备测评结果是什么（安全性，易用性，功能性，对比自研和采购的优缺点等）。内网信息梳理等。\n工具\n、安全运营，借助自动化和工具化，落实到系统，后期就是增加准确率，减少出错率，解放人力。 来实现运营的标准化，用数据和指标来衡量安全能力和风险。\n2、首先，好工具/设备有很多，关键是使用的情况。再好的工具如果没有人使用，没有人维护也起不到多少作用。还需要根据企业自身的情况（人、财）来购买或者使用。其次，好工具/设备需要具备：全量的API能力、全面的日志能力、自定义规则能力、方便与其他系统对接等基本能力。最后，一些好用的设备或产品：SIEM-Splunk，渗透漏洞-Rapid，WAF-Imperva，SLB-F5，流量-某莱，主机/容器-某云等等，想省事就直接一套某恒，近两年某亭做的也不错；开源有很多，安全人员需要根据具体情况弥补不足之处。\n3、EDR没识别中间件管理功能。至少我接触的没有。我们外包的系统很多。很多外包运维，他们安装的中间件版本都不更新也不升级，我需要监控他们这些行为。所以需要中间件管理。\n4、EDR是对终端而已吧，HIDS一般是对服务器，感觉最大的区别就是自杀机制，服务器要求HIDS的利用率达到一定程度后必须自杀，不能影响服务器正常运行。\n日常流程：\n\\1. 盘点可用资源\n安全运营负责两种类型的资产——需要保护的各种设备、流程和应用程序，以及可以使用的各种防御工具。\n• 保护什么\n安全运营的第一步目标是全面了解企业的威胁状况，不仅包括各种类型的端点、服务器和内部软件，还包括第三方服务和这些资产之间的流量。\n• 如何保护\n此外，安全运营团队还应全面了解手头的所有网络安全工具及其工作流程，以确保运营的敏捷性和高效率。\n\\2. 准备和预防性维护\n即使是装备最完善、最敏捷的响应流程也无法从一开始就阻止问题的发生。为了阻止攻击，安全运营团队需要实施预防措施。\n• 准备\n团队成员应随时了解最新的安全创新、网络犯罪的最新趋势以及即将出现的新威胁。这可以帮助公司制定安全路线图，为网络安全工作提供方向，在最坏的情况下，也可以作为现成的指导灾难恢复计划。\n• 预防性维护\n此步骤包括为增加攻击难度而采取的所有措施，比如定期维护和更新现有系统、修补漏洞，以及白名单、黑名单和保护应用程序等。\n\\3. 持续主动监控\n24h*7全天监控与扫描，标记任何异常或可疑活动。全天候监控网络可以让团队立即收到新出现威胁的通知，从而抓住预防或减轻危害的最佳时机。\n\\4. 警报优先级排名和管理\n当发出警报时，运营团队要仔细查看，识别误报，并确定威胁的攻击性以及它们可能的目标。这样，安全运营团队就可以对新出现的威胁进行分类，首先处理最紧迫的问题。\n\\5. 威胁响应\n事件一经确认，运营团队就充当第一响应者，执行诸如关闭或隔离端点、终止有害进程、删除文件等操作，目标是在最小的范围内做出响应，同时尽量不影响业务的连续性。\n\\6. 恢复和补救\n事件发生后，努力恢复系统和丢失或受损的数据，包括擦除和重新启动端点、重新配置系统，或部署可行的备份以规避勒索软件等，将网络或设备恢复到事件发生之前的状态。\n\\7. 日志管理\n收集、维护和定期审查整个组织的所有网络连接、进程启动、Shell命令执行、DNS访问、登录行为、账号变更等日志。这些数据有助于定义“正常”网络活动的基线，以揭示威胁的存在，并可用于事件发生后的补救和取证。\n\\8. 溯源调查\n事件发生后，确定发生的时间、方式和原因，这有助于防止将来发生类似的问题。\n\\9. 安全细化与提升\n为了领先于网络犯罪分子的工具和策略，运营团队需要通过各种方式不断改进技术，包括安全路线图中概述计划的实施，以及红队和紫队等动手实践。\n\\10. 合规管理\n定期审核系统，以确保其遵守CIS、等保2.0、数据安全法等相关法律法规。按照这些规定行事不仅有助于保护公司的敏感数据，还可以保护组织免受因违规造成的声誉损害和法律挑战。\n应急响应流程\n1、事件发现 来源包括扫描IP 、威胁阻断、 日志审计、 病毒木马、 入侵事件、 异常流量、 暴力破解等 或者来源通报信息CNNVD/各SRC/HW裁判组等通报信息 2、资产信息情况掌握 何时部署资产部署时间，可在后期推断日志信息，给予有利帮助 开放的访问端口，部署的哪些服务 业务内容是否敏感，核心业务还是边缘业务，业务使用对象是内部还是外部，是否涉及敏感数据等 仅内网访问还是对外开放，确认应急范围 是否有厂商维护，是否有弱口令，历史漏洞情况，是否有人维护，谁负责，确认资产归属部门，方便情况了解及沟通 3、备份保护 备份系统镜像，应用程序，数据库备份，后期备份的可以程序 4、阻断隔离 业务下线，网络隔离，进程阻断， 5、事件研判 查看history命令，查看网络连接，查看文件，查看webshell和后门文件，日志 查看架构，网络控制信息，历史漏洞，关联资产，账号 6、恶意文件等处理 7、研判结果 攻击者画像， 8、处置建议 各种个样， 9、附录：常用工具、反制、规范指南等 10.2 安全相关的框架和控制 # 10.2.1 威胁情报 # 威胁情报这里多添加一个，常见漏洞的危害如何评价？可以看国标GB/T 30279-2020 网络安全漏洞分类分级指南，也可以看这个网页，通过几张图把国标的内容简单覆盖了一下https://www.secrss.com/articles/29879\n10.2.1.1 威胁情报的概念 # 关于威胁情报的定义有很多，一般是指从安全数据中提炼的，与网络空间威胁相关的信息，包括威胁来源、攻击意图、攻击手法、攻击目标信息，以及可用于解决威胁或应对危害的知识。广义的威胁情报也包括情报的加工生产、分析应用及协同共享机制。相关的概念有资产、威胁、脆弱性等，具体定义如下。\n10.2.1.2 威胁情报的相关概念 # 资产：对组织具有价值的信息或资源，属于内部情报，通过资产测绘等方式发现。 威胁：能够通过未授权访问、毁坏、揭露、数据修改和或拒绝服务对系统造成潜在危害的起因，威胁可由威胁的主体(威胁源)、能力、资源、动机、途径、可能性和后果等多种属性来刻画 脆弱性/漏洞：可能被威胁如攻击者利用的资产或若干资产薄弱环节。 风险：威胁利用资产或一组资产的脆弱性对组织机构造成伤害的潜在可能。 安全事件：威胁利用资产的脆弱性后实际产生危害的情景。 情报来源：为了实现情报的同步和交换，各组织都制定了相应的标准和规范。主要有国标，美国联邦政府标准等。 威胁框架：比较有影响力的威胁框架主要有洛克希德-马丁的杀伤链框架(Cyber Kill Chain Framework)、MITRE的ATT\u0026amp;CK框架(Common Knowledge base of Adversary Tactics and Techniques)、ODNI的CCTF框架(Common Cyber Threat Framework，公共网空威胁框架)，以及NSA的TCTF框架(Technical Cyber Threat Framework，技术性网空威胁框架)。 10.2.1.3 敏感信息汇总 # 10.2.2 风险控制 # 10.2.2.1 常见的风险 # 会员 视频 活动 直播 电商 支付 其他 撞库盗号 视频盗看 恶意刷 挂站人气 恶意下单 盗号盗卡 钓鱼邮件 账号分享 广告屏蔽 薅羊毛 恶意图文 订单欺诈 洗钱 恶意爆破 批量注册 刷量作弊 恶意下单 短信轰炸 恶意体现 10.2.2.2 常见的防御策略 # 核身策略 APP用户异常特征 同一收货手机号 IP 同一收货地址 设备为特定型号 同一历史行为 本地APP列表中有沙盒APP 同一IP Root用户 同一设备 同设备登录过多个账号 同一支付ID 10.2.3 防御框架 # 物理层实际应用中接触较少，但仍是非常重要的位置。如果物理层设计不当，很容易被攻击者通过物理手段绕过上层防御。 数据层数据处于防御纵深较底层的位置，攻击的目标往往也是为了拿到数据，很多防御也是围绕数据不被破坏、窃取等展开的。 终端层终端包括PC、手机、IoT以及其他的智能设备，连入网络的终端是否可信是需要解决的问题。 系统层操作系统运行在终端上，可能会存在提权、非授权访问等问题。 网络层网络层使用通信线路将多台计算机相互连接起来，依照商定的协议进行通信。网络层存在MITM、DDoS等攻击。 应用层应用层是最上层，主要涉及到Web应用程序的各种攻击。 10.4 信息安全法律法规相关 # 10.4.1 敏感信息和基本功能规定 # 感谢法律法规，直接给出了哪些是敏感信息，相关厂商调研直接就可以拿型号了，而且没有限定基本功能，可以说是非常含糊了。该法律法规的名称为《中华人民共和国网络安全法》。下面列出具体的敏感信息内容：\n地图导航类，基本功能服务为“定位和导航”，必要个人信息为：位置信息、出发地、到达地。\n网络约车类，基本功能服务为“网络预约出租汽车服务、巡游出租汽车电召服务”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.乘车人出发地、到达地、位置信息、行踪轨迹；\n3.支付时间、支付金额、支付渠道等支付信息（网络预约出租汽车服务）。\n即时通信类，基本功能服务为“提供文字、图片、语音、视频等网络即时通信服务”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.账号信息：\n账号、即时通信联系人账号列表。\n网络社区类，基本功能服务为“博客、论坛、社区等话题讨论、信息分享和关注互动”，必要个人信息为：注册用户移动电话号码。\n网络支付类，基本功能服务为“网络支付、提现、转账等功能”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.注册用户姓名、证件类型和号码、证件有效期限、银行卡号码。\n网上购物类，基本功能服务为“购买商品”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.收货人姓名（名称）、地址、联系电话；\n3.支付时间、支付金额、支付渠道等支付信息。\n餐饮外卖类，基本功能服务为“餐饮购买及外送”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.收货人姓名（名称）、地址、联系电话；\n3.支付时间、支付金额、支付渠道等支付信息。\n邮件快件寄递类，基本功能服务为“信件、包裹、印刷品等物品寄递服务”，必要个人信息包括：\n1.寄件人姓名、证件类型和号码等身份信息；\n2.寄件人地址、联系电话；\n3.收件人姓名（名称）、地址、联系电话；\n4.寄递物品的名称、性质、数量。\n交通票务类，基本功能服务为“交通相关的票务服务及行程管理（如票务购买、改签、退票、行程管理等）”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.旅客姓名、证件类型和号码、旅客类型。旅客类型通常包括儿童、成人、学生等；\n3.旅客出发地、目的地、出发时间、车次/船次/航班号、席别/舱位等级、座位号（如有）、车牌号及车牌颜色（ETC服务)；\n4.支付时间、支付金额、支付渠道等支付信息。\n婚恋相亲类，基本功能服务为“婚恋相亲”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.婚恋相亲人的性别、年龄、婚姻状况。\n求职招聘类，基本功能服务为“求职招聘信息交换”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.求职者提供的简历。\n网络借贷类，基本功能服务为“通过互联网平台实现的用于消费、日常生产经营周转等的个人申贷服务”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.借款人姓名、证件类型和号码、证件有效期限、银行卡号码。\n房屋租售类，基本功能服务为“个人房源信息发布、房屋出租或买卖”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.房源基本信息：房屋地址、面积/户型、期望售价或租金。\n二手车交易类，基本功能服务为“二手车买卖信息交换”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.购买方姓名、证件类型和号码；\n3.出售方姓名、证件类型和号码、车辆行驶证号、车辆识别号码。\n问诊挂号类，基本功能服务为“在线咨询问诊、预约挂号”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.挂号时需提供患者姓名、证件类型和号码、预约挂号的医院和科室；\n3.问诊时需提供病情描述。\n旅游服务类，基本功能服务为“旅游服务产品信息的发布与订购”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.出行人旅游目的地、旅游时间；\n3.出行人姓名、证件类型和号码、联系方式。\n酒店服务类，基本功能服务为“酒店预订”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.住宿人姓名和联系方式、入住和退房时间、入住酒店名称。\n网络游戏类，基本功能服务为“提供网络游戏产品和服务”，必要个人信息为：注册用户移动电话号码。\n学习教育类，基本功能服务为“在线辅导、网络课堂等”，必要个人信息为：注册用户移动电话号码。\n本地生活类，基本功能服务为“家政维修、家居装修、二手闲置物品交易等日常生活服务”，必要个人信息为：注册用户移动电话号码。\n女性健康类，基本功能服务为“女性经期管理、备孕育儿、美容美体等健康管理服务”，无须个人信息，即可使用基本功能服务。\n用车服务类，基本功能服务为“共享单车、共享汽车、租赁汽车等服务”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.使用共享汽车、租赁汽车服务用户的证件类型和号码，驾驶证件信息；\n3.支付时间、支付金额、支付渠道等支付信息；\n4.使用共享单车、分时租赁汽车服务用户的位置信息。\n投资理财类，基本功能服务为“股票、期货、基金、债券等相关投资理财服务”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.投资理财用户姓名、证件类型和号码、证件有效期限、证件影印件；\n3.投资理财用户资金账户、银行卡号码或支付账号。\n手机银行类，基本功能服务为“通过手机等移动智能终端设备进行银行账户管理、信息查询、转账汇款等服务”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.用户姓名、证件类型和号码、证件有效期限、证件影印件、银行卡号码、银行预留移动电话号码；\n3.转账时需提供收款人姓名、银行卡号码、开户银行信息。\n邮箱云盘类，基本功能服务为“邮箱、云盘等”，必要个人信息为：注册用户移动电话号码。\n远程会议类，基本功能服务为“通过网络提供音频或视频会议”，必要个人信息为：注册用户移动电话号码。\n网络直播类，基本功能服务为“向公众持续提供实时视频、音频、图文等形式信息浏览服务”，无须个人信息，即可使用基本功能服务。\n在线影音类，基本功能服务为“影视、音乐搜索和播放”，无须个人信息，即可使用基本功能服务。\n短视频类，基本功能服务为“不超过一定时长的视频搜索、播放”，无须个人信息，即可使用基本功能服务。\n新闻资讯类，基本功能服务为“新闻资讯的浏览、搜索”，无须个人信息，即可使用基本功能服务。\n运动健身类，基本功能服务为“运动健身训练”，无须个人信息，即可使用基本功能服务。\n浏览器类，基本功能服务为“浏览互联网信息资源”，无须个人信息，即可使用基本功能服务。\n输入法类，基本功能服务为“文字、符号等输入”，无须个人信息，即可使用基本功能服务。\n安全管理类，基本功能服务为“查杀病毒、清理恶意插件、修复漏洞等”，无须个人信息，即可使用基本功能服务。\n电子图书类，基本功能服务为“电子图书搜索、阅读”，无须个人信息，即可使用基本功能服务。\n拍摄美化类，基本功能服务为“拍摄、美颜、滤镜等”，无须个人信息，即可使用基本功能服务。\n应用商店类，基本功能服务为“App搜索、下载”，无须个人信息，即可使用基本功能服务。\n实用工具类，基本功能服务为“日历、天气、词典翻译、计算器、遥控器、手电筒、指南针、时钟闹钟、文件传输、文件管理、壁纸铃声、截图录屏、录音、文档处理、智能家居助手、星座性格测试等”，无须个人信息，即可使用基本功能服务。\n演出票务类，基本功能服务为“演出购票”，必要个人信息包括：\n1.注册用户移动电话号码；\n2.观演场次、座位号（如有）；\n3.支付时间、支付金额、支付渠道等支付信息。\n10.4.2 信息安全合规部门职能分析 # 发现一篇不错的文章，网址为：https://www.freebuf.com/articles/neopoints/264820.html。\n这篇文章讲解了信息安全合规部门的具体职责，因为太长，具体内容不足就不粘贴/写了。d9a9281eacec6dbb4da0357ee40621fd66df483f\n【PKI CA体系】 # 完整的PKI/CA系统如下部分：\n安全服务器：安全服务器面向普通用户，用于提供证书申请、浏览、证书撤销列表、证书下载等安全服务；用户需要首先得到安全服务器的证书（该证书由CA颁发）； 注册机构RA：在CA体系结构中起承上启下的作用，一方面向CA转发安全服务器传输过来的证书申请请求，另一方面向LDAP服务器和安全服务器转发CA颁发的数字证书和证书撤销列表（CRL）。 LDAP服务器：Lightweight Directory Access Protocol（轻量目录访问协议），提供目录浏览服务，负责将注册机构服务器RA传输过来的用户信息以及数字证书加入到服务器上。用户通过访问LDAP服务器就能够得到其他用户的数字证书。 CA服务器：整个证书机构的核心，负责证书的签发。CA首先 产生自身的私钥和公钥，然后生成数字证书，并且将数字正常传输给安全服务器。CA还负责为安全服务器、RA服务器生成数字证书。 数据库服务器：CA中的核心部分，用于CA中数据（如密钥和用户信息等）、日志、统计信息的存储和管理。 证书申请过程 # 用户申请：用户获取CA的数字证书（根证书），与安全服务器建立连接；生成自己的公钥和私钥，将公钥和自己的身份信息提交给安全服务器，安全服务器将用户的申请信息传送给RA服务器。 RA审核：RA收到用户的申请，用户向RA证明自己的身份，RA进行核对。如果RA同意用户申请证书的请求，则对证书申请信息做数字签名；否则拒绝用户的申请。 CA发行证书：RA将用户申请和RA签名传输给CA，CA对RA数字签名做认证，如果验证通过，则同意用户请求，颁发证书，然后将证书输出。如果验证不通过，则拒绝证书申请。 RA转发证书：RA从CA得到新的证书，首先将证书输出到LDAP服务器以提供目录浏览，再通知用户证书发行成功，告知证书序列号，到指定的网址去下载证书。 用户证书获取：用户使用证书序列号去指定网址下载自己的数字证书，只有持有与申请时提交的公钥配对的私钥才能下载成功。 证书撤销过程 # 用户申请：用户向RA发送一封签名加密邮件，申请撤销证书。 RA审核：注册机构同意证书撤销，并对申请签名。 CA更新CRL：CA验证证书撤销请求的RA签名，如果正确，则同意申请，并更新CRL，并输出。 RA转发CRL：注册中心收到CRL，以多种方式将CRL公布（包括LDAP服务器）。 用户告知：用户访问LDAP服务器，下载或浏览CRL。 证书的管理 # 认证中心CA负责维护和发布证书废除列表CRL（certificate revocation lists，又称为证书黑名单）。 当一个证书，特别是其中的公钥因为其他原因无效时（不是因为到期），CRL提供了一种通知用户和其他应用的中心管理方式。CA系统生成CRL以后，放到LDAP服务器中或Web服务器的合适位置，供用户查询或下载。\n系统设计 # 最后回到系统设计的范畴\nhttps://wizardforcel.gitbooks.io/system-design-primer/content/\n学院派秘钥方面的攻击手段 # 已知的部分攻击方法\n唯密文攻击 解密算法，截获的部分密文 已知明文攻击 加密算法，截获的部分密文，一个或多个明文密文对 选择明文攻击 加密算法，截获的部分密文，自己选的明文消息和秘钥产生的密文 选择密文攻击 加密算法，截获的部分密文，自己选的密文消息和秘钥解密的明文 m序列的流密码攻击方式\n差分密码分析\n通过分析明文对的差值对密文对的差值的影响，来恢复某些秘钥比特 线性密码分析\n分组密码的运行模式\n电码本，ECB模式，对明文每次加密的密文都一样，这个无论是面对选择明文还是选择密文都会崩溃。 密码分组模式，CBC模式，攻击者可以欺骗接收方使用不同IV值，那么攻击者就能在明文的第一个分组插入自己选择的比特值，这个的攻击文档参考https://zhangzeyu2001.medium.com/attacking-cbc-mode-bit-flipping-7e0a1c185511，https://derekwill.com/2021/01/01/aes-cbc-mode-chosen-plaintext-attack/ 密码反馈模式，CFB模式，将密文单元反馈到移位寄存器 输出反馈模式，OFB模式，将加密算法的输出反馈到移位寄存器 结尾 # 唉，尴尬\n","date":"2021 年 2 月 22 日","externalUrl":null,"permalink":"/posts/2021-02-22-%E5%AE%89%E5%85%A8%E6%96%B9%E9%9D%A2%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B0%E5%AD%A6+%E5%8D%8F%E8%AE%AE%E7%AF%87/","section":"Posts","summary":"","title":"2021-02-22-安全方面的基础知识（数学+协议篇）","type":"posts"},{"content":" 2023-02-12-安全零信任 # 零信任概述（不用仔细看） # 零信任包含以下几个方面：\n现在展开讲：\n由于1 身份认证并不可靠，内网不等于可信网络，内网用户不一定是可信用户。2 网络边界越来越难以划分\n因此需要展开零信任，零信任包含以下几个要求：\n信任最小化：任何访问主体（人/设备/应用等），在访问被允许之前，都必须要经过身份认证和授权，默认不信任；换言之1.端到端加密确保传输安全2 1.企业应用或服务不再对公网可见 分配访问权限是基于业务，越细越好，遵循最小权限原则； 多源信任评估：尽可能多的和及时的获取可能影响授权的所有信息，进行安全评估。换言之提供基于网络；设备；身份；环境认证的访问控制 权限动态化：对信息进行持续的信任评估和安全响应。换言之仅对特定应用而非网络授予访问权限 可视化，智能化：通过可视化了解和评估网络中可能产生的安全威胁，进行主动和自动化的防御。 那么，在一个零信任网络里面，以下三个组件很重要：\nPolicy engine (PE) Policy administrator (PA) Policy enforcement point (PEP) 到底什么是零信任 # 一种说法是：S.I.M.=SDP+IAM（Identity and Access Management (IAM)）+微隔离.这个说起来还是很粗的，实际上就是， 所以总结来说，零信任是多个方面的结合\n身份方面 # 需要给出有哪些对应的软件\n身份方面有很多点\n身份大数据\n需要定义用户，组织，设备，资源等实体的模型。还得管理生命周期。需要能够方便的检索出来一些冗余信息 对人而言，区分是员工，还是客户等，管理每个人的组织机构信息，个人信息，标签，关联设备 设备，要建立合法设备清单库，包括设备标识，软件硬件信息，设备安全状态 应用：身份标识，服务器地址，应用提供的功能菜单， API：包括API服务是谁，访问哪些API，身份标识，接口信息，参数信息，返回信息 需要从各种终端设备同步和用户属性相关的信息，汇聚为大数据 集中管理各种不同角色，比方说用户/员工/外包，管理能力或者说检索能力很重要 身份认证的方式\n密码，口令，U盾牌 持续多因素认证 动态授权\n比方说归结为角色：网管，开发，RBAC的直观清晰，但是角色一多就是灾难。\n基于属性的授权，比方说设备的属性，设备的环境（时间，位置，ip地址），业务属性。现实往往是角色和属性的综合授权\n基于任务的授权，针对用户授予某项任务的权限，任务结束立刻收回\n策略。某种策略，一个策略应该包含策略主体，策略课题，策略条件，策略动作等。因为策略过于复杂，所以应该分层指定策略，用户的请求必须一层一层的递进，才能判断是否成功。比方说用户访问资源，先判断，用户是否有授权，再判断是否满足网络安全要求，再判断数据是否脱敏。授权策略完全可以依托于上面列举的点，比方说角色，属性，任务\n临时权限\n设备方面\n设备清单 能够识别设备，利用ID，MAC，主板号， 设备绑定，能够和用户角色绑定 设备清单库 设备安全 设备认证，相关绑定人 设备安全监测，监测设备是否安全合规 设备漏洞修复 远程擦除敏感数据 可信进程管理 设备准入基线 网络方面\n统一的入口 安全隧道网关 API安全网关 分布式网关集群 网络准入 网络入侵防护 安全DNS 数据方面\n数据访问控制 数据分级分类 数据访问控制 数据脱敏 数据泄密防护 基于零信任授权策略，在用户可信等级较低或者资源要求较高，执行数字水印，敏感文件审计 终端沙箱，在设备商划分数据安全区，敏感数据只能沙箱访问，并且最终在终端的安全区访问，也许出发在这个点？ 远程浏览器隔离 安全浏览器 安全审计\n安全审计 风险分析 新人评估 现存的零信任模型 # 零信任的分类 # 零信任分为两种，一种是对用户的，另一种是对企业内部的。对用户的标准的架构有两种\nSDP标准：三个组件，SDP客户端，SDP网关，SDP管控端。用户和网关都向SDP管控端报道，管控端通知客户和SDP网关相关的身份信息和权限校验，提前两者是相互都不清楚的：用户向管控端报告以后，管控端会给网关发用户相关信息，同时提供给用户有权连接的SDP网关列表，之后SDP客户端会使用SPA（单包授权 Single Packet Authorization，理解为敲门暗号）技术向SDP网关通信，校验身份成功即开放IP端口。 NIST的标准 针对企业，或者说针对云服务内部的，微隔离\n例子：beyondprod，\n面临的问题 # 零信任组件技术 # 1 SDP（SPA）端口隐藏 # SDP网关默认拒绝所有IP的连接，常规黑客扫描不出来 客户端和SDP控制端通信，申请通过后，控制端给SDP网关和SDP客户端发送凭据和身份信息 客户端发送一个单包到SDP网关约定的端口，SDP网关收到后会添加路由，用户就可以反映了 难题是怎么保证SPA是不可伪造的，因此如何保证秘钥？有三种方法\n客户端嵌入秘钥 用激活码生成秘钥，给用户一个随机的身份秘钥，由它派生 将临时秘钥转为正式秘钥，设定失效条件 增强的手段可以为TLS敲门技术，在clienthello里面放拓展字段\n1.1双层隐身架构 # 双层隐身架构，说白了就是在企业内网边界之外使用云网关，然后客户端接入到云网关。连接器（在内网边界）直接连接云网关，这样子实际上就是转移难度到云网关\n2零信任网关 # 作为零信任的中心，作用有两个\n分割用户和资源，零信任网关就是一个保安，或者说门卫 执行安全策略，用户连接到安全网关之后，再到达业务系统，素以安全网关可以挡住大部分的业务系统攻击。 网关有多种，比方说API网关，web代理网关\nweb代理网关功能主要是在下面写出来了。这种是所有流量的入口，主要在边界\n转发请求：根据用户域名的不同，转发到不同的服务器， 获取身份，从cookie或者数据包头部加入代表用户身份的token 验证身份，web代理网关将访问者的信息发送给管控平台，这一步严重影响性能 隐身网关。类似防火墙，可以认为只有特定身份的用户可以参与进来。\n其类似SPA的实现方式，使用UDP就可以携带特定的身份信息直接参与到具体的敲门过程。我个人觉得这里可以让DTLS参与进来。可以参考WIREGUARD协议 网络隧道网关，代理SSH等协议，四层网关\nAPI网关，针对服务器之间的访问，主要在pod或者微隔离环境的内部。一般是将请求放协议的头部\n这些最终集合成为一个个的网关平台，根据不同的功能还要同时提供负载均衡，加密传输等功能\n2.1 微隔离 # 微隔离解决的是服务器之间这么进行身份验证，安全通信的问题。\n在每个服务器的操作系统上配置agent客户端，基于微隔离组件实现。agent客户端统一由零信任管控平台管理。优点是底层无关，支持多种容器，这个实际上是发生在操作系统层面，可以理解为pod里面？ 基于云原生的虚拟化设备自身防火墙功能进行访问控制，这种方式实际上发生在node的虚拟机管理级别。 基于第三方防火墙，最僵硬 微隔离的架构\n微隔离组件的集中管控：微隔离组件有一个零信任管控平台统一管控，负责下发策略，分发证书，进行身份认证和访问控制校验 身份认证：微隔离组件启动后，要先向控制台发起身份认证，最简单的方式就是基于企业的PKI做认证。认证通过后就可以获取权限列表和可访问的资源。 服务端环境感知：微隔离的组件可以对服务端的安全状态进行检查，后续根据安全策略，阻止有风险的服务器接入零信任网络 端口暴露管理:控制暴露的端口 进程外联控制：检查是否有部分异常进程的奇怪连接，比方说shell连接外部ip地址 通信和校验过程：微隔离组件可以作为客户端或者服务端当成mtls的起点或者终点进行通信 微隔离管控平台\n提供基于身份的访问策略：在云原生的环境，容器的宿主机是不确定的，服务可能直接迁移，因此基于ip地址进行管控已经失去了意义，得使用服务的身份。即对于微服务，提供基于7层而非4层的隔离。这实际上就是说在容器里面建立一个7层的访问代理。 访问策略的构成：微隔离策略的主体和客体可以是服务器，微服务，进程。微隔离策略模型可以从自身的身份，组，标签，安全属性等维度设置访问条件 可以自动学习业务策略， 业务关系可视化 策略下发 环境感知和风险监控 3 SPIFFE的研究（微隔离） # 关于零信任在生产环境的落地，很多文章实际上说的是非常不清晰的，比方说微隔离的实现等，spiffe给出了非常实用的实现方法。spiffe和spire，主要解决微服务下的各种服务框架横行的模式下，怎么进行安全通信的问题。即，spiffe的workload相互调用时使用mtls进行调用，其证书私钥如何传递，颁发的问题。\n3.1 SPIFFE 的基本概念 # spiffe服务端先认证云环境下的node节点，在认证完node节点后，先让节点了解到工作负载（workload）有哪些，并且申请下来证书私钥。之后如果有workload要通信，就校验是否是合法workload，从而判断是否给出证书和私钥。workload校验完成之后就可以进行mtls通信啦。\nSPIFFE的基本概念\nworkload，工作负载，简单理解a workload may often be more fine-grained than a physical or virtual node – often as fine grained as individual processes on the node. SPIFFE ID，SPIFFE ID is a string that uniquely and specifically identifies a workload. Trust Domain,The trust domain corresponds to the trust root of a system. A trust domain could represent an individual, organization, environment or department running their own independent SPIFFE infrastructure. All workloads identified in the same trust domain are issued identity documents that can be verified against the root keys of the trust domain. SPIFFE Verifiable Identity Document，SVID is the document with which a workload proves its identity to a resource or caller. An SVID is considered valid if it has been signed by an authority within the SPIFFE ID’s trust domain.加密的可验证的档案，用于证明工作负载的身份。两种模式，一种是X509格式的证书和私钥，SAN（subject alternative name）放对应的spiffeid。另一种是jwt workload API，workload API provides the following：SPIFFE ID，对应的证书，相对应的Trust Bundle(A set of certificates)。简单来说提供证书数和私钥去做mtls，还有对应的CA When using X.509-SVIDs, a trust bundle is used by a destination workload to verify the identity of a source workload. A trust bundle is a collection of one or more certificate authority (CA) root certificates。复杂的网络环境下，多个不同的spiffe context交互，每个svid的ca可能不同，需要交换这些公钥信息，这些公钥信息就是trust bundle。 SPIFFE Federation：共享 SPIFFE Trust Bundle 的机制。名字起的很有趣，联邦 3.2 以SPIRE为入口学习SPIFFE # 3.2.0 SPIRE问题 # 我个人认为，从问题入手会学习的比较快，列几个我目前还没明白的点\nSPIRE只是简单的在Trust Bundle中提了一嘴用来解决动态感知客户端身份的方法，至于说业务关系的可视化，基于身份的访问策略这些都没提。这些当然可以作为附加功能直接贴到SPIRE AGENT当中，我个人觉得，授权关系基于Trust Bundle的方式来做会比较简单（因为直接调用房CA证书校验不通过就行），但是Trust Bundle的动态更新，会成为一个问题点。我想到的点是授权策略还是剥离出来，但是可以采用授权策略最后更新时间作为检查的点 SPIRE在网络内部，怎么做对应证书的过期，剔除，无效化操作？ SPIRE SERVER有签发SVID的功能，这些SVID是不是要有PKI管理，很多敏感信息也要读取KMS信息，这些证书要作为可授信的凭证参与到KMS信息的管理。那么KMS是不是应该也细分为不同Trust Domain的粒度，存储不同的敏感信息。那么一旦不同的Namespace要共享一些敏感信息，这两个KMS是不是也得共享一套Trust Bundle。跨网段的沟通协同看起来很危险。 SPIRE AGENT启动时，怎么有服务端的信息，即怎么证实访问到的服务端的身份？ SPIRE AGENT启动时，为什么先获取被授权的相关工作负载 SPIRE架构下SVID的有效期和自动更新怎么做呢？ 3.2.1 SPIRE的架构 # SPIRE的架构就两块：服务器和 Agent\n服务器负责签发 SVID ，这些SVID最终通过 Agent 传递给工作负载；它要同时保存很多workload的注册信息，简单来说就是哪些workload可以调用workload api的问题；\nSPIRE Server 负责在SPIFFE信任域管理和签发身份信息，因此它存储着 registration entries (用于判断是否应该签发出来对应的SPIFFE ID) ，签发密钥, 用 node attestation 来自动认证服务器节点, 为工作负载创建SVIDs 其架构要求一些插件的参与 Node attestor plugins 同 Node Attestation 一起认证节点 Node resolver plugins which expand the set of selectors the server can use to identify the node by verifying additional properties about the node. See the section Node Resolution for more information. Datastore plugins, 服务器检索，更新，存储信息的地方，比方说存储registration entries](https://spiffe.io/docs/latest/spire-about/spire-concepts/#workload-registration), 哪些节点已经认证好了, 这些节点的选择器是哪些 Key manager plugins,管理server这么签发SVID信息 Upstream authority plugins. 一般默认情况SPIRE服务器自己充当CA，但是你也可以用上游CA直接参与管理 Agent 部署在每个节点上，向工作负载公开 Workload API。Workload在通信之前先请求证书和私钥（SVID），真正的签发请求透明地传递到server上。\n功能\n从服务端请求SVIDs，并一直缓存它们，直到有真正的调度来了。 向Workload暴露SPIFFE Workload API，证实Workload的身份 向Workload提供他们的SVIDs 架构\nNode attestor plugins which,同 Node Attestation 一起认证节点 Workload attestor plugins – 认证工作负载，从操作系统检索进程信息，并和server端拿到的信息做比对registered the workload’s properties](https://spiffe.io/docs/latest/spire-about/spire-concepts/#workload-registration) 参考 Workload Attestation Key manager plugins, 管理如何签发和使用SVID信息 3.2.2 SPIRE下的SVID的整体流程 # 这一节内容讲述了 SPIRE 签发工作负载身份的过程。这个过程从 Agent 在节点上启动开始，持续到工作负载收到有效的 X.509 SVID 为止（注意，JWT 和 X.509 的处理方式是不同的）。下面以 AWS EC2 为例。\nSPIRE Server 启动\n除非用户配置了上游 CA 插件，Server 会生成一个自签名证书；Server 会使用这个证书来给信任域内所有的工作负载签发 SVID\n如果这是首次启动，Server 会自动生成 Trust Bundle，这些内容会被存储在 SQL 数据库中，参考https://github.com/spiffe/spire/blob/v1.5.4/doc/plugin_server_datastore_sql.md\nServer 开启注册 API，允许注册工作负载。\nSPIRE Agent 在运行了工作负载的节点上启动\nAgent 执行节点证实工作，向 Server 证明节点的身份。例如在 AWS EC2 实例上，通常会把 AWS Instance Identity Document 提交给服务器，Agent 把该证据用 TLS 提交给 Server。**这里注意！这个是双方必须先配置好的共识！**SPIRE里面这个是公用配置，自己配置的时候不要搞错哦。这里出现了第一个问题，AGENT怎么知道服务器在哪里？怎么对抗欺骗？\nServer 调用 AWS API 对这些证据进行校验\nAWS 确认身份证据的有效性，即节点通过校验\nServer 对节点进行解析，验证 Agent 节点的附加属性，并更新注册数据。例如节点使用的是 Azure Managed Service Identity（MSI）。Resolver 会根据 SPIFFE ID 解析 Tenat ID 以及 Principal ID，并用多种 Azure Service 获取额外信息\nServer 给 Agent 签发一个 SVID，证实 Agent 的身份\nAgent 用它的 SVID 以及他的 TLS 客户端证书联系 Server，试图获得它被授权的相关工作负载\nServer 用 Agent 的 SVID 验证 Agent 的身份。Agent 接下来会完成 mTLS 握手，AGENT使用 Bootstarap Bundle 完成对服务端认证。到这里我们就确定了服务器和客户端都是正确的客户端了。\nServer 从数据库中抓取所有（该 Agent 下的）认证的注册条目，实际上就是工作负载，发送给 Agent\n服务端怎么选择对应的注册条目？ Query the database for any registration entries that have the agent’s SPIFFE ID listed as their “parent SPIFFE ID”. Query the database for what additional properties the specific agent is associated with (\u0026quot;node selectors”). Query the database for any registration entries that declare at least one selection on any of those node selectors. * Recursively query the database for any registration entries that declare any of the entries obtained so far as their “parent SPIFFE ID” (descend to all children). Agent 发送工作负载的 CSR 给 Server，Server 会签署和返回 Workload SVID 给客户端，客户端进行缓存\n启动过程完成，Agent 开始监听 Workload API 的 Socket\nWorkload 调用调用 Workload API，申请 SVID\nAgent 通过调用 Workload Attestor 来初始化 Workload 的证实过程，证实过程的输入以工作负载的进程 ID 启动\nAttestor 使用内核和用户空间的调用，发现工作负载的附加信息\nAttestor 把发现的信息返回给 Agent\nAgent 通过比对缓存中的注册信息和 Workload 上报的信息，来决定是否把缓存中的 SVID 返回给工作负载。\n3.2.3 关键过程 # 有两个关键过程：\n节点证实：保障工作负载所在的节点的身份的有效性 工作负载证实：保证节点上的工作负载是有效的 3.2.3.1 Node Attestation # 节点的证实过程是在 Agent 启动过程中完成的，SPIRE 要求 Agent 在第一次连接到服务器的时候能够验明正身。在节点证实过程中，Agent 和服务器协作对 Agent 所在的节点进行校验。这个过程是通过 SPIRE 中被称为 Node Attestor 的插件完成的，这种插件的基本做法就是对节点以及所在环境进行查询和比对，来验证节点身份的有效性。\n节点证实成功之后，Agent 就收到了一个 SPIFFE ID，Agent 会把这个 ID 作为父 ID，发放给运行在这个节点上的工作负载。\n几种常见的节点身份的证据：\n云平台分发给节点的身份文档（例如 AWS 的 Instance Identity Document） 节点上 HSM 或者 TPM 硬件的私钥 安装 Agent 时候的手工验证过程 多节点系统中提供的身份凭据，例如 Kubernetes 的 SA Token 节点证实过程会返回一组属性（Selector）给服务器，这些属性能够标识出特定的节点，另外还会有 Node Resolver 来获取节点的其他属性，这些属性一起，构成了 SPIFFE ID 的附加属性。\n例如 AWS 节点的证实过程：\nAgent 上的 AWS Node Attestor 向 AWS 查询节点的身份，发送给 Agent Agent 把身份的证据发送给服务器，服务器把信息发送给 AWS Node Attestor（的服务侧） AWS Node Attestor 的服务端独立或者调用 AWS API 对前一个步骤获取到的信息进行验证。Node Attestor 还会为 Agent 创建一个 SPIFFE ID，并把 SPIFFE ID 和 Selecor 传给服务器进程 Server 返回一个 Agent 节点的 SVID SPIRE 支持多种环境的 Node Attestor，例如：\nAWS 的 EC2 实例（EC2 Instance Identity Document） Azure 虚拟机（Azure Managed Service Identities） GCE Instance（GCE Instance Identity Token） Kubernetes 节点（Kubernetes Service Account Token） 这里多赘述一下k8s的安全机制，k8s有一张rootca证书，每个node上都有对应rootca签发出来的证书和私钥 对于无法直接认证节点的平台，SPIRE 提供了如下措施：\n服务器和 Agent 之间可以生成一个预共享密钥作为加入的 Token，Agent 启动时进行验证，使用后立即过期 使用现存 X.509 证书 3.2.3.2 Workload Attestation # 工作负载的证实过程要回答的问题是：这个进程是谁？Agent 和 Server 都参与到了节点证实过程里；而工作负载的证实过程是由 Agent 完成的。\n下图展示了工作负载证明的过程：\n工作负载调用 Workload API 申请 SVID。在 Unix 系统中，这个 API 表现为一个 Unix Domain Socket Agent 调用节点的内核来认证调用者的进程 ID。然后回调用工作负载的证实插件，把进程号提供给他们 利用进程 ID 查询工作负载的额外信息，可能会和 Kubelet 等同节点服务进行交互 Attestor 把进程信息返回给 Agent Agent 把属性和注册信息进行比对，返回合适的 SVID 给工作负载。 工作负载的证实机制目前支持 Unix、Kubernetes 和 Docker。\n3.2.3 SPIRE的实践关键过程 # 具体的操作流程建议直接参考https://spiffe.io/docs/latest/try/getting-started-k8s/，这个讲的挺清楚的。\n只针对几个特定的步骤做讲解.\n部署spire-server阶段，首先要做的实际上创建spire-server的service-account，一个名叫spire-bundle的configmap(用来提供服务校验资格），和对应的更新config-map等权限，实际上，最后一个server-cluster-role.yaml就是将spire-server 的service account做绑定的。也就是下面的一个shell命令。\n# 部署spire-server阶段，手下\r$ kubectl apply \\\r-f server-account.yaml \\\r-f spire-bundle-configmap.yaml \\\r-f server-cluster-role.yaml 接下来就可以部署spire-server了，server-configmap当中实际上指定了部分有趣的东西，里面有趣的部分被我截取了出来，里面写的k8s_sat实际上用来做nodeattestor，\n简单解释下，需要参考 use_token_review_api_validation 来判断怎么做节点校验，说白了，实际上是让server校验agent提供的service token，这个service token实际上就是从node上面拿到的。。。如果use_token_review_api_validation为false，那么使用本地的service_account_key_file当中的key文件来校验token是否有效，否则使用 Kubernetes Token Review API，这时候就得提供kube_config_file文件的路径来和api服务器通信。参考 https://github.com/spiffe/spire/blob/main/doc/plugin_server_nodeattestor_k8s_sat.md\n$ kubectl apply \\\r-f server-configmap.yaml \\\r-f server-statefulset.yaml \\\r-f server-service.yaml\r官方文档里面写的use_token_review_api_validation默认不用，但是官方教程里面的还是启用了token review api，哈哈哈哈哈。service_account_allow_list是一系列service account名字，用来校验使用。关于rokenrequest api，这个东西实际上\nplugins { DataStore \u0026#34;sql\u0026#34; { plugin_data { database_type = \u0026#34;sqlite3\u0026#34; connection_string = \u0026#34;/run/spire/data/datastore.sqlite3\u0026#34; } } NodeAttestor \u0026#34;k8s_sat\u0026#34; { plugin_data { clusters = { # NOTE: Change this to your cluster name \u0026#34;demo-cluster\u0026#34; = { use_token_review_api_validation = true service_account_allow_list = [\u0026#34;spire:spire-agent\u0026#34;] } } } } KeyManager \u0026#34;disk\u0026#34; { plugin_data { keys_path = \u0026#34;/run/spire/data/keys.json\u0026#34; } } Notifier \u0026#34;k8sbundle\u0026#34; { plugin_data { } } } 这里有一点需要注意，实际上\nthe service account token does not contain claims that could be used to strongly identify the node/daemonset/pod running the agent. This means that any container running in an allowed service account can masquerade as an agent, giving it access to any identity the agent is capable of issuing. It is STRONGLY recommended that agents run under a dedicated service account.\n部署spire-client阶段，spires-agent\n比较有趣的configmap部分我也粘了出来。当客户端成功部署以后，实际上就会\n$ kubectl apply \\\r-f agent-account.yaml \\\r-f agent-cluster-role.yaml\r$ kubectl apply \\\r-f agent-configmap.yaml \\\r-f agent-daemonset.yaml 客户端的attestor，\nplugins {\rNodeAttestor \u0026#34;k8s_sat\u0026#34; {\rplugin_data {\r# NOTE: Change this to your cluster name\rcluster = \u0026#34;demo-cluster\u0026#34;\r}\r}\rKeyManager \u0026#34;memory\u0026#34; {\rplugin_data {\r}\r}\rWorkloadAttestor \u0026#34;k8s\u0026#34; {\rplugin_data {\r# Defaults to the secure kubelet port by default.\r# Minikube does not have a cert in the cluster CA bundle that\r# can authenticate the kubelet cert, so skip validation.\rskip_kubelet_verification = true\r}\r}\rWorkloadAttestor \u0026#34;unix\u0026#34; {\rplugin_data {\r}\r}\r} 最后创建两个spiffe id\n$ kubectl exec -n spire spire-server-0 -- \\\r/opt/spire/bin/spire-server entry create \\\r-spiffeID spiffe://example.org/ns/spire/sa/spire-agent \\\r-selector k8s_sat:cluster:demo-cluster \\\r-selector k8s_sat:agent_ns:spire \\\r-selector k8s_sat:agent_sa:spire-agent \\\r-node\r$ kubectl exec -n spire spire-server-0 -- \\\r/opt/spire/bin/spire-server entry create \\\r-spiffeID spiffe://example.org/ns/default/sa/default \\\r-parentID spiffe://example.org/ns/spire/sa/spire-agent \\\r-selector k8s:ns:default \\\r-selector k8s:sa:default 参考文章列在下面：\nhttps://atbug.com/what-is-spiffe-and-spire/ https://spiffe.io/docs/latest/spire-about/spire-concepts/ https://www.jetstack.io/blog/workload-identity-with-spiffe-trust-domains/ https://blog.fleeto.us/post/something-about-spire/ 基础安全软件的分析 # Vault # 相关的资料很多，毕竟是开源产品。产品资料比较全面，\n产品的优点在于：\n相比其他产品，特意提出了吊销管理Revocation，作为自己的一个特色。 密钥的管理相对而言比较灵活，可以对密钥种类，密钥功能，密钥衍生等进行检索。 缺点在于：\n根据使用接口来说，使用方式不够灵活，细节不够具体。 提供的服务包括五个角度：\n安全存储：存储介质上的私钥是加密过的，获得存储介质上的文件并不会导致信息泄露。 动态密钥生成：根据需求生成不同的密钥， 数据加密： 租约和管理：voalt中所有的密钥都有租约关联，租约到期vault自动将之吊销。 吊销：吊销管理不单独针对具体的密钥，可以针对密钥种类/密钥树等类型。 这个文章似乎不错，可以用来学习vault的结构\nhttps://shuhari.dev/blog/2018/02/vault-introduction\nself design kms document # 代码地址在这里：https://github.com/hxndg/qkms\n2022/05/03 简单写了一个版本，单纯为了写而写。实际上是当时面试xhs被刺激到，有几个点没说对然后脑子乱了\n2025/05/05 更新了这个KMS的代码，加入了手动轮转和自动轮转的功能，其中KEK只支持手动轮转，而AK支持自动轮转。下面只写设计文档了，待完成的点和一些简单的思考。\ntodo：我个人实际上不太满意这个代码，为什么呢？两点\n架构设计不好 权限管理用的casbin，很多授权功能不灵活 关于第一个问题：我目前在想这个问题，理论上模块应该按照组件划分：\n一开始我想的是划分为授权管理模块（允许谁读写某个密钥，某个namespace下的所有密钥，或者所有的密钥的权限查询），密钥管理模块（支持密钥读，支持密钥写操作），通信管理模块（负责和用户实现安全通信）。但是依赖关系授权管理和密钥管理会出现循环。\n所以我计划更正为如下几个模块，这里注意这几种模块的概念是逻辑概念\n密钥Meta模块：本质是个信息存储，存储了AK的namespace，name，meta（实际上是一堆tag） 授权管理（KAR）模块（KAR模块）：依赖密钥Meta模块，负责授权的时候检查权限。 密钥管理：支持密钥读，支持密钥写操作。任何操作都需要读取授权管理模块判断是否允许。依赖密钥Meta \u0026amp; KAR模块 通信模块：不依赖上述任何模块。 2025/05/08，KAP模块重写了，去除使用费劲的casbin，换成了OPA库。去除了KAP对密钥Meta模块的依赖，允许对不存在的ak做授权操作。\n2025/05/09，架构设计重新考虑。原先的对模块的设计实际上并不合理。所以重新明确了领域，认为领域：\n密钥管理领域：提供密钥创建，密钥读取，密钥轮转，密钥更新，密钥信息查询的功能。 密钥授权领域：提供密钥授权（读或者写），密钥信息授权功能（允许查询或者不允许查询） 领域内怎么划分为组件呢？划分服务（组件，或者理解为架构量子）\n密钥管理领域：提供密钥创建，密钥读取，密钥轮转，密钥更新，密钥信息查询的功能。 密钥模块：密钥创建，密钥读取，密钥轮转，密钥更新 密钥信息管理模块：管理密钥相关的Meta信息。 密钥授权领域：提供密钥授权（读或者写），密钥信息授权功能（允许查询或者不允许查询） 密钥授权功能模块：提供密钥授权（读或者写） 密钥信息授权模块：允许查询或者不允许查询密钥的Meta信息（这块具体怎么控制我没想好） 这里需要多说点废话，设计常见的手段有封层设计和模块化设计：分层是按照抽象层次划分，而功能模块是按照业务功能划分。实际上一般设计的时候两者结合起来做，比方说下面这个设计，纵向大的层次隔离了技术的复杂度，而每个层里面的纵向模块则是对应不同的功能\n+-----------------------+\r| 接口层 |\r| - REST API模块 |\r| - SDK模块 |\r| - CLI模块 ｜ | - RPC模块 ｜\r+-----------------------+\r| 核心层 |\r| - 密钥生命周期模块 | → 生成、轮换、销毁\r| - 访问控制模块 | → RBAC/ABAC策略引擎\r| - 加密服务模块 | → 信封加密、签名验签\r+-----------------------+\r| 安全层 |\r| - HSM代理模块 | → 硬件密钥操作\r| - 审计日志模块 | → 不可篡改日志记录\r+-----------------------+\r| 存储层 |\r| - 数据库适配模块 | → MySQL/PostgreSQL\r| - 云存储适配模块 | → AWS S3/Azure Blob\r+-----------------------+ todo：我个人还是不满意这个代码，为什么呢？\n写的跟面向过程一样，虽然写起来很简单。但是没有隔离变化，换言之不同层次的依赖没有体现，所以非常的糟糕 属性查询功能没实现，属性的设计和存储应该选用那种数据库？属性我认为可以视为key \u0026amp; value对应的数值，所以属性的组合可以认为是个json，而且是个很平的json，嵌套不深，更新次数不多。我认为当前认为客户查询的次数不多，所以打算使用postgresql的jsonb存储并建立gin索引。另一方面如果将来需要大量的查询，我认为使用ES即可。这里我多扯一句，对namepsace \u0026amp; name的查询不应当视为属性，这一方面是为了将来的变化预留（索引放到ES中提供毫秒级别查询），另一方面是因为namespace \u0026amp; name的变化和属性的变化是不同步的。总结一下，我的理想实现方法是： 主存储：使用PostgreSQL JSONB 索引层：通过Elasticsearch提供实时组合查询能力。 最后一点就是，属性还是需要和密钥放到一起 设计理念： # 整个体系的安全性需要可证明，包括信任链，通信安全的证明。 实现逻辑简单，简化不必要的部分，一些外部依赖自己实现。自洽 易用。 支持功能（按照重要性排序）： # 分级密钥：分级密钥是安全性证明的一部分 密钥轮转：密钥轮转保证泄露之后的安全 端到端通信安全：保证用户读取过程中不会泄露，也是安全性证明的一部分 密钥管理能力，支持授权可读，角色管理等功能。满足KMS可用性的要求 信封加密：待实现 详细设计 # 分级密钥 # 目前设计实例分为三层，。\n数据加密密钥(AK):将用于数据加密的密钥,也称三级密钥(AK);一般公司里面一个应用对应一个AK；每个AK存储于特定的Namspace下，有自己的name。用户读取AK时需要传递namespace \u0026amp; name 密钥加密密钥(KEK):保护三级的密钥,也称二级密钥(KEK 即对AK进行加密);一般公司里面一个部门对应一个KEK，AK被KEK保护存储于数据库中。KEK对用户是透明的，KEK隶属于namespace 根密钥(RootKey):保护二级密钥的密钥，也称一级密钥(RootKey，即是对KEK进行加密)，根密钥构成了整个密钥管理系统的关键。理论上根密钥需要使用HSM保护。 AK数据结构 # namespace name encrypted_ak key_type srand timestamp environment version kek owner lifetime rotateduration 如下属性：\nnamespace \u0026amp; name ：指定作用域和key name encrypted_ak为加密后的密钥，base64编码 key_type：密钥类型，generate的时候需要用到，目前支持RSA_4096,RSA_2048,AES-CTR-128,AES-CTR-256,AES-CTR-512 srand \u0026amp; timestamp：srand随机获取，参与加密操作。timestamp为密钥创建时间戳 environment：区分诸如test/production环境。 version：用于记录轮转/更新的次数。 kek：对应的kek name。如果AK是初次生成，那么需要查询namepsace当前记载的kek，然后生成。如果是已经有的ak，通过kek去索引对应kek。ak轮转时会自动拿到namespace对应的最新kek。 lifetime，rotateduration：lifetime是unix时间戳，指明什么时候之前是有效的，就是不归档。rotateduration是轮转的事件间隔。 待改进：\n数据库里面的密钥应该包含一个meta信息，指定包括版本，密钥等多方面信息 KEK数据结构 # KEK使用ROOTKEY+SRAND+TIMESTAMP存储于主数据库，\nname encrytped_kek key_type srand timestamp environment rk owner KEK和namespace独立，但namespace会记录当前使用的kek是谁。encrypted_kek = Encrypted(plan_kek)，kek轮转时只会发生新建操作，namespace将自己当前的kek标记为新的kek。不会将历史版本的kek更新为新版本。\n这里面有几点需要注意：\nname：kek的名称。 key_type：密钥类型，generate的时候需要用到，目前一般是默认的。但root管理员可以手动生成不同类型的KEK，并强制更新namespace使用特定的kek srand \u0026amp; timestamp：srand随机获取，参与加密操作。timestamp为密钥创建时间戳 environment：区分诸如test/production环境。 rk：对应rootkey的name，但是rk认为是不可泄露的，目前这里只会写为default。 owner：kek的owner只能是默认root的appkey，这个对用户透明，实际上意义不大。 Rootkey数据结构 # RootKey的内容是不落数据库且不明文落内存的的，理论上RootKey应该是保存于HSM。但没钱买HSM，所以实际上是用服务器的私钥+HKDF手段派生拿到的RootKey。这里实际上还有个方法，就是对于一级根密钥，推荐使用安全门限算法保证分割安全，这里是指启动的时候必须输入多个用户的秘钥，即必须多个揭密者的密钥都获得的情况下，才能成功拿到一级根密钥。保存时使用服务器的非明文落盘cache key加密保护\n密钥轮转 # 密钥轮转包含两个层面：\nKEK密钥轮转：仅支持手动轮转，由管理员触发 AK密钥轮转：支持自动轮转，添加定时任务实现。 端到端通信安全 # 这块实际上属于不需要也不应该自己实现的部分，直接使用grpc的双向认证实现。\n密钥管理能力 # 身份（证书）签发：使用服务端的CA证书签发用户证书即可\n角色管理：角色本质上只有root，因为我用的是ABAC\n授权管理：除了root，使用opa的abac实现。\n具体的数据库结构结构为\n信封加密 # 部分待优化功能 # 实现：\nanother method：包裹一层vault\n具体的客户机器，甚至包括操作数据库的机器，每台机器上存在一个KMS-Agent，每个KMS-Agent有私钥和公钥（证书），握手的时候使用证书私钥校验身份。证书当中包含该KMS-Agent的身份appkey，该KMS-Agent能够获取的秘钥必须都是对该appkey授权的秘钥。KMS-Agent获取的秘钥必须以加密方式存储，数据的结构如下，这里有一点要注意，Environment是环境变量，不会存储在数据结构里，对客户是透明的：\nnamespace name encrypted_key key_type srand timestamp version kms_secret_version namespace \u0026amp; name用来确定密钥，key_type确定key类型，比方说rsa/ecc/hmac等等，srand为随机数增加随机性，timestamp用来确定加密时间，一起参与到存储中。version用来存储秘钥的版本\nencrypted_key = Encrypted(plan_key)，秘钥为KMS-Agent Secret HKDF with srand \u0026amp; timestamp。kms_secret_version用来在迭代kms密钥时使用。\n这里面有一点要注意，encrypted_key需要使用base64编码，然后存入数据库\n数据库密钥的存储\n这里面有三点要注意，encrypted_ak需要使用base64编码，然后存入数据库\r+ kms agent，即每个docker上面的kms 私钥也是需要存储在数据库当中的，所以还需要一个agent secret table。需不需要证书库呢？\r+ 理论上，不同版本的密钥应该是只做新建，不做更新操作，换言之为了做到完全的无状态，历史的ak（请注意，这里不包括KE）不应该被直接删除，而应该是直接归档为不可用状态，换言之，此时只能管理员检索，而不是历史的数据被删除\r+ encrypted_ak使用base64编码存入数据库，方便显示和查看。\r+ namespace，name，version使用uniqueIndex\rAK授权关系，用来指定授权关系，根据指定具体的appkey来决定是不是授权\nnamespace name environment ownerappkey grantedappkey behavior namespace+name+environment用来指定秘钥是哪个，granted_appkey则指定该appkey可以获取该秘钥，behavior的权限为读和写。不过一帮都是只允许读\n用户信息\nName AppKey Cert KeyCipherText KeyType Srand TimeStamp Version KEK 用户信息实际上和普通的Ak非常类似，只不过多了appkey和cert的存储，其中的keyciphertext是密文存储的用户私钥，需要事先创建名为”user“的production的KEK。为什么需要Version，需要在用户信息过期后更新版本\nKMS初始化的操作\n初始化数据库的连接和各种内部的数据表 为了完全实现无状态\n部署层面，正常情况，自研KMS/PKI是有一个核心的，这个核心负责签发证书，密钥颁发等关键功能。这个核心是部署的重点，从功能和依赖的角度来说，可以拆为这几个方面\n对内：考虑高可用，数据一致性等方面。理论上需要除了对分部署数据库等依赖之外，包括RAM，监控什么的都做到完全的自洽\n强依赖：处于高可用的考虑，理论上机房要做双电源，双服务器等多种资源冗余。当然，我做的时候啥都没有。另外，要做到\n数据库，在当前为了保证数据一致性和高可用，如果不想自己去做，数据库可以使用云上分布式数据库。为了保证安全性，数据库有两个必须保证的点：1 不能明文存储密钥信息 2 必须做访问控制，来限制只能是核心访问，不允许外部访问。在Q的时候，我没使用高可用性，直接就是一个数据库放到特定机器，访问控制这块是只允许特定的IP连接。 独立机房 \u0026amp; 网络 \u0026amp; HSM：机房\u0026amp;网络 \u0026amp; 硬件模块要包含多个，做到物理隔离和网络隔离。硬件HSM一般也是和具体的机房在一起，如果为了高可用，确实可能需要多个机房布置存储了同样敏感信息的hsm，hsm的敏感信息同步是一个关键点。原先实现的时候没用hsm，因为不可能给钱买 弱依赖\n监控：监控服务的可用性，可用性实际上只做了简单的query探测， 堡垒机：这个实际上也没做，使用了公司的jumpserver和k8s本身的权限，对机器的特定访问只有少数授权用户可以使用 日志：日志这部分根据需要做介入，我个人是直接用阿里云k8s那一套 CI/CD：CI/CD直接嵌入了gitlab基础代码库，可以方便地直接做部署 对外：\nha/slb：对外提供服务，使用mtls进行通信。这里我使用的是k8s本身的svc做的。 参考：\n我实在Windows下面做的开发，不过linux应该一样，Golang，Grpc，Protobuf安装参考这个例子\ngolang, postgresql的安装就是直接下载exe文件，就不多说了。\n参考这个页面，https://grpc.io/docs/protoc-installation/，点进去里面找 https://github.com/google/protobuf/releases，再点击下载安装\ngo install google.golang.org/protobuf/cmd/protoc-gen-go@latest go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest # linux修改PATH变量，windows修改环境变量 export PATH=\u0026#34;$PATH:$(go env GOPATH)/bin\u0026#34; 首先根据proto生成对应的文件：\nprotoc --go_out=. --go_opt=paths=source_relative --go-grpc_out=. --go-grpc_opt=paths=source_relative proto/qkms.proto 如何构建PKI\nhttps://insights.thoughtworks.cn/microservices-authentication-token-management/ https://www.zhaohuabing.com/2018/02/03/authentication-and-authorization-of-microservice/ https://blog.cloudflare.com/how-to-build-your-own-public-key-infrastructure/ https://insights.thoughtworks.cn/tag/security/ https://devops.com/how-to-automate-pki-for-devops-with-open-source-tools/ https://www.keyfactor.com/blog/the-4-best-open-source-pki-software-solutions-and-choosing-the-right-one/ [PKI体系建设实践] # 对于甲方证书体系管理而言，有诸多实践上的问题，所以记录下遇到的问题和解决方法，最后附上几种开源的CA比较\n什么是安全的证书\n声明周期方面：证书需要按照服务类型等方面，针对性的缩短生命周期。 加解密key类型方面：使用安全的加解密秘钥类型，比方说rsa申请4096字节以上。或者说选择正确的算法 证书的安全审计，如何全面地监控证书的使用情况。\n证书的申请实际上是通过在CD的k8s context上面挂载了对应的CD的证书（私钥，身份）什么的，每次签发用哪个做自动化触发。然后直接使用ejbca的cms功能，不过生命周期比较短。 日志用的是k8s日志那一套，没有进行特别复杂的设计，因为没有那种需要。毕竟每天请求并不多 证书如何安全存储：\n如何对证书做自动化管理：\n企业内部一般是由自己的devops的，因此在CD的时候需要做镜像的机器拥有一张权限较高的证书和私钥，该证书对应的角色需要能够为服务进行证书申请。举个简单的例子，在做CD的POD上挂载阿里云的配置的secret，这个secret的内容就是证书和私钥。这里需要保证这个证书和私钥是绝对不能泄露的。 对于服务pod上的证书，这个服务pod上面的证书更新实际上就是服务pod自己的任务了，agent可以使用mtls访问证书管理服务申请和自己证书san一致的更新证书。或者使用类似acme等方式来进行更新. 理论上每个证书应该是颁发一次就直接吊销旧的，不过我们目前没实现这种。直接就是声明周期比较短，直接一周搞定 几种开源的CA对比\n四种选择，最简单的还是第一种ejbca，测试环境下的部署。这里注意，在调试情况下是不会有administor的限制的，谁都可以申请证书。因此正常使用需要使用开启了客户端认证的ejbca，然后使用控制台输出的指令，下载证书并且登陆。\ndocker run -it --rm -p 80:8080 -p 443:8443 -h qkmsca -e TLS_SETUP_ENABLED=\u0026#34;simple\u0026#34; primekey/ejbca-ce 签发证书时，需要提供三种信息\n证书侧写（certificate profile），用来提供证书的限制，比方说可以使用什么key，可以提供什么拓展。 一般情况下，证书的用处总是非常限制明显的，比方说用来做client auth，用来做root啥的 终端实体侧写（end entity profile），用来确定哪些信息需要写到证书当中，比方说邮件等等，此外还有提供证书的格式文件啥的类型 添加终端实体，这里实际上就是手动添加终端实体的过程，添加响应的用户 EJBCA还有个好处，可以将EJBCA当成一个证书管理系统使用即，CMS\nQ内部目前都没有，还需要调研关于颁发设备证书的东西，参考https://www.zybuluo.com/zhongdao/note/1000973\n参考：\nhttps://doc.primekey.com/ejbca/tutorials-and-guides/using-ejbca-as-a-certificate-management-system-cms\n证书管理\n一些实现的细节 # 那么问题来了，零信任怎么和四层的TLS建立起来连接呢？TLS基于四层，因此是其他层面的基石，那么问题来了TLS怎么和零信任契合起来呢？TLS协议实际上是个非常灵活的东西，以下几个点值得关注。\n10.3.2.0 TLS协议的基本保证 # 由于是从四层来做，因此单调地依赖层提供的保障不再现实：TLS层就要提供身份认证和权限管理的功能，而TLS上层的协议需要能够获取TLS层的身份信息。这意味着上层需要获得已经认证的资源和证书，即上层可以和下层通信。\n10.3.2.1 TLS基础协议的认证功能 # 针对TLS1.3，TLS协议的基本认证功能主要集中在服务端的证书消息和客户端的证书消息，身份和证书绑定，终端的网络情况可以和具体的拓展或者和心跳包相关联，从而服务器能够检测出是否要再次进行权限校验功能。有一点需要注意，如果开启REUSE功能或者0-RTT功能，那么意味着身份信息需要在SESSION IDENTITY里面记录相关信息，当然这不会造成太大的问题。\n10.3.2.1 TLS心跳拓展 # TLS的心跳拓展是个非常有趣的东西，这个拓展实际上就给上层协议做TLS的状态监测等方面提供了功能，换言之，这个功能使得安全网关能够主动请求并鉴定客户端的网络状态。心跳拓展包的类型为两种： heartbeat_request(1)和heartbeat_response(2)。心跳包的具体格式如下：\n心跳协议消息包含了类型，任意载荷和填充。结构如下： struct { HeartbeatMessageType type; uint16 payload_length; opaque payload[HeartbeatMessage.payload_length]; opaque padding[padding_length]; } HeartbeatMessage; 心跳消息的总长度不能超过2^14或者规定的最大分片单元的长度。 这意味着我们可以在心跳包当中嵌入任意长度的消息，只要保证安全性就可以解决问题。\n接收方要告诉对方一个告警消息“illegal_parameter这个行为也可以用来记录相关的安全信息。\n从简单的角度来说，对心跳包的拓展是最简单的检查功能。\n具体内容参考RFC 6520https://tools.ietf.org/html/rfc6520和RFC8447https://tools.ietf.org/html/rfc8447。\n10.3.2.2 TLS自定拓展 # 在TLS1.3中自定拓展是个非常有趣的事情。EncryptedExtension和ClientHello都能加入拓展，CLientHello中可以使用明文，当然如果算上0-RTT报文当中包含权限或拓展信息就很有趣。\n10.3.2.2 TLS PHA功能和安全重协商 # TLS1.3的PHA功能简直是对从新认证的完美实现，只要客户端带PHA_HANDSHAKE_AUTH拓展，那么服务器可以在任意时刻发送PHA认证消息，客户端必须按照符合格式的方式回复。当然可能服务器在收到认证报文之前可能受到大量无意义报文，这个情况要注意。\n但是PHA只是身份认证相关的工作，无法包含更多的其他信息，因此对于零信任的场景安全重协商更靠谱，可以重新产生相应的身份信息和拓展信息。\n云原生安全 # 1 从底层linux说起 # 1.1 权限模型方面 # linux为了应对权限问题，引入了一种新的权限控制模型，叫做capabilities，这种模型主要的特点是将一些特权划分成了不同的单元，并且可以灵活***地***控制其独立或者组合进行启用或禁用。参考https://www.man7.org/linux/man-pages/man7/capabilities.7.html\ncapabilities 当前作为每个线程的属性存在，也可以作用在可执行文件上。实际上使用docker作为我们运行的环境的时候，其权限就是通过设置下面的东西来确定的\n如果用作线程属性存在，我们称之为 Thread capability sets； 第一个集合，Permitted。它不会直接影响到线程的 capability，而是作为一个约束，定义了线程最多能使用的 capability 集合的上限。对于线程而言，它可以通过 capset() 这样的系统调用来对 Inheritable 和 Effective 集合进行 capability 的增加或者删除，但是所操作的这些 capability 必须先定义在 Permitted 集合中，不过也会受到 Bounding 集合的一些影响。当然，如果想要真正能通过 capset() 系统调用来操作 Inheritable 集合的话，也需要保证其 Effective 集合中有 CAP_SETPCAP 的 capability 。 第二个集合，Inheritable。它主要定义了一组跨 execve(2) 系统调用时可继承的 capability 集合。但是它的影响是会将 Inheritable 集合中的 capability 应用于新线程的 Permitted 集合中，而非直接设置成新线程的 Effective 集合。 第三个集合，Effective。它定义了线程可执行的全部特权。内核对线程执行特权操作时的检查便是去检查 Effective 集合。前面我们提到 Permitted 集合定义了线程最多能使用的 capability 集合的上限，所以可以通过删除线程 Effective 集合中的 capability 来达到禁用 capability 的目的。当然，后续也可以再从 Permitted 集合进行恢复。 第四个集合，Bounding。它定义了可被继承的 capability 集合的超集，类似于 Permitted 之于 Effective。如果一个 capability 存在于 Inheritable 中，但未定义在 Bounding 集合中，那该 capability 同样是无法进行继承的。在 Linux 2.6.25 版本之前，这是一个系统级别的全局属性；自 Linux 2.6.25 之后，它成为了每个线程独立的属性。 第五个集合，Ambient。它是对 Inheritable 集合的一种补充，从 Linux 4.3 开始引入。如果一个 capability 未在 Permitted 和 Inheritable 集合中设置，那么 Ambient 集合也不能进行设置。但如果某个 capability 已经添加到了线程的 Ambient 集合中，那么当它执行 fork() 和 execve(2) 系统调用时，便可自动继承下去。 如果用作可执行文件的扩展属性上，则称之为 File capability sets。 第一个集合，Permitted。它定义的 capability 会自动添加到线程的 Permitted 集合中，但最终线程的 Permitted 集合中的 capability 实际上是它与线程的 Bounding 集合取交集的结果。 第二个集合，Inheritable。它定义的 capability 会与线程的 Inheritable 取交集，然后添加到 execve(2) 产生的线程 Permitted 集合中。 第三个集合，Effective。它并不是一个真正的 capability 集合，它仅仅是一个标志位。如果设置为开启，那么在 execve(2) 系统调用执行后，线程 Permitted 集合中的 capability 将被同时设置到 Effective 集合中。 1.2 资源隔离 # 对于容器化技术而言，实现资源的隔离和限制是其核心，上面的权限控制只是执行相关，而资源隔离主要使用 namespace 完成，因此linux启用了cgroup。\n具体的cgroup可以参考目录/sys/fs/cgroup 下包含很多可供选择的资源目录。比方说如下图。可以针对性想限制的资源文件夹下面创建对应的新cgroup。\nqcraft@BJ-vgdog:~/qcraft$ ls -l -a /sys/fs/cgroup/ total 0 drwxr-xr-x 15 root root 380 2月 13 11:42 . drwxr-xr-x 11 root root 0 2月 13 11:42 .. dr-xr-xr-x 5 root root 0 2月 13 11:42 blkio lrwxrwxrwx 1 root root 11 2月 13 11:42 cpu -\u0026gt; cpu,cpuacct lrwxrwxrwx 1 root root 11 2月 13 11:42 cpuacct -\u0026gt; cpu,cpuacct dr-xr-xr-x 5 root root 0 2月 13 11:42 cpu,cpuacct dr-xr-xr-x 3 root root 0 2月 13 11:42 cpuset dr-xr-xr-x 6 root root 0 2月 13 11:42 devices dr-xr-xr-x 4 root root 0 2月 13 11:42 freezer dr-xr-xr-x 3 root root 0 2月 13 11:42 hugetlb dr-xr-xr-x 5 root root 0 2月 13 11:42 memory lrwxrwxrwx 1 root root 16 2月 13 11:42 net_cls -\u0026gt; net_cls,net_prio dr-xr-xr-x 3 root root 0 2月 13 11:42 net_cls,net_prio lrwxrwxrwx 1 root root 16 2月 13 11:42 net_prio -\u0026gt; net_cls,net_prio dr-xr-xr-x 3 root root 0 2月 13 11:42 perf_event dr-xr-xr-x 5 root root 0 2月 13 11:42 pids dr-xr-xr-x 2 root root 0 2月 13 11:42 rdma dr-xr-xr-x 6 root root 0 2月 13 11:42 systemd dr-xr-xr-x 6 root root 0 2月 13 11:42 unified 在容器环境中实际上docker已经按照cgroup啥的给配置了资源配比，\n总之，cgroup 的出现满足了容器对于资源配额管理的需求，同时我们可以通过使用 cgroup 对进程资源进行非常方便的资源限制，以免进程之间出现资源抢占的问题。\n在容器环境中，cgroup 的使用频率非常高，对于 Kubernetes 环境，也建议你对 Pod 进行 request 和 limit 的限制（实际上底层还是 cgroup 在起作用）。\n1.3 namespace隔离 # namespace。主要是为了让该系统中的每个进程组通过拥有自己独立的 namespace 抽象，以达到这些进程组之间的文件系统彼此隔离、互不可见的目的。\nnamespace 有很多种，目前已经实现的有 8 种：Network、PID、Mount、IPC、UTS、User、cgroup 和 Time。\n2 云原生安全 # 2.1 云原生安全 # 针对runtime安全，一般是两种情况\n事前 直接镜像内添加非root用户 镜像内不允许让root用户运行 事后 falco，https://falco.org/ 如果希望从容器内部就开始进行安全防护，那么需要关注\n容器镜像内容安全性的保障； 简单来说就是SBOM 就是一份可用于表明 用于构建软件的相关组件及其依赖项的详细信息及软件自身元数据信息 的清单文件。保证产品完整性，保证供应链安全管理 如何生成SBOM，使用syft 如何扫描SBOM，使用grype，输入syft输入的json文件 使用trivy进行镜像安全扫描 容器镜像分发过程中的安全性保障。 关于安全容器 gvisor kata containers fire cracker 2.2 kubernetes安全 # 在 Kubernetes 中所有的请求都需要经过 kube-apiserver，而 kube-apiserver 最基础的功能就是按照请求路径对请求进行处理和路由。在此之后，会分别进行认证（Authentication）和授权（Authorization）的逻辑，再之后会有准入控制器（Admission controller）等进行处理，经过这一系列处理，请求才能与 ETCD 中的数据进行交互。\nX509 客户端证书：这种方式使用很频繁，多数时候我们使用 kubectl 命令行工具和 Kubernetes 集群交互时候也是使用这种方式进行认证。 service account： Service Account 是 Kubernetes 集群内认证最关键的一环，它是进行 JWT 认证的主体。默认情况下，Kubernetes 会为每个 Pod 指定一个名为 default 的 Service Account，并且在 Pod 内挂载该 Service Account 与 kube-apiserver 的认证凭据。 想要为 ServiceAccount 进行授权，主要会涉及到以下两类资源。 Role 和 ClusterRole：这两个资源的区别是前者为 Namespace 范围的，后者是 Cluster 级别的。它们用于定义角色，以及角色所具备的权限。 RoleBinding 和 ClusterRoleBinding：这两个资源的区别是前者为 Namespace 范围的，后者是 Cluster 级别的。它们用于将角色和 Kubernetes 中具体的\u0026quot;用户\u0026quot;/\u0026ldquo;身份\u0026quot;进行绑定，完成授权。 最终还是要涉及到token request 基于 OpenID Connect Token 2.3 回到DEVSECOPS # 参考如下：\nStatic Application Security Testing\nsyft+grype做安全分析，实际上还真的发现了一些有趣的东西\nTrivy\n2.0 云安全 # 2.1 云扫描 # 云扫描包含多个部分，包含资产扫描，漏洞扫描，网站扫描和安全配置扫描。现在一部分企业连清楚自己有哪些东西都不知道\n资产扫描，发现企业内部资产和互联网报路面为主 需要回答企业的核心资产是什么 扫描内容包含企业的各种核心资产，除了硬件资源还包括软件资源，数据等，总结来说是硬件资产和软件资产 除了常规的内网icmp扫描，还可以通过网络层流量，云环境开放接口 漏洞扫描 需要衡量漏洞的严重程度 网站扫描 主要针对网站引用，做黑河扫描 安全配置扫描 针对不同平台的安全配置扫描，比方说服务器，数据库等 下面给一些开源的扫描工具\n资产扫描工具\nNMAP，扫描主机和开放端口，确定哪些服务在运行，推测主机平台等信息 ZMAP MASSCAN 漏洞扫描工具\nopenvas nessus 网站扫描\nnikto sqlmap xsser 安全配置扫描\nlynis 2.3 云防护 # 安全攻击层出不穷，从防御的角度，需要有防御的工具，因此出现了WAF，和防火墙一样WAF保护的是网站类应用，其目标是防御逐入，xss，cc工具，\n一些开源的云waf工具\nmodsecurity，nginx+modsecurity openresty+ngx_lua_waf 2.4 云SIEM # 检测和分析中心\n3 数据安全实践 # 数据安全能力成熟度模型（Data Security Capability Maturity Mode,简称DSMM）是阿里的一套模型，一般来说按照下面的方面进行分类。如果从通用的角度来管理，还需要注意几个细节方面：1 合规管理，需要专门的法务和技术人员对数据合规的法律法规进行对自身数据的分析 2 数据资产管理 3 元数据管理，这里面之所以单独提出来元数据，是因为元数据是数据最外层的表现，也是敏感的终端\n数据采集安全\n数据分级分类机制安全管理，需要能够。**工具方面需要有相应的数据资产管理工具，实现对数据分类分级自动进行标示。**分类可以按照业务，关系，内容进行分类。分级可以按照价值，敏感程度，司法影响范围分级。比方说可以拆分为非敏感数据，敏感数据，涉密数据。里面还可以继续拆分为公开，首先公开，内部使用，限制使用，审核公开，保密管理，禁止公开。不过这些流程是可以慢慢拓展的，不是必须不变的 根据数据不同的级别指定不同的标示和管理 应对不同类别和级别的数据建立相应的访问控制，数据加解密，数据脱敏 明确等级变更的流程，因为数据级别可能会发生改变，因此需要明确等级变更的流程 数据采集安全管理，工具方面需要有详细的日志记录功能，确保数据采集和授权过程中记录的完整性 明确数据源，频度，渠道，方式，数据防伪和类型进行风险评估。 给出明确的数据采集原则，定义业务的数据采集流程和方法。同时对外部数据源的合法性进行辨认。 确保采集过程中的个人信息和重要数据不泄露 数据源鉴别及记录 能够认证数据源 对数据需要做到能够数据溯源，即可以通过打标的方式或者是逆向函数的方式 数据质量管理 数据传输安全\n数据传输加密，工具部分要对数据完整性做检测，部署对通道安全配置，密码算法配置，密钥管理等手段做审核和监控的技术 明确数据传输的安全要求，比方说传输通道加密，数据内容加密 网络可用性管理，这个需要保证网络对抗入侵，数据泄漏等方面攻击 数据存储安全\n该部分主要保证数据完整性，保密性和可用性即CIA三个方面 存储物理介质的安全 存储逻辑介质的安全**，明确各数据逻辑存储介质的管理员，由其负责执行数据逻辑存储系统，系统设备的安全管理和运维工作。要明确存储系统的账号权限管理，访问控制，日志管理，加密管理。要确保数据租户是相互隔离的** 数据备份和恢复，明确数据备份和恢复的管理制度；明确数据备份和恢复的频率，防伪，工具过程，日志记录，数据保存市场；明确归档数据的压缩或者加密要求；明确授权管控，非授权人员不得访问 数据处理安全\n脱敏 分析 保证数据正当使用，完全隔离用户，整个过程透明最简单 终端安全，需要保证数据使用的终端是安全的，也是一个复杂的话题 数据交换安全。我们必须能够对数据进行审批和授权，确定数据的范围/类型/内容/格式/.\n数据共享安全 保证数据共享的原则和安全规范，明确数据使用者的安全责任和安全防护能力 数据发包安全 明确数据公开内容，适用范围及规范，明确发布者和使用者的权利和义务 数据接口安全 明确数据接口安全访问控制策略，明确接口的安全限制和安全控制策略，比方说使用身份鉴别，访问控制，授权策略，签名，时间戳等 明确接口名称，接口参数等 明确数据的使用目的，供应方式，保密约定等 数据销毁安全\n[Q数据保护方案] # 长久以来，诸如run数据，保密数据全都是以明文方式放在阿里云OSS上，在数据传递/使用的过程中极易造成数据的泄露，因此需要提供数据安全的方案。利用已经存在的KMS方案，可以建立对应的授权和保密机制。类比金钱交易，现金就是具体的数据，银行卡就是生成的token，token可以无负担地在服务之间流转\n生成方调用数据加密服务保存run数据，提供数据名字参数（数据名字需包含逻辑含义）；数据加密服务返回一个token，代指该数据 数据加密服务使用使用方的名字/服务名字为kek（namepsace），数据名字为name，生成一个秘钥，存储到kms中。 使用该namespace（kek）和name生成的秘钥（ak），对数据进行加密。加密完成后做hash生成token。需要保存该token和，namepsace \u0026amp; name的对应关系，方便检索。这里ldap就有用了 生成方获取该token后就可以将token代指数据，传递给具体使用方，整个数据在传递过程当中没有明文传递的。 token需要提供数据匿名的功能，即不暴露数据拥有者和使用者的信息 使用方获得token之后，向数据生成方请求token数据的授权，从而进行解密 token数据的授权读取需要拆分为两个部分，授权的部分实际上是授权kms里面的某个秘钥给使用方可读 token对应的数据的读取应该是发送密文到使用方本地，然后使用方利用授权拿到的秘钥做解密 这种方案的优点为\ntoken对应为kms，可以轻松的轮转秘钥等东西 可以轻松的生成文件分享的途径，到期进行文件的管控，比方说删除 这种方案的缺点为\n数据不可轻易分割 信封加密\n用户发送（创建）一个KEK。利用该KEK生成对应的AK，并使用KEK加密，将加密以后的AK密文和AK明文一起返回给用户 用户使用AK的明文做加密，将数据密文和加密的秘钥一起存储。销毁明文秘钥 用户存储密文秘钥和密文文件一起存储到本地 用户使用的时候调用KEK解密密文秘钥，拿到明文秘钥解密即可 如果提供给外部，原始数据应当包含一些冗余信息（二进制格式的grpc proto可以非常方便的添加容易），这些冗余信息为第三方身份信息。使用流程如下\n数据做加密存储，加密使用的秘钥使用KEK做加密后和密文数据放到一起，存储于云上或者某个地方 用户调用提供的接口，（它需要有一个身份或者说证书什么的）从我们的KMS服务拿到对应的KEK对加面的秘钥做解密之后，开始解密相应的文件 以上操作应该发生在数据的接入层，也就是说整个过程除了用户的身份信息，对用户都是透明的。 参考下四维的敏感地图是怎么使用的\n与“使用STS临时访问凭证访问OSS”结合的数据保护方案，\n终端用户应该使用软件内嵌证书来控制最末端的身份认证体系，通过证书进行管理\n一些问题\nPKI设计部分：证书精确的粒度到底是什么？文档里面写的是车端VIN+ECU，这是说不同的板子使用不同的证书吗？车端业务后段是都一张证书，不做具体的区分吗？ CA及证书层级：只有这么几层吗？中间CA的层级有多少？另外trustbundle这么交换 证书签名：上传CSR是说提供托管公钥，私钥不存储的能力吗？如果不提供，云端是否要保存私钥？提供什么能力？ 证书本身的签发不是什么问题，但是证书的安全使用，存储才是关键，如果cover？以后再设计？likey cover DK，DK的meta表里面为什么没有对应kek的版本？我理解kek是有中间态的吧？ 结尾 # 唉，尴尬\n","date":"2021 年 2 月 22 日","externalUrl":null,"permalink":"/posts/2023-02-12-%E5%AE%89%E5%85%A8%E9%9B%B6%E4%BF%A1%E4%BB%BB/","section":"Posts","summary":"","title":"2023-02-12-安全零信任","type":"posts"},{"content":"","date":"2021 年 1 月 31 日","externalUrl":null,"permalink":"/tags/hex/","section":"Tags","summary":"","title":"Hex","type":"tags"},{"content":" 汇编笔记 # 几本书一起看，笔记互相添加，嗯，真是个糟糕的主意。目前实际上是《X86_64组织结构及汇编入门》的笔记，还没有王爽汇编的部分。\n第一章-第三章 # 前面几章实际上没啥好说的，也就补码，反码那部分有点意思，不过原先上学的时候都学过。\n第四章-第五章 逻辑门与逻辑电路 # 4.1-4.2 布尔逻辑基础 # literal有两个含义\nIn computer science, a literal is a notation for representing a fixed value in source code. 这个是给编程/计算机科学用的 In mathematical logic, a literal is an atomic formula (atom) or its negation. The definition mostly appears in proof theory (of classical logic), e.g. in conjunctive normal form and the method of resolution. 数学里面是个极简的数学公式 A presence of a variable or its complement in an expression. 布尔算式里面更具体 product term布尔逻辑里的“乘积表达式”，minterm每个变量都有的乘积表达式（无论里面是x还是^X），sum of products(SoP)乘积表达式的求和，sum of minterms(SoM)每个乘积表达式都是minterm的SoP\n八种使得minterm为1的组合，如图\nsum term布尔逻辑里的“加法表达式”，maxterm每个变量都有的加法表达式（无论里面是x还是^X），products of sums(PoS)加法表达式的求乘，product of materms(PoM)每个加法表达式都是maxterm的PoS\n八种使得maxterm为0的组合，如图\n4.3 布尔函数冷处理(?) # mSoP\nmPoS\n莫利斯卡诺，卡诺图K-map，非常有用的用于分析逻辑的方法，具体方法因为是英文版不是很清楚，明天查清了再写下来。\n第六章 CPU # 6.1 CPU总览 # 总线 L1缓存 寄存器 指令指针 指令寄存器 控制单元 ALU 标志寄存器 6.2 CPU寄存器 # 下面的调用习惯，或者说calling convention是System V AMD64 ABI，还有微软那边的一派别，详情参考https://en.wikipedia.org/wiki/X86_calling_conventions#x86-64_calling_conventions\n6.3 CPU与内存/IO的交互 # 6.4 CPU指令执行流程 # 现代处理器体系结构往往采用指令队列，那么如何进行指令执行流程呢？\n6.5 使用GDB观察程序 # 一些指令:\nN 代码行数级别的，不进入执行的单步执行 S 代码行数级别的，进入加执行的单步执行 SI 机器码级别的单步执行 Info Reg 查看寄存器 第七章：使用汇编语言编程 # 没什么特别值得记载的，只需要记住\nmovq %rsp, %rbp #这里的%用来表示寄存器，AT\u0026amp;T语法的通用格式是movs src, dest。如果是inter语法，那么就反过来 movs dest, src。dest和src中至少得有一个寄存器\nmovl $0, %eax #这里的$表示一个常量\nleave 指令等同于\nmovq %rbp, %rsp\rpopq %rbp b =\u0026gt; byte =\u0026gt; 8 bits w =\u0026gt; word =\u0026gt; 16 bits l =\u0026gt; long =\u0026gt; 32 bits，it\u0026rsquo;s always called dword q =\u0026gt;quadword =\u0026gt; 64 bis 这里显示的都是整数，我们来看点浮点数的指令，下面看到一个不明白的就写一条，慢慢建一个表\nCVTSI2SS — Convert Doubleword Integer to Scalar Single-Precision Floating-Point Value\rCVTSS2SI — Convert Scalar Single-Precision Floating-Point Value to Doubleword Integer\rCVTTSS2SI — Convert with Truncation Scalar Single-Precision Floating-Point Value to Integer\rCVTSS2SD — Convert Scalar Single-Precision Floating-Point Value to Scalar Double-Precision Floating-Point Value\rMOVSS — Move or Merge Scalar Single-Precision Floating-Point Value 更具体的指令，看这个：\n除了上述的内容，还需要多赘述几句寻址方式。首先，x86是小端的典型代表，也就是低地址放低位数据，高地址放高位数据。\n寻址方式可以参考链接https://zhuanlan.zhihu.com/p/355261639，下面的内容直接就是我抄过来的，感谢原作者。\nx86 寄存器功能 # x86 寄存器功能列表如下：\n在x86的abi中注：以 main 函数中调用函数 add为例 ，main 为调用者，add 为被调用者。在 main 函数调用 add 之前，应该将【EAX, ECX, EDX】保存到栈中，在 add 函数中应该将【EBX, ESI, EDI, EBP】保存到栈中，在函数执行完成后，恢复原始数据。\n操作数类型 # 在 x86 指令中，包括三类操作数：立即数、寄存器和存储器引用。\n立即数：即常数，任何可以用 32 位寄存器表示的数，都可以作为立即数。立即数使用前缀$进行表示，后面可跟十进制或者十六进制。使用 代表任意立即数。例如：$0x10 或者 $16 ，都表示数字 16。\n寄存器：用符号 表示任意寄存器 a , 使用 表示寄存器 a 的值。\n存储器引用：存储器引用表示存储器某个地址的数据。用 表示地址 Addr 的值。\n寻址方式 # x86 包括 7 种寻址方式，分别为：立即数寻址、寄存器寻址、绝对寻址、间接寻址、基址+偏移寻址、变址寻址、比例变址寻址。\n前三种寻址方式的表示即上面立即数的表示方式。\n间接寻址：通过访问寄存器 的值( )，访问对应地址的值。使用符号 表示。例如：EAX 寄存器为 0x0001 ，地址 0x0001 的值为0x1234。则 的值为0x1234\n基址+偏移寻址：通过寄存器 和立即数 ，访问地址： 处的值。使用符号 表示。\n完整寻址方式见下表，我实际上感觉类型存储器，第三行的Imm的写的有点令人迷惑，在x86里面，实际上看到这个的形式应该是mov rax, [0xff]的样子，There’s one exception to this: x86_64 allows for a 64-bit displacement with the a* registers.\n立即数 、基址寄存器 、变址寄存器 、比例因子 （其值为 1、2、4、8)。\n上面都是中文，翻译的莫名其妙的寻址分类，不如直接对应下面的英文的分类\nDisplacement Base Base + Index Base + Displacement Base + Index + Displacement Base + (Index * Scale) (Index * Scale) + Displacement Base + (Index * Scale) + Displacement rip relative 除此之外，具体的可以看下面的图片，\nok，let\u0026rsquo;s give a raw example with at\u0026amp;t example:simple example below\nregister direct: The data value is located in a CPU register. syntax: name of the register with a “%” prefix.\nexample: movl %eax, %ebx immediate data: The data value is located immediately after the instruc- tion. Source operand only.\nsyntax: data value with a “$” prefix.\nexample: movl $0xabcd1234, %ebx base register plus offset: The data value is located in memory. The address of the memory location is the sum of a value in a base register plus an offset value.\nsyntax: use the name of the register with parentheses around the name and the offset value immediately be- fore the left parenthesis.\nexample: movl $0xaabbccdd, 12(%eax) rip-relative: The target is a memory address determined by adding an offset to the current address in the rip register.\nsyntax: a programmer-defined label\nexample: je somePlace indexed: The data value is located in memory. The address of the memory location is the sum of the value in the base_register plus scale times the value in the in- dex_register, plus the offset. syntax: place parentheses around the comma separated list (base_register, index_register, scale) and preface it with the offset. example: movl $0x6789cdef, -16(%edx, %eax, 4) for complex example ,check link https://blog.yossarian.net/2020/06/13/How-x86_64-addresses-memory\n第八章：程序数据-输入，存储，输出 # 8.1-8.3 设计本地变量的栈 # 一些最基础的东西：\n汇编传递参数的时候，用哪个寄存器传参数，约定俗称的，得看ABI。需要保存哪些二进制到栈里，也需要记录values in registers rbx, rbp, rsp, and r12 – r15 be preserved by the called function 。具体的ABISystem V Application Binary Interface AMD64 Architecture Processor Supplement 我上传到了网盘上，哪天上班的路上翻翻看。 栈顶也就是RSP值得位置从来都是有数值的，进栈的时候是先减指针再放入数据sp = sp-8;stack[sp]=value，出栈的时候是先拿出来数据，再加指针var=stack[sp];sp = sp+8 .rodata对应于只读数据， at\u0026amp;t 对应的rbp本地栈上变量的表示方法为offset(register_name) ，实际上我们就是在每个局部函数的栈帧(stack frame )里修改本地变量，这里的栈帧指针就是frame pointer, rbp寄存器 。而stack pointer就是rsp寄存器 被调用函数在进入call之后，也就是刚执行的时候，它的流程为(这里有一点要注意，必须先保存caller\u0026rsquo;s rbp再保存其他寄存器的值)：\nSave the caller’s value in the frame pointer on the stack. Copy the current value in the stack pointer to the frame pointer. Subtract a value from the stack pointer to allow for the local variables. 函数执行完毕的时候，我们可以观察到：\nThe local variables are located in an area of the call stack – between the addresses in the rsp and rbp registers. The rbp register is a pointer to the bottom (the numerically highest address) of the local variable area. The remaining area of the stack can be accessed using the stack pointer (rsp) as always. 下面的两张图，图8.5是刚进入call执行完头几步之后的栈帧的示意图。图8.6是执行完了leave，正要执行ret的时候的栈，可以看到局部变量都被释放了。可以注意到rbp寄存器的值同样是16的倍数。\n几条新的指令，equ指令，leaq指令，ret指令作用不同：\nret指令相当于pop %rip leaq用于取地址 que相当于给某个地址取名字 需要注意到，C中有两种类型的变量，static和automatic：\natuomatic类型在栈上建立 static程序一致性，该变量就建立了，然后在程序的生命周期一直活着 8.4 本地变量的栈 # ABI规定了本地变量的栈上结构应该符合什么规律：\nEach variable should be aligned on an address that is a multiple of its size. The address in the stack pointer (rsp) should be a multiple of 16 immediately before another function is called. 总之就这两点，具体看ABI。\n8.5-8.6 syscall系统调用和32位程序调用流程 # 本质上没啥变化，就不写了\n第九章：计算 # 9.3.2 机器码格式 # eflags寄存器储存运算的结果。本章基本也属于理解性的东西比较多，唯一一个可能要知道就是编码格式。\n每条指令可以拆分成1-15字节，不同的字节有不同的作用：\nOpcode This is the first byte in the instruction and specifies the basic operation performed by executing the instruction. It can also include operand location. 如果没有prefix那么opecode就是第一个字节，opcode里面实际上也有w位 ModRM The mode/register/memory byte specifies operand locations and how they are accessed. SIB The scale/index/base byte specifies operand locations and how they are accessed. Data These bytes are used to encode constants, either those that are part of the program, or those that are relative address offsets to operand locations in memory. Prefix If placed in before the opcode, these modify the behavior of the instruction, typically the size of the operands. 9.3.3 REX前缀 # 一般不加，加了是为了能够制定用哪个寄存器，使用四位来改变指令，因此REX.R, REX.X, and REX.B bits in the REX prefix byte as the high-order bits for specifying registers. A fourth bit in the REX prefix, the REX.W bit, is set to 1 when the operand is 64 bits. For all other operand sizes — 8, 16, or 32 bits — REX.W is set to 0.\n这里要注意\n3bit的寄存器字段可以出在opcode/modrm/sib字段里，根据指令的不同。 rex bit包括rex.r，rex.x或者rex.b在REX前缀里 如果需要协商rex前缀，那么64位指令的rex.w位必须为1 9.3.4 modrm # 表明操作数和地址的关系，mm都是11的话，那就是两个寄存器，其他情况会变\n9.3.5 SIB # 这个暂时还没看到，先不用着急，等到了13章再回来补上\n总之，机器码看的我很蛋疼。\n第十章流程控制 # 10.1 循环 # cmp指令，根据后面的b,w,l,q来判断后面的两个操作数。执行的操作是减法，只会改变EFLAGS寄存器的值，包括of,sf,zf,af,pf,cf。\ntest指令，根据后面的b,w,l,q来判断后面的两个操作数。执行的操作是bit-wise and 。只会改变EFLAGS寄存器的值，包括sf,zf,pf，cf和of都置为0，AF的值未定义。\njcc指令，cc根据不同的条件变化。这里面有个问题就是：\n比较的时候ja，就是jmp above，jb，就是jmp below也就是两个参与比较的数都是无符号数 比较的时候jg，就是jmp greater，jl，就是jmp below，也就是两个参与比较的数都是有符号数 jmp指令，无条件跳转\nX86_64汇编拓展指令，有两种：\nsign extend，往高位补1，比方说movssd，后面两个字符sd分别表示size of the source operand and d the size of the destination operand ，高位补1 zero extend，往高位补0，比方说movzsd，后面两个字符sd分别表示size of the source operand and d the size of the destination operand ，高位补0 inc指令，根据后面的b,w,l,q判断增加的值。有一点需要注意增加的到底是多少位。另一点是需要注意，一块内存，里面放了目标的地址，我们每次加一，是改变这块内存上面放着的地址的值，每次地址加个一。\n10.2 二元操作 # 二元操作也没啥特别稀奇的，就是流程有点绕，then代码块最后会有个无条件Jmp蹦过else代码块。\n对于复杂一些的逻辑操作，比方说while( value\u0026gt;= 0 \u0026amp;\u0026amp; value \u0026lt; 9)就是比较条件多一些，按照顺序比较，和C语言中比较的流程一致，英文叫做short-circuit evaluation.\nX86_64提供了一个简单的条件赋值语句，cmovcc src, dst。不过我感觉看到的不多啊\n第十一章 # 本章主要是高层语言和汇编语言的实际联系。When one function calls another, the information that is required to provide the interface between the two is called an activation record. 这种调用参数时的传递关系很蛋疼，不过还好X86_64的ABI给出了一整套限制。 In 64-bit mode six of the general purpose registers and a portion of the call stack are used for the activation record. The area of the stack used for the activation record is called a stack frame.\n调用函数（注意区分“被调用函数”）多于六个参数时，用stack frame传递参数 返回地址 调用函数的帧指针 局部变量 常常包含：\n寄存器里参数的拷贝 Copies of values in the registers that must be preserved by a function — rbx, r12 – r15. 除此之外，一些通用规则：\nEach argument is passed within an 8-byte unit. For example, passing three char values requires three registers. This 8-byte rule also applies to arguments passed on the stack. Local variables can be allocated to take up only the amount of memory they require. For example, three char values can be accommodated in a three-byte memory area. The address in the frame pointer (rbp register) must always be a multiple of sixteen. It should never be changed within a function, except during the prologue and epilogue. The address in the stack pointer (rsp register) must always be a multiple of sixteen before transferring program flow to another function. 需要引入一个redzone的概念，The ABI [25] defines the 128 bytes beyond the stack pointer— that is, the 128 bytes at addresses lower than the one in the rsp register — as a red zone. The operating system is not allowed to use this area, so the function can use it for temporary storage of values that do not need to be saved when another function is called.\n11.2 64位参数多于6个 # 多于6个的时候，倒着（参数列表，从右向左）扔进stack，然后一call，这几个参数正好在栈里面返回地址的上面，如上图和下图所示。\n总结起来就是：\n对于调用函数：\nAssume that the values in the rax, rcx, rdx, rsi, rdi and r8 – r11 registers will be changed by the called function. The first six arguments are passed in the rdi, rsi, rdx, rcx, r8, and r9 registers in left-to-right order. Arguments beyond six are stored on the stack as though they had been pushed onto the stack in right-to-left order. Use the call instruction to invoke the function you wish to call. 刚进入被调用函数时：\nSave the caller’s frame pointer by pushing rbp onto the stack Establish a new frame pointer at the current top of stack by copying rsp to rbp. Allocate space on the stack for all the local variables, plus any required register save space, by subtracting the number of bytes required from rsp; this value must be a multiple of sixteen. If a called function changes any of the values in the rbx, rbp, rsp, or r12 – r15 registers, they must be saved in the register save area, then restored before returning to the calling function. If the function calls another function, save the arguments passed in registers on the stack 在被调用函数里面的时候：\nrsp is pointing to the current bottom of the stack that is accessible to this function. Observe the usual stack discipline (see §8.2). In particular, DO NOT use the stack pointer to access arguments or local variables. Arguments passed in registers to the function and saved on the stack are accessed by negative offsets from the frame pointer, rbp. Arguments passed on the stack to the function are accessed by positive offsets from the frame pointer, rbp. Local variables are accessed by negative offsets from the frame pointer, rbp 当离开被调用函数的时候：\nPlace the return value, if any, in eax. Restore the the values in the rbx, rbp, rsp, and r12 – r15 registers from the register save area in the stack frame. Delete the local variable space and register save area by copying rbp to rsp. Restore the caller’s frame pointer by popping rbp off the stack save area. Return to calling function with ret. 补一点内存对齐的内容：\n编译器会尽量避免数据被两次读取，因此会积极主动地采用内存对齐的操作进行执行。原则为两条：\n结构体第一个成员的偏移量（offset）为0，以后每个成员相对于结构体首地址的 offset 都是该成员大小与实际的对齐值\t中较小那个的整数倍，如有需要编译器会在成员之间加上填充字节。 结构体的总大小为 实际的对齐值 的整数倍，如有需要编译器会在最末一个成员之后加上填充字节。 换言之，可以说结果是，下面的说法也不是很对：\n基本类型的对齐值就是其sizeof值 结构体的对齐值是其成员的最大对齐值 编译器可以设置一个对齐值，但是类型的实际对齐值是该类型的对齐值与设定的对齐值取最小值得来。 结构体的成员为数组的时候，计算对齐值是根据数据元素的长度，而不是数组的整体大小 第十二章：位运算，乘法除法 # 12.1-2 逻辑运算 # 几条新指令：\nands，和原先一致s可以是b,w,l,q ors，和原先一致s可以是b,w,l,q xors，和原先一致s可以是b,w,l,q shrs，和原先一致s可以是b,w,l,q。右移，高位补0，低位，或者说被移除的位拷贝到cf里 sars，和原先一致s可以是b,w,l,q。右移，高位补和原先最高位一样的数字，低位，或者说被移除的位拷贝到cf里 shls，和原先一致s可以是b,w,l,q。左移，低位补0，高位，或者说被移除的位拷贝到cf里 sals，和原先一致s可以是b,w,l,q。左移，低位补0，高位，或者说被移除的位拷贝到cf里 12.3 乘法 # 几条新指令：\nmuls，和原先一致s可以是b,w,l,q。unsigned乘法，目的操作数必须在al,ax,eax,rax寄存器里。C语言里面，认为unsigned模式是循环或者说是reduced modulo的 imuls，和原先一致s可以是b,w,l,q。signed乘法，这个的格式很多，有三种imuls source; imuls source,destination;imuls immediate,source,destination; 12.4 除法 # 几条新指令：\ndivs，和原先一致s可以是b,w,l,q。无符号除法，和muls用的操作数都一样的 idivs，和原先一致s可以是b,w,l,q。有符号除法，和muls用的操作数都一样的。可没有imuls那么花里胡哨的 12.6 取补码 # 二进制取补码\nnegs，和原先一致s可以是b,w,l,q。 第十三章：C/C++语言和汇编的转换 # 使用gdb调试的时候，输入layout asm就能一遍调试，一边看asm的代码了\n13.1 部分算数运算的优化和转换 # 13.1.1 乘法 # 13.1.2 除法 # 13.1.2.1 无符号除法的几种形式 # 无符号除法的对应的形式主要有三种，1 除数是2的幂次 2\n代码\n#include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { printf(\u0026#34;argc / 16 = %u\u0026#34;, (unsigned)argc / 16); printf(\u0026#34;argc / 3 = %u\u0026#34;, (unsigned)argc / 3); printf(\u0026#34;argc / 7 = %u\u0026#34;, (unsigned)argc / 7); return 0; } 可以看到，针对2的幂次就是直接右移，针对非2的幂次。除法做了相应的优化，计算出来一个魔数，如果魔术小于四字节整数范围那就直接计算，可是如果超过累四字节，那就\nDump of assembler code for function main:\r0x000055555555464a \u0026lt;+0\u0026gt;:\tpush %rbp\r0x000055555555464b \u0026lt;+1\u0026gt;:\tmov %rsp,%rbp\r=\u0026gt; 0x000055555555464e \u0026lt;+4\u0026gt;:\tsub $0x10,%rsp\r0x0000555555554652 \u0026lt;+8\u0026gt;:\tmov %edi,-0x4(%rbp)\r0x0000555555554655 \u0026lt;+11\u0026gt;:\tmov %rsi,-0x10(%rbp)\r0x0000555555554659 \u0026lt;+15\u0026gt;:\tmov -0x4(%rbp),%eax\r0x000055555555465c \u0026lt;+18\u0026gt;:\tshr $0x4,%eax #对应argc / 16 = %u\r0x000055555555465f \u0026lt;+21\u0026gt;:\tmov %eax,%esi\r0x0000555555554661 \u0026lt;+23\u0026gt;:\tlea 0xec(%rip),%rdi # 0x555555554754\r0x0000555555554668 \u0026lt;+30\u0026gt;:\tmov $0x0,%eax\r0x000055555555466d \u0026lt;+35\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt;\r0x0000555555554672 \u0026lt;+40\u0026gt;:\tmov -0x4(%rbp),%eax\r0x0000555555554675 \u0026lt;+43\u0026gt;:\tmov $0xaaaaaaab,%edx\r0x000055555555467a \u0026lt;+48\u0026gt;:\tmul %edx # argc / 3 的核心，虽然是乘法但是右移以后是除法\r0x000055555555467c \u0026lt;+50\u0026gt;:\tmov %edx,%eax\r0x000055555555467e \u0026lt;+52\u0026gt;:\tshr %eax # short-hand for SAR EAX,1\r0x0000555555554680 \u0026lt;+54\u0026gt;:\tmov %eax,%esi\r0x0000555555554682 \u0026lt;+56\u0026gt;:\tlea 0xda(%rip),%rdi # 0x555555554763\r0x0000555555554689 \u0026lt;+63\u0026gt;:\tmov $0x0,%eax\r0x000055555555468e \u0026lt;+68\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt;\r0x0000555555554693 \u0026lt;+73\u0026gt;:\tmov -0x4(%rbp),%ecx\r0x0000555555554696 \u0026lt;+76\u0026gt;:\tmov $0x24924925,%edx\r0x000055555555469b \u0026lt;+81\u0026gt;:\tmov %ecx,%eax\r0x000055555555469d \u0026lt;+83\u0026gt;:\tmul %edx\r0x000055555555469f \u0026lt;+85\u0026gt;:\tmov %ecx,%eax\r0x00005555555546a1 \u0026lt;+87\u0026gt;:\tsub %edx,%eax\r0x00005555555546a3 \u0026lt;+89\u0026gt;:\tshr %eax\r0x00005555555546a5 \u0026lt;+91\u0026gt;:\tadd %edx,%eax\r0x00005555555546a7 \u0026lt;+93\u0026gt;:\tshr $0x2,%eax\r0x00005555555546aa \u0026lt;+96\u0026gt;:\tmov %eax,%esi\r0x00005555555546ac \u0026lt;+98\u0026gt;:\tlea 0xbe(%rip),%rdi # 0x555555554771\r0x00005555555546b3 \u0026lt;+105\u0026gt;:\tmov $0x0,%eax\r0x00005555555546b8 \u0026lt;+110\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt;\r0x00005555555546bd \u0026lt;+115\u0026gt;:\tmov $0x0,%eax\r0x00005555555546c2 \u0026lt;+120\u0026gt;:\tleaveq\r0x00005555555546c3 \u0026lt;+121\u0026gt;:\tretq\rEnd of assembler dump. 13.1.2.2 有符号除法除数是正数的几种形式 # 对C语言而言，除法规则是向0取整\n#include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argc[]) { printf(\u0026#34;argc / 8 = %d\u0026#34;, argc / 8); printf(\u0026#34;argc / 9 = %d\u0026#34;, argc / 9); printf(\u0026#34;argc / 7 = %d\u0026#34;, argc / 7); return 0; } 可以看到对2的幂次的除法\n(gdb) disass\rDump of assembler code for function main:\r0x000055555555464a \u0026lt;+0\u0026gt;:\tpush %rbp\r0x000055555555464b \u0026lt;+1\u0026gt;:\tmov %rsp,%rbp\r=\u0026gt; 0x000055555555464e \u0026lt;+4\u0026gt;:\tsub $0x10,%rsp\r0x0000555555554652 \u0026lt;+8\u0026gt;:\tmov %edi,-0x4(%rbp)\r0x0000555555554655 \u0026lt;+11\u0026gt;:\tmov %rsi,-0x10(%rbp)\r0x0000555555554659 \u0026lt;+15\u0026gt;:\tmov -0x4(%rbp),%eax\r0x000055555555465c \u0026lt;+18\u0026gt;:\tlea 0x7(%rax),%edx\r0x000055555555465f \u0026lt;+21\u0026gt;:\ttest %eax,%eax # argc / 8\r0x0000555555554661 \u0026lt;+23\u0026gt;:\tcmovs %edx,%eax\r0x0000555555554664 \u0026lt;+26\u0026gt;:\tsar $0x3,%eax\r0x0000555555554667 \u0026lt;+29\u0026gt;:\tmov %eax,%esi\r0x0000555555554669 \u0026lt;+31\u0026gt;:\tlea 0xf4(%rip),%rdi # 0x555555554764\r0x0000555555554670 \u0026lt;+38\u0026gt;:\tmov $0x0,%eax\r0x0000555555554675 \u0026lt;+43\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt;\r0x000055555555467a \u0026lt;+48\u0026gt;:\tmov -0x4(%rbp),%ecx\r0x000055555555467d \u0026lt;+51\u0026gt;:\tmov $0x38e38e39,%edx # argc / 9\r0x0000555555554682 \u0026lt;+56\u0026gt;:\tmov %ecx,%eax\r0x0000555555554684 \u0026lt;+58\u0026gt;:\timul %edx\r0x0000555555554686 \u0026lt;+60\u0026gt;:\tsar %edx\r0x0000555555554688 \u0026lt;+62\u0026gt;:\tmov %ecx,%eax\r0x000055555555468a \u0026lt;+64\u0026gt;:\tsar $0x1f,%eax\r0x000055555555468d \u0026lt;+67\u0026gt;:\tsub %eax,%edx\r0x000055555555468f \u0026lt;+69\u0026gt;:\tmov %edx,%eax\r0x0000555555554691 \u0026lt;+71\u0026gt;:\tmov %eax,%esi\r0x0000555555554693 \u0026lt;+73\u0026gt;:\tlea 0xd8(%rip),%rdi # 0x555555554772\r0x000055555555469a \u0026lt;+80\u0026gt;:\tmov $0x0,%eax\r0x000055555555469f \u0026lt;+85\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt;\r0x00005555555546a4 \u0026lt;+90\u0026gt;:\tmov -0x4(%rbp),%ecx\r0x00005555555546a7 \u0026lt;+93\u0026gt;:\tmov $0x92492493,%edx # argc / 7\r0x00005555555546ac \u0026lt;+98\u0026gt;:\tmov %ecx,%eax\r0x00005555555546ae \u0026lt;+100\u0026gt;:\timul %edx\r0x00005555555546b0 \u0026lt;+102\u0026gt;:\tlea (%rdx,%rcx,1),%eax\r0x00005555555546b3 \u0026lt;+105\u0026gt;:\tsar $0x2,%eax\r0x00005555555546b6 \u0026lt;+108\u0026gt;:\tmov %eax,%edx\r0x00005555555546b8 \u0026lt;+110\u0026gt;:\tmov %ecx,%eax\r0x00005555555546ba \u0026lt;+112\u0026gt;:\tsar $0x1f,%eax\r0x00005555555546bd \u0026lt;+115\u0026gt;:\tsub %eax,%edx\r0x00005555555546bf \u0026lt;+117\u0026gt;:\tmov %edx,%eax\r0x00005555555546c1 \u0026lt;+119\u0026gt;:\tmov %eax,%esi\r0x00005555555546c3 \u0026lt;+121\u0026gt;:\tlea 0xb6(%rip),%rdi # 0x555555554780\r0x00005555555546ca \u0026lt;+128\u0026gt;:\tmov $0x0,%eax\r0x00005555555546cf \u0026lt;+133\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt;\r0x00005555555546d4 \u0026lt;+138\u0026gt;:\tmov $0x0,%eax\r0x00005555555546d9 \u0026lt;+143\u0026gt;:\tleaveq\r0x00005555555546da \u0026lt;+144\u0026gt;:\tretq\rEnd of assembler dump.\r(gdb) 13.1.2.3 有符号除法除数是负数的几种形式 # #include \u0026lt;stdio.h\u0026gt;\rint main(int argc, char* argv[]) {\rprintf(\u0026#34;argc / -4 = %d\u0026#34;, argc / -4);\rprintf(\u0026#34;argc / -5 = %d\u0026#34;, argc / -5);\rprintf(\u0026#34;argc / -7 = %d\u0026#34;, argc / -7);\rreturn 0;\r} (gdb) disass\rDump of assembler code for function main:\r0x000055555555464a \u0026lt;+0\u0026gt;:\tpush %rbp\r0x000055555555464b \u0026lt;+1\u0026gt;:\tmov %rsp,%rbp\r=\u0026gt; 0x000055555555464e \u0026lt;+4\u0026gt;:\tsub $0x10,%rsp\r0x0000555555554652 \u0026lt;+8\u0026gt;:\tmov %edi,-0x4(%rbp)\r0x0000555555554655 \u0026lt;+11\u0026gt;:\tmov %rsi,-0x10(%rbp)\r0x0000555555554659 \u0026lt;+15\u0026gt;:\tmov -0x4(%rbp),%eax\r0x000055555555465c \u0026lt;+18\u0026gt;:\tlea 0x3(%rax),%edx\r0x000055555555465f \u0026lt;+21\u0026gt;:\ttest %eax,%eax\r0x0000555555554661 \u0026lt;+23\u0026gt;:\tcmovs %edx,%eax\r0x0000555555554664 \u0026lt;+26\u0026gt;:\tsar $0x2,%eax\r0x0000555555554667 \u0026lt;+29\u0026gt;:\tneg %eax\r0x0000555555554669 \u0026lt;+31\u0026gt;:\tmov %eax,%esi\r0x000055555555466b \u0026lt;+33\u0026gt;:\tlea 0xf2(%rip),%rdi # 0x555555554764\r0x0000555555554672 \u0026lt;+40\u0026gt;:\tmov $0x0,%eax\r0x0000555555554677 \u0026lt;+45\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt;\r0x000055555555467c \u0026lt;+50\u0026gt;:\tmov -0x4(%rbp),%ecx\r0x000055555555467f \u0026lt;+53\u0026gt;:\tmov $0x66666667,%edx\r0x0000555555554684 \u0026lt;+58\u0026gt;:\tmov %ecx,%eax\r0x0000555555554686 \u0026lt;+60\u0026gt;:\timul %edx\r0x0000555555554688 \u0026lt;+62\u0026gt;:\tmov %edx,%eax\r0x000055555555468a \u0026lt;+64\u0026gt;:\tsar %eax\r0x000055555555468c \u0026lt;+66\u0026gt;:\tsar $0x1f,%ecx\r0x000055555555468f \u0026lt;+69\u0026gt;:\tmov %ecx,%edx\r0x0000555555554691 \u0026lt;+71\u0026gt;:\tsub %eax,%edx\r0x0000555555554693 \u0026lt;+73\u0026gt;:\tmov %edx,%eax\r0x0000555555554695 \u0026lt;+75\u0026gt;:\tmov %eax,%esi\r0x0000555555554697 \u0026lt;+77\u0026gt;:\tlea 0xd5(%rip),%rdi # 0x555555554773\r0x000055555555469e \u0026lt;+84\u0026gt;:\tmov $0x0,%eax\r0x00005555555546a3 \u0026lt;+89\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt;\r0x00005555555546a8 \u0026lt;+94\u0026gt;:\tmov -0x4(%rbp),%ecx\r0x00005555555546ab \u0026lt;+97\u0026gt;:\tmov $0x92492493,%edx\r0x00005555555546b0 \u0026lt;+102\u0026gt;:\tmov %ecx,%eax\r0x00005555555546b2 \u0026lt;+104\u0026gt;:\timul %edx\r0x00005555555546b4 \u0026lt;+106\u0026gt;:\tlea (%rdx,%rcx,1),%eax\r0x00005555555546b7 \u0026lt;+109\u0026gt;:\tsar $0x2,%eax\r0x00005555555546ba \u0026lt;+112\u0026gt;:\tsar $0x1f,%ecx\r0x00005555555546bd \u0026lt;+115\u0026gt;:\tmov %ecx,%edx\r0x00005555555546bf \u0026lt;+117\u0026gt;:\tsub %eax,%edx\r0x00005555555546c1 \u0026lt;+119\u0026gt;:\tmov %edx,%eax\r0x00005555555546c3 \u0026lt;+121\u0026gt;:\tmov %eax,%esi\r0x00005555555546c5 \u0026lt;+123\u0026gt;:\tlea 0xb6(%rip),%rdi # 0x555555554782\r0x00005555555546cc \u0026lt;+130\u0026gt;:\tmov $0x0,%eax\r0x00005555555546d1 \u0026lt;+135\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt;\r0x00005555555546d6 \u0026lt;+140\u0026gt;:\tmov $0x0,%eax\r0x00005555555546db \u0026lt;+145\u0026gt;:\tleaveq\r0x00005555555546dc \u0026lt;+146\u0026gt;:\tretq\rEnd of assembler dump.\r(gdb) 13.2 控制流程的汇编 # 来看一点控制结构的代码，对于if而言，gcc/clang会考虑启用分支预测，这样子命中的情况下不会触发跳转，而没命中触发两次跳转。下面给了一个多个ifelse对比的例子，可以看出来，多个ifelse的语句，会分别根据跳转的情况走到不同的语句块，比方说if命中跳到A，没命中跳到B\n#include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { if (argc \u0026gt; 0) { printf(\u0026#34;argc \u0026gt; 0\u0026#34;); } else if (argc == 0) { printf(\u0026#34;argc == 0\u0026#34;); } else { printf(\u0026#34;argc \u0026lt;= 0\u0026#34;); } return 0; } Dump of assembler code for function main:\r=\u0026gt; 0x0000555555554560 \u0026lt;+0\u0026gt;:\tsub $0x8,%rsp\r0x0000555555554564 \u0026lt;+4\u0026gt;:\tcmp $0x0,%edi\r0x0000555555554567 \u0026lt;+7\u0026gt;:\tjg 0x55555555459a \u0026lt;main+58\u0026gt;\r0x0000555555554569 \u0026lt;+9\u0026gt;:\tje 0x555555554585 \u0026lt;main+37\u0026gt;\r0x000055555555456b \u0026lt;+11\u0026gt;:\tlea 0x1e5(%rip),%rsi # 0x555555554757\r0x0000555555554572 \u0026lt;+18\u0026gt;:\tmov $0x1,%edi\r0x0000555555554577 \u0026lt;+23\u0026gt;:\txor %eax,%eax\r0x0000555555554579 \u0026lt;+25\u0026gt;:\tcallq 0x555555554540 \u0026lt;__printf_chk@plt\u0026gt;\r0x000055555555457e \u0026lt;+30\u0026gt;:\txor %eax,%eax\r0x0000555555554580 \u0026lt;+32\u0026gt;:\tadd $0x8,%rsp\r0x0000555555554584 \u0026lt;+36\u0026gt;:\tretq\r0x0000555555554585 \u0026lt;+37\u0026gt;:\tlea 0x1c1(%rip),%rsi # 0x55555555474d\r0x000055555555458c \u0026lt;+44\u0026gt;:\tmov $0x1,%edi\r0x0000555555554591 \u0026lt;+49\u0026gt;:\txor %eax,%eax\r0x0000555555554593 \u0026lt;+51\u0026gt;:\tcallq 0x555555554540 \u0026lt;__printf_chk@plt\u0026gt;\r0x0000555555554598 \u0026lt;+56\u0026gt;:\tjmp 0x55555555457e \u0026lt;main+30\u0026gt;\r0x000055555555459a \u0026lt;+58\u0026gt;:\tlea 0x1a3(%rip),%rsi # 0x555555554744\r0x00005555555545a1 \u0026lt;+65\u0026gt;:\tmov $0x1,%edi\r0x00005555555545a6 \u0026lt;+70\u0026gt;:\txor %eax,%eax\r0x00005555555545a8 \u0026lt;+72\u0026gt;:\tcallq 0x555555554540 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555545ad \u0026lt;+77\u0026gt;:\tjmp 0x55555555457e \u0026lt;main+30\u0026gt;\rEnd of assembler dump. 和多ifelse的跳转不同，尽管也有好多的比较，switch case看起来就是单纯的比较，跳转到对应的语句块。没命中的话就继续做比较，简单来说就是没命中的情况下，不会\n#include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { int n=1; scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); switch (n) { case 1: printf(\u0026#34;n == 1\u0026#34;); break; case 3: printf(\u0026#34;n == 3\u0026#34;); break; case 100: printf(\u0026#34;n == 100\u0026#34;); break; default: break; } return 0; } (gdb) disass\rDump of assembler code for function main:\r=\u0026gt; 0x0000555555554610 \u0026lt;+0\u0026gt;:\tsub $0x18,%rsp\r0x0000555555554614 \u0026lt;+4\u0026gt;:\tlea 0x229(%rip),%rdi # 0x555555554844\r0x000055555555461b \u0026lt;+11\u0026gt;:\tmov %fs:0x28,%rax\r0x0000555555554624 \u0026lt;+20\u0026gt;:\tmov %rax,0x8(%rsp)\r0x0000555555554629 \u0026lt;+25\u0026gt;:\txor %eax,%eax\r0x000055555555462b \u0026lt;+27\u0026gt;:\tlea 0x4(%rsp),%rsi\r0x0000555555554630 \u0026lt;+32\u0026gt;:\tmovl $0x1,0x4(%rsp)\r0x0000555555554638 \u0026lt;+40\u0026gt;:\tcallq 0x5555555545f0 \u0026lt;scanf@plt\u0026gt;\r0x000055555555463d \u0026lt;+45\u0026gt;:\tmov 0x4(%rsp),%eax\r0x0000555555554641 \u0026lt;+49\u0026gt;:\tcmp $0x3,%eax\r0x0000555555554644 \u0026lt;+52\u0026gt;:\tje 0x555555554691 \u0026lt;main+129\u0026gt;\r0x0000555555554646 \u0026lt;+54\u0026gt;:\tcmp $0x64,%eax\r0x0000555555554649 \u0026lt;+57\u0026gt;:\tje 0x55555555467c \u0026lt;main+108\u0026gt;\r0x000055555555464b \u0026lt;+59\u0026gt;:\tsub $0x1,%eax\r0x000055555555464e \u0026lt;+62\u0026gt;:\tje 0x555555554667 \u0026lt;main+87\u0026gt;\r0x0000555555554650 \u0026lt;+64\u0026gt;:\txor %eax,%eax\r0x0000555555554652 \u0026lt;+66\u0026gt;:\tmov 0x8(%rsp),%rdx\r0x0000555555554657 \u0026lt;+71\u0026gt;:\txor %fs:0x28,%rdx\r0x0000555555554660 \u0026lt;+80\u0026gt;:\tjne 0x5555555546a6 \u0026lt;main+150\u0026gt;\r0x0000555555554662 \u0026lt;+82\u0026gt;:\tadd $0x18,%rsp\r0x0000555555554666 \u0026lt;+86\u0026gt;:\tretq\r0x0000555555554667 \u0026lt;+87\u0026gt;:\tlea 0x1d9(%rip),%rsi # 0x555555554847\r0x000055555555466e \u0026lt;+94\u0026gt;:\tmov $0x1,%edi\r0x0000555555554673 \u0026lt;+99\u0026gt;:\txor %eax,%eax\r0x0000555555554675 \u0026lt;+101\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x000055555555467a \u0026lt;+106\u0026gt;:\tjmp 0x555555554650 \u0026lt;main+64\u0026gt;\r0x000055555555467c \u0026lt;+108\u0026gt;:\tlea 0x1d2(%rip),%rsi # 0x555555554855\r0x0000555555554683 \u0026lt;+115\u0026gt;:\tmov $0x1,%edi\r0x0000555555554688 \u0026lt;+120\u0026gt;:\txor %eax,%eax\r0x000055555555468a \u0026lt;+122\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x000055555555468f \u0026lt;+127\u0026gt;:\tjmp 0x555555554650 \u0026lt;main+64\u0026gt;\r0x0000555555554691 \u0026lt;+129\u0026gt;:\tlea 0x1b6(%rip),%rsi # 0x55555555484e\r0x0000555555554698 \u0026lt;+136\u0026gt;:\tmov $0x1,%edi\r0x000055555555469d \u0026lt;+141\u0026gt;:\txor %eax,%eax\r0x000055555555469f \u0026lt;+143\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555546a4 \u0026lt;+148\u0026gt;:\tjmp 0x555555554650 \u0026lt;main+64\u0026gt;\r0x00005555555546a6 \u0026lt;+150\u0026gt;:\tcallq 0x5555555545d0 \u0026lt;__stack_chk_fail@plt\u0026gt;\rEnd of assembler dump. 对于switch的结构不是有序线性，两个case之间的值差别较大的时候，可以通过建立索引表来做优化\n#include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { int n=1; scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); switch (n) { case 1: printf(\u0026#34;n == 1\u0026#34;); break; case 2: printf(\u0026#34;n == 2\u0026#34;); break; case 3: printf(\u0026#34;n == 3\u0026#34;); break; case 4: printf(\u0026#34;n == 4\u0026#34;); break; case 5: printf(\u0026#34;n == 5\u0026#34;); break; case 6: printf(\u0026#34;n == 6\u0026#34;); break; case 255: printf(\u0026#34;n == 255\u0026#34;); break; } return 0; } Dump of assembler code for function main:\r=\u0026gt; 0x0000555555554610 \u0026lt;+0\u0026gt;:\tsub $0x18,%rsp\r0x0000555555554614 \u0026lt;+4\u0026gt;:\tlea 0x2a9(%rip),%rdi # 0x5555555548c4\r0x000055555555461b \u0026lt;+11\u0026gt;:\tmov %fs:0x28,%rax\r0x0000555555554624 \u0026lt;+20\u0026gt;:\tmov %rax,0x8(%rsp)\r0x0000555555554629 \u0026lt;+25\u0026gt;:\txor %eax,%eax\r0x000055555555462b \u0026lt;+27\u0026gt;:\tlea 0x4(%rsp),%rsi\r0x0000555555554630 \u0026lt;+32\u0026gt;:\tmovl $0x1,0x4(%rsp)\r0x0000555555554638 \u0026lt;+40\u0026gt;:\tcallq 0x5555555545f0 \u0026lt;scanf@plt\u0026gt;\r0x000055555555463d \u0026lt;+45\u0026gt;:\tmov 0x4(%rsp),%eax\r0x0000555555554641 \u0026lt;+49\u0026gt;:\tcmp $0x4,%eax\r0x0000555555554644 \u0026lt;+52\u0026gt;:\tje 0x55555555470b \u0026lt;main+251\u0026gt;\r0x000055555555464a \u0026lt;+58\u0026gt;:\tjle 0x555555554693 \u0026lt;main+131\u0026gt;\r0x000055555555464c \u0026lt;+60\u0026gt;:\tcmp $0x6,%eax\r0x000055555555464f \u0026lt;+63\u0026gt;:\tje 0x5555555546de \u0026lt;main+206\u0026gt;\r0x0000555555554655 \u0026lt;+69\u0026gt;:\tjl 0x5555555546c9 \u0026lt;main+185\u0026gt;\r0x0000555555554657 \u0026lt;+71\u0026gt;:\tcmp $0xff,%eax\r0x000055555555465c \u0026lt;+76\u0026gt;:\tjne 0x555555554678 \u0026lt;main+104\u0026gt;\r0x000055555555465e \u0026lt;+78\u0026gt;:\tlea 0x28c(%rip),%rsi # 0x5555555548f1\r0x0000555555554665 \u0026lt;+85\u0026gt;:\tmov $0x1,%edi\r0x000055555555466a \u0026lt;+90\u0026gt;:\txor %eax,%eax\r0x000055555555466c \u0026lt;+92\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x0000555555554671 \u0026lt;+97\u0026gt;:\tnopl 0x0(%rax)\r0x0000555555554678 \u0026lt;+104\u0026gt;:\txor %eax,%eax\r0x000055555555467a \u0026lt;+106\u0026gt;:\tmov 0x8(%rsp),%rdx\r0x000055555555467f \u0026lt;+111\u0026gt;:\txor %fs:0x28,%rdx\r0x0000555555554688 \u0026lt;+120\u0026gt;:\tjne 0x555555554723 \u0026lt;main+275\u0026gt;\r0x000055555555468e \u0026lt;+126\u0026gt;:\tadd $0x18,%rsp\r0x0000555555554692 \u0026lt;+130\u0026gt;:\tretq\r0x0000555555554693 \u0026lt;+131\u0026gt;:\tcmp $0x2,%eax\r0x0000555555554696 \u0026lt;+134\u0026gt;:\tje 0x5555555546f3 \u0026lt;main+227\u0026gt;\r0x0000555555554698 \u0026lt;+136\u0026gt;:\tjg 0x5555555546b4 \u0026lt;main+164\u0026gt;\r0x000055555555469a \u0026lt;+138\u0026gt;:\tsub $0x1,%eax\r0x000055555555469d \u0026lt;+141\u0026gt;:\tjne 0x555555554678 \u0026lt;main+104\u0026gt;\r0x000055555555469f \u0026lt;+143\u0026gt;:\tlea 0x221(%rip),%rsi # 0x5555555548c7\r0x00005555555546a6 \u0026lt;+150\u0026gt;:\tmov $0x1,%edi\r0x00005555555546ab \u0026lt;+155\u0026gt;:\txor %eax,%eax\r0x00005555555546ad \u0026lt;+157\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555546b2 \u0026lt;+162\u0026gt;:\tjmp 0x555555554678 \u0026lt;main+104\u0026gt;\r0x00005555555546b4 \u0026lt;+164\u0026gt;:\tlea 0x21a(%rip),%rsi # 0x5555555548d5\r0x00005555555546bb \u0026lt;+171\u0026gt;:\tmov $0x1,%edi\r0x00005555555546c0 \u0026lt;+176\u0026gt;:\txor %eax,%eax\r0x00005555555546c2 \u0026lt;+178\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555546c7 \u0026lt;+183\u0026gt;:\tjmp 0x555555554678 \u0026lt;main+104\u0026gt;\r0x00005555555546c9 \u0026lt;+185\u0026gt;:\tlea 0x213(%rip),%rsi # 0x5555555548e3\r0x00005555555546d0 \u0026lt;+192\u0026gt;:\tmov $0x1,%edi\r0x00005555555546d5 \u0026lt;+197\u0026gt;:\txor %eax,%eax\r0x00005555555546d7 \u0026lt;+199\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555546dc \u0026lt;+204\u0026gt;:\tjmp 0x555555554678 \u0026lt;main+104\u0026gt;\r0x00005555555546de \u0026lt;+206\u0026gt;:\tlea 0x205(%rip),%rsi # 0x5555555548ea\r0x00005555555546e5 \u0026lt;+213\u0026gt;:\tmov $0x1,%edi\r0x00005555555546ea \u0026lt;+218\u0026gt;:\txor %eax,%eax\r0x00005555555546ec \u0026lt;+220\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit---\r0x00005555555546f1 \u0026lt;+225\u0026gt;:\tjmp 0x555555554678 \u0026lt;main+104\u0026gt;\r0x00005555555546f3 \u0026lt;+227\u0026gt;:\tlea 0x1d4(%rip),%rsi # 0x5555555548ce\r0x00005555555546fa \u0026lt;+234\u0026gt;:\tmov $0x1,%edi\r0x00005555555546ff \u0026lt;+239\u0026gt;:\txor %eax,%eax\r0x0000555555554701 \u0026lt;+241\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x0000555555554706 \u0026lt;+246\u0026gt;:\tjmpq 0x555555554678 \u0026lt;main+104\u0026gt;\r0x000055555555470b \u0026lt;+251\u0026gt;:\tlea 0x1ca(%rip),%rsi # 0x5555555548dc\r0x0000555555554712 \u0026lt;+258\u0026gt;:\tmov $0x1,%edi\r0x0000555555554717 \u0026lt;+263\u0026gt;:\txor %eax,%eax\r0x0000555555554719 \u0026lt;+265\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x000055555555471e \u0026lt;+270\u0026gt;:\tjmpq 0x555555554678 \u0026lt;main+104\u0026gt;\r0x0000555555554723 \u0026lt;+275\u0026gt;:\tcallq 0x5555555545d0 \u0026lt;__stack_chk_fail@plt\u0026gt;\rEnd of assembler dump. 关于switch还可以使用开启平衡树的结构，来减少比较的次数。\n关于循环结构，do while；while do；for，三种循环都有自己的特点，简单来说。在release模式下，do while没什么变化，而while do会先进行一个if的比较跳转，如果可以直接走就直接走，然后转换为while do的结构；至于for结构也是同样的方法，拆出来初始化阶段，然后把内部结构转换为循环。\n#include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { int i = 0; int sum_i = 0; do { sum_i += i; i++; } while( i \u0026lt;= argc ); printf( \u0026#34;sum_i is %d\u0026#34;, sum_i); int j = 0; int sum_j = 0; while (j \u0026lt;= 2*argc ) { sum_j += j; j++; } printf( \u0026#34;sum_j is %d\u0026#34;, sum_j); int sum_k = 0; for (int k = 0; k \u0026lt; 3*argc; k++) { sum_k += k; } printf( \u0026#34;sum_k is %d\u0026#34;, sum_k); return 0; } Dump of assembler code for function main:\r=\u0026gt; 0x0000555555554560 \u0026lt;+0\u0026gt;:\tpush %rbx\r0x0000555555554561 \u0026lt;+1\u0026gt;:\txor %edx,%edx\r0x0000555555554563 \u0026lt;+3\u0026gt;:\tmov %edi,%ebx\r0x0000555555554565 \u0026lt;+5\u0026gt;:\txor %eax,%eax\r0x0000555555554567 \u0026lt;+7\u0026gt;:\tnopw 0x0(%rax,%rax,1)\r0x0000555555554570 \u0026lt;+16\u0026gt;:\tadd %eax,%edx\r0x0000555555554572 \u0026lt;+18\u0026gt;:\tadd $0x1,%eax\r0x0000555555554575 \u0026lt;+21\u0026gt;:\tcmp %ebx,%eax\r0x0000555555554577 \u0026lt;+23\u0026gt;:\tjle 0x555555554570 \u0026lt;main+16\u0026gt;\r0x0000555555554579 \u0026lt;+25\u0026gt;:\tlea 0x214(%rip),%rsi # 0x555555554794\r0x0000555555554580 \u0026lt;+32\u0026gt;:\txor %eax,%eax\r0x0000555555554582 \u0026lt;+34\u0026gt;:\tmov $0x1,%edi\r0x0000555555554587 \u0026lt;+39\u0026gt;:\tcallq 0x555555554540 \u0026lt;__printf_chk@plt\u0026gt;\r0x000055555555458c \u0026lt;+44\u0026gt;:\tmov %ebx,%ecx\r0x000055555555458e \u0026lt;+46\u0026gt;:\tadd %ecx,%ecx\r0x0000555555554590 \u0026lt;+48\u0026gt;:\tjs 0x5555555545f0 \u0026lt;main+144\u0026gt;\r0x0000555555554592 \u0026lt;+50\u0026gt;:\tadd $0x1,%ecx\r0x0000555555554595 \u0026lt;+53\u0026gt;:\txor %edx,%edx\r0x0000555555554597 \u0026lt;+55\u0026gt;:\txor %eax,%eax\r0x0000555555554599 \u0026lt;+57\u0026gt;:\tnopl 0x0(%rax)\r0x00005555555545a0 \u0026lt;+64\u0026gt;:\tadd %eax,%edx\r0x00005555555545a2 \u0026lt;+66\u0026gt;:\tadd $0x1,%eax\r0x00005555555545a5 \u0026lt;+69\u0026gt;:\tcmp %eax,%ecx\r0x00005555555545a7 \u0026lt;+71\u0026gt;:\tjne 0x5555555545a0 \u0026lt;main+64\u0026gt;\r0x00005555555545a9 \u0026lt;+73\u0026gt;:\tlea 0x1f0(%rip),%rsi # 0x5555555547a0\r0x00005555555545b0 \u0026lt;+80\u0026gt;:\txor %eax,%eax\r0x00005555555545b2 \u0026lt;+82\u0026gt;:\tmov $0x1,%edi\r0x00005555555545b7 \u0026lt;+87\u0026gt;:\tcallq 0x555555554540 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555545bc \u0026lt;+92\u0026gt;:\tlea (%rbx,%rbx,2),%ecx\r0x00005555555545bf \u0026lt;+95\u0026gt;:\ttest %ecx,%ecx\r0x00005555555545c1 \u0026lt;+97\u0026gt;:\tjle 0x5555555545f4 \u0026lt;main+148\u0026gt;\r0x00005555555545c3 \u0026lt;+99\u0026gt;:\txor %eax,%eax\r0x00005555555545c5 \u0026lt;+101\u0026gt;:\txor %edx,%edx\r0x00005555555545c7 \u0026lt;+103\u0026gt;:\tnopw 0x0(%rax,%rax,1)\r0x00005555555545d0 \u0026lt;+112\u0026gt;:\tadd %eax,%edx\r0x00005555555545d2 \u0026lt;+114\u0026gt;:\tadd $0x1,%eax\r0x00005555555545d5 \u0026lt;+117\u0026gt;:\tcmp %eax,%ecx\r0x00005555555545d7 \u0026lt;+119\u0026gt;:\tjne 0x5555555545d0 \u0026lt;main+112\u0026gt;\r0x00005555555545d9 \u0026lt;+121\u0026gt;:\tlea 0x1cc(%rip),%rsi # 0x5555555547ac\r0x00005555555545e0 \u0026lt;+128\u0026gt;:\tmov $0x1,%edi\r0x00005555555545e5 \u0026lt;+133\u0026gt;:\txor %eax,%eax\r0x00005555555545e7 \u0026lt;+135\u0026gt;:\tcallq 0x555555554540 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555545ec \u0026lt;+140\u0026gt;:\txor %eax,%eax\r0x00005555555545ee \u0026lt;+142\u0026gt;:\tpop %rbx\r0x00005555555545ef \u0026lt;+143\u0026gt;:\tretq\r0x00005555555545f0 \u0026lt;+144\u0026gt;:\txor %edx,%edx\r0x00005555555545f2 \u0026lt;+146\u0026gt;:\tjmp 0x5555555545a9 \u0026lt;main+73\u0026gt;\r0x00005555555545f4 \u0026lt;+148\u0026gt;:\txor %edx,%edx\r0x00005555555545f6 \u0026lt;+150\u0026gt;:\tjmp 0x5555555545d9 \u0026lt;main+121\u0026gt;\rEnd of assembler dump.\r(gdb) 13.3 函数的工作原理 # 函数是分析的重点，C/C++里面，函数参数传参顺序为从右向左一次入栈，最先定义参数最后入栈。对于C++有三种调用约定，但是对于X64只有一种，即cdicl，另外Integer arguments are passed in registers RCX, RDX, R8, and R9. Floating point arguments are passed in XMM0L, XMM1L, XMM2L, and XMM3L. 16-byte arguments are passed by reference. Parameter passing is described in detail in Parameter passing. These registers, and RAX, R10, R11, XMM4, and XMM5, are considered volatile, or potentially changed by a callee on return. Register usage is documented in detail in x64 register usage and Caller/callee saved registers.\ncdicl: The parameters are pushed from right to left (so that the first parameter is nearest to top-of-stack), and the caller cleans the parameters. Function names are decorated by a leading underscore. stdcall: This is the calling convention used for Win32, with exceptions for variadic functions (which necessarily use __cdecl) and a very few functions that use __fastcall. Parameters are pushed from right to left [corrected 10:18am] and the callee cleans the stack. Function names are decorated by a leading underscore and a trailing @-sign followed by the number of bytes of parameters taken by the function. fatstcall:The first two parameters are passed in ECX and EDX, with the remainder passed on the stack as in __stdcall. Again, the callee cleans the stack. Function names are decorated by a leading @-sign and a trailing @-sign followed by the number of bytes of parameters taken by the function (including the register parameters). #include \u0026lt;stdio.h\u0026gt; void addNumber(int n1) { n1 += 1; printf(\u0026#34;%d\\n\u0026#34;, n1); } int main(int argc, char* argv[]) { int n = 0; scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); addNumber(n); return 0; } (gdb) disass\rDump of assembler code for function main:\r=\u0026gt; 0x0000555555554610 \u0026lt;+0\u0026gt;:\tsub $0x18,%rsp\r0x0000555555554614 \u0026lt;+4\u0026gt;:\tlea 0x21d(%rip),%rdi # 0x555555554838\r0x000055555555461b \u0026lt;+11\u0026gt;:\tmov %fs:0x28,%rax\r0x0000555555554624 \u0026lt;+20\u0026gt;:\tmov %rax,0x8(%rsp)\r0x0000555555554629 \u0026lt;+25\u0026gt;:\txor %eax,%eax\r0x000055555555462b \u0026lt;+27\u0026gt;:\tlea 0x4(%rsp),%rsi\r0x0000555555554630 \u0026lt;+32\u0026gt;:\tmovl $0x0,0x4(%rsp)\r0x0000555555554638 \u0026lt;+40\u0026gt;:\tcallq 0x5555555545f0 \u0026lt;scanf@plt\u0026gt;\r0x000055555555463d \u0026lt;+45\u0026gt;:\tmov 0x4(%rsp),%eax\r0x0000555555554641 \u0026lt;+49\u0026gt;:\tlea 0x1ec(%rip),%rsi # 0x555555554834\r0x0000555555554648 \u0026lt;+56\u0026gt;:\tmov $0x1,%edi\r0x000055555555464d \u0026lt;+61\u0026gt;:\tlea 0x1(%rax),%edx\r0x0000555555554650 \u0026lt;+64\u0026gt;:\txor %eax,%eax\r0x0000555555554652 \u0026lt;+66\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x0000555555554657 \u0026lt;+71\u0026gt;:\tmov 0x8(%rsp),%rcx\r0x000055555555465c \u0026lt;+76\u0026gt;:\txor %fs:0x28,%rcx\r0x0000555555554665 \u0026lt;+85\u0026gt;:\tjne 0x55555555466e \u0026lt;main+94\u0026gt;\r0x0000555555554667 \u0026lt;+87\u0026gt;:\txor %eax,%eax\r0x0000555555554669 \u0026lt;+89\u0026gt;:\tadd $0x18,%rsp\r0x000055555555466d \u0026lt;+93\u0026gt;:\tretq\r0x000055555555466e \u0026lt;+94\u0026gt;:\tcallq 0x5555555545d0 \u0026lt;__stack_chk_fail@plt\u0026gt;\rEnd of assembler dump.\r(gdb) 再看一个例子\n#include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { int n = 0; scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); char ch = 2; scanf(\u0026#34;%c\u0026#34;, \u0026amp;ch); printf(\u0026#34;%d %c\\n\u0026#34;, n , ch); return 0; } (gdb) disass\rDump of assembler code for function main:\r=\u0026gt; 0x0000555555554610 \u0026lt;+0\u0026gt;:\tsub $0x18,%rsp\r0x0000555555554614 \u0026lt;+4\u0026gt;:\tlea 0x209(%rip),%rdi # 0x555555554824\r0x000055555555461b \u0026lt;+11\u0026gt;:\tmov %fs:0x28,%rax\r0x0000555555554624 \u0026lt;+20\u0026gt;:\tmov %rax,0x8(%rsp)\r0x0000555555554629 \u0026lt;+25\u0026gt;:\txor %eax,%eax\r0x000055555555462b \u0026lt;+27\u0026gt;:\tlea 0x4(%rsp),%rsi\r0x0000555555554630 \u0026lt;+32\u0026gt;:\tmovl $0x0,0x4(%rsp)\r0x0000555555554638 \u0026lt;+40\u0026gt;:\tcallq 0x5555555545f0 \u0026lt;scanf@plt\u0026gt;\r0x000055555555463d \u0026lt;+45\u0026gt;:\tlea 0x3(%rsp),%rsi\r0x0000555555554642 \u0026lt;+50\u0026gt;:\tlea 0x1de(%rip),%rdi # 0x555555554827\r0x0000555555554649 \u0026lt;+57\u0026gt;:\txor %eax,%eax\r0x000055555555464b \u0026lt;+59\u0026gt;:\tmovb $0x2,0x3(%rsp)\r0x0000555555554650 \u0026lt;+64\u0026gt;:\tcallq 0x5555555545f0 \u0026lt;scanf@plt\u0026gt;\r0x0000555555554655 \u0026lt;+69\u0026gt;:\tmovsbl 0x3(%rsp),%ecx\r0x000055555555465a \u0026lt;+74\u0026gt;:\tmov 0x4(%rsp),%edx\r0x000055555555465e \u0026lt;+78\u0026gt;:\tlea 0x1c5(%rip),%rsi # 0x55555555482a\r0x0000555555554665 \u0026lt;+85\u0026gt;:\txor %eax,%eax\r0x0000555555554667 \u0026lt;+87\u0026gt;:\tmov $0x1,%edi\r0x000055555555466c \u0026lt;+92\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x0000555555554671 \u0026lt;+97\u0026gt;:\tmov 0x8(%rsp),%rdx\r0x0000555555554676 \u0026lt;+102\u0026gt;:\txor %fs:0x28,%rdx\r0x000055555555467f \u0026lt;+111\u0026gt;:\tjne 0x555555554688 \u0026lt;main+120\u0026gt;\r0x0000555555554681 \u0026lt;+113\u0026gt;:\txor %eax,%eax\r0x0000555555554683 \u0026lt;+115\u0026gt;:\tadd $0x18,%rsp\r0x0000555555554687 \u0026lt;+119\u0026gt;:\tretq\r0x0000555555554688 \u0026lt;+120\u0026gt;:\tcallq 0x5555555545d0 \u0026lt;__stack_chk_fail@plt\u0026gt;\rEnd of assembler dump.\r(gdb) X64的调用约定，有两种：\nMicrosoft x64 calling convention：The Microsoft x64 calling convention[18][19] is followed on Windows and pre-boot UEFI (for long mode on x86-64). The first four arguments are placed onto the registers. That means RCX, RDX, R8, R9 for integer, struct or pointer arguments (in that order), and XMM0, XMM1, XMM2, XMM3 for floating point arguments. Additional arguments are pushed onto the stack (right to left). Integer return values (similar to x86) are returned in RAX if 64 bits or less. Floating point return values are returned in XMM0. Parameters less than 64 bits long are not zero extended; the high bits are not zeroed.\nStructs and unions with sizes that match integers are passed and returned as if they were integers. Otherwise they are replaced with a pointer when used as an argument. When an oversized struct return is needed, another pointer to a caller-provided space is prepended as the first argument, shifting all other arguments to the right by one place.[20]\nWhen compiling for the x64 architecture in a Windows context (whether using Microsoft or non-Microsoft tools), stdcall, thiscall, cdecl, and fastcall all resolve to using this convention.\nIn the Microsoft x64 calling convention, it is the caller\u0026rsquo;s responsibility to allocate 32 bytes of \u0026ldquo;shadow space\u0026rdquo; on the stack right before calling the function (regardless of the actual number of parameters used), and to pop the stack after the call. The shadow space is used to spill RCX, RDX, R8, and R9,[21] but must be made available to all functions, even those with fewer than four parameters.\nThe registers RAX, RCX, RDX, R8, R9, R10, R11 are considered volatile (caller-saved).[22]\nThe registers RBX, RBP, RDI, RSI, RSP, R12, R13, R14, and R15 are considered nonvolatile (callee-saved).[22]\nFor example, a function taking 5 integer arguments will take the first to fourth in registers, and the fifth will be pushed on top of the shadow space. So when the called function is entered, the stack will be composed of (in ascending order) the return address, followed by the shadow space (32 bytes) followed by the fifth parameter.\nIn x86-64, Visual Studio 2008 stores floating point numbers in XMM6 and XMM7 (as well as XMM8 through XMM15); consequently, for x86-64, user-written assembly language routines must preserve XMM6 and XMM7 (as compared to x86 wherein user-written assembly language routines did not need to preserve XMM6 and XMM7). In other words, user-written assembly language routines must be updated to save/restore XMM6 and XMM7 before/after the function when being ported from x86 to x86-64.\nStarting with Visual Studio 2013, Microsoft introduced the __vectorcall calling convention which extends the x64 convention.\nSystem V AMD64 ABI：The calling convention of the System V AMD64 ABI is followed on Solaris, Linux, FreeBSD, macOS,[23] and is the de facto standard among Unix and Unix-like operating systems. The OpenVMS Calling Standard on x86-64 is based on the System V ABI with some extensions needed for backwards compatibility.[24] The first six integer or pointer arguments are passed in registers RDI, RSI, RDX, RCX, R8, R9 (R10 is used as a static chain pointer in case of nested functions[25]: 21 ), while XMM0, XMM1, XMM2, XMM3, XMM4, XMM5, XMM6 and XMM7 are used for the first floating point arguments.[25]: 22 As in the Microsoft x64 calling convention, additional arguments are passed on the stack.[25]: 22 Integer return values up to 64 bits in size are stored in RAX while values up to 128 bit are stored in RAX and RDX. Floating-point return values are similarly stored in XMM0 and XMM1.[[25]](https://en.wikipedia.org/wiki/X86_calling_conventions#cite_note-AMD-25): 25 The wider YMM and ZMM registers are used for passing and returning wider values in place of XMM when they exist.[[25]](https://en.wikipedia.org/wiki/X86_calling_conventions#cite_note-AMD-25): 26, 55 If the callee wishes to use registers RBX, RSP, RBP, and R12–R15, it must restore their original values before returning control to the caller. All other registers must be saved by the caller if it wishes to preserve their values.[25]: 16 For leaf-node functions (functions which do not call any other function(s)), a 128-byte space is stored just beneath the stack pointer of the function. The space is called the red zone. This zone will not be clobbered by any signal or interrupt handlers. Compilers can thus utilize this zone to save local variables. Compilers may omit some instructions at the starting of the function (adjustment of RSP, RBP) by utilizing this zone. However, other functions may clobber this zone. Therefore, this zone should only be used for leaf-node functions. gcc and clang offer the -mno-red-zone flag to disable red-zone optimizations.\nIf the callee is a variadic function, then the number of floating point arguments passed to the function in vector registers must be provided by the caller in the AL register.[25]: 55 Unlike the Microsoft calling convention, a shadow space is not provided; on function entry, the return address is adjacent to the seventh integer argument on the stack.\n13.4 变量在内存中的位置和访问方式 # 变量有很多种，一种一种看：\n全局变量：在编译链接的时候就确定变量的位置，运行的时候直接使用全局变量的地址进行访问。 全局静态变量：全局静态变量和全局变量是一样的 局部静态变量：局部静态变量和全局静态变量本质没区别，其生命周期和全局变量一样子的，不过有一个地方不一样就是怎么保证只初始化一次呢？实际上是局部静态变量会有一个flag来控制是不是检查过。 堆变量：堆变量是最简单也是最直接的变量了 #include \u0026lt;stdio.h\u0026gt; int g_global = 0x12345678; void showStatic(int n) { static int g_static = n; printf(\u0026#34;%d\\n\u0026#34;, g_static); } int main(int argc, char* argv[]) { for (int i = 0; i \u0026lt; 5 ; ++i) { showStatic(i); } scanf(\u0026#34;%d\u0026#34;, \u0026amp;g_global); printf(\u0026#34;%d\u0026#34;, g_global); return 0; } (gdb) disass\rDump of assembler code for function main:\r=\u0026gt; 0x0000555555554690 \u0026lt;+0\u0026gt;:\tsub $0x8,%rsp\r0x0000555555554694 \u0026lt;+4\u0026gt;:\txor %edi,%edi\r0x0000555555554696 \u0026lt;+6\u0026gt;:\tcallq 0x555555554810 \u0026lt;_Z10showStatici\u0026gt;\r0x000055555555469b \u0026lt;+11\u0026gt;:\tmov $0x1,%edi\r0x00005555555546a0 \u0026lt;+16\u0026gt;:\tcallq 0x555555554810 \u0026lt;_Z10showStatici\u0026gt;\r0x00005555555546a5 \u0026lt;+21\u0026gt;:\tmov $0x2,%edi\r0x00005555555546aa \u0026lt;+26\u0026gt;:\tcallq 0x555555554810 \u0026lt;_Z10showStatici\u0026gt;\r0x00005555555546af \u0026lt;+31\u0026gt;:\tmov $0x3,%edi\r0x00005555555546b4 \u0026lt;+36\u0026gt;:\tcallq 0x555555554810 \u0026lt;_Z10showStatici\u0026gt;\r0x00005555555546b9 \u0026lt;+41\u0026gt;:\tmov $0x4,%edi\r0x00005555555546be \u0026lt;+46\u0026gt;:\tcallq 0x555555554810 \u0026lt;_Z10showStatici\u0026gt;\r0x00005555555546c3 \u0026lt;+51\u0026gt;:\tlea 0x200946(%rip),%rsi # 0x555555755010 \u0026lt;g_global\u0026gt;\r0x00005555555546ca \u0026lt;+58\u0026gt;:\tlea 0x227(%rip),%rdi # 0x5555555548f8\r0x00005555555546d1 \u0026lt;+65\u0026gt;:\txor %eax,%eax\r0x00005555555546d3 \u0026lt;+67\u0026gt;:\tcallq 0x555555554660 \u0026lt;scanf@plt\u0026gt;\r0x00005555555546d8 \u0026lt;+72\u0026gt;:\tmov 0x200932(%rip),%edx # 0x555555755010 \u0026lt;g_global\u0026gt;\r0x00005555555546de \u0026lt;+78\u0026gt;:\tlea 0x213(%rip),%rsi # 0x5555555548f8\r0x00005555555546e5 \u0026lt;+85\u0026gt;:\tmov $0x1,%edi\r0x00005555555546ea \u0026lt;+90\u0026gt;:\txor %eax,%eax\r0x00005555555546ec \u0026lt;+92\u0026gt;:\tcallq 0x555555554640 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555546f1 \u0026lt;+97\u0026gt;:\txor %eax,%eax\r0x00005555555546f3 \u0026lt;+99\u0026gt;:\tadd $0x8,%rsp\r0x00005555555546f7 \u0026lt;+103\u0026gt;:\tretq\rEnd of assembler dump.\r(gdb) ni\r0x0000555555554694 in main ()\r(gdb) ni\r0x0000555555554696 in main ()\r(gdb) si\r0x0000555555554810 in showStatic(int) ()\r(gdb) disass\rDump of assembler code for function _Z10showStatici:\r=\u0026gt; 0x0000555555554810 \u0026lt;+0\u0026gt;:\tpush %rbx\r0x0000555555554811 \u0026lt;+1\u0026gt;:\tmovzbl 0x200808(%rip),%eax # 0x555555755020 \u0026lt;_ZGVZ10showStaticiE8g_static\u0026gt;\r0x0000555555554818 \u0026lt;+8\u0026gt;:\ttest %al,%al\r0x000055555555481a \u0026lt;+10\u0026gt;:\tje 0x555555554840 \u0026lt;_Z10showStatici+48\u0026gt;\r0x000055555555481c \u0026lt;+12\u0026gt;:\tmov 0x200806(%rip),%ebx # 0x555555755028 \u0026lt;_ZZ10showStaticiE8g_static\u0026gt;\r0x0000555555554822 \u0026lt;+18\u0026gt;:\tmov %ebx,%edx\r0x0000555555554824 \u0026lt;+20\u0026gt;:\tlea 0xc9(%rip),%rsi # 0x5555555548f4\r0x000055555555482b \u0026lt;+27\u0026gt;:\tmov $0x1,%edi\r0x0000555555554830 \u0026lt;+32\u0026gt;:\tpop %rbx\r0x0000555555554831 \u0026lt;+33\u0026gt;:\txor %eax,%eax\r0x0000555555554833 \u0026lt;+35\u0026gt;:\tjmpq 0x555555554640 \u0026lt;__printf_chk@plt\u0026gt;\r0x0000555555554838 \u0026lt;+40\u0026gt;:\tnopl 0x0(%rax,%rax,1)\r0x0000555555554840 \u0026lt;+48\u0026gt;:\tmov %edi,%ebx\r0x0000555555554842 \u0026lt;+50\u0026gt;:\tlea 0x2007d7(%rip),%rdi # 0x555555755020 \u0026lt;_ZGVZ10showStaticiE8g_static\u0026gt;\r0x0000555555554849 \u0026lt;+57\u0026gt;:\tcallq 0x555555554670 \u0026lt;__cxa_guard_acquire@plt\u0026gt;\r0x000055555555484e \u0026lt;+62\u0026gt;:\ttest %eax,%eax\r0x0000555555554850 \u0026lt;+64\u0026gt;:\tje 0x55555555481c \u0026lt;_Z10showStatici+12\u0026gt;\r0x0000555555554852 \u0026lt;+66\u0026gt;:\tlea 0x2007c7(%rip),%rdi # 0x555555755020 \u0026lt;_ZGVZ10showStaticiE8g_static\u0026gt;\r0x0000555555554859 \u0026lt;+73\u0026gt;:\tmov %ebx,0x2007c9(%rip) # 0x555555755028 \u0026lt;_ZZ10showStaticiE8g_static\u0026gt;\r0x000055555555485f \u0026lt;+79\u0026gt;:\tcallq 0x555555554650 \u0026lt;__cxa_guard_release@plt\u0026gt;\r0x0000555555554864 \u0026lt;+84\u0026gt;:\tjmp 0x555555554822 \u0026lt;_Z10showStatici+18\u0026gt;\rEnd of assembler dump. 13.5 结构体和类 # C++中的类有各种函数，比方说private/public/protected等，但这些实际上都是编译的时候追究的选项，等到成了汇编的时候就和结构体没什么区别了。这时候有个问题，对象长度应该这么计算呢？这时候有下面三个方面要考虑，除此之外还有就是对象是不是处于全局区等多方面因素\n空类：空类没有数据成员，但可以有函数成员，如果没长度那么没发初始化this指针，其长度为1字节。 内存对齐：实际上有内存对齐的时候这个规则上面就有，具体得看实现编译器的文档了 静态数据成员：静态数据成员实际上是 我们通过下面的例子重点看以下几点：\nthis指针是这么传递和调用的，这点我们看persion的setage函数，通过这个例子我们能明白 结构体作为参数是怎么传递的，我们能够发现对于短的结构体，会直接利用压栈手段把数据结构搞进去，对于长的数据结构会采用数据复制的手段。这里面还有一点要注意，我们的代码里面是没有复制构造函数和移动构造函数的， 结构体作为函数的返回值是这么传递的，编译器会先在栈里面申请出来返回对象的内存空间，然后调用返回对象的函数，该函数会将返回的结构体的内容复制到申请的内存空间，再将对象复制给目标对象。这里面有一个C++生命周期的小坑，为什么临时内存空间要在调用方的帧栈里面呢？想这个情况getPersion().count，如果这个不在调用方里面申请内存，那么这时候这个对象的内存明显就被释放了。这也是为什么C++里面搞出来move语句的原因。这里面还有一点，当对象作为返回值，如果该对象是个局部变量，那么不能返回该对象的首地址或者引用（实际上引用这里就是指针） 这里面有个地方可能会很有意思，编译器要是上了O2优化可能代码不会有那么明显的调用了，看下面的例子，直接就把对象压扁成了普通对象，然后所有的操作都直接对外表现了。\n#include \u0026lt;stdio.h\u0026gt; class Persion { public: void setAge(int age) { this-\u0026gt;age = age; } void showPersion() { printf(\u0026#34;age = %d, height = %d\u0026#34;, age, height); } public: int age; int height; char name[32]; }; void show(Persion persion1, Persion persion2) { printf(\u0026#34;persion 1 age = %d, persion 2 height = %d\u0026#34;,persion1.age, persion2.height ); } Persion getPersoin() { Persion persion; int persion_age = 0; scanf(\u0026#34;%d\u0026#34;, \u0026amp;persion_age); persion.age = persion_age; persion.height = 180; return persion; } int main(int argc, char* argv[]) { Persion persion1; int persion_age = 0; scanf(\u0026#34;%d\u0026#34;, \u0026amp;persion_age); persion1.setAge(persion_age); // 这里的printf的rdi是参数的个数，第二个参数是\u0026#34;Persion : %d \\n\u0026#34;放在了esi里面，然后直接压扁了，可以看到直接就是拿出来 printf(\u0026#34;Persion : %d \\n\u0026#34;, persion1.age); // Persion persion2 = getPersoin(); show(persion1, persion2); persion1.showPersion(); persion2.showPersion(); return 0; } Dump of assembler code for function main:\r0x0000555555554610 \u0026lt;+0\u0026gt;:\tpush %rbp\r0x0000555555554611 \u0026lt;+1\u0026gt;:\tpush %rbx\r0x0000555555554612 \u0026lt;+2\u0026gt;:\tlea 0x331(%rip),%rdi # 0x55555555494a\r0x0000555555554619 \u0026lt;+9\u0026gt;:\tsub $0x18,%rsp\r0x000055555555461d \u0026lt;+13\u0026gt;:\tmov %fs:0x28,%rax\r=\u0026gt; 0x0000555555554626 \u0026lt;+22\u0026gt;:\tmov %rax,0x8(%rsp)\r0x000055555555462b \u0026lt;+27\u0026gt;:\txor %eax,%eax\r0x000055555555462d \u0026lt;+29\u0026gt;:\tmov %rsp,%rsi\r0x0000555555554630 \u0026lt;+32\u0026gt;:\tmovl $0x0,(%rsp)\r0x0000555555554637 \u0026lt;+39\u0026gt;:\tcallq 0x5555555545f0 \u0026lt;scanf@plt\u0026gt;\r0x000055555555463c \u0026lt;+44\u0026gt;:\tmov (%rsp),%ebx\r0x000055555555463f \u0026lt;+47\u0026gt;:\tlea 0x2e2(%rip),%rsi # 0x555555554928\r0x0000555555554646 \u0026lt;+54\u0026gt;:\tmov $0x1,%edi\r0x000055555555464b \u0026lt;+59\u0026gt;:\txor %eax,%eax\r0x000055555555464d \u0026lt;+61\u0026gt;:\tmov %ebx,%edx\r0x000055555555464f \u0026lt;+63\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x0000555555554654 \u0026lt;+68\u0026gt;:\tlea 0x4(%rsp),%rsi\r0x0000555555554659 \u0026lt;+73\u0026gt;:\tlea 0x2ea(%rip),%rdi # 0x55555555494a\r0x0000555555554660 \u0026lt;+80\u0026gt;:\txor %eax,%eax\r0x0000555555554662 \u0026lt;+82\u0026gt;:\tmovl $0x0,0x4(%rsp)\r0x000055555555466a \u0026lt;+90\u0026gt;:\tcallq 0x5555555545f0 \u0026lt;scanf@plt\u0026gt;\r0x000055555555466f \u0026lt;+95\u0026gt;:\tlea 0x282(%rip),%rsi # 0x5555555548f8\r0x0000555555554676 \u0026lt;+102\u0026gt;:\tmov $0xb4,%ecx\r0x000055555555467b \u0026lt;+107\u0026gt;:\tmov %ebx,%edx\r0x000055555555467d \u0026lt;+109\u0026gt;:\tmov $0x1,%edi\r0x0000555555554682 \u0026lt;+114\u0026gt;:\txor %eax,%eax\r0x0000555555554684 \u0026lt;+116\u0026gt;:\tmov 0x4(%rsp),%ebp\r0x0000555555554688 \u0026lt;+120\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x000055555555468d \u0026lt;+125\u0026gt;:\tlea 0x2a3(%rip),%rsi # 0x555555554937\r0x0000555555554694 \u0026lt;+132\u0026gt;:\txor %ecx,%ecx\r0x0000555555554696 \u0026lt;+134\u0026gt;:\tmov %ebx,%edx\r0x0000555555554698 \u0026lt;+136\u0026gt;:\tmov $0x1,%edi\r0x000055555555469d \u0026lt;+141\u0026gt;:\txor %eax,%eax\r0x000055555555469f \u0026lt;+143\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555546a4 \u0026lt;+148\u0026gt;:\tlea 0x28c(%rip),%rsi # 0x555555554937\r0x00005555555546ab \u0026lt;+155\u0026gt;:\tmov %ebp,%edx\r0x00005555555546ad \u0026lt;+157\u0026gt;:\txor %eax,%eax\r0x00005555555546af \u0026lt;+159\u0026gt;:\tmov $0xb4,%ecx\r0x00005555555546b4 \u0026lt;+164\u0026gt;:\tmov $0x1,%edi\r0x00005555555546b9 \u0026lt;+169\u0026gt;:\tcallq 0x5555555545e0 \u0026lt;__printf_chk@plt\u0026gt;\r0x00005555555546be \u0026lt;+174\u0026gt;:\tmov 0x8(%rsp),%rdx\r0x00005555555546c3 \u0026lt;+179\u0026gt;:\txor %fs:0x28,%rdx\r0x00005555555546cc \u0026lt;+188\u0026gt;:\tjne 0x5555555546d7 \u0026lt;main+199\u0026gt;\r0x00005555555546ce \u0026lt;+190\u0026gt;:\tadd $0x18,%rsp\r0x00005555555546d2 \u0026lt;+194\u0026gt;:\txor %eax,%eax\r0x00005555555546d4 \u0026lt;+196\u0026gt;:\tpop %rbx\r0x00005555555546d5 \u0026lt;+197\u0026gt;:\tpop %rbp\r0x00005555555546d6 \u0026lt;+198\u0026gt;:\tretq\r0x00005555555546d7 \u0026lt;+199\u0026gt;:\tcallq 0x5555555545d0 \u0026lt;__stack_chk_fail@plt\u0026gt;\rEnd of assembler dump. 我们来看一个简单版本的，sizeof string = 32，这里面实际上有个点可能需要注意到就是string的结构到底是什么？\ntemplate \u0026lt;typename T\u0026gt; struct basic_string { char* begin_; size_t size_; union { size_t capacity_; char sso_buffer[16]; }; }; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; class Persion { public: void setAge(int age) { age_ = age; } int getAge() { return age_; } void setName(std::string name){ name_ = name; } void showPersion() { printf(\u0026#34;age = %d, height = %d\u0026#34;, age_, height_); std::cout \u0026lt;\u0026lt;\u0026#34; persion name is \u0026#34; \u0026lt;\u0026lt; name_; } public: int age_; int height_; std::string name_; }; Persion getPersoin() { Persion persion; int persion_age = 0; scanf(\u0026#34;%d\u0026#34;, \u0026amp;persion_age); persion.setAge(persion_age); std::string commonName=\u0026#34;hello,world\u0026#34;; persion.setName(commonName); return persion; } int main(int argc, char* argv[]) { Persion persion = getPersoin(); persion.showPersion(); return 0; } (gdb) disass\rDump of assembler code for function main:\r=\u0026gt; 0x0000555555554b70 \u0026lt;+0\u0026gt;:\tpush %rbp\r0x0000555555554b71 \u0026lt;+1\u0026gt;:\tpush %rbx\r0x0000555555554b72 \u0026lt;+2\u0026gt;:\tsub $0x38,%rsp\r0x0000555555554b76 \u0026lt;+6\u0026gt;:\tmov %rsp,%rbx\r0x0000555555554b79 \u0026lt;+9\u0026gt;:\tmov %rbx,%rdi\r0x0000555555554b7c \u0026lt;+12\u0026gt;:\tmov %fs:0x28,%rax\r0x0000555555554b85 \u0026lt;+21\u0026gt;:\tmov %rax,0x28(%rsp)\r0x0000555555554b8a \u0026lt;+26\u0026gt;:\txor %eax,%eax\r0x0000555555554b8c \u0026lt;+28\u0026gt;:\tcallq 0x555555554e40 \u0026lt;_Z10getPersoinv\u0026gt;\r0x0000555555554b91 \u0026lt;+33\u0026gt;:\tmov 0x4(%rsp),%ecx\r0x0000555555554b95 \u0026lt;+37\u0026gt;:\tmov (%rsp),%edx\r0x0000555555554b98 \u0026lt;+40\u0026gt;:\tlea 0x4a5(%rip),%rsi # 0x555555555044\r0x0000555555554b9f \u0026lt;+47\u0026gt;:\tmov $0x1,%edi\r0x0000555555554ba4 \u0026lt;+52\u0026gt;:\txor %eax,%eax\r0x0000555555554ba6 \u0026lt;+54\u0026gt;:\tcallq 0x555555554aa0 \u0026lt;__printf_chk@plt\u0026gt;\r0x0000555555554bab \u0026lt;+59\u0026gt;:\tlea 0x4a8(%rip),%rsi # 0x55555555505a\r0x0000555555554bb2 \u0026lt;+66\u0026gt;:\tlea 0x201467(%rip),%rdi # 0x555555756020 \u0026lt;_ZSt4cout@@GLIBCXX_3.4\u0026gt;\r0x0000555555554bb9 \u0026lt;+73\u0026gt;:\tmov $0x11,%edx\r0x0000555555554bbe \u0026lt;+78\u0026gt;:\tcallq 0x555555554b10 \u0026lt;_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l@plt\u0026gt;\r0x0000555555554bc3 \u0026lt;+83\u0026gt;:\tmov 0x10(%rsp),%rdx\r0x0000555555554bc8 \u0026lt;+88\u0026gt;:\tmov 0x8(%rsp),%rsi\r0x0000555555554bcd \u0026lt;+93\u0026gt;:\tlea 0x20144c(%rip),%rdi # 0x555555756020 \u0026lt;_ZSt4cout@@GLIBCXX_3.4\u0026gt;\r0x0000555555554bd4 \u0026lt;+100\u0026gt;:\tcallq 0x555555554b10 \u0026lt;_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l@plt\u0026gt;\r0x0000555555554bd9 \u0026lt;+105\u0026gt;:\tmov 0x8(%rsp),%rdi\r0x0000555555554bde \u0026lt;+110\u0026gt;:\tadd $0x18,%rbx\r0x0000555555554be2 \u0026lt;+114\u0026gt;:\tcmp %rbx,%rdi\r0x0000555555554be5 \u0026lt;+117\u0026gt;:\tje 0x555555554bec \u0026lt;main+124\u0026gt;\r0x0000555555554be7 \u0026lt;+119\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554bec \u0026lt;+124\u0026gt;:\txor %eax,%eax\r0x0000555555554bee \u0026lt;+126\u0026gt;:\tmov 0x28(%rsp),%rcx\r0x0000555555554bf3 \u0026lt;+131\u0026gt;:\txor %fs:0x28,%rcx\r0x0000555555554bfc \u0026lt;+140\u0026gt;:\tjne 0x555555554c05 \u0026lt;main+149\u0026gt;\r0x0000555555554bfe \u0026lt;+142\u0026gt;:\tadd $0x38,%rsp\r0x0000555555554c02 \u0026lt;+146\u0026gt;:\tpop %rbx\r0x0000555555554c03 \u0026lt;+147\u0026gt;:\tpop %rbp\r0x0000555555554c04 \u0026lt;+148\u0026gt;:\tretq\r0x0000555555554c05 \u0026lt;+149\u0026gt;:\tcallq 0x555555554b00 \u0026lt;__stack_chk_fail@plt\u0026gt;\r0x0000555555554c0a \u0026lt;+154\u0026gt;:\tmov 0x8(%rsp),%rdi\r0x0000555555554c0f \u0026lt;+159\u0026gt;:\tadd $0x18,%rbx\r0x0000555555554c13 \u0026lt;+163\u0026gt;:\tmov %rax,%rbp\r0x0000555555554c16 \u0026lt;+166\u0026gt;:\tcmp %rbx,%rdi\r0x0000555555554c19 \u0026lt;+169\u0026gt;:\tje 0x555555554c20 \u0026lt;main+176\u0026gt;\r0x0000555555554c1b \u0026lt;+171\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554c20 \u0026lt;+176\u0026gt;:\tmov %rbp,%rdi\r0x0000555555554c23 \u0026lt;+179\u0026gt;:\tcallq 0x555555554b40 \u0026lt;_Unwind_Resume@plt\u0026gt;\rEnd of assembler dump.\r(gdb) 我们来看一个完整的保存了结构体的复杂版本的，\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; class Persion { public: void setAge(int age) { age_ = age; } int getAge() { return age_; } void setName(std::string name){ name_ = name; } void showPersion() { printf(\u0026#34;age = %d, height = %d\u0026#34;, age_, height_); std::cout \u0026lt;\u0026lt;\u0026#34; persion name is \u0026#34; \u0026lt;\u0026lt; name_; } public: int age_; int height_; std::string name_; }; void show(Persion persion1, Persion persion2) { printf(\u0026#34;persion 1 age = %d, persion 2 height = %d\u0026#34;,persion1.getAge(), persion2.getAge() ); } Persion getPersoin() { Persion persion; int persion_age = 0; scanf(\u0026#34;%d\u0026#34;, \u0026amp;persion_age); persion.setAge(persion_age); std::string commonName=\u0026#34;hello,world\u0026#34;; persion.setName(commonName); return persion; } int main(int argc, char* argv[]) { Persion persion1; int persion_age = 0; scanf(\u0026#34;%d\u0026#34;, \u0026amp;persion_age); persion1.setAge(persion_age); Persion persion2 = getPersoin(); show(persion1, persion2); persion1.showPersion(); persion2.showPersion(); return 0; } Dump of assembler code for function main:\r=\u0026gt; 0x0000555555554b70 \u0026lt;+0\u0026gt;:\tpush %r14\r0x0000555555554b72 \u0026lt;+2\u0026gt;:\tpush %r13\r0x0000555555554b74 \u0026lt;+4\u0026gt;:\tlea 0x6b0(%rip),%rdi # 0x55555555522b\r0x0000555555554b7b \u0026lt;+11\u0026gt;:\tpush %r12\r0x0000555555554b7d \u0026lt;+13\u0026gt;:\tpush %rbp\r0x0000555555554b7e \u0026lt;+14\u0026gt;:\tpush %rbx\r0x0000555555554b7f \u0026lt;+15\u0026gt;:\tsub $0xd0,%rsp\r0x0000555555554b86 \u0026lt;+22\u0026gt;:\tlea 0x10(%rsp),%rbx\r0x0000555555554b8b \u0026lt;+27\u0026gt;:\tlea 0xc(%rsp),%rsi\r0x0000555555554b90 \u0026lt;+32\u0026gt;:\tmovq $0x0,0x20(%rsp)\r0x0000555555554b99 \u0026lt;+41\u0026gt;:\tmov %fs:0x28,%rax\r0x0000555555554ba2 \u0026lt;+50\u0026gt;:\tmov %rax,0xc8(%rsp)\r0x0000555555554baa \u0026lt;+58\u0026gt;:\txor %eax,%eax\r0x0000555555554bac \u0026lt;+60\u0026gt;:\tlea 0x18(%rbx),%rax\r0x0000555555554bb0 \u0026lt;+64\u0026gt;:\tmovb $0x0,0x28(%rsp)\r0x0000555555554bb5 \u0026lt;+69\u0026gt;:\tmovl $0x0,0xc(%rsp)\r0x0000555555554bbd \u0026lt;+77\u0026gt;:\tmov %rax,0x18(%rsp)\r0x0000555555554bc2 \u0026lt;+82\u0026gt;:\txor %eax,%eax\r0x0000555555554bc4 \u0026lt;+84\u0026gt;:\tcallq 0x555555554b20 \u0026lt;scanf@plt\u0026gt;\r0x0000555555554bc9 \u0026lt;+89\u0026gt;:\tmov 0xc(%rsp),%eax\r0x0000555555554bcd \u0026lt;+93\u0026gt;:\tlea 0x40(%rsp),%rbp\r0x0000555555554bd2 \u0026lt;+98\u0026gt;:\tmov %rbp,%rdi\r0x0000555555554bd5 \u0026lt;+101\u0026gt;:\tmov %eax,0x10(%rsp)\r0x0000555555554bd9 \u0026lt;+105\u0026gt;:\tcallq 0x555555554fa0 \u0026lt;_Z10getPersoinv\u0026gt;\r0x0000555555554bde \u0026lt;+110\u0026gt;:\tmov 0x40(%rsp),%eax\r0x0000555555554be2 \u0026lt;+114\u0026gt;:\tlea 0xa0(%rsp),%r12\r0x0000555555554bea \u0026lt;+122\u0026gt;:\tmov 0x48(%rsp),%rsi\r0x0000555555554bef \u0026lt;+127\u0026gt;:\tmov 0x50(%rsp),%rdx\r0x0000555555554bf4 \u0026lt;+132\u0026gt;:\tlea 0x8(%r12),%rdi\r0x0000555555554bf9 \u0026lt;+137\u0026gt;:\tmov %eax,0xa0(%rsp)\r0x0000555555554c00 \u0026lt;+144\u0026gt;:\tmov 0x44(%rsp),%eax\r0x0000555555554c04 \u0026lt;+148\u0026gt;:\tadd %rsi,%rdx\r0x0000555555554c07 \u0026lt;+151\u0026gt;:\tmov %eax,0xa4(%rsp)\r0x0000555555554c0e \u0026lt;+158\u0026gt;:\tlea 0x18(%r12),%rax\r0x0000555555554c13 \u0026lt;+163\u0026gt;:\tmov %rax,0xa8(%rsp)\r0x0000555555554c1b \u0026lt;+171\u0026gt;:\tcallq 0x555555554eb0 \u0026lt;_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12_M_constructIPcEEvT_S7_St20forward_iterator_tag.isra.27\u0026gt;\r0x0000555555554c20 \u0026lt;+176\u0026gt;:\tmov 0x10(%rsp),%eax\r0x0000555555554c24 \u0026lt;+180\u0026gt;:\tlea 0x70(%rsp),%r13\r0x0000555555554c29 \u0026lt;+185\u0026gt;:\tmov 0x18(%rsp),%rsi\r0x0000555555554c2e \u0026lt;+190\u0026gt;:\tmov 0x20(%rsp),%rdx\r0x0000555555554c33 \u0026lt;+195\u0026gt;:\tlea 0x8(%r13),%rdi\r0x0000555555554c37 \u0026lt;+199\u0026gt;:\tmov %eax,0x70(%rsp)\r0x0000555555554c3b \u0026lt;+203\u0026gt;:\tmov 0x14(%rsp),%eax\r0x0000555555554c3f \u0026lt;+207\u0026gt;:\tadd %rsi,%rdx\r0x0000555555554c42 \u0026lt;+210\u0026gt;:\tmov %eax,0x74(%rsp)\r0x0000555555554c46 \u0026lt;+214\u0026gt;:\tlea 0x18(%r13),%rax\r0x0000555555554c4a \u0026lt;+218\u0026gt;:\tmov %rax,0x78(%rsp)\r0x0000555555554c4f \u0026lt;+223\u0026gt;:\tcallq 0x555555554eb0 \u0026lt;_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12_M_constructIPcEEvT_S7_St20forward_iterator_tag.isra.27\u0026gt;\r0x0000555555554c54 \u0026lt;+228\u0026gt;:\tmov 0xa0(%rsp),%ecx\r0x0000555555554c5b \u0026lt;+235\u0026gt;:\tmov 0x70(%rsp),%edx\r0x0000555555554c5f \u0026lt;+239\u0026gt;:\tlea 0x582(%rip),%rsi # 0x5555555551e8\r0x0000555555554c66 \u0026lt;+246\u0026gt;:\tmov $0x1,%edi\r0x0000555555554c6b \u0026lt;+251\u0026gt;:\txor %eax,%eax\r0x0000555555554c6d \u0026lt;+253\u0026gt;:\tcallq 0x555555554aa0 \u0026lt;__printf_chk@plt\u0026gt;\r0x0000555555554c72 \u0026lt;+258\u0026gt;:\tmov 0x78(%rsp),%rdi\r0x0000555555554c77 \u0026lt;+263\u0026gt;:\tadd $0x18,%r13\r0x0000555555554c7b \u0026lt;+267\u0026gt;:\tcmp %r13,%rdi\r0x0000555555554c7e \u0026lt;+270\u0026gt;:\tje 0x555555554c85 \u0026lt;main+277\u0026gt;\r0x0000555555554c80 \u0026lt;+272\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554c85 \u0026lt;+277\u0026gt;:\tmov 0xa8(%rsp),%rdi\r0x0000555555554c8d \u0026lt;+285\u0026gt;:\tadd $0x18,%r12\r0x0000555555554c91 \u0026lt;+289\u0026gt;:\tcmp %r12,%rdi\r0x0000555555554c94 \u0026lt;+292\u0026gt;:\tje 0x555555554c9b \u0026lt;main+299\u0026gt;\r0x0000555555554c96 \u0026lt;+294\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554c9b \u0026lt;+299\u0026gt;:\tmov %rbx,%rdi\r0x0000555555554c9e \u0026lt;+302\u0026gt;:\tcallq 0x5555555550e0 \u0026lt;_ZN7Persion11showPersionEv\u0026gt;\r0x0000555555554ca3 \u0026lt;+307\u0026gt;:\tmov %rbp,%rdi\r0x0000555555554ca6 \u0026lt;+310\u0026gt;:\tcallq 0x5555555550e0 \u0026lt;_ZN7Persion11showPersionEv\u0026gt;\r0x0000555555554cab \u0026lt;+315\u0026gt;:\tmov 0x48(%rsp),%rdi\r0x0000555555554cb0 \u0026lt;+320\u0026gt;:\tadd $0x18,%rbp\r0x0000555555554cb4 \u0026lt;+324\u0026gt;:\tcmp %rbp,%rdi\r0x0000555555554cb7 \u0026lt;+327\u0026gt;:\tje 0x555555554cbe \u0026lt;main+334\u0026gt;\r0x0000555555554cb9 \u0026lt;+329\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554cbe \u0026lt;+334\u0026gt;:\tmov 0x18(%rsp),%rdi\r0x0000555555554cc3 \u0026lt;+339\u0026gt;:\tadd $0x18,%rbx\r0x0000555555554cc7 \u0026lt;+343\u0026gt;:\tcmp %rbx,%rdi\r0x0000555555554cca \u0026lt;+346\u0026gt;:\tje 0x555555554cd1 \u0026lt;main+353\u0026gt;\r0x0000555555554ccc \u0026lt;+348\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554cd1 \u0026lt;+353\u0026gt;:\txor %eax,%eax\r0x0000555555554cd3 \u0026lt;+355\u0026gt;:\tmov 0xc8(%rsp),%rcx\r0x0000555555554cdb \u0026lt;+363\u0026gt;:\txor %fs:0x28,%rcx\r0x0000555555554ce4 \u0026lt;+372\u0026gt;:\tjne 0x555555554cf6 \u0026lt;main+390\u0026gt;\r0x0000555555554ce6 \u0026lt;+374\u0026gt;:\tadd $0xd0,%rsp\r0x0000555555554ced \u0026lt;+381\u0026gt;:\tpop %rbx\r0x0000555555554cee \u0026lt;+382\u0026gt;:\tpop %rbp\r0x0000555555554cef \u0026lt;+383\u0026gt;:\tpop %r12\r0x0000555555554cf1 \u0026lt;+385\u0026gt;:\tpop %r13\r0x0000555555554cf3 \u0026lt;+387\u0026gt;:\tpop %r14\r0x0000555555554cf5 \u0026lt;+389\u0026gt;:\tretq\r0x0000555555554cf6 \u0026lt;+390\u0026gt;:\tcallq 0x555555554b00 \u0026lt;__stack_chk_fail@plt\u0026gt;\r0x0000555555554cfb \u0026lt;+395\u0026gt;:\tmov 0x78(%rsp),%rdi\r0x0000555555554d00 \u0026lt;+400\u0026gt;:\tadd $0x18,%r13\r0x0000555555554d04 \u0026lt;+404\u0026gt;:\tmov %rax,%r14\r0x0000555555554d07 \u0026lt;+407\u0026gt;:\tcmp %r13,%rdi\r0x0000555555554d0a \u0026lt;+410\u0026gt;:\tje 0x555555554d11 \u0026lt;main+417\u0026gt;\r0x0000555555554d0c \u0026lt;+412\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554d11 \u0026lt;+417\u0026gt;:\tmov %r14,%r13\r0x0000555555554d14 \u0026lt;+420\u0026gt;:\tmov 0xa8(%rsp),%rdi\r0x0000555555554d1c \u0026lt;+428\u0026gt;:\tadd $0x18,%r12\r0x0000555555554d20 \u0026lt;+432\u0026gt;:\tcmp %r12,%rdi\r0x0000555555554d23 \u0026lt;+435\u0026gt;:\tje 0x555555554d2a \u0026lt;main+442\u0026gt;\r0x0000555555554d25 \u0026lt;+437\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554d2a \u0026lt;+442\u0026gt;:\tmov %r13,%r12\r0x0000555555554d2d \u0026lt;+445\u0026gt;:\tmov 0x48(%rsp),%rdi\r0x0000555555554d32 \u0026lt;+450\u0026gt;:\tadd $0x18,%rbp\r0x0000555555554d36 \u0026lt;+454\u0026gt;:\tcmp %rbp,%rdi\r0x0000555555554d39 \u0026lt;+457\u0026gt;:\tje 0x555555554d40 \u0026lt;main+464\u0026gt;\r0x0000555555554d3b \u0026lt;+459\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554d40 \u0026lt;+464\u0026gt;:\tmov 0x18(%rsp),%rdi\r0x0000555555554d45 \u0026lt;+469\u0026gt;:\tadd $0x18,%rbx\r0x0000555555554d49 \u0026lt;+473\u0026gt;:\tcmp %rbx,%rdi\r0x0000555555554d4c \u0026lt;+476\u0026gt;:\tje 0x555555554d53 \u0026lt;main+483\u0026gt;\r0x0000555555554d4e \u0026lt;+478\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555554d53 \u0026lt;+483\u0026gt;:\tmov %r12,%rdi\r0x0000555555554d56 \u0026lt;+486\u0026gt;:\tcallq 0x555555554b40 \u0026lt;_Unwind_Resume@plt\u0026gt;\r0x0000555555554d5b \u0026lt;+491\u0026gt;:\tmov %rax,%r13\r0x0000555555554d5e \u0026lt;+494\u0026gt;:\tjmp 0x555555554d14 \u0026lt;main+420\u0026gt;\r0x0000555555554d60 \u0026lt;+496\u0026gt;:\tmov %rax,%r12\r0x0000555555554d63 \u0026lt;+499\u0026gt;:\tjmp 0x555555554d2d \u0026lt;main+445\u0026gt;\r0x0000555555554d65 \u0026lt;+501\u0026gt;:\tmov %rax,%r12\r0x0000555555554d68 \u0026lt;+504\u0026gt;:\tjmp 0x555555554d40 \u0026lt;main+464\u0026gt;\rEnd of assembler dump.\r(gdb)\rDump of assembler code for function _Z10getPersoinv:\r=\u0026gt; 0x0000555555554fa0 \u0026lt;+0\u0026gt;:\tpush %r14\r0x0000555555554fa2 \u0026lt;+2\u0026gt;:\tpush %r13\r0x0000555555554fa4 \u0026lt;+4\u0026gt;:\tlea 0x18(%rdi),%r13\r0x0000555555554fa8 \u0026lt;+8\u0026gt;:\tpush %r12\r0x0000555555554faa \u0026lt;+10\u0026gt;:\tpush %rbp\r0x0000555555554fab \u0026lt;+11\u0026gt;:\tpush %rbx\r0x0000555555554fac \u0026lt;+12\u0026gt;:\tmov %rdi,%rbx\r0x0000555555554faf \u0026lt;+15\u0026gt;:\tsub $0x60,%rsp\r0x0000555555554fb3 \u0026lt;+19\u0026gt;:\tmov %r13,0x8(%rdi)\r0x0000555555554fb7 \u0026lt;+23\u0026gt;:\tmovq $0x0,0x10(%rdi)\r0x0000555555554fbf \u0026lt;+31\u0026gt;:\tmovb $0x0,0x18(%rdi)\r0x0000555555554fc3 \u0026lt;+35\u0026gt;:\tlea 0xc(%rsp),%rsi\r0x0000555555554fc8 \u0026lt;+40\u0026gt;:\tlea 0x25c(%rip),%rdi # 0x55555555522b\r0x0000555555554fcf \u0026lt;+47\u0026gt;:\tmov %fs:0x28,%rax\r0x0000555555554fd8 \u0026lt;+56\u0026gt;:\tmov %rax,0x58(%rsp)\r0x0000555555554fdd \u0026lt;+61\u0026gt;:\txor %eax,%eax\r0x0000555555554fdf \u0026lt;+63\u0026gt;:\tmovl $0x0,0xc(%rsp)\r0x0000555555554fe7 \u0026lt;+71\u0026gt;:\tcallq 0x555555554b20 \u0026lt;scanf@plt\u0026gt;\r0x0000555555554fec \u0026lt;+76\u0026gt;:\tmov 0xc(%rsp),%eax\r0x0000555555554ff0 \u0026lt;+80\u0026gt;:\tlea 0x10(%rsp),%r12\r0x0000555555554ff5 \u0026lt;+85\u0026gt;:\tlea 0x24f(%rip),%rdx # 0x55555555524b\r0x0000555555554ffc \u0026lt;+92\u0026gt;:\tlea -0xb(%rdx),%rsi\r0x0000555555555000 \u0026lt;+96\u0026gt;:\tmov %r12,%rdi\r0x0000555555555003 \u0026lt;+99\u0026gt;:\tmov %eax,(%rbx)\r0x0000555555555005 \u0026lt;+101\u0026gt;:\tlea 0x10(%r12),%rax\r0x000055555555500a \u0026lt;+106\u0026gt;:\tmov %rax,0x10(%rsp)\r0x000055555555500f \u0026lt;+111\u0026gt;:\tcallq 0x555555554eb0 \u0026lt;_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12_M_constructIPcEEvT_S7_St20forward_iterator_tag.isra.27\u0026gt;\r0x0000555555555014 \u0026lt;+116\u0026gt;:\tlea 0x30(%rsp),%rbp\r0x0000555555555019 \u0026lt;+121\u0026gt;:\tmov 0x10(%rsp),%rsi\r0x000055555555501e \u0026lt;+126\u0026gt;:\tmov 0x18(%rsp),%rdx\r0x0000555555555023 \u0026lt;+131\u0026gt;:\tlea 0x10(%rbp),%rax\r0x0000555555555027 \u0026lt;+135\u0026gt;:\tmov %rbp,%rdi\r0x000055555555502a \u0026lt;+138\u0026gt;:\tadd %rsi,%rdx\r0x000055555555502d \u0026lt;+141\u0026gt;:\tmov %rax,0x30(%rsp)\r0x0000555555555032 \u0026lt;+146\u0026gt;:\tcallq 0x555555554eb0 \u0026lt;_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12_M_constructIPcEEvT_S7_St20forward_iterator_tag.isra.27\u0026gt;\r0x0000555555555037 \u0026lt;+151\u0026gt;:\tlea 0x8(%rbx),%rdi\r0x000055555555503b \u0026lt;+155\u0026gt;:\tmov %rbp,%rsi\r0x000055555555503e \u0026lt;+158\u0026gt;:\tcallq 0x555555554ab0 \u0026lt;_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE9_M_assignERKS4_@plt\u0026gt;\r0x0000555555555043 \u0026lt;+163\u0026gt;:\tmov 0x30(%rsp),%rdi\r0x0000555555555048 \u0026lt;+168\u0026gt;:\tadd $0x10,%rbp\r0x000055555555504c \u0026lt;+172\u0026gt;:\tcmp %rbp,%rdi\r0x000055555555504f \u0026lt;+175\u0026gt;:\tje 0x555555555056 \u0026lt;_Z10getPersoinv+182\u0026gt;\r0x0000555555555051 \u0026lt;+177\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555555056 \u0026lt;+182\u0026gt;:\tmov 0x10(%rsp),%rdi\r0x000055555555505b \u0026lt;+187\u0026gt;:\tadd $0x10,%r12\r0x000055555555505f \u0026lt;+191\u0026gt;:\tcmp %r12,%rdi\r0x0000555555555062 \u0026lt;+194\u0026gt;:\tje 0x555555555069 \u0026lt;_Z10getPersoinv+201\u0026gt;\r0x0000555555555064 \u0026lt;+196\u0026gt;:\tcallq 0x555555554af0 \u0026lt;_ZdlPv@plt\u0026gt;\r0x0000555555555069 \u0026lt;+201\u0026gt;:\tmov 0x58(%rsp),%rcx\r0x000055555555506e \u0026lt;+206\u0026gt;:\txor %fs:0x28,%rcx\r0x0000555555555077 \u0026lt;+215\u0026gt;:\tmov %rbx,%rax\r0x000055555555507a \u0026lt;+218\u0026gt;:\tjne 0x555555555089 \u0026lt;_Z10getPersoinv+233\u0026gt;\r0x000055555555507c \u0026lt;+220\u0026gt;:\tadd $0x60,%rsp\r0x0000555555555080 \u0026lt;+224\u0026gt;:\tpop %rbx\r0x0000555555555081 \u0026lt;+225\u0026gt;:\tpop %rbp\r0x0000555555555082 \u0026lt;+226\u0026gt;:\tpop %r12\r0x0000555555555084 \u0026lt;+228\u0026gt;:\tpop %r13\r0x0000555555555086 \u0026lt;+230\u0026gt;:\tpop %r14\r0x0000555555555088 \u0026lt;+232\u0026gt;:\tretq 13.6 构造函数和析构函数 # 13.7 虚函数 # 13.8 类的关系 # 一些代码范例 # (gdb) b main Breakpoint 1 at 0x55555555464e (gdb) r Starting program: /home/qcraft/code_test/ass_c++/a.out Breakpoint 1, 0x000055555555464e in main () (gdb) disass Dump of assembler code for function main: 0x000055555555464a \u0026lt;+0\u0026gt;:\tpush %rbp 0x000055555555464b \u0026lt;+1\u0026gt;:\tmov %rsp,%rbp =\u0026gt; 0x000055555555464e \u0026lt;+4\u0026gt;:\tsub $0x20,%rsp 0x0000555555554652 \u0026lt;+8\u0026gt;:\tmov %edi,-0x14(%rbp) 0x0000555555554655 \u0026lt;+11\u0026gt;:\tmov %rsi,-0x20(%rbp) 0x0000555555554659 \u0026lt;+15\u0026gt;:\tcvtsi2ssl -0x14(%rbp),%xmm0 0x000055555555465e \u0026lt;+20\u0026gt;:\tmovss %xmm0,-0x4(%rbp) 0x0000555555554663 \u0026lt;+25\u0026gt;:\tcvtss2sd -0x4(%rbp),%xmm0 0x0000555555554668 \u0026lt;+30\u0026gt;:\tlea 0xc5(%rip),%rdi # 0x555555554734 0x000055555555466f \u0026lt;+37\u0026gt;:\tmov $0x1,%eax 0x0000555555554674 \u0026lt;+42\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt; 0x0000555555554679 \u0026lt;+47\u0026gt;:\tmovss -0x4(%rbp),%xmm0 0x000055555555467e \u0026lt;+52\u0026gt;:\tcvttss2si %xmm0,%eax 0x0000555555554682 \u0026lt;+56\u0026gt;:\tmov %eax,-0x14(%rbp) 0x0000555555554685 \u0026lt;+59\u0026gt;:\tmov -0x14(%rbp),%eax 0x0000555555554688 \u0026lt;+62\u0026gt;:\tmov %eax,%esi 0x000055555555468a \u0026lt;+64\u0026gt;:\tlea 0xa6(%rip),%rdi # 0x555555554737 0x0000555555554691 \u0026lt;+71\u0026gt;:\tmov $0x0,%eax 0x0000555555554696 \u0026lt;+76\u0026gt;:\tcallq 0x555555554520 \u0026lt;printf@plt\u0026gt; 0x000055555555469b \u0026lt;+81\u0026gt;:\tmov $0x0,%eax 0x00005555555546a0 \u0026lt;+86\u0026gt;:\tleaveq 0x00005555555546a1 \u0026lt;+87\u0026gt;:\tretq End of assembler dump. (gdb) shell cat test.cpp #include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { float f = (float)argc; printf(\u0026#34;%f\u0026#34;, f); argc = (int)f; printf(\u0026#34;%d\u0026#34;, argc); return 0; } (gdb) 14 linux 二进制分析学习 # 15 linux kernel mod and code protect # 15.1 lkm # Refer to https://xcellerator.github.io/posts/linux_rootkits_01/\n结尾 # 唉，尴尬\n","date":"2021 年 1 月 31 日","externalUrl":null,"permalink":"/posts/2021-01-31-%E6%B1%87%E7%BC%96%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"","title":"汇编笔记","type":"posts"},{"content":" 代码整洁之道 # 行百里者半九十，但是到五十的时候就发现，有很多的地方是要提前注意到的。\n大狗的代码规范： # 命名规则1，函数/变量命名应当名副其实，在提供尽量短，尽量精确的同时，避免使用任何的混义词。对于函数，动作最好保持在最前面，且使用和老代码一致的含义。 函数规则1，函数的应当提供流程上相同层面的抽象，不同层面的抽象应当隐藏到函数里面的函数去。每个函数应当尽量短于100行。除此之外，函数内部实现的时候也应该操作同层级的对象，而不应该将不同层级的对象混淆。函数的编写者应当提供一种，暴露行为，隐藏数据的函数抽象。非常具体，告诉改了什么操作的函数是在函数内部，给抽象层级更高的函数使用的操作。 函数规则2，函数应当尽量简洁，重复代码抽象，使用包了一层的异常处理做失败检查和清理操作。 第一章：整洁代码 # 总结起来是写代码的总览三条：\n能通过所有测试； 没有重复代码； 体现系统中的全部设计理念； 包括尽量少的实体， 比如类、 方法、 函数等。 第二章：命名 # 如何命名变量函数？\n名副其实：代码/变量的名字应当说明大部分问题，它是干什么的，它坐了什么事情，应该怎么用。比方说list就不如server_list，4不如定义一个对象cell[marked]更具体 避免误导：将变量的抽象结构和具体结构区分开，比方说你实现的是set的功能，用的是list的数据结构，那么不要命名为list。还有个例子，比方说“l”和“1”长得很像。 参数名应当可以精确区分：比方说有一个Product类，然后有一个ProductInfo类和ProductData类，那么名字不一样，但是却没法区分这些。再比方说Variable如此的粗糙，变量，什么变量？ 使用可读的人话：getymdhms(生成年月日时分秒)，就远不如genDateAndTime好，不要用那种给非人看的代码 放弃该死的前缀吧 避免灵机一动的命名，避免思维映射：如果某个东西有专有领域的命名，用它用它用它，不要犹豫换个通俗易懂的名字，完全没有必要。如果有 对于某个类的名词，既然是对象就用名词，不要用动词：实际上可以类比，对数据做保护，对数据做封装，别对动作做保护/封装。 对于函数的命名，应当动作提前，尽量避免出现语义不明的new初始化等之类 统一概念，每个概念用一个词，比方说ADD就是添加，那么ADD应该一直是添加，而不该是两个求和。 不要在名字里面添加没用的语境。对于地址而言，address明显就是具体的地址。而NetAddress冥想就不如URL，尽量短，尽量有效话，尽量精确。 第三章：函数 # 如何将函数缩短？\n函数行数应当少于100行 函数应当每次只做一件事：每个函数实际上可以分解为，为了XXX，干YYY。利用这种方式，将相同层侧的抽象提取出来，然后组织为第一层。 每个函数一个抽象层级。自顶向下读代码： 向下规则 函数参数应当尽量少，尽量将参数减少到三元以内。一部分情况下，一元函数的对象可以是event(事件)等参数，但是总而言之，不要传入BOOL类型的变量做参数，因为TRUE和FALSE是一个非常令人迷惑的标识，不如在确定TRUE/FALSE之后调用不同的函数。当参数的个数超过三个的时候，就需要将参数封装为类了。=有点类似TLS自动机里面的SESSION查询那块= 数据传送对象:这个本来是第六章的内容，我直接挪过来了。 函数的名字应当尽可能简单清晰，比方说writeField(name)能清晰的让人理解写name字段的值，就比write(name)好 无副作用，函数应当只提供代码承诺的服务，应当避免任何未承诺的服务，对比到自动机，比方说函数内部命名是message_certficate_hello，然后内部却修改了sslp-\u0026gt;sstate。这就是非常典型的副作用 分隔指令和询问，换言之不要让一个动词set的意思和seted一样，令人混淆，不过这个我觉得还好 使用异常处理来做清理操作，而不是用返回值，因为返回值会将事情搞复杂。实际上这个就类似平时代码里面的goto:clean_up。 异常处理外面包一层，这样子不会破坏异常处理的结构 结构化编程：尽量让大函数有一个统一的入口和出口，不要直接返回，类比例子是你优化之前的handle_file_sync_cmd，糟糕的流程，随时都可能返回。最后改成了统一入口和出口。 不断检查和取消重复：没有谁能写出来完美的程序，不断尝试抽象和提取，不断检查，提取重复代码。 第四章：注释 # 第五章：格式 # 没啥好说的，一直的代码风格就成\n第六章：对象和数据结构 # 我们提供的对象和具体的对象并不一样，比方说一个车的类，和具体的汽车并不一致，我们将汽车的属性隐藏到了车这个类的里面。 著名的得墨忒耳律（The Law of Demeter）认为， 模块不应了解它所操作对象的内部情形。换言之，类C的方法f只应该调用一下对象的方法：C，由f创建的对象，作为参数传递给f的对象，由C的实体变量持有的对象。 火车失事问题：这种问题常常是因为引入了一连串的方法，就类似火车前进，这种代码是的某个具体的函数知道了当前ctxt对象拥有的属性和结构，想想看一个高抽象层面的函数了解了一大堆细节，这合适吗？还是那句话，层级干层级的事情 Options opts = ctxt.getOptions(); File scratchDir = opts.getScratchDir(); final String outputDir = scratchDir.getAbsolutePath(); 另一种混杂不是函数内部操作不同层级对象的问题了，另一种是将对象和数据结构混杂在一起。 第七章：错误处理 # 使用统一的异常处理，而不是分开写，这样子能使代码简洁很多 第八章：边界 # 第十章：类 # SRP，单一权责原则，类或模块应有且只有一条加以修改的理由。如果改代码的时候发现有两个修改理由，说明改继续抽象了 内聚：类应该只有少量实体变量，类中的每个方法都应该操作一个或多个这种变量。如果大部分的实体变量没用到，很可能你应该单独抽取这些变量到别的类型了。 为了修改而组织，减少之间的依赖 DIP原则，类应当依赖于抽象，而不是代码 第十一章：系统 # 这章可以说是屠龙只技，为什么要看这个？因为打算重构certm的代码和逻辑。命名和函数角度的整洁属于低层次抽象，同样需要关注高层次抽象。\n将系统的构造和使用区分开，起始过程的逻辑和起始过程之后的运行时逻辑应当拆分开。 结尾 # 唉，尴尬\n","date":"2021 年 1 月 28 日","externalUrl":null,"permalink":"/posts/2021-01-28-%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"","title":"代码整洁之道","type":"posts"},{"content":"","date":"2021 年 1 月 26 日","externalUrl":null,"permalink":"/tags/lock/","section":"Tags","summary":"","title":"Lock","type":"tags"},{"content":" 多处理编程的艺术 # 这本书我估计得看两遍，第一遍看算法/理论，第二遍看一遍证明。\n锁/同步常用检测思维： # 如何保证互斥？ 如何保证公平性？简单来说，锁的先后顺序保证就是公平 如何保证不会饿死？ 如何保证不会出现唤醒丢失/虚假唤醒？如果检测是否需要睡眠，和正式进入睡眠不是一步，一般就需要防备唤醒丢失。防备唤醒丢失的方法还是，使用锁来保证“同步”的线程不会出现同时执行交互的操作（同步的概念看第十章的开头）。虚假唤醒是指当醒过来的时候发现条件不满足(阅读第八章)，因此需要多次检测条件(条件变量)是否满足 锁/同步设计常用思路： # 对于相同(原子)变量的操作常常是导致性能消耗的关键，因此想办法将同样一个（原子）变量，拆分为属于不同部分的操作，见第十章对于有限同步队列最后 的点评与操作。除此之外，对同一事物的竞争是导致性能消耗的关键第十章的双数数据结构提供了一种保护操作。 除了对相同（原子）变量的操作导致性能消耗，另一方面，强行要求指令线性执行，而不是并发执行也会导致性能不高，对于这种问题： 具体见例子第十一章的11.3节：之所以无锁栈性能不好，不是因为top产生了竞争，而是因为强制要求线性并发，不能多个同时burst，这种加个缓冲垫的想法是非常常见且有效的。一个更具体的例子是： 这两条具体的理念看第十二章的12.2节，再看看合并树的操作。总而言之，尽量避免memory contention\u0026mdash;多个线程同时访问相同的内存地址和尽量实现real parallelism， 无锁操作实现的关键往往是有每个前提保证的，就以第十章的无锁队列实现为例，每一步都要求保证当前操作的节点是最后的节点！设计无锁的数据结构建议看第十章无锁队列 第一章 introduction # 第二章 互斥锁 # 2.1-2.5 互斥锁的几个例子 # 两种简单的锁，这两种锁各有各的缺点，但是相互补足了对面：一种锁的驱动机制会导致另一种锁卡住\npertson锁，结合了两种锁的优点\nfilter锁，适合多个线程，结合了多个线程的特点，有两个可以保证：\n总会有某个线程进入第l层成功。 倘若有多个线程想进入第l层，那么至少会有一个线程被阻塞。 1\tclass Filter implements Lock { 2 int[] level; 3 int[] victim; 4 public Filter(int n) { 5 level = new int[n]; 6 victim = new int[n]; // use 1..n-1 7 for (int i = 0; i \u0026lt; n; i++) { 8 level[i] = 0; 9 } 10 } 11 public void lock() { 12 int me = ThreadID.get(); 13 for (int i = 1; i \u0026lt; n; i++) { // attempt to enter level i 14 level[me] = i; 15 victim[i] = me; 16 // spin while conflicts exist 17 while ((∃k != me) (level[k] \u0026gt;= i \u0026amp;\u0026amp; victim[i] == me)) {}; 18 } 19 } 20 public void unlock() { 21 int me = ThreadID.get(); 22 level[me] = 0; 23 } 24 } 2.6-2.8 贝克算法和label有序性的理解 # 公正性，将锁分成doorway section核waiting section。\n兰博贝克算法，贝克算法要求后来的线程拿到的label必须是更大的。\n1 class Bakery implements Lock { 2 boolean[] flag; 3 Label[] label; 4 public Bakery (int n) { 5 flag = new boolean[n]; 6 label = new Label[n]; 7 for (int i = 0; i \u0026lt; n; i++) { 8 flag[i] = false; label[i] = 0; 9\t} 10 } 11 public void lock() { 12 int i = ThreadID.get(); 13 flag[i] = true; 14 label[i] = max(label[0], ...,label[n-1]) + 1; 15 while ((∃k != i)(flag[k] \u0026amp;\u0026amp; (label[k],k) \u0026lt;\u0026lt; (label[i],i))) {}; 16 } 17 public void unlock() { 18 flag[ThreadID.get()] = false; 19 } 20 } 实际上就是个单调的线性 (label[i], i) \u0026lt;\u0026lt; (label[j], j)) if and only if label[i] \u0026lt; label[j] or label[i] = label[j] and i \u0026lt; j. 接下来提出了有向图的概念，a-\u0026gt;b的意思是a晚于b发生。对于两个线程，我们只需要设置三个token的图，如图2.13s所示，既能保证他们是有序的。为了能够解决多线程的复杂情况，使用有向图来表示，提出下面的说法，实际上H也是图：\nWe say that A dominates B in G if every node of A has edges directed to every node of B. G ◦ H 就是graph multiplication ，Replace every node v of G by a copy of H (denoted Hv), and let Hv dominate Hu in G ◦ H if v dominates u in G. 这里所谓的图的替代，是指直接全替代代表一个节点？ 对于label算法的理解：理解n个线程的label算法的关键是token代表的节点从来都是有序构成一个环，而不会出现不知道label相互竞争的情况。对两个线程而言，之所以两个线程不会出现label的竞争是因为T2的最短路径里要求三个节点。这部分建议直接看中文第一版的《多处理器编程的艺术》。这部分没看的特别明白需要重看。\n下面是一些要注意到的名词：\nDirected graph 有向图 Precedence graph 前趋图 irreflexive 自反关系：对自己是不成立的 antisymmetric 反对称关系 transitive 传递关系 trivial 容易得，不费力得 safety properties 不可进入非法状态 liveness properties运行状态中会达到的糟糕状态，只能找维基百科的说法 safety properties informally require that \u0026ldquo;something bad will never happen\u0026rdquo; 2.9 基于读/写操作的锁的不足 # Is there a clever Lock algorithm based on reading and writing memory that avoids this overhead? We now demonstrate that the answer is no. 为什么不能呢？因为如果多个线程同时读写，那么他们的结果可能在看到之前就被别的线程改写了。所以必须需要N个地方，换言之每个线程只能改自己的 A Lock object state s is inconsistent in any global state where some thread is in the critical section, but the lock state is compatible with a global state in which no thread is in the critical section or is trying to enter the critical section. 这里实际上实说，互斥的锁必然是状态一致的，不一致会导致互斥失败 第三章 并发编程 # 这一章是帮助理解什么是顺序一致性的，但是感觉读起来很蛋疼。这里面实际上有一个问题，怎么判断一个数据结构是不是满足线程安全呢？\n3.0-3.3一个反直觉但正确的顺序一致性 # sequential consistency 顺序一致性，这个由下面两个定理定义。我们当然想要求real time order，但这里的sequential consistency并不保持real-time order，它并不要求要求不同线程之间存在的一种顺序，使得一个fifo的dequeue和enqueue是正确的。换言之，这种顺序一致性只是保证了一个线程内的程序调用顺序和代码顺序是一致的，这并不违背我们按照《A primer xxx》给出的顺序一致性。建议直接看这个问题：https://stackoverflow.com/questions/19209274/example-of-execution-which-is-sequentially-consistent-but-not-quiescently-consis\nPrinciple 3.3.1. Method calls should appear to happen in a one-at-a-time, sequential order. 这个只要求一个接一个.\nPrinciple 3.3.2. Method calls should appear to take effect in program order. 程序的调用顺序应该和代码的执行顺序是一致的，而且应当符合我们的预期。\n顺序一致性并不是阻塞的，这句话有点令人感觉蛋疼，和工业也不相符。\n这里引入了一个复合的概念，每个个体满足p，如果全体也满足p那么就说p这个条件是复合的。但是对于SC则不满足这一点具体的例子见P57，这东西违背了顺序一致性，因为它自己构成了一个循环\n3.4-3.5 线性一致性和静态一致性 # 这个东西就比刚才那个更符合人类的想法了。\nPrinciple 3.4.1. Each method call should appear to take effect instantaneously at some moment between its invocation and response. 就是可以将真正执行的时候，看成一个时刻，这个时刻在call发生和response返回之间。这就是线性一致性 Principle 3.5.1. Method calls separated by a period of quiescence should appear to take effect in their real-time order. 严格按照发生时刻的顺序执行，这个就是静态一致性 3.6 线性一致性的正式定义 # 非常恶心，非常非常恶心，不说人话的典型，锁的理论表达，包括下面几章等以后再看吧。\n第七章 自旋锁和竞争 # 这章实际上需要理解的就是锁的有序性，我们只要保证锁的获取是有序的，不会出现多个进入，那么就满足了互斥。然后只要不断将等待时间乘以二，那么就可以减少同时的争用。先进先出属于OPTIONAL的选项。\n7.1-7.4 几种不同的锁 # TAS锁，TTAS锁，回退锁，为什么性能不一致？实际上是因为TAS锁竞争的时候对于缓存要求太高，经常要求使得其他的缓存无效，TTAS只要求GetS操作，不会强行同步总线和缓存。回退锁是减少了竞争的发生，实际上就是让出来临界区。实际上这东西提供了我们三个东西：\n代码层面我们认为逻辑一致性的东西，已经在一定程度上避免了问题的出现，但是这种层面只是问题设计的第一层面 因为代码是需要跑的，所以在实现的时候不但要考虑上层层面，还要考虑底层层面的实现，对锁而言就是缓存协议，同步等的代价 最后一个就是要养成一个从上向下，看到底层的习惯了。还得尝试提出，实现方面的抽象。 TAS锁：\n1 public class TASLock implements Lock { 2 AtomicBoolean state = new AtomicBoolean(false); 3 public void lock() { 4 while (state.getAndSet(true)) {} 5 } 6 public void unlock() { 7 state.set(false); 8 } 9 } TTAS锁：\n1 public class TTASLock implements Lock { 2 AtomicBoolean state = new AtomicBoolean(false); 3 public void lock() { 4 while (true) { 5 while (state.get()) {}; 6 if (!state.getAndSet(true)) 7 return; 8 } 9 } 10 public void unlock() { 11 state.set(false); 12 } 13 } 回退锁：\n1 public class Backoff { 2 final int minDelay, maxDelay; 3 int limit; 4 public Backoff(int min, int max) { 5 minDelay = min; 6 maxDelay = max; 7 limit = minDelay; 8 } 9 public void backoff() throws InterruptedException { 10 int delay = ThreadLocalRandom.current().nextInt(limit); 11 limit = Math.min(maxDelay, 2 * limit); 12 Thread.sleep(delay); 13 } 14 } 1 public class BackoffLock implements Lock { 2 private AtomicBoolean state = new AtomicBoolean(false); 3 private static final int MIN_DELAY = ...; 4 private static final int MAX_DELAY = ...; 5 public void lock() { 6 Backoff backoff = new Backoff(MIN_DELAY, MAX_DELAY); 7 while (true) { 8 while (state.get()) {}; 9 if (!state.getAndSet(true)) { 10 return; 11 } else { 12 backoff.backoff(); 13 } 14 } 15 } 16 public void unlock() { 17 state.set(false); 18 } 19 ... 20 } 7.5 基于队列的锁 # 7.5.1 基于数组的锁 # 基于数组的队列锁，tail是原子变量，保证每个线程都不会取到一样的值。每个flag[slot]为true代表锁可用，而flag[slot]为false代表不可用。因为使用了共享的一个数组，让多个线程不会在同一个地方产生竞争，因为可以提供竞争较少的服务。但是如果发生了高速缓存伪共享，(也就是说，不同内存块的内容被缓存到同一块缓存行上，不同的CPU对同一块缓存行的独写，注意这个不是同一个地址的独写，会导致高速缓存频繁的换入换出)同样会导致竞争激烈。因此如果把指针转动的幅度变大，就可以有效避免高速缓存伪共享的问题。\n这东西我感觉像是一个表盘，转到谁就代表谁可以写数据，这个锁的传递是释放的时候传递的。但是有个问题如果最后又重新转到了头部，那么就会出现同时有两个线程获得锁了，这很糟糕。下面还是从三个层面来考虑：\nFIFO，是的，这个锁是FIFO的 会饿死吗？不会，只要能排上号的线程，最后都是会转到的 1 public class ALock implements Lock { 2 ThreadLocal\u0026lt;Integer\u0026gt; mySlotIndex = new ThreadLocal\u0026lt;Integer\u0026gt; (){ 3 protected Integer initialValue() { 4 return 0; 5 } 6 }; 7 AtomicInteger tail; 8 volatile boolean[] flag; 9 int size; 10 public ALock(int capacity) { 11 size = capacity; 12 tail = new AtomicInteger(0); 13 flag = new boolean[capacity]; 14 flag[0] = true; 15 } 16 public void lock() { 17 int slot = tail.getAndIncrement() % size; 18 mySlotIndex.set(slot); 19 while (!flag[slot]) {}; 20 } 21 public void unlock() { 22 int slot = mySlotIndex.get(); 23 flag[slot] = false; 24 flag[(slot + 1) % size] = true; 25 } 26 } 7.5.2 基于CLH队列的锁 # 这个不如叫做链表锁吧，这个东西的有序是用链表的getAndSet保证的，因为要求锁的传递。这个东西对NUMA不友好，因为每个线程判断是不是可以上锁的时候都是要看前面的缓存块是不是锁住的。我们看看这个锁提供的特性\n饿死，不会饿死 FIFO，确实FIFO 1 public class CLHLock implements Lock { 2 AtomicReference\u0026lt;QNode\u0026gt; tail; 3 ThreadLocal\u0026lt;QNode\u0026gt; myPred; 4 ThreadLocal\u0026lt;QNode\u0026gt; myNode; 5 public CLHLock() { 6 tail = new AtomicReference\u0026lt;QNode\u0026gt;(new QNode()); 7 myNode = new ThreadLocal\u0026lt;QNode\u0026gt;() { 8 protected QNode initialValue() { 9 return new QNode(); 10 } 11 }; 12 myPred = new ThreadLocal\u0026lt;QNode\u0026gt;() { 13 protected QNode initialValue() { 14 return null; 15 } 16 }; 17 } 18 public void lock() { 19 QNode qnode = myNode.get(); 20 qnode.locked = true; 21 QNode pred = tail.getAndSet(qnode); 22 myPred.set(pred); 23 while (pred.locked) {} 24 } 25 public void unlock() { 26 QNode qnode = myNode.get(); 27 qnode.locked = false; 28 myNode.set(myPred.get()); 29 } 30 class QNode { 31 volatile boolean locked = false; 32 } 33 } 7.5.3 MCS队列锁 # 这个锁不一样的地方是，每个线程看是否执行都是看自己控制的对象，所以每个对象都必须等待前面的对象释放掉自己。由于只有一个tail是可以原子CompareAndSet的，所以在unlokc的时候需要用tail这个fast path来等待slow path也就是后面的节点和前面节点挂起来的操作。这个锁和CLH锁相比，优点相同，但是因为检查的是本地的内存，所以对NUMA更友好。\n1 public class MCSLock implements Lock { 2 AtomicReference\u0026lt;QNode\u0026gt; tail; 3 ThreadLocal\u0026lt;QNode\u0026gt; myNode; 4 public MCSLock() { 5 tail = new AtomicReference\u0026lt;QNode\u0026gt;(null); 6 myNode = new ThreadLocal\u0026lt;QNode\u0026gt;() { 7 protected QNode initialValue() { 8 return new QNode(); 9 } 10 }; 11 } 12 public void lock() { 13 QNode qnode = myNode.get(); 14 QNode pred = tail.getAndSet(qnode); 15 if (pred != null) { 16 qnode.locked = true; 17 pred.next = qnode; 18 // wait until predecessor gives up the lock 19 while (qnode.locked) {} 20 } 21 } 22 public void unlock() { 23 QNode qnode = myNode.get(); 24 if (qnode.next == null) { 25 if (tail.compareAndSet(qnode, null)) 26 return; 27 // wait until successor fills in its next field 28 while (qnode.next == null) {} 29 } 30 qnode.next.locked = false; 31 qnode.next = null; 32 } 33 class QNode { 34 volatile boolean locked = false; 35 volatile QNode next = null; 36 } 37 } 7.6 实现了超时功能的基于队列的锁 # 对于回退锁等简单锁，超时很简单，几步以后直接返回。而对于队列锁，返回则很难，不能直接把自己的锁标记为成功，因此采用一种lazy的做法，标记为abandoned，如果被抛弃的锁发现前面这货是被丢弃的，那么直接去检查之前的锁。下面的实现里，如果某个QNode的pred字段为NULL，那么要么是还没获取到锁，在等待获得锁，要么是还没获得锁，打释放掉锁。如果QNode的pred字段指向QNode AVAILABLE，那么这个QNode之前关联的线程已经释放，可以获取这个锁。如果pred字段指向其他节点，非NULL，也不是AVAILABLE，说明前面的QNode关联的线程放弃了锁请求，我们直接占有这个QNode去做检查。\n1 public class TOLock implements Lock{ 2 static QNode AVAILABLE = new QNode(); 3 AtomicReference\u0026lt;QNode\u0026gt; tail; 4 ThreadLocal\u0026lt;QNode\u0026gt; myNode; 5 public TOLock() { 6 tail = new AtomicReference\u0026lt;QNode\u0026gt;(null); 7 myNode = new ThreadLocal\u0026lt;QNode\u0026gt;() { 8 protected QNode initialValue() { 9 return new QNode(); 10 } 11 }; 12 } 13 ... 14 static class QNode { 15 public volatile QNode pred = null; 16 } 17 } 18 public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { 19 long startTime = System.currentTimeMillis(); 20 long patience = TimeUnit.MILLISECONDS.convert(time, unit); 21 QNode qnode = new QNode(); 22 myNode.set(qnode); 23 qnode.pred = null; 24 QNode myPred = tail.getAndSet(qnode); 25 if (myPred == null || myPred.pred == AVAILABLE) { 26 return true; 27 } 28 while (System.currentTimeMillis() - startTime \u0026lt; patience) { 29 QNode predPred = myPred.pred; 30 if (predPred == AVAILABLE) { 31 return true; 32 } else if (predPred != null) { 33 myPred = predPred; 34 } 35 } 36 if (!tail.compareAndSet(qnode, myPred)) 37 qnode.pred = myPred; 38 return false; 39 } 40 public void unlock() { 41 QNode qnode = myNode.get(); 42 if (!tail.compareAndSet(qnode, null)) 43 qnode.pred = AVAILABLE; 44 } 7.7 层次锁 # 跨cluster锁的解决方式，不外乎锁队列。请求同类(cluster)队列的锁被称为队列锁。每个不同的cluster请求一个大的共享的锁，每次线程申请锁的时候，先锁cluster内部的锁，在请不同cluster共享的锁。释放的时候先检查本cluster内部有没有锁等着，有的话先释放自己cluster的锁，然后让自己cluster的锁跑着，等到确定没有了再释放大共享锁。\n7.8 复合锁 # 一种结合了好理解，而且要求常量空间的锁。实际上就是等待队列前面的锁该等就死等着把，等待队列后面的锁你们按照指数级别增长等待事件，嗯，既减少了竞争，又让前面的线程忙等。这种原地的写法实际上在我看来，糟糕透了，炫技意味浓厚。\nacquireQNode就是尝试进入队列 spliceQNode则尝试 waitForPredecessor尝试获取锁，等待一段时间 1 public class CompositeLock implements Lock{ 2 private static final int SIZE = ...; 3 private static final int MIN_BACKOFF = ...; 4 private static final int MAX_BACKOFF = ...; 5 AtomicStampedReference\u0026lt;QNode\u0026gt; tail; 6 QNode[] waiting; 7 ThreadLocal\u0026lt;QNode\u0026gt; myNode = new ThreadLocal\u0026lt;QNode\u0026gt;() { 8 protected QNode initialValue() { return null; }; 9 }; 10 public CompositeLock() { 11 tail = new AtomicStampedReference\u0026lt;QNode\u0026gt;(null,0); 12 waiting = new QNode[SIZE]; 13 for (int i = 0; i \u0026lt; waiting.length; i++) { 14 waiting[i] = new QNode(); 15 } 16 } 17 public void unlock() { 18 QNode acqNode = myNode.get(); 19\tacqNode.state.set(State.RELEASED); 20 myNode.set(null); 21 } 22 ... 23 } 24 enum State {FREE, WAITING, RELEASED, ABORTED}; 25 class QNode { 26 AtomicReference\u0026lt;State\u0026gt; state; 27 QNode pred; 28 public QNode() { 29 state = new AtomicReference\u0026lt;State\u0026gt;(State.FREE); 30 } 31 } 32 public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { 33 long patience = TimeUnit.MILLISECONDS.convert(time, unit); 34 long startTime = System.currentTimeMillis(); 35 Backoff backoff = new Backoff(MIN_BACKOFF, MAX_BACKOFF); 36 try { 37 QNode node = acquireQNode(backoff, startTime, patience); 38 QNode pred = spliceQNode(node, startTime, patience); 39 waitForPredecessor(pred, node, startTime, patience); 40 return true; 41 } catch (TimeoutException e) { 42 return false; 43 } 44 } 45 private QNode acquireQNode(Backoff backoff, long startTime, long patience) 46 throws TimeoutException, InterruptedException { 47 QNode node = waiting[ThreadLocalRandom.current().nextInt(SIZE)]; 48 QNode currTail; 49 int[] currStamp = {0}; 50 while (true) { 51 if (node.state.compareAndSet(State.FREE, State.WAITING)) { 52 return node; 53 } 54 currTail = tail.get(currStamp); 55 State state = node.state.get(); 56 if (state == State.ABORTED || state == State.RELEASED) { 57 if (node == currTail) { 58 QNode myPred = null; 59 if (state == State.ABORTED) { 60 myPred = node.pred; 61 } 62 if (tail.compareAndSet(currTail, myPred, currStamp[0], currStamp[0]+1)) { 63 node.state.set(State.WAITING); 64 return node; 65 } 66 } 67 } 68 backoff.backoff(); 69 if (timeout(patience, startTime)) { 70 throw new TimeoutException(); 71 } 72 } 73 } 74 private QNode spliceQNode(QNode node, long startTime, long patience) 75 throws TimeoutException { 76 QNode currTail; 77 int[] currStamp = {0}; 78 do { 79 currTail = tail.get(currStamp); 80 if (timeout(startTime, patience)) { 81 node.state.set(State.FREE); 82 throw new TimeoutException(); 83 } 84\t} while (!tail.compareAndSet(currTail, node, currStamp[0], currStamp[0]+1)); 85 return currTail; 86 } 87 private void waitForPredecessor(QNode pred, QNode node, 88 long startTime, long patience) 89 throws TimeoutException { 90 int[] stamp = {0}; 91 if (pred == null) { 92 myNode.set(node); 93 return; 94 } 95 State predState = pred.state.get(); 96 while (predState != State.RELEASED) { 97 if (predState == State.ABORTED) { 98 QNode temp = pred; 99 pred = pred.pred; 100 temp.state.set(State.FREE); 101 } 102 if (timeout(patience, startTime)) { 103 node.pred = pred; 104 node.state.set(State.ABORTED); 105 throw new TimeoutException(); 106 } 107 predState = pred.state.get(); 108 } 109 pred.state.set(State.FREE); 110 myNode.set(node); 111 return; 112 } 7.9 快速锁？ # 第八章 条件变量 # 因为我们能让线程自旋保持锁的争用，所以如果是自旋锁，我们可以保证总会有线程抢到锁。但是如果做的是睡眠操作而且没有条件变量，那就蛋疼了，如果做互斥唤醒的话我们必须得有条件变量来帮忙我们执行，否则我们没办法唤醒某个具体的线程。得看看C11的内置条件变量是怎么回事。\n所有的语言都有无法唤醒(lost wake up)问题，有两种解决无法唤醒问题的方法：\nAlways signal all processes waiting on a condition, not just one. Specify a timeout when waiting 这里面有几个地方需要注意，一个是虚假唤醒（spurious wakeup），另一个是惊群。C++11现在并没有解决虚假唤醒的问题。目前很多人把惊群也当作虚拟唤醒的一种。如果只看维基百科，惊群也是虚假唤醒的一种，但是在早期的版本，会出现没发信号就唤醒的情况：\n惊群：导致一个提前被唤醒的线程把资源给抢了，后面唤醒的线程发现条件不满足 spurious wakeup 如果有惊群效应导致一个提前被唤醒的线程把资源给抢了，后面唤醒的线程发现条件不满足，这个也叫做虚假唤醒。也有可能是根本就没有生产者线程发信号，wait就直接返回了，这也是虚假唤醒。不同的平台提供不同的保证，pthread说是不会出现第二个情况。具体虚假唤醒的定义看维基百科https://en.wikipedia.org/wiki/Spurious_wakeup 8.3 读写锁 # 读写锁两个特性，实际上书里给的两种读写锁都是用的可冲入锁，什么意思，可以多次进入一个锁：\nNo thread can acquire the write lock while any thread holds either the write lock or the read lock. No thread can acquire the read lock while any thread holds the write lock. 光看这两个条件，有没有这种感觉，因为写锁获取之前必须所有的读锁/写锁都释放掉，所以和上面对应起来有种\nwrite.lock(): while(还有读锁/写锁活着) { condition.wait(); } read.lock(): while(写锁活着) { condition.wait(); } 看看读写锁的代码实现，会发现可重入锁是关键，可重入锁保护的是谁？保护的实际上是write \u0026amp; readAcquires \u0026amp; redReleases对象，也就是锁内部的关键数据。但是我感觉这个实现没有避开多读者之间的竞争啊，还是有问题，当然也确实在一定程度上降低了读者的竞争。可重入锁的代码啥的看下面：\n23 private class ReadLock implements Lock { 24 public void lock() { 25 lock.lock(); 26 try { 27 while (writer) 28 condition.await(); 29 readAcquires++; 30 } finally { 31 lock.unlock(); 32 } 33 } 34 public void unlock() { 35 lock.lock(); 36 try { 37 readReleases++; 38 if (readAcquires == readReleases) 39 condition.signalAll(); 40 } finally { 41 lock.unlock(); 42 } 43 } 44 } 45 private class WriteLock implements Lock { 46 public void lock() { 47 lock.lock(); 48 try { 49 while (writer) 50 condition.await(); 51 writer = true; 52 while (readAcquires != readReleases) 53 condition.await(); 54 } finally { 55 lock.unlock(); 56 } 57 } 58 public void unlock() { 59 lock.lock(); 60 try { 61 writer = false; 62 condition.signalAll(); 63 } finally { 64 lock.unlock(); 65 } 66 } 67 } 8.4 可重入锁 # 没想到吧JOJO，可重入锁才是本章节的关键啊，哈哈哈，实在是没话可说，这本书真的是不讲人话的典型啊。\n第九章 链表并发 # 这一章实际上是得意识到追求绝对的准确和减少竞争避免问题出现是很难一起实现的\n9.1-9.3 一堆理念的废话 # 9.3这节的重点并不是，所谓的线性/链表实现blablabla之类的东西，而是从不变式到抽象不变式，再到属性检查的部分是它的精髓，从某种意义来说也是最大的败笔，我在看实现方面的理念，你给我扯一堆没用的东西，然后说了一堆抽象的废话，就忽然结束了。\n我们知道缓存的不变式(invariant)是SWMR和DATA-VALUE，对抽象数据结构而言，不变式是什么？嗯，我目前也不知道，不过不变式应该满足下面这两条。这些不变式也被叫做freedom from interference：\nthe property holds when the object is created, and once the property holds, no thread can take a step that makes it false. 类比到我们这个例子里面，我们需要看每个同步时候的指令到底干了些啥，比方说insert(),remove()。在通过方法研究这些属性的时候，要能区分开他们代表的抽象和具体实际代码。抽象不变式只对对象抽象有效果，实现的不变式要跟着具体实现变化。下面的每节就是看各种不同级别的实现。\n9.4-9.5 各种粒度同步(锁) # 细粒度锁为了能够保证先后的正确，因此必须，“手把手”的去获取锁。换言之：it acquires the lock for a node (except the head node) while holding (i.e., before releasing) the lock for its predecessor. 在获取某个节点锁之前要先获取它之前的锁。这个行为被称作lock coupling锁耦合(也叫做连接器)。这要求每个线程获取耦合锁的时候，具体获取耦合锁里面的一个锁的先后顺序要一致！\n9.6 乐观同步(锁) # 嗯，那个出租车司机的笑话挺形象的。感觉除了这个之外没啥值得看额。。。也不完全是，对链表的插入和查询都不需要锁，或者说，拿个读锁去操作，写锁做别的事情。之所以这个能这么干，有个很大的原因就是删除操作并不是把单元的内存释放了，而是把关联的关系去掉了。但是，被删除的节点的-\u0026gt;next属性依然指向下个节点。也就是说即使你拿到的是无效了的指针，它依然能找到下个元素。\n那么这里面乐观了什么？这里实际上就是假设当我进行删除/查找/插入操作的时候，不会有其他的进程让我已经获得的节点失效。我这里面得意识到：\n先读的关系，后获取的锁，所以需要validate。 如果是先获取的锁，后读的关系，那就不需要validate了。这就是乐观同步和细粒度锁的区别。 具体乐观锁的优化就是懒同步，下面是乐观同步的代码，主要有个问题是它的访问需要加锁，那么怎么解决呢？。\n1 public boolean add(T item) { //增加 2 int key = item.hashCode(); 3 while (true) { 4 Node pred = head; 5 Node curr = pred.next; 6 while (curr.key \u0026lt; key) { 7 pred = curr; curr = curr.next; 8 } 9 pred.lock(); 10 try { 11 curr.lock(); 12 try { 13 if (validate(pred, curr)) { 14 if (curr.key == key) { 15 return false; 16 } else { 17 Node node = new Node(item); 18 node.next = curr; 19 pred.next = node; 20 return true; 21 } 22 } 23 } finally { 24 curr.unlock(); 25 } 26 } finally { 27 pred.unlock(); 28 } 29 } 30 } 31 public boolean remove(T item) {//这个是删除操作 32 int key = item.hashCode(); 33 while (true) { 34 Node pred = head; 35 Node curr = pred.next; 36 while (curr.key \u0026lt; key) { 37 pred = curr; curr = curr.next; 38 } 39 pred.lock(); 40 try { 41 curr.lock(); 42 try { 43 if (validate(pred, curr)) { 44 if (curr.key == key) { 45 pred.next = curr.next; 46 return true; 47 } else { 48 return false; 49 } 50 } 51 } finally { 52 curr.unlock(); 53 } 54 } finally { 55 pred.unlock(); 56 } 57 } 58 } 9.7 懒同步(锁) # 懒同步实际上就是给每个节点加个标签，来表示它是不是有效的。这个东西实际上相当于一大堆读锁，每次发现某个数据没用了就直接CompareAndSet(Valid=false)。如果需要添加的节点的key已经存在，先改变值，再改变valid属性。每次发现数量太多了，不够用了再唤醒写锁。实际上你猜我想起来了什么，我想起来了mem_sem这个东西，这也是lasy_synchronization同步。\n当着这个东西有个问题，就是会导致执行真正删除的时候很麻烦，为了能够detach节点，需要检查现在的detach的节点是不是有效的，相比于乐观同步，懒同步在移除节点的时候先标记无效，再移除关联关系。但是因为有可能找到无效的指针，所以检索找不到的可能性存在(具体见pdf的P218)\n33 public boolean contains(T item) { 34 int key = item.hashCode(); 35 Node curr = head; 36 while (curr.key \u0026lt; key) 37 curr = curr.next; 38 return curr.key == key \u0026amp;\u0026amp; !curr.marked; 39 } 9.8 无锁同步 # dada~到了最后就是重头戏了，无锁同步。本质就是同时看两个条件是不是满足，实质还是锁\n建议看看这个C++11的例子，很有趣https://stackoverflow.com/questions/40247249/what-is-the-c-11-atomic-library-equivalent-of-javas-atomicmarkablereferencet和具体的atomic比较的例子https://www.cnblogs.com/haippy/p/3301408.html这部分还是建议直接看原理吧。\n下面的代码里，window负责找到之前的节点和当前的节点\n1 class Window { 2 public Node pred, curr; 3 Window(Node myPred, Node myCurr) { 4 pred = myPred; curr = myCurr; 5 } 6 } 7 Window find(Node head, int key) { 8 Node pred = null, curr = null, succ = null; 9 boolean[] marked = {false}; 10 boolean snip; 11 retry: while (true) { 12 pred = head; 13 curr = pred.next.getReference(); 14 while (true) { 15 succ = curr.next.get(marked); 16 while (marked[0]) { 17 snip = pred.next.compareAndSet(curr, succ, false, false); 18 if (!snip) continue retry; 19 curr = succ; 20 succ = curr.next.get(marked); 21 } 22 if (curr.key \u0026gt;= key) 23 return new Window(pred, curr); 24 pred = curr; 25 curr = succ; 26 } 27 } 28 } 第十章：队列，内存管理和ABA问题 # 对pool（池）而言，操作分为部分和全部，部分是需要满足条件才能执行，如果条件不满足就阻塞的操作，全部是指立刻发生，或者返回错误码或者返回结果的操作。如果一个部分操作，需要另一个方法和它重叠才能发生，就说这个方法是同步的。\n池提供了不同的公平性保证，如FIFO（队列），和LIFO（栈）。这章主要说队列。\n10.1-10.3有限同步队列的实现 # 两个条件变量，两个锁，下面的代码很巧妙的避免了“唤醒丢失”问题，这里要注意，为什么发现为空的时候要拿到deqLock呢？因为有唤醒丢失的问题，为什么会有唤醒丢失？因为：\n对于发布唤醒的线程而言(我们这里以enqueue为例)，虽然size是原子变量，但是从对size的判断再到mustWakeDequeuers = true;中间是有一个过程的，我们必须保证deq线程不能在notEmptyCondition.signalAll();之后进入睡眠，所以需要用deqLock进行保护。同理看deq算法 对于准备被唤醒的线程而言(我们这里以dequeue为例)，虽然size是原子变量，但是从对size的判断再到notFullCondition 条件变量的等待是有个过程的，因此需要让enqueue线程获得enqLock来保证先后性。 有限同步队列的问题是，每次都要操作两个锁deqLock和enqLock，同时enq和deq操作都要动size，因此将size拆分为enqSideSize 和deqSideSize 。队列的实际上都市enqSideSize+deqSideSize。enq操作检测enqSideSize大小，小于容量则继续。如果到达容量就锁住deqLock，把deqSideSize加到enqSideSize，然后重置deqSideSize为0\n1 public class BoundedQueue\u0026lt;T\u0026gt; { 2 ReentrantLock enqLock, deqLock; 3 Condition notEmptyCondition, notFullCondition; 4 AtomicInteger size; 5 volatile Node head, tail; 6 final int capacity; 7 public BoundedQueue(int _capacity) { 8 capacity = _capacity; 9 head = new Node(null); 10 tail = head; 11 size = new AtomicInteger(0); 12 enqLock = new ReentrantLock(); 13 notFullCondition = enqLock.newCondition(); 14 deqLock = new ReentrantLock(); 15 notEmptyCondition = deqLock.newCondition(); 16 } 17 ... 18 } 19 protected class Node { 20 public T value; 21 public volatile Node next; 22 public Node(T x) { 23 value = x; 24 next = null; 25 } 26 } 27 public void enq(T x) { 28 boolean mustWakeDequeuers = false; 29 Node e = new Node(x); 30 enqLock.lock(); 31 try { 32 while (size.get() == capacity) 33 notFullCondition.await(); 34 tail.next = e; 35 tail = e; 36 if (size.getAndIncrement() == 0) 37 mustWakeDequeuers = true; 38 } finally { 39 enqLock.unlock(); 40 } 41 if (mustWakeDequeuers) { 42 deqLock.lock(); 43 try { 44 notEmptyCondition.signalAll(); 45 } finally { 46 deqLock.unlock(); 47 } 48 } 49 } 50 public T deq() { 51 T result; 52 boolean mustWakeEnqueuers = false; 53 deqLock.lock(); 54 try { 55 while (head.next == null) 56 notEmptyCondition.await(); 57 result = head.next.value; 58 head = head.next; 59 if (size.getAndDecrement() == capacity) { 60 mustWakeEnqueuers = true; 61 } 62 } finally { 63 deqLock.unlock(); 64 } 65 if (mustWakeEnqueuers) { 66 enqLock.lock(); 67 try { 68 notFullCondition.signalAll(); 69 } finally { 70 enqLock.unlock(); 71 } 72 } 73 return result; 74 } 10.4 无限全部队列 # 无限同步队列不会产生死锁，enq必然成功，deq最多抛出个异常，实现非常简单。\n1 public void enq(T x) { 2 Node e = new Node(x); 3 enqLock.lock(); 4 try { 5 tail.next = e; 6 tail = e; 7 } finally { 8 enqLock.unlock(); 9 } 10 } 11 public T deq() throws EmptyException { 12 T result; 13 deqLock.lock(); 14 try { 15 if (head.next == null) { 16 throw new EmptyException(); 17 } 18 result = head.next.value; 19 head = head.next; 20 } finally { 21 deqLock.unlock(); 22 } 23 return result; 24 } 10.5 无锁无限队列 # 先简单思考，对于无锁队列（以链表方式实现而言），问题在于：\nenq的时候，怎么确保添加到最后一个节点。换言之，我一开始看到的last和最后写入的last是一个吗？ tail-\u0026gt;next的变化和tail的变化是同一步吗？怎么保证两个都成功？换言之，怎么保证添加新节点和挪动tail指针是原子的呢？我们必然得先添加新节点，再挪动tail指针。 相对应的，我们针对这两个问题分析：\nenq的时候，如果last不是tail，说明最后节点失效。如果next不为NULL，说明最后节点有人添加，但是未必失效。所以在此CompareAndSet(tail)节点。我感觉没必要。。。。。实际上函数里面如果发现tail不是last节点，就重新获取last节点。 每次操作都是确保在当时last == tail的，然后尝试添加。如果发现next不是NULL，那么再次尝试重新获取tail。如果是NULL那么CompareAndSet，CAS成功了的话，更新tail，如果不成功说明有别的更新tail了，我们不用管。实际上还是通过CAS来保证添加新节点和挪动tail指针两步虽然是分割的，但是实际执行起来是原子的。每一步的检查都在确定当前的last节点是最后一个节点。 现在分析一下，该队列。更新tail节点是lazy的，enq方法的29-31行实际上帮助了tail的挪动。\n1 public class LockFreeQueue\u0026lt;T\u0026gt; { 2 AtomicReference\u0026lt;Node\u0026gt; head, tail; 3 public LockFreeQueue() { 4 Node node = new Node(null); 5 head = new AtomicReference(node); 6 tail = new AtomicReference(node); 7 } 8 ... 9 } 10 public class Node { 11 public T value; 12 public AtomicReference\u0026lt;Node\u0026gt; next; 13 public Node(T value) { 14 this.value = value; 15 next = new AtomicReference\u0026lt;Node\u0026gt;(null); 16 } 17 } 18 public void enq(T value) { 19 Node node = new Node(value); 20 while (true) { 21 Node last = tail.get(); 22 Node next = last.next.get(); 23 if (last == tail.get()) { 24 if (next == null) { 25 if (last.next.compareAndSet(next, node)) { 26 tail.compareAndSet(last, node); 27 return; 28 } 29 } else { 30 tail.compareAndSet(last, next); 31 } 32 } 33 } 34 } 35 public T deq() throws EmptyException { 36 while (true) { 37 Node first = head.get(); 38 Node last = tail.get(); 39 Node next = first.next.get(); 40 if (first == head.get()) { 41 if (first == last) { 42 if (next == null) { 43 throw new EmptyException(); 44 } 45 tail.compareAndSet(last, next); 46 } else { 47 T value = next.value; 48 if (head.compareAndSet(first, next)) 49 return value; 50 } 51 } 52 } 53 } 10.6 内存回收和ABA问题 # 本节主要说的是内存回收\n每个线程维持自己的内存回收队列是最简单的实现，自己操作自己不会引起任何同步问题。 10.7 双数数据结构 # 这个实际上我没看，感觉用处不大。\n第11章 栈和释放(?) # 11.1-11.2 无锁栈 # CompareAndSet的实现，没啥问题\n11.3-11.4 消除（？） # 之所以无锁栈性能不好，不是因为top产生了竞争，而是因为强制要求线性并发，不能多个同时burst。这里我们引入一个观察：一个push和一个pop会相互抵消，因此如果直接取消一对push和pop，就可以不对栈做操作。实际上这里是在数组里面添加了一个缓冲垫\u0026mdash;一个缓冲数组。但是这个方法实际上并不再是后入后出了。而且只要对数组操作就有满不满吧？此外，我得说那个投票的笑话太牛逼了，一下子把出现的问题描述的非常清楚。\n11.4.1 交换类型的实现 # 本质上是个缓冲垫，这个里面还有个问题就是，每个线程的随机数发生器必须不一样！否则都打到一个线程上了。缓冲垫不再随机，性能随之下降，相当于退化为原本的无锁栈了。\n1 public class LockFreeExchanger\u0026lt;T\u0026gt; { 2 static final int EMPTY = ..., WAITING = ..., BUSY = ...; 3 AtomicStampedReference\u0026lt;T\u0026gt; slot = new AtomicStampedReference\u0026lt;T\u0026gt;(null, 0); 4 public T exchange(T myItem, long timeout, TimeUnit unit) 5 throws TimeoutException { 6 long nanos = unit.toNanos(timeout); 7 long timeBound = System.nanoTime() + nanos; 8 int[] stampHolder = {EMPTY}; 9 while (true) { 10 if (System.nanoTime() \u0026gt; timeBound) 11 throw new TimeoutException(); 12 T yrItem = slot.get(stampHolder); 13 int stamp = stampHolder[0]; 14\tswitch(stamp) { 15 case EMPTY: 16 if (slot.compareAndSet(yrItem, myItem, EMPTY, WAITING)) { 17 while (System.nanoTime() \u0026lt; timeBound) { 18 yrItem = slot.get(stampHolder); 19 if (stampHolder[0] == BUSY) { 20 slot.set(null, EMPTY); 21 return yrItem; 22 } 23 } 24 if (slot.compareAndSet(myItem, null, WAITING, EMPTY)) { 25 throw new TimeoutException(); 26 } else { 27 yrItem = slot.get(stampHolder); 28 slot.set(null, EMPTY); 29 return yrItem; 30 } 31 } 32 break; 33 case WAITING: 34 if (slot.compareAndSet(yrItem, myItem, WAITING, BUSY)) 35 return yrItem; 36 break; 37 case BUSY: 38 break; 39 default: // impossible 40 ... 41 } 42 } 43 } 44 } 11.4.2 缓冲垫下的并发栈 # 并发的缓冲垫，避免原子操作的失败。这里面rangePolicy.getRange()操作如果是小范围的，那么在线程数量不多的情况下就容易增加命中，如果范围很大，会降低线程的忙等。\n1 public class EliminationBackoffStack\u0026lt;T\u0026gt; extends LockFreeStack\u0026lt;T\u0026gt; { 2 static final int capacity = ...; 3 EliminationArray\u0026lt;T\u0026gt; eliminationArray = new EliminationArray\u0026lt;T\u0026gt;(capacity); 4 static ThreadLocal\u0026lt;RangePolicy\u0026gt; policy = new ThreadLocal\u0026lt;RangePolicy\u0026gt;() { 5 protected synchronized RangePolicy initialValue() { 6 return new RangePolicy(); 7 } 8 9\tpublic void push(T value) { 10 RangePolicy rangePolicy = policy.get(); 11 Node node = new Node(value); 12 while (true) { 13 if (tryPush(node)) { 14 return; 15 } else try { 16 T otherValue = eliminationArray.visit(value, rangePolicy.getRange()); 17 if (otherValue == null) { 18 rangePolicy.recordEliminationSuccess(); 19 return; // exchanged with pop 20 } 21 } catch (TimeoutException ex) { 22 rangePolicy.recordEliminationTimeout(); 23 } 24 } 25 } 26 } 27 public T pop() throws EmptyException { 28 RangePolicy rangePolicy = policy.get(); 29 while (true) { 30 Node returnNode = tryPop(); 31 if (returnNode != null) { 32 return returnNode.value; 33 } else try { 34 T otherValue = eliminationArray.visit(null, rangePolicy.getRange()); 35 if (otherValue != null) { 36 rangePolicy.recordEliminationSuccess(); 37 return otherValue; 38 } 39 } catch (TimeoutException ex) { 40 rangePolicy.recordEliminationTimeout(); 41 } 42 } 43 } 第十二章：计数，排序和分布式协作 # 两种方式衡量并发，很神奇的是，对于分布式系统而言，这两个并不是互相矛盾的.：\nlatency, the time it takes an individual method call to complete throughput, the overall rate at which method calls complete 12.3 软件合并 # 合并树，本质是每次都让主动的进程去做操作。但是这个实现并不是那么简单，每个节点都要自旋一段时间，来保证两个线程可以碰上对方，因此给个节点要有自己的状态码。不过想一想合并树这个操作真的还挺骚，但是在最极端的情况下，这个算法并不怎么好使\n1 public class Node { 2 enum CStatus{IDLE, FIRST, SECOND, RESULT, ROOT}; 3 boolean locked; 4 CStatus cStatus; 5 int firstValue, secondValue; 6 int result; 7 Node parent; 8 public Node() { 9 cStatus = CStatus.ROOT; 10 locked = false; 11 } 12 public Node(Node myParent) { 13 parent = myParent; 14 cStatus = CStatus.IDLE; 15 locked = false; 16 } 17 ... 18 } 合并树代码\n合并树的preCombine方法需要保证原子吧，感觉有点问题啊。\n1 public CombiningTree(int width) { 2 Node[] nodes = new Node[2 * width - 1]; 3 nodes[0] = new Node(); 4 for (int i = 1; i \u0026lt; nodes.length; i++) { 5 nodes[i] = new Node(nodes[(i-1)/2]); 6 } 7 leaf = new Node[width]; 8 for (int i = 0; i \u0026lt; leaf.length; i++) { 9 leaf[i] = nodes[nodes.length - i - 1]; 10 } 11 } 12 public int getAndIncrement() { 13 Stack\u0026lt;Node\u0026gt; stack = new Stack\u0026lt;Node\u0026gt;(); 14 Node myLeaf = leaf[ThreadID.get()/2]; 15 Node node = myLeaf; 16 // precombining phase 17 while (node.precombine()) { 18 node = node.parent; 19 } 20 Node stop = node; 21 // combining phase 22 int combined = 1; 23 for (node = myLeaf; node != stop; node = node.parent) { 24 combined = node.combine(combined); 25 stack.push(node); 26 } 27 // operation phase 28 int prior = stop.op(combined); 29 // distribution phase 30 while (!stack.empty()) { 31 node = stack.pop(); 32 node.distribute(prior); 33 } 34 return prior; 35 } 对流程的理解还是得看图，a和b图时A处于preCombine阶段，c图时，A负责combine负责合并底下的每个节点，它先等待B线程释放锁。d图B释放了锁，然后A获得锁开始合并。A在operation阶段，如果是操作root节点，那就直接加了。如果不是，那就将值存到左值，然后通知每个被block的节点。结果返回了，A进入分发阶段，\n12.5 计数网络 # 唉，尴尬\n","date":"2021 年 1 月 26 日","externalUrl":null,"permalink":"/posts/2021-01-26-%E5%A4%9A%E5%A4%84%E7%90%86%E7%BC%96%E7%A8%8B%E7%9A%84%E8%89%BA%E6%9C%AF%E7%AC%AC%E4%BA%8C%E7%89%88%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"","title":"多处理编程的艺术第二版笔记","type":"posts"},{"content":"","date":"2021 年 1 月 24 日","externalUrl":null,"permalink":"/tags/kernel/","section":"Tags","summary":"","title":"Kernel","type":"tags"},{"content":" 内存学习(4)-理解linux虚拟内存管理 # 这部分流程我看了两个版本，一个是linux 2.6.34，另一个是linux 5.0的版本，大同小异。书翻了《深入理解Linux虚拟内存管理》，《笨叔的奔跑吧linux内核》和各种各样自的博客。出于对于大神Mel gorman的敬意，我下面的内容会尽量和《深入理解Linux虚拟内存管理》保持一致。我这里写的东西，都是针对5.0的内核代码。但是有一点要注意，在理解linux虚拟内存管理之前，要先对计算机系统有一定的了解。\n第一章：简介 # 为什么linux的虚拟内存难以理解，从我个人的角度来看，是因为：\n版本变化巨大，很多新的feature不断增加，而中文互联网的资料过于分散，不适合学习 层出不穷的黑魔法和trick，知道的会觉得理解，不知道就不理解 内核的很多功能都是自洽的，不去看mail，根本不知道到底怎么吵出来的这个东西。 所以我自己的这个博客一方面是为了记录自己的学习，另一方面也是希望如果有人有疑问，刚好看到我的博客，能得到解答。当然，更建议直接看这个网页guts直接讲的视频，很不错\nhttps://hackmd.io/@sysprog/linux-memory?type=view\n第二章：描述物理内存 # linux是一种适用于各种体系结构的系统，因此需要一种与体系结构无关的方式来描述内存，这一章重点就是讲节点，管理区，以及节点和管理区如何初始化的。对于NUMA系统而言，\n系统中，每个节点链接到一个以NULL结尾的pgdata_list链表，其中的每个节点利用pg_data_tnode_next链接到下一个节点。每个节点内部又被分成不同的struct zone_struct，或者说管理区。一般终端关注的是ZONE_NORMAL，这个ZONE里面的内存地址被称为线性映射地址(实际上就是加上个系统偏移量)。对于X86系统而言，因为其可用的地址最多只能到4G，它的管理区如下：\nZONE_DMA为16MB，给很多驱动用\nZONE_NORMAL为16MB-896MB的地址空间，这部分直接映射X86虚拟地址里4G内存里的第4GB。一个疑问是为什么这块的大小是896MB，是因为896MB是直接映射或者说线性映射的地址，如果全映射了，那么第4GB就全是线性映射的部分，没办法映射其它地址(比方说高端地址)的空间了。\nZONE_HIGHMEM为896MB以上的地址空间，这部分ZONE在X86_64位上实际已经没多少用了。\n对于现在电脑常用的X86_64位而言，它源码里定义的ZONE如下所示，具体为什么定义这部分看注释，源码下面是我司的8G虚拟机地址空间：\nenum zone_type { #ifdef CONFIG_ZONE_DMA ZONE_DMA,\t//如果设备不能对ZONE_NORMAL的地址做DMA，那么久单独挖出来这么一块，具体的范围与架构有关，我们这里先默认是16MB #endif #ifdef CONFIG_ZONE_DMA32 ZONE_DMA32,\t//对于X86_64机器而言，之所以需要两个DMA是因为有的设备只能做16MB的DMA，而有的设备能做32bit内存也就是4G的DMA\t#endif ZONE_NORMAL,\t//本质来说这实际上就已经是线性区， #ifdef CONFIG_HIGHMEM ZONE_HIGHMEM,\t//高端内存区，这块内存如果内存想访问需要映射到自己的地址空间里，目前看起来也就X86用了(?)，也就是高于900MB的地址空间。 #endif ZONE_MOVABLE,\t//这个内存区很有趣，是个实际上并不真正存在的内存区。 #ifdef CONFIG_ZONE_DEVICE ZONE_DEVICE, #endif __MAX_NR_ZONES }; 对于X86体系而言，许多kernel的操作都只能在ZONE_NORMAL上操作，因此，在kernel操作高端内存的地址的时候，往往需要先映射到最后1GB里面的映射区间 。系统的内存被划分成大小确定的许多块，每个块被称为物理页面帧，每个物理页面帧都由一个struct page描述，所有的结构都存在一个全局的mem_map数组里，该数组通常存放在ZONE_NORMAL的首部。\n对于X86_64体系而言，目前的地址可以说都是线性映射区，不过映射不一样而已。\n2.1节点 # 下面贴了pglist_data结构里的每个字段，具体的含义需要自己去查。关注的重点主要是linux2.6和linux5.0的不同点：\nlru_lock，5.0里lru_lock被挪入了节点里，也就是每次管理的就是具体的节点。 lruevec，5.0里也被挪到了节点里 node_mem_map是个扁平内存模型下的概念，具体几种Linux的内存模型看这篇文章。 typedef struct pglist_data { struct zone node_zones[MAX_NR_ZONES]; struct zonelist node_zonelists[MAX_ZONELISTS]; int nr_zones; #ifdef CONFIG_FLAT_NODE_MEM_MAP\t/* means !SPARSEMEM */ struct page *node_mem_map; #ifdef CONFIG_PAGE_EXTENSION struct page_ext *node_page_ext; #endif #endif #if defined(CONFIG_MEMORY_HOTPLUG) || defined(CONFIG_DEFERRED_STRUCT_PAGE_INIT) /* * Must be held any time you expect node_start_pfn, * node_present_pages, node_spanned_pages or nr_zones to stay constant. * * pgdat_resize_lock() and pgdat_resize_unlock() are provided to * manipulate node_size_lock without checking for CONFIG_MEMORY_HOTPLUG * or CONFIG_DEFERRED_STRUCT_PAGE_INIT. * * Nests above zone-\u0026gt;lock and zone-\u0026gt;span_seqlock */ spinlock_t node_size_lock; #endif unsigned long node_start_pfn; unsigned long node_present_pages; /* total number of physical pages */ unsigned long node_spanned_pages; /* total size of physical page range, including holes */ int node_id; wait_queue_head_t kswapd_wait; //为kswapd新添加的等待队列链表，每个节点都有一个kswapedN wait_queue_head_t pfmemalloc_wait; struct task_struct *kswapd;\t/* Protected by mem_hotplug_begin/end() */ int kswapd_order; enum zone_type kswapd_classzone_idx; int kswapd_failures;\t/* Number of \u0026#39;reclaimed == 0\u0026#39; runs */ #ifdef CONFIG_COMPACTION int kcompactd_max_order; enum zone_type kcompactd_classzone_idx; wait_queue_head_t kcompactd_wait; struct task_struct *kcompactd; #endif /* * This is a per-node reserve of pages that are not available * to userspace allocations. */ unsigned long\ttotalreserve_pages; #ifdef CONFIG_NUMA /* * zone reclaim becomes active if more unmapped pages exist. */ unsigned long\tmin_unmapped_pages; unsigned long\tmin_slab_pages; #endif /* CONFIG_NUMA */ /* Write-intensive fields used by page reclaim */ ZONE_PADDING(_pad1_) spinlock_t\tlru_lock; #ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT /* * If memory initialisation on large machines is deferred then this * is the first PFN that needs to be initialised. */ unsigned long first_deferred_pfn; #endif /* CONFIG_DEFERRED_STRUCT_PAGE_INIT */ #ifdef CONFIG_TRANSPARENT_HUGEPAGE spinlock_t split_queue_lock; struct list_head split_queue; unsigned long split_queue_len; #endif /* Fields commonly accessed by the page reclaim scanner */ struct lruvec\tlruvec; unsigned long\tflags; ZONE_PADDING(_pad2_) /* Per-node vmstats */ struct per_cpu_nodestat __percpu *per_cpu_nodestats; atomic_long_t\tvm_stat[NR_VM_NODE_STAT_ITEMS]; } pg_data_t; 保护模式下，IA-32只能使用4GB的物理内存，支持PAE之后，可以支持64GB的内存。\n2.2 管理区 # 如何确定是从哪个管理区分配出来的？看下面这片文章。\nhttps://www.codenong.com/cs109638783/\n每个结构的作用和定义如下：\nstruct zone { /* Read-mostly fields */ /* zone watermarks, access with *_wmark_pages(zone) macros */ unsigned long _watermark[NR_WMARK];//管理区极值，分别对应WMARK_MIN,WMARK_LOW,WMARK_HIGH, unsigned long watermark_boost; unsigned long nr_reserved_highatomic; /* * We don\u0026#39;t know if the memory that we\u0026#39;re going to allocate will be * freeable or/and it will be released eventually, so to avoid totally * wasting several GB of ram we must reserve some of the lower zone * memory (otherwise we risk to run OOM on the lower zones despite * there being tons of freeable ram on the higher zones). This array is * recalculated at runtime if the sysctl_lowmem_reserve_ratio sysctl * changes. */ long lowmem_reserve[MAX_NR_ZONES]; #ifdef CONFIG_NUMA int node; #endif struct pglist_data\t*zone_pgdat;//反指回具体的节点 struct per_cpu_pageset __percpu *pageset; #ifndef CONFIG_SPARSEMEM /* * Flags for a pageblock_nr_pages block. See pageblock-flags.h. * In SPARSEMEM, this map is stored in struct mem_section */ unsigned long\t*pageblock_flags; #endif /* CONFIG_SPARSEMEM */ /* zone_start_pfn == zone_start_paddr \u0026gt;\u0026gt; PAGE_SHIFT */ unsigned long\tzone_start_pfn; /* * spanned_pages is the total pages spanned by the zone, including * holes, which is calculated as: * spanned_pages = zone_end_pfn - zone_start_pfn; * * present_pages is physical pages existing within the zone, which * is calculated as: *\tpresent_pages = spanned_pages - absent_pages(pages in holes); * * managed_pages is present pages managed by the buddy system, which * is calculated as (reserved_pages includes pages allocated by the * bootmem allocator): *\tmanaged_pages = present_pages - reserved_pages; * * So present_pages may be used by memory hotplug or memory power * management logic to figure out unmanaged pages by checking * (present_pages - managed_pages). And managed_pages should be used * by page allocator and vm scanner to calculate all kinds of watermarks * and thresholds. * * Locking rules: * * zone_start_pfn and spanned_pages are protected by span_seqlock. * It is a seqlock because it has to be read outside of zone-\u0026gt;lock, * and it is done in the main allocator path. But, it is written * quite infrequently. * * The span_seq lock is declared along with zone-\u0026gt;lock because it is * frequently read in proximity to zone-\u0026gt;lock. It\u0026#39;s good to * give them a chance of being in the same cacheline. * * Write access to present_pages at runtime should be protected by * mem_hotplug_begin/end(). Any reader who can\u0026#39;t tolerant drift of * present_pages should get_online_mems() to get a stable value. */ atomic_long_t\tmanaged_pages; unsigned long\tspanned_pages; unsigned long\tpresent_pages; const char\t*name; #ifdef CONFIG_MEMORY_ISOLATION /* * Number of isolated pageblock. It is used to solve incorrect * freepage counting problem due to racy retrieving migratetype * of pageblock. Protected by zone-\u0026gt;lock. */ unsigned long\tnr_isolate_pageblock; #endif #ifdef CONFIG_MEMORY_HOTPLUG /* see spanned/present_pages for more description */ seqlock_t\tspan_seqlock; #endif int initialized; /* Write-intensive fields used from the page allocator */ ZONE_PADDING(_pad1_) /* free areas of different sizes */ struct free_area\tfree_area[MAX_ORDER]; //空闲区域位图，三种类型:可移动，可回收，不可移动。ORDER为具体的阶 /* zone flags, see below */ unsigned long\tflags; /* Primarily protects free_area */ spinlock_t\tlock;\t//保护锁 /* Write-intensive fields used by compaction and vmstats. */ ZONE_PADDING(_pad2_) /* * When free pages are below this point, additional steps are taken * when reading the number of free pages to avoid per-cpu counter * drift allowing watermarks to be breached */ unsigned long percpu_drift_mark; #if defined CONFIG_COMPACTION || defined CONFIG_CMA /* pfn where compaction free scanner should start */ unsigned long\tcompact_cached_free_pfn; //内存平整用 /* pfn where async and sync compaction migration scanner should start */ unsigned long\tcompact_cached_migrate_pfn[2]; #endif #ifdef CONFIG_COMPACTION /* * On compaction failure, 1\u0026lt;\u0026lt;compact_defer_shift compactions * are skipped before trying again. The number attempted since * last failure is tracked with compact_considered. */ unsigned int\tcompact_considered; unsigned int\tcompact_defer_shift; int\tcompact_order_failed; #endif #if defined CONFIG_COMPACTION || defined CONFIG_CMA /* Set to true when the PG_migrate_skip bits should be cleared */ bool\tcompact_blockskip_flush; #endif bool\tcontiguous; ZONE_PADDING(_pad3_) /* Zone statistics */ atomic_long_t\tvm_stat[NR_VM_ZONE_STAT_ITEMS]; //原子数据的统计。 atomic_long_t\tvm_numa_stat[NR_VM_NUMA_STAT_ITEMS]; } ___c 2.3 物理页面 # 每一个对应一个具体的页帧，根据不同的用途，union字段里面选择不同的资源。当然实际页表里面存储的都是PFN，也就是page frame number，可以很轻松的得到物理内存地址为X的页帧号为X\u0026raquo;PAGE_SHIFT\nstruct page { unsigned long flags;\t/* Atomic flags, some possibly 应该还是用flag来反向映射管理区吧，不过似乎没必要了 * updated asynchronously */ /* * Five words (20/40 bytes) are available in this union. * WARNING: bit 0 of the first word is used for PageTail(). That * means the other users of this union MUST NOT use the bit to * avoid collision and false-positive PageTail(). */ union { struct {\t/* Page cache and anonymous pages */ /** * @lru: Pageout list, eg. active_list protected by * zone_lru_lock. Sometimes used as a generic list * by the page owner. */ struct list_head lru; /* See page-flags.h for PAGE_MAPPING_FLAGS */ struct address_space *mapping; pgoff_t index;\t/* Our offset within mapping. */ /** * @private: Mapping-private opaque data. * Usually used for buffer_heads if PagePrivate. * Used for swp_entry_t if PageSwapCache. * Indicates order in the buddy system if PageBuddy. */ unsigned long private; }; struct {\t/* slab, slob and slub */ union { struct list_head slab_list;\t/* uses lru */ struct {\t/* Partial pages */ struct page *next; #ifdef CONFIG_64BIT int pages;\t/* Nr of pages left */ int pobjects;\t/* Approximate count */ #else short int pages; short int pobjects; #endif }; }; struct kmem_cache *slab_cache; /* not slob */ /* Double-word boundary */ void *freelist;\t/* first free object */ union { void *s_mem;\t/* slab: first object */ unsigned long counters;\t/* SLUB */ struct {\t/* SLUB */ unsigned inuse:16; unsigned objects:15; unsigned frozen:1; }; }; }; struct {\t/* Tail pages of compound page */ unsigned long compound_head;\t/* Bit zero is set */ /* First tail page only */ unsigned char compound_dtor; unsigned char compound_order; atomic_t compound_mapcount; }; struct {\t/* Second tail page of compound page */ unsigned long _compound_pad_1;\t/* compound_head */ unsigned long _compound_pad_2; struct list_head deferred_list; }; struct {\t/* Page table pages */ unsigned long _pt_pad_1;\t/* compound_head */ pgtable_t pmd_huge_pte; /* protected by page-\u0026gt;ptl */ unsigned long _pt_pad_2;\t/* mapping */ union { struct mm_struct *pt_mm; /* x86 pgds only */ atomic_t pt_frag_refcount; /* powerpc */ }; #if ALLOC_SPLIT_PTLOCKS spinlock_t *ptl; #else spinlock_t ptl; #endif }; struct {\t/* ZONE_DEVICE pages */ /** @pgmap: Points to the hosting device page map. */ struct dev_pagemap *pgmap; unsigned long hmm_data; unsigned long _zd_pad_1;\t/* uses mapping */ }; /** @rcu_head: You can use this to free a page by RCU. */ struct rcu_head rcu_head; }; union {\t/* This union is 4 bytes in size. */ /* * If the page can be mapped to userspace, encodes the number * of times this page is referenced by a page table. */ atomic_t _mapcount; /* * If the page is neither PageSlab nor mappable to userspace, * the value stored here may help determine what this page * is used for. See page-flags.h for a list of page types * which are currently stored here. */ unsigned int page_type; unsigned int active;\t/* SLAB */ int units;\t/* SLOB */ }; /* Usage count. *DO NOT USE DIRECTLY*. See page_ref.h */ atomic_t _refcount; #ifdef CONFIG_MEMCG struct mem_cgroup *mem_cgroup; #endif /* * On machines where all RAM is mapped into kernel address space, * we can simply calculate the virtual address. On machines with * highmem some memory is mapped into kernel virtual memory * dynamically, so we need a place to store that address. * Note that this field could be 16 bits on x86 ... ;) * * Architectures with slow multiplication can define * WANT_PAGE_VIRTUAL in asm/page.h */ #if defined(WANT_PAGE_VIRTUAL) void *virtual;\t/* Kernel virtual address (NULL if not kmapped, ie. highmem) */ #endif /* WANT_PAGE_VIRTUAL */ #ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS int _last_cpupid; #endif } _struct_p 第三章 页表管理 # __startup_64初始化64位机器\n第四章 内存的分配和管理 # 在64位下已经没有高端内存的概念了，为什么还需要vmalloc？\n物理内存的分配 # 虚拟内存的分配 # vmalloc # brk # 第六章 页缓存和块缓存 # 几种不同的同步方案：\n不同的线程，比方说pdflush线程，周期性激活，将缓存的内容写回 pdflush线程的第二种运作方式，缓存中修改的数据项显著增加，则执行写回 用户态提供了各种系统调用诸如sync来让系统 块缓存的两种结构，\npage_cache_alloc分配一个即将加入页缓存的新页分配数据结构。\nadd_to_page_cache添加页面到页缓存\nfind_get_page获取缓存页，使用基数树保存所有的基数树时很有用\n在页上等待，回写的页会标记PG_writeback标志位\n第七章 交换管理 # 页面的回收并不能等到不够了再开始，每次kswaped都是在到达low水位开始工作，到min产生direct 回收，到high则停止回收。\n缓存也不是一上来就近lru_list而是现在PER_CPU的pagevec里面放着。\n那么何时会进行内存的回收呢？\nsynchronous page reclaim，即当遭遇分配内存失败的时候，一言不合，然后直接调用page frame reclaiming进行回收。例如：在分配page buffer的时候（alloc_page_buffers），如果分配不成功，直接调用free_more_memory进行内存回收。或者在调用__alloc_pages的时候，如果分配不成功，直接调用try_to_free_pages进行内存回收。当然，其实free_more_memory也是调用try_to_free_pages来实现页面回收的。 Suspend to disk（Hibernation）的场景。系统hibernate的时候需要大量内存，这时候会调用shrink_all_memory来回收指定数目的page frame。 kswapd场景。Kswapd是一个专门用来进行页面回收的内核线程。 slab内存分配器会定时的queue work到system_wq上去，从而会周期性的调用cache_reap来回收slab上的空闲内存。 内存回收的策略是什么？\n没有办法回收的page frame。包括空闲页面（已经在free list上面，也就不需要劳驾page frame reclaim机制了）、保留页面（设定了PG_reserved，例如内核正文段、数据段等等）、内核动态分配的page frame、用户进程的内核栈上的page frame、临时性的被锁定的page frame（即设定了PG_locked flag，例如在进行磁盘IO的时候）、mlocked page frame（有VM_LOCKED标识的VMA） 可以交换到磁盘的page frame（swappable）。用户空间的匿名映射页面（用户进程堆和栈上的page frame）、tmpfs的page frame。 可以同步到磁盘的page frame（syncable）。用户空间的文件映射（file mapped）页面，page cache中的page frame（其内容会对应到某个磁盘文件），block device的buffered cache、disk cache中的page frame（例如inode cache） 可以直接释放的page frame。各种内存cache（例如 slab内存分配器）中还没有使用的那些page frame、没有使用的dentry cache。 除此之外，还有一些达成共识的东西：\n尽量不要修改page table。例如回收各种没有使用的内核cache的时候，我们直接回收，根本不需要修改页表项。而用户空间进程的页面回收往往涉及将对应的pte条目修改为无效状态。 除非调用mlock将page锁定，否则所有的用户空间对应的page frame都应该可以被回收。 如果一个page frame被多个进程共享，那么我们需要清除所有的pte entry，之后才能回收该页面。 不要回收那些最近使用（访问）过的page frame，或者说优先回收那些最近没有访问的page frame。 尽量先回收那些不需要磁盘IO操作的page frame。 为了能够降低对于active_list和inactive_list的操作(因为频繁操作产生竞争)，因此在两者之间加了一个一个LRU cache，使用了pagevec的缓冲，用来\n交换区 # 缓存区创建的步骤由用户空间工具mkswap创建，激活交换区则需要使用系统调用sys_swapon\nlinux5.0的交换管理发生了一些变化，多了一些项：\nstruct swap_info_struct { unsigned long\tflags;\t/* SWP_USED etc: see above 是否使用等标志位*/ signed short\tprio;\t/* swap priority of this type 优先级*/ //交换区优先级 struct plist_node list;\t/* entry in swap_active_head */ signed char\ttype;\t/* strange name for an index */ unsigned int\tmax;\t/* extent of the swap_map 交换区当前包含的页数，不仅计算可用的槽数，也包括因为块设备故障损坏或用于管理目的的槽位*/ unsigned char *swap_map;\t/* vmalloc\u0026#39;ed array of usage counts 包含的项数和交换区槽位数目相同，访问计数*/ struct swap_cluster_info *cluster_info; /* cluster info. Only for SSD */ struct swap_cluster_list free_clusters; /* free clusters list */ unsigned int lowest_bit;\t/* index of first free in swap_map 这个和下面这个都是用来提高交换区访问速度，直接知道可以用哪个的*/ unsigned int highest_bit;\t/* index of last free in swap_map */ unsigned int pages;\t/* total of usable pages of swap 交换区可用槽位的个数 */ unsigned int inuse_pages;\t/* number of those currently in use 已经使用的交换区*/ unsigned int cluster_next;\t/* likely index for next allocation */ unsigned int cluster_nr;\t/* countdown to next cluster search */ struct percpu_cluster __percpu *percpu_cluster; /* per cpu\u0026#39;s swap location per cpu的交换位置*/ struct swap_extent *curr_swap_extent; /* 这个对应当前正在操作的缓存文件的list的位置，因为可能有多个相连，直接找到 */ struct swap_extent first_swap_extent; /* 这个对应于间隔的缓存文件，因为文件形式的缓存在地址上未必是连续的 */ struct block_device *bdev;\t/* swap device or bdev of swap file 交换设备，指向文件或分区所在底层快设备的block_device */ struct file *swap_file;\t/* seldom referenced */ unsigned int old_block_size;\t/* seldom referenced */ #ifdef CONFIG_FRONTSWAP unsigned long *frontswap_map;\t/* frontswap in-use, one bit per page */ atomic_t frontswap_pages;\t/* frontswap pages in-use counter */ #endif spinlock_t lock;\t/* * protect map scan related fields like * swap_map, lowest_bit, highest_bit, * inuse_pages, cluster_next, * cluster_nr, lowest_alloc, * highest_alloc, free/discard cluster * list. other fields are only changed * at swapon/swapoff, so are protected * by swap_lock. changing flags need * hold this lock and swap_lock. If * both locks need hold, hold swap_lock * first. */ spinlock_t cont_lock;\t/* * protect swap count continuation page * list. */ struct work_struct discard_work; /* discard worker */ struct swap_cluster_list discard_clusters; /* discard clusters list */ struct plist_node avail_lists[0]; /* * entries in swap_avail_heads, one * entry per node. * Must be last as the number of the * array is nr_node_ids, which is not * a fixed value so have to allocate * dynamically. * And it has to be an array so that * plist_for_each_* can work. */ }; 交换区的第一个槽位，用来存储交换一些交换特征。\n交换缓存 # swap cache是什么？交换缓存交换缓存是为了方便多个进程共享的内存页换入时能直到是否已经在内存中存在。\n换出时 换入时，换入页将停留在交换缓存，直到所有进程都从交换区请求该页，且知道该页在内存中的新位置。 具体用的结构是swp_entry_t\ntypedef struct { unsigned long val; } swp_entry_t; val里面的低60位，高5位为交换区标识符，代码直接定义了获取的具体type和offset的方法：\n结尾 # 唉，尴尬\n","date":"2021 年 1 月 24 日","externalUrl":null,"permalink":"/posts/2021-01-24-%E5%86%85%E5%AD%98%E5%AD%A6%E4%B9%A04-%E7%90%86%E8%A7%A3linux%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","section":"Posts","summary":"","title":"内存学习(4)-理解linux虚拟内存管理","type":"posts"},{"content":" 尝试翻译内存模型和缓存一致性 # 建议读者在阅读前搞明白缓存和计算机的一些基础知识，诸如缓存是怎么设计，缓存为何使用物理内存做标记，CPU的乱序指令，在指令队列和结果队列上是如何进行的。建议阅读《现代体系结构上的unix系统》和wiki百科。对内容有疑问建议直接stackoverflow或者看英文，对内容有异议可以直接回复我或者在github上发patch。\n第一章:内存一致性和缓存一致性引论 # 许多操作系统和大部分多和芯片(多核处理器)支持共享物理内存。在一个共享物理内存的系统中，每个核都可能读写同一个地址。这种设计的目标是追求良好的功效：比方说高性能，低能耗，低消耗()\n第二章：缓存一致性基础 # 本章我们会充分介绍缓存一致性来帮助理解强定序模型（也可被译为一致性内存模型，SC）如何和缓存交互。从2.1节开始我们会展示本书一直涉及到的强定序模型。为了简化本章节和其他章节的理论复杂性，我们选择最简单的系统模型来展示需要关注的重要事项；到第九章我们才会涉及到更复杂的系统模型。2.2讲述有哪些必须解决的缓存一致性问题及为什么会有缓存不一致问题出现。2.3节给出了缓存一致性概念具体的定义。（这里多赘述一点，X86硬件实现缓存一致性，而ARM并非如此！需要软件实现）\n2.1 基线系统模型(BASELINE SYSTEM MODEL) # 本书里，我们将系统视为一个拥有多个处理器，共享同一个物理内存，所有的处理器都可以对所有的物理地址进行载入和存储操作的模型。该基线系统包含一个单独的多核芯片和芯片外的物理内存，就如同图2.1展示的那样。多核芯片包含多个单线程的处理器，每个处理都有自己的私有数据缓存。每个核共享一个最低层级缓存（last-level cache (LLC) ）。当我们谈到“缓存”这个词，我们指的是每个核上的私有数据缓存而不是最低层级缓存。每个核的私有数据成员通过物理地址生成索引和标记，采取写回策略(注，不明白什么是写回策略的可以看《现代体系结构上的unix系统》)。处理器们和最低层级缓存使用交互网络（interconnection network）通信。尽管最低层级缓存也在处理器芯片上，但从逻辑角度来看，是个“内存部分缓存”(memory-side cache)，因此并不会导致任何缓存一致性问题。从逻辑层面来看，最低层级缓存直接和内存交互，提供降低内存访问延迟和增加内存访问带宽的功能。它同样充当（多处理器芯片的）片上内存控制器角色。\n我们的基线系统模型忽略了很多和本书内容无关，但是很常见的设计。这些设计包括指令缓存，多级缓存，多处理器共享一级缓存，虚拟地址缓存，TLB，DMA。同时，我们忽略包含多个多核芯片的系统。这些会添加不必要复杂度的话题，以后再说。\n2.2 关键问题：缓存不一致到底是怎样发生的？ # 缓存不一致之所以会出现是因为一个很基本的问题：多个角色可以并行地访问内存和缓存的入口。现代操作系统里，这些角色包括处理器，DMA控制器，和一些其他的可读写缓存和内存的外部设备。在本书里，我们将目光投射于处理器，但这并不意味可以无视处理器以外的角色。\n表2.1展示了一个缓存不一致的例子，一开始内存地址A和两个处理器的本地缓存都存储值42。在时刻1，处理器1改变了其缓存和内存地址A储存的值，从42变到43。这使得处理器2缓存里的值过时。处理器2在执行一个while循环的载入，重复地从它自己的本地缓存中载入已经过时的A的值42。很明显，这个缓存不一致的例子，是由于处理器1对A的储存行为，对处理器2是不可见，而导致的。\n为了避免这种缓存不一致问题，系统必须实现缓存一致性协议（cache coherence protocol ）才能保证处理器1的结果对处理器2是可见的。设计和实现缓存一致性协议是第六章-第九章的主要话题。\n2.3 缓存一致性协议接口 # 通俗的说，缓存一致性协议必须保证写操作对所有的处理器可见。本节，我们会正式地从缓存一致性接口中抽象出缓存一致性协议。\n处理器通过缓存一致性协议提供的两个接口来进行交互：(1)读请求(read-request)，该请求将内存地址作为参数，该请求的结果是向处理器返回一个值。(2)写请求(write-request)将内存地址作为参数1，将要写入的值作为参数2，该请求的结果是向处理器返回一个确认值。\n无论是学术还是工业界，目前已经由许多缓存一致性协议出现，我们会根据这些缓存一致性协议提供的接口进行区分，具体来说就是通过缓存一致性是否和内存一致性密不可分来区分。\n一致性不可区分协议 这种协议，执行写请求时，即使没有返回确认，写入的结果立刻对其他核可见。因为写操作是同步传播的，第一种缓存一致性协议就如同工作在一个原子操作内存系统上(缓存仿佛不存在一样)。任何和这种缓存一致性协议交互的子系统-比方说处理器管线-可以认为它正在和一个没有缓存的原子操作内存系统交互。从追求实现代码顺序一致性的角度来看，这种协议免去了程序员对多核系统中变量值不同的担忧。这种缓存一致性协议将缓存透明化，仿佛移除了缓存的存在，只有原子操作内存系统。这种协议的实现，将问题丢给了处理器管线（硬件）解决。 一致性可区分协议 这种协议的写结果是异步传播的，因此写操作的确认可能在其他核可见之前就返回给当前核，从而可以在其他核上观测到过期的变量。然而，为了不违背内存一致性的要求，这种类型的缓存一致性协议必须保证写入的值所显示的顺序，和写入操作写入的顺序是一致的（我理解为，如果写入操作的顺序是a,b,c,d,e，那么其他核看到的顺序也得是a,b,c,d,e。不能出现a,d,c,b,e这种混乱的顺序）。图2.2中，处理器管线和缓存一致性协议一起努力实现内存一致性。第二种类型的缓存一致性多见于GPU。 本书主要关注第一种缓存一致性协议，第二种类型的协议到第十章才会讨论。\n2.4 缓存不变式 # 究竟缓存一致性协议应当满足什么不变式，才能使得缓存透明化，将物理内存和缓存系统抽象成一个原子内存系统呢？目前无论是工业界还是学术界，已经有多种缓存一致性的定义，我们可不想把他们都列出来。作为替代，我们会给出一种体现缓存一致性本质的定义。在侧边栏里，我们会讨论其他定义，展示他们和我们的定义有什么关系。\n我们将缓存一致性协议定义为满足单写多读不变式（SWMR(single-writer–multiple-reader )）的协议。任何一个时刻，对于特定的内存地址，在任何一个时刻，如果该地址的内容只被一个核修改，不存在其他核也在同时进行读或写操作，或者（这个或者对应于那个“如果该地址”）此时没有任何一个核进行写操作，多个核在对这块地址进行读操作。换另一种说法，对任何内存块而言，该块的生命周期被分为多个周期。每个周期里，该内存块只会处于两种状况：一种状况是只有一个核拥有读+写权限，另一种状况是有多个核(也可能一个都没有)拥有只读权限。图2.3展示了将内存块生命周期拆分开的例子。\n除了SWMR不变式，缓存一致性协议同样要求操作内存块值的行为可以被正确的传播（）。设想图2.3中的例子，即使满足了SWMR不变式，如果第一个只读周期，核2和核5读到了不同的值，那么系统就不满足协议一致性了。相似地，如果核1没能成功读取核3在读+写周期写入的值，或者核1，核2，核3没能读取到核1存储的值，协议一致性再次被打破。\n因此，必须满足SWMR不变式和数据值操作正确(Data-Value Invariant )不变式才能满足缓存一致性协议，数据值操作正确不变式保证了处理器在读周期，能正确读到该内存块处于读+写周期时最后写入的值。\n其他的缓存一致性协议不变式的定义和我们的大同小异。（下面的翻译是我胡编的）虎符协议，只有拿到所有的虎符才能执行调兵操作（写操作），否则只能执行报数操作（读操作）。在任意时刻，只可能有一个调兵操作（写操作）或者多个报数操作（读操作）。\n2.4.1 实现缓存不变式 # 上一节提到的几个不变式暗示了缓存一致性协议如何工作。大部分缓存一致性协议，被称为“无效化协议”，就满足这些不变式。如果一个核想读取一块内存，就向其他核发送消息请求获取该内存块的值并确保不会有其他核已经缓存了这个内存块的值，且（其他核）处于读+写状态。该消息会终止任何当前活跃的读+写状态，并开始一个只读周期。如何该核相对某个内存块写，它会对其他核发送请求获取该内存块的值，并确定其它核没有缓存该内存块，无论他们是出于只读还是读+写状态。该请求会终止任何活跃的读+写或只读的周期，并开始一个新的读+写周期。后续的章节(6-9章)拓展了这种协议的抽象模型，但实现一致性基本的理念不变。\n2.4.2 缓存的粒度 # 一个核可以以多种粒度执行载入和储存操作，粒度一般从1-64字节浮动。理论上来说，缓存一致性可以以任意粒度执行。然后现实环境里缓存一致性的粒度经常和缓存块大小保持一致\u0026mdash;真实硬件以缓存块长度实现缓存一致性。对真实硬件而言，基本不可能出现一个核修改缓存块的第一个字节，其他核修改该缓存块的其他字节(对缓存的修改通常都是整行的，从实现角度和理论角度，效率更好实现简单)。尽管以缓存块长度为缓存一致性实行的粒度更为普遍，我们需要认识到缓存一致性协议可以以其他粒度实现。\n2.4.3 缓存一致性何时重要 # 无论我们选择如何定义缓存一致性，缓存一致性只在特定情况下至关重要。架构设计者必须清楚缓存一致性是否生效。我们指出两条缓存一致性的准则(我理解为缓存一致性提供的保证)。\n缓存一致性对任何层级的缓存和共享物理内存都适用。这些结构包括L1数据缓存，L2级别缓存，共享的LLC，和主存。此外诸如L1指令缓存和TLB同样适用。(这句话需要注意，这些结构并不包含per core write buffer，也就是每个核的写缓存器。写缓冲器和L1/L2/LLC cache并不是一个东西，如果这个不清楚，看TSO和PSO的时候会产生很多疑问) 缓存一致性对程序员是透明的。处理器管线(pipeline)和一致性模型一同努力提供强定序的内存模型，程序员只能注意到强定序的内存模型。 第三章 顺序一致性 # 本章研究内存顺序一致性模型，该模型给程序员和实现者定义了共享物理内存的系统在程序执行时，应当提供什么样子的时序：程序员知道系统可以提供什么样子的时序，实现者知道系统应当提供什么样子的时序。我们先在3.1节给出为什么要定义内存行为，3.2节给出内存一致性模型应该做些什么，3.3节对比内存一致性和缓存一致性。\n我们之后研究最直观的一致性模型强定序，或者说顺序一致性模型。强定序之所以重要，一方面是因为该模型是很多程序员期待的共享物理内存提供的模型，另一方面是因为它是理解下两章弱内存序模型(宽松内存序模型)的基础。我们现在3.4节给出强定序的基本理念，然后给出形式化定义(3.5节)。3.6节讨论强定序的实现，3.7节讲解基于缓存一致性的强定序，3.8节讲解更激进的优化，3.9节讲解强定序下原子指令的实现。3.10和3.11节我们研究MIPS R10000的现实例子，并给出一些参考资料。\n3.1 共享物理内存时的行为问题 # 为了理解为什么需要定义共享物理内存时，操作内存哪些表现是正常的，看表3.1中双核处理器的例子(这个例子，和本章所有其他例子一致，都认为变量的初始值为0)：大部分程序员会期待核C2的寄存器r2会获得值NEW。然而，一部分现代计算机系统上，r2的值可以为0。\n硬件如果重排核C1的两条存储指令S1和S2，就会导致r2获得0值。如果我们只看核C1的执行，不关心和其他线程的交互，那么重排S1和S2似乎没有什么问题，因为两者访问的是不同的地址。18页的侧边栏描述了硬件可能以怎样的方式重排指令，储存操作自然也在这些指令中。\n伴随着S1和S2的重排，指令执行的顺序可能为S2，L1，L2，S1\u0026ndash;如同表格3.2所示。\n这种指令执行的顺序满足缓存一致性，它并没有违背SWMR不变式。换言之，违背缓存一致性并不是导致这个显而易见错误的原因。让我们考虑用于提供互斥(mutual exclusion，详情参加《多处理器编程的艺术》修订版)Dekker算法提供的例子，该例子如同表3.3所示。在指令执行之后，r1和r2中的值可能是多少？下意识地，读者可能认为会是下面三种值：\n(r1, r2) = (0, NEW) 执行顺序为 S1, L1, S2, then L2 (r1, r2) = (NEW, 0) 执行顺序为 S2, L2, S1, and L1 (r1, r2) = (NEW, NEW), 执行顺序为 S1, S2, L1, and L2 令人惊讶的是在大部分机器上，比方说intel和AMD提供的X86系统上，由于FIFO写缓冲器的存在(这部分请看后面的章节，现在不明白无所谓)，(r1, r2) = (0, 0) 的情况同样可能出现。\n一些读者难以对这个例子表示认同，他们认为如果这个例子是正确的，那么程序执行的结果岂不是不固定了？这对于编程者来说也不是一个明确的编程模型。然而，现代多处理器体系结构的执行流本身就是不确定的，所有我们知道的体系结构又允许指令并行执行（流水线执行）。执行结果是否确定是由线程之间明确的进行同步操作来保证的，因此当定义什么是共享物理内存的多处理器机器正确的内存模型时，我们必须认可执行结果可能有多种正确的答案。\n更一般地来讲，内存表现出来的结果通常要适用于所有的应用程序执行的结果，即使这些程序执行的是错误的操作/复杂的操作（比方说非阻塞算法）。然而在第五章，我们会看到一些高层语言模型确实允许一些执行的结果出现未定义的行为，换言之面临data race。（实际上是弱内存序，看到第五章就明白咋回事了）\n3.2什么是内存一致性模型 # 内存一致性模型，或者说内存模型是一种技术规范，该技术规范指明了多线程程序操作共享的物理内存时的合法行为。对多线程程序而言，它指明了该执行过存储操作的多线程程序，动态的载入会返回什么样的值。和单线程程序执行不同，有多种正确的行为。\n通俗的说，内存一致性模型MC(memory consistency)将指令操作分为遵守MC和不遵守MC两种。这种划分从指令执行角度划分，相对应的也可以从实现角度划分。一个MC实现系统指的是该系统只允许遵守MC的指令，一个非MC实现系统值得是该系统有时允许非MC指令的执行。\n从一开始，我们一直假设程序执行硬件指令集中的指令，此外我们假设内存通过物理内存进行访问(也就是说，我们不关系虚拟内存和地址翻译的影响)。第五章我们会讨论高层次语言(high-level languages (HLLs) )，我们将会发现编译器如果在编译分配变量的指令时，把寄存器指定为该变量，会导致该高层语言内存模型类似的行为类似硬件重拍内存访问顺序(翻译存疑)\n3.3 内存一致性VS缓存一致性 # 第二章使用两个不变式给出了缓存一致性的定义，我们在此非正式地重复一下。SWMR不变式确保在任何时候，对于一个给定地址的内存位置，要么(a)一个核心可以写（和读）这个地址，要么(b)0个或更多的核心可以只读它。数据-值不变式（data-value invarient)确保对内存中数据的更新可以被正确传递，从而内存中对该数据的缓存副本总是包含最新版本的value。\n缓存一致性似乎可以定义共享内存的正确行为？其实不然。从图3.1中我们可以看到，一致性协议只是为处理器核心管道提供了一个内存系统的抽象（换言之就是只是提供了几个核对内存当中行为操作的合法规定，并不能决定着写操作的顺序和具体表现）。它并不能单独决定共享内存最终表现出来的行为；指令流水线在决定最终表现出来的行为时也起了很大作用。比方说，如果流水线（pipeline，我理解是指令pipeline）重新排序，并采用和程序顺序相背的顺序提交内存操作\u0026ndash;即使一致性协议正确地完成了它的工作\u0026ndash;共享内存的所表现出来的结果，可能斌不会如同我们期待的一般。\n总结来说：\n缓存一致性不等同于内存一致性 内存一致性可以将缓存一致性视为一个非常有用的黑盒（就是指关注结果，不关注实现） 3.4 内存一致性的基本想法 # 最直观的内存一致性模型是强定序SC。它首先由Lam-port[12]正式提出。我们现在来给出内存一致性的基本定义，对单核而言，强定序（SC）为 “单纯看指令执行的结果，就好像指令按照程序执行的顺序（指令序）执行”，然后再定义了多核顺序一致性“指令执行的结果，看起来就好像多核按照某种时序执行，同时每个核指令执行的顺序同程序指定的顺序一致”。将所有指令真实的执行顺序被称为内存时序(memory order)。在内存一致性的强定序SC模型中，内存时序不违反任何一个核上执行的程序顺序，但其他一致性模型可能并不总会保证内存时序和程序顺序一致。\n图3.2展示了表3.1中示例程序如何执行，中间的竖线代表真实的执行顺序就是内存序，每个核的竖线代表程序序，我们使用运算符\u0026lt; m代表内存序先发生，所以op1 \u0026lt;m op2代表o1 在内存序上先于op2发生。同样地，我们使用操作符\u0026lt;p来代表每个核的程序顺序，所以op1 \u0026lt;p op2意味着在该核的程序顺序中op1先于op2发生。在SC下，内存顺序符合（原本是respect）每个核的程序顺序。\u0026ldquo;符合 \u0026ldquo;指如果op1 \u0026lt;p op2那么op1 \u0026lt;m op2。注释中的值（/* \u0026hellip; */）给出了加载或存储的值。这段程序执行结束时，r2的值为new的。更一般地说，表格 3.1中程序的所有执行结果都伴随着r2的值为new。唯一的非确定性\u0026ndash;L1从flag中获得SET值之前取到0的次数\u0026ndash;是不重要的。\n这个例子说明了强定序的价值。在第3.1节中，如果你预期r2最终的结果为NEW的，那么你可能就已经隐约意识到了强定序，只不过没有Lamport那么精确而已。 图3.3进一步揭示了强定序的价值，它展示了表3.3中程序的四种执行流程。图3.3a-c描述了对应于三个直观输出的SC执行情况。(r1, r2) = (0, NEW), (NEW, 0), 或 (NEW, NEW)。请注意，图3.3c只描述了导致（r1, r2）=（NEW, NEW）的四种可能的强定序执行顺序中的一种；这里的执行顺序是{S1, S2, L1, L2}，其他的是{S1, S2, L2, L1}，{S2, S1, L1, L2}，以及{S2, S1, L2, L1}。因此，在图3.3a-c中，有种合法的强定序执行顺序。 图3.3d显示了会导致（r1，r2）=（0，0）结果的一个非强定序执行流程。对于这个输出，没有办法创建一个符合程序顺序的内存序。程序序显示：\nS1 \u0026lt;p L1 S2 \u0026lt;p L2 但内存序显示：\nL1 \u0026lt;m S2(所以r1为0) L2 \u0026lt;m S1(所以r2为0) 考虑到所有这些约束条件的结果会导致一个循环，与执行的顺序是相背的的。图3.3d中的额外弧线说明了这个循环在哪里。 我们刚刚看到了六个强定序的执行流程和一个非强定序的执行流。这可以帮助我们理解强定序的实现：一个强定序的实现必须允许前六个执行中的一个或多个，但不能允许第七种执行流程。\n3.5 强定序的简单定义 # 在这一节中，我们将给出强定序的定义，从而方便我们能够将强定序与接下来两章中的较弱的内存一致性模型进行比较。我们采用Weaver和Germond使用的符号\u0026ndash;这是一种指定一致性的公理方法，我们将在第11章中详细讨论：L(a)和S(a)分别代表对地址a的加载和存储。顺序\u0026lt;p和\u0026lt;m分别定义了程序序和全局内存序，具体些就是程序序\u0026lt;p是每个核逻辑上（顺序上）执行内存操作的顺序。全局内存顺序\u0026lt;m是对所有核上表现出来的内存操作的真实顺序。 一个抢定序的执行需要以下条件。\n（1）每个核其储存和载入操作的全局顺序，遵守该核上执行程序视角的顺序，无论他们是不是在操作同一地址\nIf L(a) \u0026lt;p L(b) ； L(a) \u0026lt;m L(b) /* Load-\u0026gt;Load */\nIf L(a) \u0026lt;p S(b) ； L(a) \u0026lt;m S(b) /* Load-\u0026gt;Store */\nIf S(a) \u0026lt;p S(b) ； S(a) \u0026lt;m S(b) /* Store-\u0026gt;Store */\nIf S(a) \u0026lt;p L(b) ； S(a) \u0026lt;m L(b) /* Store-\u0026gt;Load */\n（2）每一个核上对某物理地址执行的载入操作，都会获得从多核的视角出发(多核内存时序global memory order)，该载入操作之前发生的对该物理地址最近的储存结果。\n简单总结下，对于SC而言其指令的基本逻辑为：\n原子读-改-写（RMW）指令，我们将在第3.9节深入讨论，它进一步限制了可表现出来的执行结果。例如，每个tas指令的执行都要求表现出来的加载和存储的存储在逻辑上的顺序和内存序一致中（也就是说，在它们之间没有其他相同或不同地址的内存操作干扰，实际上就是cas不会有中间态）。\n我们在表3.4中总结了强定序的内存序表现出的行为。例如，如果一个给定的线程在程序序上表现出一个加载在一个存储之前（即加载在表中是 \u0026ldquo;操作1\u0026rdquo;，存储在表中是 \u0026ldquo;操作2\u0026rdquo;），那么这个交叉点的表项是一个 \u0026ldquo;X\u0026rdquo;，表示这些操作在内存序上表现的结果和程序序一致。对于强定序而言，所有的内存序都必须符合程序序；在其他的一致性模型下，我们在接下来的两章中研究，这些约束中的一些被放松了（也就是说，别的内存模型的内存序表中的一些条目不是 \u0026ldquo;X\u0026quot;了）。\n一个强定序的实现只允许强定序的指令执行。严格来说，这是强定序的安全保证（safety property不会造成恶劣的后果，我理解就是底线要求，最低级别的保证）。强定序的实现还应该提供一定的有效性保证（liveness proterty我理解就是高于底线的要求，就是附加的有利用价值的保证，这两个英文单词我原先搜索过大致理解意思，但是翻译得不好，建议读者自己google一下然后理解意思）。具体来说，一个store操作必须最终对反复尝试读该数据的load可见。这个属性被称为最终写传递，通常由一致性协议来保证。更一般地说，避免饿死和提供一定的公平性也是有价值的，但这些问题超出了我们对内存一致性的讨论。\n3.6 简单的强定序实现 # 有两种简单的强定序实现方便我们理解\n多任务并行单核处理器\n第一种实现方式：人们可以通过在单核（单处理器）上按照程序序执行所有线程来实现多线程用户级软件的强定序。线程T1的指令在核心C1上执行，直到上下文切换到线程T2，等等。在上下文切换时，在切换到新的线程之前，必须完成任何未决的内存操作。由于每个线程的指令在其执行流中作为一个原子块执行（并且由于处理器按照指令序执行），所有的强定序规则都不会被违背。\nThe Switch\n另一种实现方式，我们可以用一系列处理器、一个开关和内存来实现强定序，如图3.4所示。假设每个核按其程序序挨个向开关提交内存操作。每个核可以使用任何不影响其向开关提交指令内存序的优化措施。例如，可以使用一个简单的带有分支预测的五级指令流水线。\n这种实现，每次开关挑选一个核，允许其提交符合内存序的load/store操作，并且并且可以不断重复这个流程。开关可以以任何算法（例如随机）来挑选核，只要这些方法不会使得一些核被饿死即可。。\n评估\n这些实现的优点在于他们实现了一种能同时提供（1）指令级别强定序（2）实现强定序的一种标准模型。switch体系证明了强定序可以无需缓存或者缓存一致性而实现。\n这些实现的缺点在于，这些实现的性能并不同增长的核数成正比：第一种实现中单核存在性能瓶颈，第二种实现中switch和内存存在性能瓶颈。这些瓶颈导致部分人错误地认为强定序不可能实现真正的指令并行。我们接下来会看到事实并非如此。\n3.7 一个兼容缓存一致性的简单SC实现 # 缓存一致性有利于强定序的实现，它可以帮助我们实现并行地执行不冲突的load和store\u0026ndash;如果两个操作是指向同一个地址，并且其中至少有一个操作是存储的话，就会发生冲突。此外，从概念理解这样一个系统也很简单。\n在这里，我们把缓存一致性视为一个实现了第二章的SWMR不变性的黑盒。我们通过略微揭示这个黑盒的实现来展示一点L1 cache相关的的内容。\n使用状态修改（M）来表示一个L1cache可以执行写入和读取。 使用状态共享（S）来表示一个或多个内核可以读取各自的L1 cache 让GetM和GetS分别表示每个核尝试使自己的l1 cache获取M/S状态的一致性请求。 我们不需要深入了解缓存一致性是如何实现的，这一点在第6章及以后的章节中讨论。\n图3.5a描述了图3.4的模型，开关和内存被一个缓存一致性黑盒取代。每个核按其程序序一次向高速缓存一致性内存系统提出内存操作请求。该内存系统需要在满足同一核的下一个请求之前，先满足了每个已经发出的请求。\n图3.5b \u0026ldquo;打开 \u0026ldquo;了该内存系统的黑盒，显示出每个内核都连接到自己的L1高速缓存（我们将在后面讨论多线程）。如果内存系统对B块的加载或存储有适当的一致性权限（加载的状态为M或S，存储的状态为M），它就可以执行这个加载或存储。此外，只要相应的L1缓存有适当的权限，内存系统就可以并行地响应来自不同内核的请求。例如，图3.6a描述了四个内核各自寻求进行内存操作之前的缓存状态。这四个操作并不冲突，可以被各自的L1缓存满足，因此可以同时进行。如图3.6b所示，我们可以任意排列这些操作以获得合法的SC执行模型。更为普遍的是，只要L1缓存满足SWMR的操作总是可以并发进行，因为一致性的SWMR不变式确保了它们是不冲突的。\n总结下，我们已经实现了满足下面几条的强定序：\n充分利用了缓存的低延迟和总线带宽的优势。 与其所使用的高速缓存一致性协议一样具有可扩展性（我理解就是可以伴随核数增长而性能增长） 降低了实现多核环境实现缓存一致性的难度 3.8使用缓存一致性优化SC实现 # 不绑定预取\n预测处理器\n设想一个以指令序执行的处理器，该处理器同样进行指令预测，这些指令包含储存和载入执行，如果发生了指令错误预测这些指令也可能被无效化。这些无效的储存和载入看起来和预取比较类似，同样都对SC不会造成错误的影响。一个发生在分支预测之后的载入L1 CACHE，无论预测错误还是成功()都会向寄存器返回一个值。如果载入操作被无效化，处理器丢弃寄存器的更新，抹除任何载入引发的副作用，就好像没有执行载入操作一样。缓存则不需要撤销这次预取，一方面不必要，另一方面提前载入数据可以在再次请求这块地址时提高性能。执行储存时，处理器可能执行GetM请求，但在确定执行储存之前不会将缓存里的结果更新。\n提问：一个实现SC的系统，处理器发布缓存一致性的请求时，这些请求必然符合指令序吗？答案：错，CPU可以以任意顺序发布缓存请求。\n指令乱序处理器\n说起来这个解释起来并不简单，建议直接看原版论文https://courses.engr.illinois.edu/cs533/sp2019/reading_list/gharachorloo91two.pdf\n每个Load指令都是从memory到L1 cache\nGharachorloo et al提供了两种保障多核下SC的检查。1如果处理器先执行了L2，在它提交L2的请求，并真正使用L2载入的数据之前之前，检查L2的缓存是否依然存在。只要缓存还在，那么L2的值不可能在执行载入和提交之前发生改变(因为SWMR，但我没理解。既然是载入，那么怎么会有提交呢，唯一可能的即使就是提交到Cache)。为执行此检查，处理器跟踪L2的地址并检查该物理地址关联的内存块和缓存一致性请求。一个GetM请求暗示另一个核注意到L2失序，该请求说明预测失败，需要抹消该无效预测（如果没明白为什么一个GetM会导致请求失效，建议看看SC的第二个要求，即Load要返回它之前最近的Store操作。举个例子）。\n另一种方法是通过重放，如果先执行L2，在L1执行完毕之后L2的值和缓存里的值保持一致，那就说明改变顺序是没有影响的，因为值是一样的。\n这两种做法从本质来说就是提前执行某个load，只要结果是不干扰执行的\n指令乱序处理器的预取\n多线程\n3.9 SC模型的原子操作 # 编写多线程代码时，程序员应该能够同步多线程的读写(同步的意思是指使线程操作操作在时间上出现一致性和统一化的现象，对程序员而言，并不是指同时发生，而是有先后顺序的发生)，这些同步性常常需要进行一对操作。这种操作通过提供原子级别的读改写指令实现。读改写RMW(read-modify-write)对正确实现同步机制，自旋锁与其他同步优先级至关重要。\n更激进的RMWs实现利用SC只需要将请求保持特定顺序(不是很通畅)，一个核将其缓存中特定的block置为状态M，即可执行读改写操作。直到任何其他一致性缓存消息对该block生成。\n3.10 真实的例子MIPS R1000 # 3.11 强定序的更多资料 # 第四章 # 4.1 TSO/X86设计的缘由 # 处理器很早就支持利用写缓冲器(write (store) buffers )去延时(hold)已经提交(commited/retired)，但还没进入缓存(cache)的储存操作。当提交储存操作时，载入操作进入写缓冲器。直到该内存块的内容以获得读+写的周期写入缓存时，才会将该储存操作从写缓冲器中取出。很显然，储存操作进入写缓冲器可以发生在获取对该内存块的读+写周期，写缓冲器因此降低了一次储存失败延迟。由于储存操作是如此常见，延迟写入看起来很有益，最妙的是，储存操作尝试跟新内存的操作不会干扰处理器状态，不会使得处理器停止继续执行指令。\n4.4.1 实现原子指令 # 在TSO体系中实现原子级别读改写指令和强定序体系中实现原子级别读改写指令的操作基本一致。关键的不同只在于TSO体系下允许载入操作从时间序看来比指令序在它之前的储存操作先执行。对读改写指令造成的影响就是储存操作可能被写到写缓存器中。\n为了更好的理解TSO体系中的读改写指令，我们将读改写指令视为一对紧密结合的载入操作和储存操作。\n读改写指令的读指令部分不能比指令序在它之前的读指令先执行，这没有什么难以理解。但读者可能在为深入思考的情况下，认为读改写指令里的读指令会比已存在于写缓存器里的写指令更早执行，真实情况并非如此。如果读改写的读指令部分时序上早于写缓存器里的指令，那么紧随读指令部分执行的写指令部分会比写缓冲器中的写指令更早执行，这违背了TSO体系上STORE-STORE指令的执行序。因此读改写指令的读部分不能早于一个指令序上早于它的储存指令。\n这些时序的要求限制了读改写指令的实现，由于读改写的读指令部分必须晚于写缓冲器里的写指令，因此原子级别读改写指令会在执行读指令部分之前将写缓存器清空（使内部的写指令执行完）。为了能够是的写操作部分紧跟读指令部分，该读指令会尝试获取读+写的缓存权限，普通的读指令往往只需要读权限。最后为了保证读改写指令的原子性，缓存控制器可能不会\n给出TSO的结果模型：\n第五章 弱内存序 # 上两章我们探索了强定序(SC)和完全存储定序(TSO)。\n本章我们探寻一种时序限制更弱的内存一致性模型，这种模型只保留程序员“需求”的指令序。这样子的好处blablabla\n完全探索这种模型超出本章的内容，本章只是一个提供一种基本的指引，帮助读者理解这种体系的限制。为此，我们以XC(5.2)为例，讨论XC的种种实现。这些实现包括原子指令。\n5.1 动机 # 理解弱一致性内存模型可比理解强定序和完全存储定序困难多了。既然有如此多的不便，干嘛折腾弱一致性内存模型？本节我们首先展示一些指令序并不是那么至关重要的例子，然后讨论下指令序不重要时一部分优化操作。\n5.1.2 利用重排序的机会 # 假设一个弱内存一致性模型可能重拍所有没有内存栅栏分割的指令，因此程序员必须清楚哪些指令必须被固定顺序。对程序员而言，这是个缺点，但对计算机而言这可能更便于优化。下面我们讨论一些普遍而且重要的优化，更深入的话题就不在本书中讨论了。\n5.1.2.1 非先进先出，合并式写缓冲器 # 上一章中完全存储定序使用写缓冲器来降低写操作的延迟。相比于使用先进先出写缓冲器的完全存储定序，弱内存一致性模型采用了优化性更彻底的可合并非先进先出写缓冲器（即两个指令序不相邻的写操作可以合并到一起添加到到写缓冲器中）。这种可合并非先进先出的写缓冲器和完全存储定序体系中要求必须先进先出的存储相违背。我们提供的弱内存序体系中只要两条写指令不被栅栏分割，那就可以合并添加到可合并非先进先出写缓冲器里。\n5.1.2.2 简单的指令预测 # 强定序和完全存储定序模型里，处理器可以预测接下来要执行的指令，从而能够提前执行某些指令。从表现结果来看，类似乱序执行接下来的指令，当然执行这些指令的结果在确定这些指令应当执行之前并不会提交。这种预测和检测机制增加了硬件的性能消耗和复杂度。除了多消耗了计算资源，这种机制意味着指令级别的并行被某些有限状态资源所限制。弱内存序体系中，处理器可以无视指令序和缓存一致性请求（其他核发出来的）请求执行载入命令。在弱内存序里，这些载入操作是否执行是不可预测的(尽管它们可能通过分支预测) 这段话实际上有个问题，就是在问，弱内存序里，在某些指令不被确定是否执行前，载入操作的结果会不会提前commit?这里需要区分内存序指令序。建议阅读https://stackoverflow.com/questions/52215031/how-is-load-store-reordering-possible-with-in-order-commit和https://stackoverflow.com/questions/39670026/out-of-order-instruction-execution-is-commit-order-preserved。除此之外，典型的弱内存序ARM里面指令交互相关建议看这个网页https://azeria-labs.com/memory-instructions-load-and-store-part-4/。这里我建议想一想这一点，无论哪种内存序，只保证线程执行的结果和单线程执行的结果保持一致，这里单线程和结果是重点。\n5.2 一个弱内存序例子 # 5.2.1 XC模型的基本理念 # XC的内存序会保证一下指令序不会被重拍：\n载入 =\u0026gt; 屏障 储存 =\u0026gt; 屏障 屏障 =\u0026gt; 屏障 屏障 =\u0026gt; 载入 屏障 =\u0026gt; 储存 此外，XC对于两条相同指令的操作不会重排，这和完全存储定序保持了一致：\n载入 =\u0026gt; 载入 (对相同地址) 载入 =\u0026gt; 储存 (对相同地址) 储存 =\u0026gt; 储存 (对相同地址) XC同样保证，同一线程里，对某地址内存块执行载入操作，会获取该线程载入操作之前的对相同地址的储存指令的结果。因此上面应该可以加上一条 储存 =\u0026gt; 载入 （相同地址），但因为这种操作因为正式来说属于分流(bypass)，所以没写到上面。\n5.2.2 在XC模型下使用栅栏的例子 # 屏障F1保证了指令的时序，看起来很有用。但一部分读者诧异于屏障F2的作用。\n5.3 实现XC模型 # 本章节讨论实现XC。我们会沿用前两章实现强定序和完全存储定序的方法-将指令重拍和缓存一致性协议拆开，来设计实现XC模型。在完全存储定序中，每个核和缓存系统之间都添加了一个先入先出写缓冲器。对于XC模型而言，每个核和缓存系统之间都会添加一个重排单元，该重排单元会将储存和载入操作重排。\n如同图5.3a描述的那样，XC运行符合：\n载入，储存，屏障按照程序指令序\u0026lt;p离开每个核Ci，并进入每个核Ci的重排单元的尾部。 每个核的重排单元会处理并将操作从队尾挪到队头，处理操作的顺序要么按照程序指令序，或者根据下面的几条规定将指令重排。一个屏障在到达重排单元的头部被丢弃。 当switch选择执行核Ci的操作时，它会执行核C重排单元队头的操作。 重排单元重排操作时，遵循三种规则：\n屏障\u0026mdash;屏障可以通过多种方式实现，但是他们必须正确实现操作排序。尤其是在操作的目标地址不同时，重排单元不能执行重排操作，保证原本的顺序，这些顺序包括：载入 =\u0026gt; 屏障，储存 =\u0026gt; 屏障，屏障 =\u0026gt; 屏障，屏障 =\u0026gt; 载入，屏障 =\u0026gt; 储存 对相同地址的操作：对相同的地址的操作不允许被重排，这些操作包括：载入 =\u0026gt; 载入 (对相同地址)，载入 =\u0026gt; 储存 (对相同地址)，储存 =\u0026gt; 储存 (对相同地址) 分流：必须保证对相同地址的load能看到之前store的结果。 上面的规定并不奇怪，它们只是5.2.3节的规则换了一种表述。\n上两章，无论是强定序还是完全存储定序，我们都使用缓存一致性内存体系替代了switch和内存体系。正如图5.3b所示，这对于XC同样适用。缓存一致性协议实现了全局的内存序，但和原先不同的是，全局的内存序可能会由于重排单元的存在而和指令序大为不同。\n那么从完全存储定序提升到XC模型，性能提高了多少呢？很不幸，这个答案和5.1.2节讨论的内容相关，诸如先进先出写缓冲器和可合并非先进先出写缓冲区性能比较？分支预测支持几何？\n5.3.1 在XC模型中实现原子指令 # 在支持XC模型的系统中实现原子级别读改写有很多方法。实现原子级别读改写的方法同样依赖于系统是如何实现XC模型的。本节中，我们假设XC系统包含多个指令乱序处理器，每个指令乱序处理器通过一个可合并非先入先出写缓冲器和内存相连。\n另一种实现原子级别读改写并不在本书讨论的范围里，表格5.6中，我们展示了一种典型的临界区操作，自然也包括锁争用和锁释放。对完全存储定序，原子级别读写操作用来获取锁，储存操作用来释放锁。对XC模型，情况变的更为复杂，XC模型并不强制要求原子级别读改写晚于临界区代码执行，因此必须在获取锁的代码之后加个屏障，锁释放同样要在之前加一个屏障，避免锁释放的操作和临界区操作被重排。简而言之，锁的使用必须通过屏障保护。\n5.3.2 在XC模型中实现屏障 # 不同体系里屏障的实现方法有三种：\n对强定序而言，所有的屏障都可被视为空转(no-ops)。 另一种实现方式是将Xi所有的内存操作执行完毕后，认为屏障已经起作用了，然后再开始执行Yi的操作。这种方式，通俗形容起来和“将缓冲器排空，再写入操作”一样，是一种非常常见但耗费昂贵的实现方式。 另一种实现方式无需“将缓冲器排空”，只保证必须执行的一致性操作执行完毕。这种方式并不在本书设计的范围里。尽管这种方式设计实现起来比较困难，但比“将缓冲器排空”带来更好的性能。 无论上面哪种情况，屏障必须能够清楚何时Xi执行完毕，对于一个常常分流缓存一致性的储存操作而言，知道何时执行完毕的方法可能十分巧妙。\n5.3.3 警告 # 一个XC模型的实现者可能会认为：我在实现一个弱内存序模型，所以最终的时序了无限制。事实并非如此，XC的很多规范必须被遵守，\n5.4 实现无竞争的一致性程序 # to have their cake and eat it too. 想要鱼和熊掌兼得。\nYou can\u0026rsquo;t have your cake and eat it (too) 鱼和熊掌不可兼得\n幸运的是，对数据无竞争(data-race-free（DRF）)程序而言，实现这两个目标是可能的。通俗的来说，当两个线程同时访问同一块内存地址，其中一个线程在写数据，两个线程没有任何同步关系就会导致同步问题的出现。强定序下，数据无竞争程序的开发者只需要正确的标识同步操作就可以开发此类程序，在XC模型下，数据无竞争程序的开发者需要使用原子级别读改写和屏障来实现同步标签的同步工作。这种方法是诸如JAVA和C++的高级语言同步原语的基石。\n让我们来看看表5.6和表5.8提供\n从这两个例子中可以看出，“顺序一致性的数据无竞争”(DRF)概念包含以下含义：\n存在数据竞争的指令执行揭示了XC模型下的储存载入重排序，或者 如果想对“顺序一致性的数据无竞争(SC for DRF)”有一个更具体的理解，需要对以下概念有认识：\n一些内存操作被标记为“同步”（“同步操作”），其余默认被标记为“数据”（“数据操作”）。“同步”（同步操作）包含锁的获取和释放 两个不同核上对同一块内存的数据操作Di和Dj，只要其中有一个是储存，我们就称这两个操作“违背”。 两个不同核上对同一块内存（比方说锁）的同步操作Si和Sj，只要其中一个操作是写操作就称这两个操作“违背”（对于自旋锁的获取和释放都是违背，而两个对读写锁的读锁并不违背） 两个同步操作Si和Sj，只要两个操作直接“违背”或者Si和Sk“违背”，而Sk和Sj在同一个核上执行，且Sk的指令序早于Sj，我们就说这两个操作“及物违背”。 两个数据操作Di和Dj如果“违背”，且在全局的时序上没有一对及物违背的同步操作Si和Sj发生在两者之间，那么Di和Dj就发生了“竞争”。换句话说，一对违背的数据操作Di \u0026lt;m Dj并不会发生数据竞争，只要有一对及物违背的同步操作Si和Sj，满足Di \u0026lt;m Si \u0026lt;m Sj \u0026lt;m Dj。上面的两种说法，Di和Si在同一个核(线程)上，Dj和Sj在同一个核（线程）上。 一段满足顺序一致性的流程，只要不发生数据竞争，我们就称该流程满足“顺序一致性的数据无竞争”。 如果一个程序所有的流程都没发生争用，那么我们就称该程序是“顺序一致性的数据无竞争”的。 对XC模型而言，程序员或底层开发者需要使用屏障来确保同步操作执行顺序是正确的。\n5.5 一些弱内存序的术语 # 5.5.1 释放一致性 # 5.5.2 可视性和写原子性 # 可视性意味着“如果我看待某事发生，且告知了你，那么你也会看到”\n写原子性（也被称为储存原子性，多拷贝原子性）意味着“如果一个核执行了储存操作，那么所有其他核都能立刻看到”。XC模型的缓存一致性内存模型保证了其是符合写原子性的。写入之前，没有任何一个核可以看到新储存的值，写入之后，其他核只能看到两种情况：要么这次存储的新值，要么这之后存贮的值里的一种，而不能看到被这次存储覆盖的过去的值(这里面有两个含义：1写入以后，其他核只能看到新值，或者更新的值2写入成功之前，只有执行写入的核看到这个值，其他核看到的值都早于这个写入的值)。写原子性使得处理器可以比其他核更早的看到他自己存储的值，因此，有人认为这个名字的xxx\n写原子性存在意味着必然存在可视性，举个例子表格5.9里，核C2注意到S1，执行一个屏障，然后执行S2。因为满足写原子性，因此C3必然能看到S1 可视性存在并不能说明写原子性存在，举个例子表格5.10里，假设核C1和C3共享一个写缓冲区，而C2和C4共享一个写缓冲区。当C1把S1放入C1和C3的写缓冲器里，很明显只有C1自己和C3的L1可以看到。相似的，当C2把S2放入C2和C4的写缓冲器里，很明显只有C2自己和C4的L3可以看到。只要C3的L2和C4的L4在写缓冲器把两个储存操作写入缓存一致性内存之前，那么写原子性必然得不到满足。 总之，我们的XC模型提供了写原子性和可视性。由于写原子性暗示了可视性，所以我们以前只提及写原子性。建议继续阅读https://azeria-labs.com/memory-instructions-load-and-store-part-4/\n第六章 缓存一致性协议 # 6.1 全局视角看缓存一致性 # 一致性协议的目的是通过满足2.3节的两个不变式来提供缓存一致性。\nSWMR不变式 数值正确不变式 为实现这些不变式，我们将每个存储设备-每个缓存和LLC/物理内存-和一个有限状态自动机联系起来，并将结合了自动机的存储设备称为“一致性控制器(coherence controller )”。这些一致性控制器通过确保交换信息时满足SWMR和数据正确不变式的有效性，构建了一个分布式的系统。缓存协议规定了这些一致性控制器的互动通过制定。\n不同的一致性控制器有不同的职责。缓存部分的一致性控制器，我们称之缓存控制器，如图6.1一样工作。缓存控制器提供服务时必须满足两个方面的资源：在“处理器角度”，缓存控制器提供接口实现储存和载入功能，并返回对应的值。一次缓存缺失会导致缓存控制器发起一致性事务，这里是发起一个一致性请求请求获得处理器需求的内存块。缓存一致性请求在交互网络上传递。一致性事务包含一致性请求和其他的交换信息(比方说从其他缓存控制器返回的数据回复信息)，其他信息往往是为了满足一致性请求而产生。一致性事务和消息的种类和具体一致性协议密不可分。\n6.2 描述缓存一致性协议 # 6.3 缓存一致性协议的例子 # 6.4 总览缓存一致性设计 # 6.4.1 状态 # 系统如果只有一个角色，每个缓存的状态可以用有效/无效区分。有效的内存块又可以被划分成“脏”块\u0026ndash;该块的数据和其他的块拷贝相比，最后被处理器修改。举个例子，一个L1缓存采用写回策略的二级缓存，L1缓存中的数据可能是脏的，从而使得L2缓存的数据过时。\n一个有多个角色的系统可以使用这几种简单的状态，但我们常常想讲有效状态区分开。我们希望能够从四个角度将内存块的状态区分开：有效性，脏性质，独占性，和拥有性。后两者是SMP系统所独有的：\n有效性，一个有效的数据块，其内容（数据）必然是最新的。该数据块可读，但如果想可写需要再获得独占性。 脏性质，如同单核处理器一样，如果缓存的数据是更新过的，而LLC/物理内存的数据是陈旧的，缓存控制器因此有必要将此数据最终写回到LLC/物理内存里。脏性质的反义词是“干净” 独占性，如果该缓存里的内存块，是系统上唯一被缓存的拷贝(这句话暗指的意思是LLC中可能有该数据块) 拥有性，如果某缓存控制器负责应答该对内存块的缓存请求，我们就将该缓存控制器称为该内存块的拥有者。大部分协议中，每个数据块在某段时间都是有其拥有者的。一个内存块不会在其控制权被拥有者转让出去之前，因为容量不足和缓存行冲突，就把数据从缓存写回到内存里。 本节，我们先讨论常用的状态，\n许多缓存一致性协议使用Sweazey and Smith 第一次引入的五种经典状态MOESI 里的子集作为其状态。三个基础状态为MSI，O和E不属于基础状态，但也很常用。每个状态的特性并不相同，感觉需要英文做精确表述。\nM(odified): The block is valid, exclusive, owned, and potentially dirty. The block may be read or written. The cache has the only valid copy of the block, the cache must respond to requests for the block, and the copy of the block at the LLC/memory is potentially stale. M代表着数据是有效，独占，被当前缓存控制器拥有，有可能已经被修改了。 S(hared): The block is valid but not exclusive, not dirty, and not owned. The cache has a read-only copy of the block. Other caches may have valid, read-only copies of the block. S代表数据不被独占，不被缓存控制器拥有，不脏。 I(nvalid): The block is invalid. The cache either does not contain the block or it contains a potentially stale copy that it may not read or write. In this primer, we do not distinguish between these two situations, although sometimes the former situation may be denoted as the “Not Present” state. I代表无效，这个很好理解，没有或者说数据老旧。 O(wned): The block is valid, owned, and potentially dirty, but not exclusive. The cache has a read-only copy of the block and must respond to requests for the block. Other caches may have a read-only copy of the block, but they are not owners. The copy of the block in the LLC/memory is potentially stale. O状态是有效，被当前缓存控制器拥有，可能是脏的，但不是独占的。当前缓存控制器有用一份内存块的只读拷贝(这个状态的目的是啥呢？我理解是延缓写入内存，但是同样保持有效性，这个是比X86_MESI（见下）能够更晚写回内存的，由于S共享只读，但是不脏，因此如果要释放M状态的值需要写回内存，而O共享只读，可能脏，能够不写会内存，是M的一个简单退化，减少了性能的差异？) E(xclusive): The block is valid, exclusive, and clean. The cache has a read-only copy of the block. No other caches have a valid copy of the block, and the copy of the block in the LLC/memory is up-to-date. In this primer, we consider the block to be owned when it is in the Exclusive state, although there are protocols in which the Exclusive state is not treated as an ownership state. E状态是有效，独占，而且干净。当前缓存是只有内存块的只读拷贝，其他缓存块则没有改块的只读拷贝，LLC/物理内存的数据和缓存控制器里的块是一致的。 使用文氏图来表达其关系，四个特性是其集合，但是其内容并不是十分严格，Modified属于Dirtiness的子集吗？并不，Modified是有不被修改的可能的\n这里需要协商平时经常说的MESI状态：\nModified 当前cache的内容有效，数据已被修改而且与内存中的数据不一致，数据只在当前cache里存在 Exclusive 当前cache的内容有效，数据与内存中的数据一致，数据只在当前cache里存在 Shared 当前cache的内容有效，数据与内存中的数据一致，数据在多个cache里存在 Invalid 当前cache无效 讲平时的MESI称为X86_MESI，将MOESI称为LIB_MOESI，会发现：\nX86_M是LIB_M的子集，因为X86M是必然脏，而LIB_M是可脏可不脏的。实际上LIB_M是一种大的权限，是SMWR里的可读可写。 X86_E是LIB_E的同义词，两者都保证缓存和LLC/物理内存的数据一样新 X86_S是LIB_S的同义词， X86_I是LIB_I的同义词， X86里没有O这个状态，因为LIB_O里，如果一个数据不被当前缓存控制器独占的，但是被占有，是脏的。必然有一个曾经的M状态导致它脏，简答来说就是M和S能够保证O不被使用。因此X86实际上实现的是个简单的MOESI 让我来再细细的捋一下X86_MESI和LIB_MOESI的区别，这里使用一开始说的四个特点:\nX86_M=Dirtyness+Exclusivity X86_S = Validity+Cleaness+N_exclusivity X86_E = Validity +Exclusivity+Cleaness X86_I = Nothing Happen 6.4.2 事务 # 理论研究者和实际工作者的实现往往是不同的，平时说到缓存协议一般就是MESI协议\n结尾 # 唉，尴尬\n","date":"2021 年 1 月 11 日","externalUrl":null,"permalink":"/posts/2021-01-11-%E5%B0%9D%E8%AF%95%E7%BF%BB%E8%AF%91%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/","section":"Posts","summary":"","title":"尝试翻译内存模型和缓存一致性","type":"posts"},{"content":" 平凡的编辑剧情角色设计 # 属性值 # 口才(这个选项用于说服他人，比方说劝作者接受建议，和酒保交流，要不要改成魅力呢，也会影响其他认识的人对你的亲切感) 灵感(这个选项用于能够和作者角落作品的时候想到高明的建议) 敏感(这个属性用于发现一些的情况，比方说话外之意) 学识(这个选项用于当和其他人对话的时候，答话的时候能说出一些高明的回答) 健康(这个属性影响和作者出去玩的时候遇到的事情，比方说遇险，还有就是容不容易生病，得病或者不得病。诊所遇见的作者，或者每天的工作时间) 金钱(这个作为隐藏的属性吧，毕竟金钱能够决定你是不是资助作者，或者能不能在酒吧喝一杯)\n出现并重点认识的作者 # 杰拉德，海明威，JK罗琳，史蒂芬金，大刘(三体)，平凡的世界，阿婆，洛基(这个只能在海明威的老人与海出版后，在酒吧或者诊所看到)，罗素(必须由较高的学识才能触发出版这个人书籍的前提)，巴尔扎卡(但巴尔扎克我并不熟悉)，梭罗，钱钟书(出版他书的前提是和他混熟以后吐槽不少婚姻生活)，列夫托尔斯泰(https://www.zhihu.com/question/43203803 这个问题里面对俄罗斯的评价很好，可以作为敏感的属性)，马克吐温，乔治奥威尔，克苏鲁系列。局外人（加缪，回答他一系列的问题，最终诞生面纱、月亮和六便士，西西弗神话）\n佛教、道教、老子\n有些人喜欢直来直去，对这种人说话需要选择直接的劝说，\n有些人不喜欢被直接劝阻，只能选择使用委婉转达的方式进行劝解，\n有的人喜欢喝酒放荡，那么只能选择喝酒来达成目标。\n想了下，可以再加入一些辩驳的任务：\n反驳“婚姻就是合法的卖淫” 嘲讽2000rmb》3000usd 抨击涨价去库存，或者加入是首相的一些观点 加入什么是真正的民主，最终导致 加入娱乐致死的映射，通过在酒吧的对话把嘲讽的话语说出来 被禁锢的头脑，嘲讽对发展文化的思考 作为邻居出场的任务 # 1s，\n暴躁的老头，叔本华\n李鸿章传\n剧情任务（彩蛋） # 去琴行，看到一个搬东西的工人看着mtv边喝酒边说这些摇滚明星不值得一提 酒吧里面的tv，说一些俏皮话，最好是和星战相关的内容 结尾 # 唉，尴尬\n","date":"2021 年 1 月 8 日","externalUrl":null,"permalink":"/posts/2021-01-08-%E5%B9%B3%E5%87%A1%E7%9A%84%E7%BC%96%E8%BE%91%E5%89%A7%E6%83%85%E8%A7%92%E8%89%B2%E8%AE%BE%E8%AE%A1/","section":"Posts","summary":"","title":"平凡的编辑剧情角色设计","type":"posts"},{"content":" USTACK系统的ATCPZONE设计 # 前言 # 简单看看ATCP ZONE怎么做的\n分类流程 # 分配流程有限从per cpu cache取出来。\natcp_zalloc函数，会将当前当前ATCP进程的ID保存到atcpid里 每个ATCP线程都会首先尝试从自己的per atcp cache也就是一个长长的链表中取出来数据：这个链表每个元素的第一个字节位置存储的是下个元素的位置cache-\u0026gt;zc_items[j] = ((void **) item)[MM_NEXT_ADDR_POSITION];。取成功就返回，取失败就找缓存池申请atcp_zpool_alloc(j, zzone-\u0026gt;zpool, flags | M_DOMAIN);。然后再次尝试分配。 缓存池申请函数atcp_zpool_alloc首先判断分配多少数量为佳，以cache-\u0026gt;zc_batchalloc为上限。然后锁住每个zpool对应的锁，然后每次从per zpool的空闲数据链表里拆出来一个item，然后把新的item放到每个atcp cache的链表头部。如果满足直接释放锁返回，反之调用atcp_zpool_slab函数给zpool申请新元素 函数atcp_zpool_slab函数就开始干脏活累活了，还是要锁住ZP_LOCK(zpool, domain) (\u0026amp;(zpool)-\u0026gt;zp_lock[domain])，然后按照part_slab, free_slab的顺序尝试分配结构，成功的话，while (slab-\u0026gt;us_freecount \u0026gt; 0 \u0026amp;\u0026amp; ZP_FREECNT(zpool, domain) \u0026lt;= zpool-\u0026gt;zp_freemin)通过位图计算出part_slab上的第一个空闲目标直接放到zpool上，失败就调用atcp_slab_alloc分配新的slab，直接插入到part_slab上。上面无论失败还是成功如果发现alloc一个slab不够满足ZP_FREECNT(zpool, domain) \u0026lt; zpool-\u0026gt;zp_freemin都会继续循环。 函数atcp_slab_alloc是向huge page申请内存的操作。这部分就不赘述了，下面是调用流程。 ZTCP_ZONE的初始化 # 这部分主要看怎么计算出来的着色操作，\n结尾 # 唉，尴尬\n","date":"2021 年 1 月 7 日","externalUrl":null,"permalink":"/posts/2021-01-17-ustack%E7%B3%BB%E7%BB%9F%E7%9A%84atcpzone%E8%AE%BE%E8%AE%A1/","section":"Posts","summary":"","title":"USTACK系统的ATCPZONE设计","type":"posts"},{"content":" 记录一些遇见的有趣BUG # 前言 # 这篇博客的目的是记录下遇见过的有趣BUG\n今天想想忽然觉得比较搞笑，几个公司做的东西不一样就会遇到各种不同的问题：在huayao涉及到的都是操作系统/内核/内存很多本身的问题，因为代码很老，做的东西又很底层，直接DPDK在用户态开搞；在mt公司涉及到的都是不规范的代码/不规范的环境/不规范的C/C++开发流程；在轻舟涉及到的就是各种新工具比方说buildfarm/bazel，但是面临的问题很多都是仿真测试，业务环境，k8s的问题。。。\nBUG列表 # 1 因为引用库和数据结构对不上触发的COREDUMP # 1.1 Bug 100606 - [FT 2000]Atcp coredump at raise () when repeat bug98307. # ARM平台上，对一个消息做softssl hash，会触发COREDUMP\n这个BUG本质上是个金丝雀(canary)保护的例子，出现的原因是栈溢出。 出现的原因是两方面的叠加： 1 openssl自己保护的SHA512_CTX结构和我们自己的不一致，openssl的末尾多两个unsigned int。 2 引用的库操作是OPENSSL的库，OPENSSL会对OPENSSL结构下的SHA512_CTX末尾两个数字进行操作。 这里面存在两个问题 1 两个不同文件的同名数据结构，编译器为什么不认为出错就过去了？ 2 为什么X86下不会认为出错，不会产生访问异常？\n第一个问题比较好解答，编译和链接是不同过程，链接是不可能知道这还有两个数据区别。 第二个问题需要仔细检查，隐藏着几个小问题：X86架构上有没有canary保护？缺页中断保护的究竟是什么？是数据，还是异常内存访问？为什么ARM架构下就触发了canary保护？ 在USTACK原本的X86架构上，编译选项没有加上fstack-protect，导致编译器不会有fstack-protect-all标记，因此X86不会编入金丝雀保护。而ARM平台下，\n2 CACHE_LINE_SIZE不同导致的COREDUMP # 2.1 Bug 98768 - [FT 2000]There is backend coredump when use command “debug trace tcp all” to capture packages # ATCP enqueue数据，BACKEND进程DEQUEUE会触发COREDUMP。\n一开始怀疑点是代码乱序，因为代码确实存在乱序可能性。没有任何内存屏障保护等等。 但是看到br-\u0026gt;br_cons_mask和br-\u0026gt;br_prod_mask不同开始怀疑，毕竟这个变量对消费者生产者都一样，也不会更改，怎么可能不同？\n最后在ATCP和BACKEND里面使用命令#define offset_of(type, memb) ((unsigned long)(\u0026amp;((type *)0)-\u0026gt;memb))检查发现两个进程的CACHE_LINE_SIZE不同，因而读取失败。最终修复除了引用相同头文件修复CACHE_LINE_SIZE还更新了RTE_RING代码。\n3 因为OPENSSL用的NID和国密不一致导致的失败 # 3.1 Bug 94844 - [2020.6]CLI Cannot Import CFCA SM2 Encryption Digital Envelope. # 这个BUG的排查比较花时间，因为出问题的点一开始没想到。毕竟头疼医头脚疼医脚是最直接的反应。\n起因是QA拿着CFCA的申请请求去找CA了，发现签回来的信封导入不进去。\n我一开始以为是10.4代码因为OPENSSL我们大改(OPENSSL1.1.1d的代码PATCH了国密，健康检查很多东西)，所以验签失败。检查OPENSSL验签的代码，后来发现似乎没什么逻辑错误，产生了怀疑。将熟悉信封导入到10.3.1的系统也失败产生了怀疑。\n拿asn1 dump检查CSR申请请求的时候发现问题所在了，CSR里面的公钥为0x000\u0026hellip;.相当于CA每次都在给错误的公钥做签名。出现问题的根本原因是因为OPENSSL看国密的NID是NID_X9_62_id_ecPublicKey(408)，但国内把国密的NID改成了NID_sm2(1172)。OPENSSL取公钥的时候发现NID不匹配就直接返回NULL了，但是CSR会成功生成。所以这个BUG是OPENSSL PATCH国密错+CA错导致的，两个地方都没报才会没发现。实际上这块因为NID不一致的问题很多，修改了好几个这种BUG。不过触发条件很奇葩。\n4 兆芯CPU的BUG # 4.1 Bug 103720 - [1850_ZX]The ECC key can\u0026rsquo;t import \u0026amp; Bug 103313 - [1850_ZX][auto] ssl does not work. \u0026amp; Bug 103951 - The cert process coredump when APV starts on U5580-ZX-C platform \u0026amp; \u0026hellip; # 103720直接现象是不能导入一个secp384r1对应的EC 私钥，103313直接现象是不能正确生成2048的私钥/公钥，其它的一些BUG也有这个问题，大部分都是触发了断言，assert((*wnumtop)==0，很多都是div引起的。问题平台为ZX-5580CPU，其它的X86_64平台都没问题。这个BUG的排查特别花时间，虽然我早就猜到了应该是汇编级别的错误，但是汇编的错误藏得太深了，而且103313大师没有找到ROOT-CAUSE而是打PATCH绕开了问题，导致ROOT-CAUSE很难查。\n首先导入私钥的时候，报错报的的是\n140737347789312:error:1012606B:elliptic curve routines:EC_POINT_set_affine_coordinates:point is not on curve:crypto/ec/ec_lib.c:812: 也就是说验证点不在椭圆曲线上，这个函数EC_POINT_is_on_curve嵌套地特别深，但是查了很久发现问题并不在私钥的坐标上（椭圆曲线私钥是个点），反而是椭圆曲线的GROUP对应的公钥信息不对。追查为什么椭圆曲线的公钥信息不对，汇编级别的指令特别难插，关键点的条件基本找不到。废了九牛二虎之力最后发现问题所在竟然是ZX CPU的问题：\n经过追究发现，根本原因出在div 上：ZX 5580 CPU对于特定输入会算错，稳定复现 无论正常机器还是错误机器，div %rcx汇编指令/机器码都相同，且进行运算的值相同。 div是无符号整数除法，高64位置于rdx，低64置于rax。触发运算结束，除数放于rax，余数放于rdx里。\n正常机器的div前后的寄存器值分别为：\n正常机器 div前\nrax 0x0\t0 rcx 0xffffffffffffffff\t-1 rdx 0xffffffff00000001\t-4294967295 正常机器 div后\nrax 0xffffffff00000001\t-4294967295 rcx 0xffffffffffffffff\t-1 rdx 0xffffffff00000001\t-4294967295 错误机器的div前后的寄存器值分别为： 错误机器 div前\n(gdb) info reg rax 0x0 0 rcx 0xffffffffffffffff -1 rdx 0xffffffff00000001 -4294967295 错误机器 div后\nrax 0x1 1 rcx 0xffffffffffffffff -1 rdx 0x1 1 为了验证div在正常机器上运算正常，所以我用python做了以下验证\n\u0026gt;\u0026gt;\u0026gt; print(a) \u0026gt;\u0026gt;\u0026gt; 340282366841710300967557013911933812736 \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;0x%x\u0026#39;%a) \u0026gt;\u0026gt;\u0026gt; 0xffffffff000000010000000000000000 \u0026gt;\u0026gt;\u0026gt; print(b) \u0026gt;\u0026gt;\u0026gt; 18446744073709551615 \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;0x%x\u0026#39;%b) \u0026gt;\u0026gt;\u0026gt; 0xffffffffffffffff \u0026gt;\u0026gt;\u0026gt; print(a/b) \u0026gt;\u0026gt;\u0026gt; 18446744069414584321 \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;0x%x\u0026#39;%(a/b)) \u0026gt;\u0026gt;\u0026gt; 0xffffffff00000001 \u0026gt;\u0026gt;\u0026gt; print(a-b*(a/b)) \u0026gt;\u0026gt;\u0026gt; 18446744069414584321 \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;0x%x\u0026#39;%(a-b*(a/b))) \u0026gt;\u0026gt;\u0026gt; 0xffffffff00000001 为了验证是不是还有别的机器有这种问题，我写了一个test.c可以用来验证别的ZX CPU是不是也有这个问题。结果输出为1的都有这问题，结果输出位-4294967295的都是正常机器。经过测试，发现只有ZHAOXIN KaiXian KX-U5580@1.8GHz有这个问题，ZHAOXIN KaiSheng KH-37800D@2.7GHz没有这个问题，\n#include \u0026lt;stdio.h\u0026gt; #define BN_ULONG unsigned long long * unsigned long long n0 = 18446744069414584321; unsigned long long n1 = 0; unsigned long long d0 = 18446744073709551615; unsigned long long q = 4294967295; #if 0 BN_ULONG bn_div_words(BN_ULONG h, BN_ULONG l, BN_ULONG d) \\ { __asm__ ( \u0026#34;pushq %rbp\\n\\t\u0026#34; \u0026#34;movq (%rsp), %rbp\\n\\t\u0026#34; \u0026#34;movabsq $0xcef9f3930, %rax\\n\\t\u0026#34; \u0026#34;pushq %rax\\n\\t\u0026#34; \u0026#34;movq (%rsp), %rbp\\n\\t\u0026#34; \u0026#34;leaq 0x30(%rsp), %rsp\\n\\t\u0026#34; ); } #endif BN_ULONG bn_div_words(BN_ULONG h, BN_ULONG l, BN_ULONG d) { BN_ULONG ret, waste; asm(\u0026#34;divq %4\u0026#34;:\u0026#34;=a\u0026#34;(ret), \u0026#34;=d\u0026#34;(waste) : \u0026#34;a\u0026#34;(l), \u0026#34;d\u0026#34;(h), \u0026#34;r\u0026#34;(d) : \u0026#34;cc\u0026#34;); return ret; } int main() { q = bn_div_words(n0, n1, d0); printf(\u0026#34;q is %lld\\n\u0026#34;, q); return 0; } 4.2 Bug 102140 - Atcp coredump and can not find interface when performance test SoftSSl(ECDHE-ECDSA-AES128-SHA256) # 坦白讲上面这个BUG和4.1的CPU型号不同，这个是 C-QuadCore C4600@2.0GHz。目前看起来，在 C-QuadCore C4600@2.0GHz上，每次MOVQ RBP都会触发的COREDUMP，而ZX-5580U没有这个问题，具体原因还没找到。等要到设备再研究。\n5 不同gcc编译器编译代码混用导致的问题 # 5.1 gcc 4.8 unordered_map coredump in gcc 5.0 # 今天遇到一个很有意思的BUG，一个4.8.5编出来的so库给gcc5.3.1用，一find就会coredump。查找的的时候使用的结构和函数为为：\nclass T { private: ... std::unordered_map\u0026lt;std::string, T*\u0026gt; T; pthread_rwlock_t rwlock; ... public: static T *instance() { static T inst; return \u0026amp;inst; } ... }; pthread_rwlock_rdlock(\u0026amp;rwlock); auto it = T_map.find(ns_key_name); if (it != T_map.end()) { pthread_rwlock_unlock(\u0026amp;rwlock); return it-\u0026gt;second; } 这个问题可以说是非常蛋疼了，最后惊奇的发现，在gcc5.0的库里面，T结构上锁的时候参数rdi明明应该是rwlock，却修改了T_map的_M_buckets结构，仔细查看发现gcc4.8里面的unordered_map是48字节，所以锁的位置是unordered_map+48。而gcc5里面unordered_map是56字节，理论上应该上锁的位置是unordered_map+56，但是.so里面代码还是对+48位置上锁导致错误修改_T_buckets从而coredump。\n6 签名数据变长导致的COREUMP # 今天可以说是一个特别蛋疼的问题，一开始一直没想到。在做ECDSA/RSA签名的优化。然后想当然的认为，消息摘要缓冲区长度不需要超过64字节，那么签名结果缓冲区不需要超过64字节。然后出了一连串莫名其妙的问题：ecdsa签名/研签的时候没出错，rsa签名完了，ret之后，一打印signature的内容就疯狂coredump。然后lldb/gdb报告coredump的点是string的assign即赋值函数，我一开始没明白单线程赋值为啥会core。后来反应过来内存访问越界了。。。好坑！\n/* 签名的最后结果并不一定小于64，对ECDSA而言256bit可以达到72字节。所以signature_buf长度最好保存1024，直接防备rsa 4096的密钥 */ static bool ecdsa_sha256_sign_openssl(const std::string \u0026amp;message, const std::string \u0026amp;pem_private_key, std::string \u0026amp;signature) { uint32_t digest_len = 0; uint32_t signature_len = 0; unsigned char digest[EVP_MAX_MD_SIZE]; char signature_buf[EVP_MAX_MD_SIZE];\t//这个地方错了，长度64不能够存储足够的签名信息。对rsa4096/ecdsa等都会超过64字节。最后修改所有的signature_buf为1024字节就好了 std::string key = \u0026#34;-----BEGIN PRIVATE KEY-----\\n\u0026#34; + pem_private_key + \u0026#34;\\n-----END PRIVATE KEY-----\u0026#34;; BIO *bio = BIO_new(BIO_s_mem()); if (bio == nullptr) { return false; } BIO_puts(bio, key.c_str()); EC_KEY *ec_key = PEM_read_bio_ECPrivateKey(bio, NULL, NULL, NULL);; if (ec_key == nullptr) { BIO_free(bio); return false; } EVP_MD_CTX *md_ctx = EVP_MD_CTX_create(); if (md_ctx == nullptr) { BIO_free(bio); EC_KEY_free(ec_key); return false; } bool ret = true; bzero(digest, EVP_MAX_MD_SIZE); if (EVP_DigestInit(md_ctx, EVP_sha256()) \u0026lt;= 0 ||EVP_DigestUpdate(md_ctx, (const void *)message.c_str(), message.length()) \u0026lt;= 0 ||EVP_DigestFinal(md_ctx, digest, \u0026amp;digest_len) \u0026lt;= 0 ||ECDSA_sign(0, digest, digest_len, (unsigned char*)signature_buf, \u0026amp;signature_len, ec_key) \u0026lt;= 0) { ret = false; } if (ret == true) { std::string final_sig(signature_buf, signature_len); signature = final_sig; } BIO_free(bio); EC_KEY_free(ec_key); EVP_MD_CTX_destroy(md_ctx); return ret; } 7 openssl base64的bug # 今天做代码测试的时候发现的一个问题，openssl自己实现的openssl有bug，经常会出现本来应该解码错误的情况解码成功。然后无论是1.1.1k还是1.0.2k都是错误的。然后我看了boringssl的实现，发现boringssl是对的。太坑了！\n8 log4cplus的奇怪问题 # 这个问题实际上没找到解决问题，简单描述下问题怎么回事。我打了一个动态库，依赖1.1.3的log4cplus，boost169，然后我使用的环境是gcc 4.8.5(这个对c11的支持不完全)。然后客户用gcc8.3.1使用这个库的时候用了另一个日志库，另一个日志库包含了1.2.2的log4cplus库，然而这引发了一个非常奇怪的问题。\n每次load配置文件的时候，会检查存储配置的map里面是不是存在字符串layout的，触发一个从char*到string的隐式转换，但是每次转换都会在malloc里面的_int_malloc触发core。当然如果使用gcc4.8.5也会触发这个问题。我检查了从string的构造到malloc与Properties的各种属性和参数，都正常，但是每次都会稳定core，就非常奇怪。本身也看不到具体的malloc的代码，就很蛋疼。\n发现实际上问题并不是直接处在char*的转换上，而是上一次分配664字节的RollingFileAppender的时候的mutex加锁的位置会破坏malloc的结果，mutex的位置竟然超出了RollingFileAppender的范围，多写了8个字节。\n具体的现象表现为\ng++ main.cpp /usr/lib64/libclogV2.a ./auth_centos7_4cpp.so -std=c++11 -o -g statica.out，使用静态库编译出来的log4cplus::RollingFileAppender::RollingFileAppender分配出来的RollingFileAppender是664字节，锁的位置在RollingFileAppender之内，mutex的位置和我自己include的头文件结构位置匹配。\n但是使用g++ main.cpp /usr/lib64/libclogV2.so ./auth_centos7_4cpp.so -std=c++11 -o -g statica.out时rollingFileAppender的大小还是664字节，但是mutex的偏移不在664之内，在664之外会写坏内存，mutex的位置和clogV2包含的头文件结构位置匹配。\n查看实现单独使用clogV2动/静态库链接的时候，发现RollingFileAppender的大小是680字节，原来clogV2用的log4cplus是基于1.2.2的，而我们用的log4cplus是1.1.3的版本，这两个版本的头文件不一致，导致数据结构RollingFileAppender大小不同，因为我们包入了头文件，每次真正malloc的时候实际上都是分配664字节，也就是说并没有分配680字节。这种行为就属于标准的UB，才会出现这种问题。\n下面是具体查询的流程。\n我个人在centos7，gcc4.8.5尝试复现这个问题，环境参数如下\n/* gcc 8.3.1 调用编译出来的库和clogV2.so的命令为 g++ main.cpp ./auth_centos7_4cpp.so /usr/lib64/libclogV2.so 执行的时候触发core */ (gdb) bt #0 0x0000000000000000 in ?? () #1 0x00007ffff79d7d18 in log4cplus::spi::ObjectRegistryBase::putVal (this=0x604270, name=..., object=\u0026lt;optimized out\u0026gt;) at objectregistry.cxx:87 #2 0x00007ffff79e3ab8 in log4cplus::spi::FactoryRegistry\u0026lt;log4cplus::spi::LayoutFactory\u0026gt;::put (object=..., this=0x604270) at ../include/log4cplus/spi/factory.h:163 #3 log4cplus::initializeFactoryRegistry () at factory.cxx:169 #4 0x00007ffff79cd47b in log4cplus::initializeLog4cplus () at global-init.cxx:374 #5 0x00007ffff79cd4ed in (anonymous namespace)::_static_log4cplus_initializer::_static_log4cplus_initializer ( this=0x7ffff7dda74a \u0026lt;(anonymous namespace)::initializer\u0026gt;) at global-init.cxx:557 #6 __static_initialization_and_destruction_0 (__priority=\u0026lt;optimized out\u0026gt;, __initialize_p=1) at global-init.cxx:569 #7 0x00007ffff7dea9c3 in _dl_init_internal () from /lib64/ld-linux-x86-64.so.2 #8 0x00007ffff7ddc17a in _dl_start_user () from /lib64/ld-linux-x86-64.so.2 #9 0x0000000000000001 in ?? () #10 0x00007fffffffe3a1 in ?? () #11 0x0000000000000000 in ?? () (gdb) /* 如果先使用clogV2的动态库，再调用auth动态库，命令为g++ main.cpp /usr/lib64/libclogV2.so ./auth_centos7_4cpp.so，同样core。最奇怪的事情是如果使用libclogV2的静态库不会core*/ (gdb) bt #0 0x00007ffff63cb3d7 in raise () from /lib64/libc.so.6 #1 0x00007ffff63ccac8 in abort () from /lib64/libc.so.6 #2 0x00007ffff640df67 in __libc_message () from /lib64/libc.so.6 #3 0x00007ffff6417b36 in _int_malloc () from /lib64/libc.so.6 #4 0x00007ffff641a78c in malloc () from /lib64/libc.so.6 #5 0x00007ffff6cda18d in operator new(unsigned long) () from /lib64/libstdc++.so.6 #6 0x00007ffff6d38cd9 in std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator\u0026lt;char\u0026gt; const\u0026amp;) () from /lib64/libstdc++.so.6 #7 0x00007ffff6d3a561 in char* std::string::_S_construct\u0026lt;char const*\u0026gt;(char const*, char const*, std::allocator\u0026lt;char\u0026gt; const\u0026amp;, std::forward_iterator_tag) () from /lib64/libstdc++.so.6 #8 0x00007ffff6d3a998 in std::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;::basic_string(char const*, std::allocator\u0026lt;char\u0026gt; const\u0026amp;) () from /lib64/libstdc++.so.6 #9 0x00007ffff7b9815b in log4cplus::helpers::Properties::exists(char const*) const () from /lib64/libclogV2.so #10 0x00007ffff7b4b895 in log4cplus::Appender::Appender(log4cplus::helpers::Properties const\u0026amp;) () from /lib64/libclogV2.so #11 0x00007ffff7b6714f in log4cplus::FileAppenderBase::FileAppenderBase(log4cplus::helpers::Properties const\u0026amp;, std::_Ios_Openmode) () from /lib64/libclogV2.so #12 0x00007ffff7b71646 in log4cplus::FileAppender::FileAppender(log4cplus::helpers::Properties const\u0026amp;, std::_Ios_Openmode) () from /lib64/libclogV2.so //已经出错了 #13 0x00007ffff7b71959 in log4cplus::RollingFileAppender::RollingFileAppender(log4cplus::helpers::Properties const\u0026amp;) () from /lib64/libclogV2.so #14 0x00007ffff77009f1 in log4cplus::spi::FactoryTempl\u0026lt;log4cplus::RollingFileAppender, log4cplus::spi::AppenderFactory\u0026gt;::createObject ( this=\u0026lt;optimized out\u0026gt;, props=...) at ../include/log4cplus/spi/factory.h:242 #15 0x00007ffff7b50bb9 in log4cplus::PropertyConfigurator::configureAppenders() () from /lib64/libclogV2.so #16 0x00007ffff7b53d2e in log4cplus::PropertyConfigurator::configure() () from /lib64/libclogV2.so #17 0x00007ffff7b53f24 in log4cplus::PropertyConfigurator::doConfigure(std::string const\u0026amp;, log4cplus::Hierarchy\u0026amp;, unsigned int) () from /lib64/libclogV2.so #18 0x00007ffff744ed07 in AuthService::Init (this=this@entry=0x6089c0) at /home/vgdog/code/sts/auth_sdk_cpp/source/auth_service_real.cpp:9 #19 0x00007ffff744c6ac in kms::Singleton\u0026lt;AuthService\u0026gt;::instance () at /home/vgdog/code/sts/auth_sdk_cpp/source/./utils/Singleton.h:54 #20 inf::auth::AuthServiceSignInit (param=...) at /home/vgdog/code/sts/auth_sdk_cpp/source/auth_service.cpp:8 #21 0x0000000000400dee in main () /* 查询发现log4cplus::Properties是没有问题的*/ /* 所以拜托SRE把glibc的源代码装上，开始查，在进入log4cplus::helpers::Properties::exists(char const*)前，这块内存就已经被破坏了 ，内存地址在watch *(struct malloc_chunk *) 0x60eed0上，开始检测这块地址，可以发现实际上是在创建一个智能指针，具体的类型为helpers::SharedObjectPtr\u0026lt;Appender\u0026gt; SharedAppenderPtr*/ /* 所以实际上是分配内存，然后构造相应的mutex的流程时破坏了malloc的内存结构，ok，问题找到了分配出来的地址返回之后修改mutex的时候会直接修改内存块的size，具体看这里*/ /* 初始化mutex的时候的参数和调用栈*/ (gdb) info reg rax 0x7ffff7dd5bb0\t140737351867312 rbx 0x60ec40\t6351936 rcx 0x60ec30\t6351920 rdx 0x60ec40\t6351936 rsi 0x1\t1 rdi 0x60eed8\t6352600 (gdb) bt #0 0x00007ffff7ba4510 in log4cplus::thread::Mutex::Mutex(log4cplus::thread::Mutex::Type) () from /lib64/libclogV2.so #1 0x00007ffff7b71934 in log4cplus::RollingFileAppender::RollingFileAppender(log4cplus::helpers::Properties const\u0026amp;) () from /lib64/libclogV2.so #2 0x00007ffff77009f1 in log4cplus::spi::FactoryTempl\u0026lt;log4cplus::RollingFileAppender, log4cplus::spi::AppenderFactory\u0026gt;::createObject ( this=\u0026lt;optimized out\u0026gt;, props=...) at ../include/log4cplus/spi/factory.h:242 #3 0x00007ffff7b50bb9 in log4cplus::PropertyConfigurator::configureAppenders() () from /lib64/libclogV2.so #4 0x00007ffff7b53d2e in log4cplus::PropertyConfigurator::configure() () from /lib64/libclogV2.so #5 0x00007ffff7b53f24 in log4cplus::PropertyConfigurator::doConfigure(std::string const\u0026amp;, log4cplus::Hierarchy\u0026amp;, unsigned int) () from /lib64/libclogV2.so (gdb) p (\u0026amp;((struct malloc_chunk *) 0x60eed0)-\u0026gt;size) $103 = (size_t *) 0x60eed8 /* 链接clogV2的静态库的话malloc的参数是664字节，也就是sizeof(log4cplus::RollingFileAppender)，地址为0x60cfd0，堆的地址是从低到高增长的，所以size在0x60cfd0+664的地方为实际的大小，是1025。所以我们能看到具体构造mutex的时候mutex的地址为0x60d258，log4cplus::thread::Mutex::Mutex (this=0x60d258, t=log4cplus::thread::Mutex::RECURSIVE)。这个地址减去log4cplus::RollingFileAppender的起始地址为648的偏移，也就是说还在分配出来的内存量里面*/ /*而链接clogV2动态库的话malloc的参数是664字节，返回地址为(void *) 0x60ec40，实际大小为0x60ec40+664的地址也就是1025。而构造mutex时mutex的地址为0x60eed8，但是操作的偏移量为664字节，换言之mutex写的已经超了，那么为什么会出现这种问题呢？ */ /* 现在实际上是初始化SharedObejct部分的mutex*/ Dump of assembler code for function log4cplus::RollingFileAppender::RollingFileAppender(log4cplus::helpers::Properties const\u0026amp;): =\u0026gt; 0x00007ffff79e94d0 \u0026lt;+0\u0026gt;:\tmov %rbx,-0x30(%rsp) 0x00007ffff79e94d5 \u0026lt;+5\u0026gt;:\tmov %rbp,-0x28(%rsp) 0x00007ffff79e94da \u0026lt;+10\u0026gt;:\tmov %rdi,%rbx 0x00007ffff79e94dd \u0026lt;+13\u0026gt;:\tmov %r14,-0x10(%rsp) 0x00007ffff79e94e2 \u0026lt;+18\u0026gt;:\tmov %r12,-0x20(%rsp) 0x00007ffff79e94e7 \u0026lt;+23\u0026gt;:\tlea 0x280(%rdi),%r14 /* 静态库的偏移量时0x280，也就是说在库的内部，是正确的*/ 0x00007ffff79e94ee \u0026lt;+30\u0026gt;:\tmov %r13,-0x18(%rsp) 0x00007ffff79e94f3 \u0026lt;+35\u0026gt;:\tmov %r15,-0x8(%rsp) 0x00007ffff79e94f8 \u0026lt;+40\u0026gt;:\tsub $0x58,%rsp 0x00007ffff79e94fc \u0026lt;+44\u0026gt;:\tmov 0x3d0fa5(%rip),%rax # 0x7ffff7dba4a8 0x00007ffff79e9503 \u0026lt;+51\u0026gt;:\tmov %rsi,%rbp 0x00007ffff79e9506 \u0026lt;+54\u0026gt;:\tmov $0x1,%esi 0x00007ffff79e950b \u0026lt;+59\u0026gt;:\tadd $0x10,%rax 0x00007ffff79e950f \u0026lt;+63\u0026gt;:\tmov %rax,0x280(%rdi) 0x00007ffff79e9516 \u0026lt;+70\u0026gt;:\tlea 0x288(%rdi),%rdi 0x00007ffff79e951d \u0026lt;+77\u0026gt;:\tcallq 0x7ffff76e6f40 \u0026lt;_ZN9log4cplus6thread5MutexC1ENS1_4TypeE@plt\u0026gt; (gdb) info reg rax 0x60cfd0\t6344656 rbx 0x60cfd0\t6344656 rcx 0x60cfc0\t6344640 rdx 0x60cfd0\t6344656 rsi 0x7fffffffdf60\t140737488346976 rdi 0x60cfd0\t6344656 rbp 0x7fffffffe050\t0x7fffffffe050 rsp 0x7fffffffdec8\t0x7fffffffdec8 r8 0x400\t1024 r9 0x298\t664 r10 0x7fffffffd2a0\t140737488343712 r11 0x7ffff79e94d0\t140737347753168 r12 0x7fffffffdf60\t140737488346976 r13 0x7ffff72663e0\t140737339876320 r14 0x7fffffffe060\t140737488347232 r15 0x7fffffffdf60\t140737488346976 rip 0x7ffff79e94d0\t0x7ffff79e94d0 \u0026lt;log4cplus::RollingFileAppender::RollingFileAppender(log4cplus::helpers::Properties const\u0026amp;)\u0026gt; eflags 0x202\t[ IF ] cs 0x33\t51 ss 0x2b\t43 ds 0x0\t0 es 0x0\t0 fs 0x0\t0 gs 0x0\t0 Dump of assembler code for function _ZN9log4cplus19RollingFileAppenderC1ERKNS_7helpers10PropertiesE: =\u0026gt; 0x00007ffff7b71900 \u0026lt;+0\u0026gt;:\tpush %r15 0x00007ffff7b71902 \u0026lt;+2\u0026gt;:\tpush %r14 0x00007ffff7b71904 \u0026lt;+4\u0026gt;:\tpush %r13 0x00007ffff7b71906 \u0026lt;+6\u0026gt;:\tpush %r12 0x00007ffff7b71908 \u0026lt;+8\u0026gt;:\tmov %rsi,%r12 0x00007ffff7b7190b \u0026lt;+11\u0026gt;:\tpush %rbp 0x00007ffff7b7190c \u0026lt;+12\u0026gt;:\tpush %rbx 0x00007ffff7b7190d \u0026lt;+13\u0026gt;:\tmov %rdi,%rbx 0x00007ffff7b71910 \u0026lt;+16\u0026gt;:\tlea 0x298(%rdi),%rdi /* rdi是rollingfileAppender的值，直接加了0x298，直接就偏移过多了啊，就超过了sizeof(rollingFileAppender）了，赋值完了rdi就是(gdb) p/x 0x60ec40+0x298 $14 = 0x60eed8，直接就越界了*/ 0x00007ffff7b71917 \u0026lt;+23\u0026gt;:\tmov $0x1,%esi 0x00007ffff7b7191c \u0026lt;+28\u0026gt;:\tsub $0x38,%rsp 0x00007ffff7b71920 \u0026lt;+32\u0026gt;:\tmov 0x266139(%rip),%rax # 0x7ffff7dd7a60 0x00007ffff7b71927 \u0026lt;+39\u0026gt;:\tadd $0x10,%rax 0x00007ffff7b7192b \u0026lt;+43\u0026gt;:\tmov %rax,-0x8(%rdi) 0x00007ffff7b7192f \u0026lt;+47\u0026gt;:\tcallq 0x7ffff7b3fbb0 \u0026lt;_ZN9log4cplus6thread5MutexC1ENS1_4TypeE@plt\u0026gt; rax 0x60ec40\t6351936 rbx 0x60ec40\t6351936 rcx 0x60ec30\t6351920 rdx 0x60ec40\t6351936 rsi 0x7fffffffe090\t140737488347280 rdi 0x60ec40\t6351936 rbp 0x7fffffffdff0\t0x7fffffffdff0 rsp 0x7fffffffdf38\t0x7fffffffdf38 r8 0x400\t1024 r9 0x298\t664 r10 0x7fffffffd320\t140737488343840 r11 0x7ffff7b71900\t140737349359872 r12 0x7fffffffe090\t140737488347280 r13 0x7fffffffe198\t140737488347544 r14 0x7fffffffdfe0\t140737488347104 r15 0x0\t0 rip 0x7ffff7b71900\t0x7ffff7b71900 \u0026lt;log4cplus::RollingFileAppender::RollingFileAppender(log4cplus::helpers::Properties const\u0026amp;)\u0026gt; eflags 0x202\t[ IF ] cs 0x33\t51 ss 0x2b\t43 ds 0x0\t0 es 0x0\t0 fs 0x0\t0 gs 0x0\t0 9 openssl和boringssl混用的bug # 10 GRPC调用的问题 # 今天在写grpc的UT的时候，忽然爆了一个错误：\nliboffboard_Sdashboard_Sproto_Slibscenarios_Ucc_Ugrpc.so: undefined symbol: _ZN4grpc24g_core_codegen_interfaceE 先拿c++filt看下\nc++filt _ZN4grpc24g_core_codegen_interfaceE grpc::g_core_codegen_interface 看起来是grpc的代码，在bazel的BUILD里面加上了一句搞完了\n\u0026#34;@com_github_grpc_grpc//:grpc++\u0026#34;, 11 REbase错误 # 今天写代码的时候发现CI出错了，然后发现postsubmit bazel build出错。感觉revert，revert完了当事人把原始代码贴了下发现依赖是加了的，后来看了下发现，rebase代码的时候前面有一个修改间接rebase的MR，一开始以为是间接依赖被删除导致的，但是我还是感觉有点迷惑，原始的commit 是加的直接依赖那个头文件的trajectory_developer啊， 他加的trajectory_developer依赖的是两个地方，cyclist_behavior_predictor \u0026amp; vehicle_intention_predictor。怎么rebase完了加依赖的地方就成了 cyclist_behavior_predictor \u0026amp; vehicle_behavior_predictor。\n我感觉这属于rebase的错误了\n12 DOUBLE NAN的问题 # 这几天postsubmit的pipeline出现了问题，出现了一个非常奇怪的问题，问题代码为：\nPlannerState other_state = state; //EXPECT_EQ(state, state); EXPECT_EQ(state, other_state); \u0026lt;======问题出在这句上，但是即使上一句也会报这个错误 //一般也不会出错，得用下面的语句 bazel test -c opt --cache_test_results=no //onboard/planner:planner_state_test --spawn_strategy=local 百思不得其解，最后问了川，发现是double的默认值为nan了，PlannerState结构体里面有一个double的结构体，默认初始化是nan，而nan和自己比较为false，换言之下面的代码的靠下的部分是true的，从而会报错。我最后改了代码加了C++11的isnan判断，发现确实打印了错误。那么问题来了，为什么同样的在local模式会出现这个错误？IEEE 754-1985中，用指数部分全为1、小数部分非零表示NaN。也就是说IEEE 754-1985中，用指数部分全为1、小数部分非零表示NaN。以32位IEEE单精度浮点数的NaN为例，按位表示即：S111 1111 1AXX XXXX XXXX XXXX XXXX XXXX，S为符号位，符号位S的取值无关紧要；A是小数部分的最高位（the most significant bit of the significand），其取值表示了NaN的类型：小数部分不能全为0，小数部分除了A之外的部分被称为NaN的payload；[注 1]\n64位IEEE单精度浮点数的NAN也是这样子，也是一开始是11111\u0026hellip;，然后小数部分为全为0\n而这个int的值为1111111111111111111111111111111111111111101000000000000000000000，十进制为18446744073703259376，十六进制为ffffffffffa00000，去跑isnan发现还是为nan\n然后最有趣的事情来了，这个数字即使是做运算也就是nan-nan，结果也还是nan而不是零，也就是说减法不能用，等于不能用，符号运算全不能用。所以这个问题的最彻底解决方法还是显示初始化\nstruct PlannerState { ... double current_route_s; \u0026lt;=== 问题出在这一行 ... }; bool PlannerState::operator==(const PlannerState\u0026amp; other) const { ... current_route_s != current_route_s //这个语句是true的， if (isnan(current_route_s)) { LOG(INFO) \u0026lt;\u0026lt; \u0026#34;what is nan default?\u0026#34;; } ... } 看了一下拷贝出错的地方的汇编代码是下面的代码中间的地方，也非常直接，那么直接对这个赋值的地方呢？\n0x55555557283e \u0026lt;+798\u0026gt;: callq 0x55555558c010 ; symbol stub for: qcraft::planner::SpacetimePlannerTrajectories::SpacetimePlannerTrajectories(qcraft::planner::SpacetimePlannerTrajectories const\u0026amp;) 0x555555572843 \u0026lt;+803\u0026gt;: vmovsd 0x5e0(%r15), %xmm0 ; xmm0 = mem[0],zero 0x55555557284c \u0026lt;+812\u0026gt;: vmovsd %xmm0, 0x5e0(%r13) //0x5e0的偏移为double current_route_s所在的地方， 0x555555572855 \u0026lt;+821\u0026gt;: leaq 0x5e8(%r13), %rdi 0x55555557285c \u0026lt;+828\u0026gt;: leaq 0x5e8(%r15), %rsi //0x6a0的偏移为MissionStageProto的所在地方 0x555555572863 \u0026lt;+835\u0026gt;: callq 0x555555576a00 ; ::LanePath() at lane_path.h:26 0x555555571fd8 \u0026lt;+536\u0026gt;: callq 0x55555558bed0 ; symbol stub for: qcraft::planner::SpacetimePlannerTrajectories::SpacetimePlannerTrajectories(google::protobuf::Arena*, bool) -\u0026gt; 0x555555571fdd \u0026lt;+541\u0026gt;: vxorps %xmm0, %xmm0, %xmm0 0x555555571fe1 \u0026lt;+545\u0026gt;: vmovups %ymm0, 0x608(%r15) 0x555555571fea \u0026lt;+554\u0026gt;: vmovups %ymm0, 0x5e8(%r15) //可以看到实际上对double的操作就没做，最多就是一个0x5e8地址的写操作，那得看有没有相应的初始化了，找一下初始化的代码,也就是说malloc的代码 0x555555571ff3 \u0026lt;+563\u0026gt;: movq $0x0, 0x628(%r15) 0x555555571ffe \u0026lt;+574\u0026gt;: movb $0x1, 0x630(%r15) 0x555555572006 \u0026lt;+582\u0026gt;: vxorps %xmm1, %xmm1, %xmm1 0x55555557200a \u0026lt;+586\u0026gt;: vmovups %xmm1, 0x648(%r15) 0x555555572013 \u0026lt;+595\u0026gt;: movq $0x0, 0x658(%r15) 0x55555557201e \u0026lt;+606\u0026gt;: movq $0x0, 0x668(%r15) 0x555555572029 \u0026lt;+617\u0026gt;: movq %r13, 0x670(%r15) 0x555555572030 \u0026lt;+624\u0026gt;: leaq 0x678(%r15), %rbx 0x555555572037 \u0026lt;+631\u0026gt;: vmovups %ymm0, 0x678(%r15) 0x555555572040 \u0026lt;+640\u0026gt;: movabsq $0x7fefffffffffffff, %rax ; imm = 0x7FEFFFFFFFFFFFFF 0x55555557204a \u0026lt;+650\u0026gt;: movq %rax, 0x698(%r15) //这个砍掉8字节 0x555555572051 \u0026lt;+657\u0026gt;: leaq 0x6a0(%r15), %rdi //0x6a0是要传递给MissionStageProto的this指针或者说首地址 0x555555572058 \u0026lt;+664\u0026gt;: xorl %esi, %esi 0x55555557205a \u0026lt;+666\u0026gt;: xorl %edx, %edx 0x55555557205c \u0026lt;+668\u0026gt;: vzeroupper 0x55555557205f \u0026lt;+671\u0026gt;: callq 0x55555558bee0 ; symbol stub for: qcraft::MissionStageProto::MissionStageProto(google::protobuf::Arena*, bool) 13 多线程下folly:：threadlocal问题 # 这几天维护代码库的时候报了一个错误，报错如下\n[----------] Global test environment tear-down [==========] 1 test from 1 test suite ran. (7 ms total) [ PASSED ] 1 test. terminate called after throwing an instance of \u0026#39;std::system_error\u0026#39; what(): pthread_setspecific failed: Invalid argument 然后追了一下，下面是完整的调用栈，看了一下为什么。主线程退出的时候，调用pthread_key_delete删除了5这个pkey，但是之后又使用pthread_setspecific来操作这个pkey了。所以在操作的时候报错\n[qcraft@qcraft-dev-qcraft:/qcraft(master) ] $ [qcraft@qcraft-dev-qcraft:/qcraft(master) ] $ lldb bazel-bin/onboard/prediction/container/objects_history_test (lldb) target create \u0026#34;bazel-bin/onboard/prediction/container/objects_history_test\u0026#34; Current executable set to \u0026#39;/qcraft/bazel-bin/onboard/prediction/container/objects_history_test\u0026#39; (x86_64). (lldb) b pthread_setspecific Breakpoint 1: no locations (pending). WARNING: Unable to resolve breakpoint to any actual locations. (lldb) b pthread_key_create Breakpoint 2: no locations (pending). WARNING: Unable to resolve breakpoint to any actual locations. (lldb) b pthread_key_delete Breakpoint 3: no locations (pending). WARNING: Unable to resolve breakpoint to any actual locations. (lldb) r ... Process 6522 resuming # ， Process 6522 stopped * thread #1, name = \u0026#39;objects_history\u0026#39;, stop reason = breakpoint 3.1 frame #0: 0x00007ffff0c9a0d0 libpthread.so.0`pthread_key_delete libpthread.so.0`pthread_key_delete: -\u0026gt; 0x7ffff0c9a0d0 \u0026lt;+0\u0026gt;: cmpl $0x3ff, %edi ; imm = 0x3FF 0x7ffff0c9a0d6 \u0026lt;+6\u0026gt;: ja 0x7ffff0c9a100 ; \u0026lt;+48\u0026gt; 0x7ffff0c9a0d8 \u0026lt;+8\u0026gt;: movl %edi, %edi 0x7ffff0c9a0da \u0026lt;+10\u0026gt;: leaq 0x20b23f(%rip), %rax ; __GI___pthread_keys (lldb) register read General Purpose Registers: rax = 0x00005555556519e0 objects_history_test`folly::threadlocal_detail::PthreadKeyUnregister::instance_ rbx = 0x0000000000000001 rcx = 0x0000000000000001 rdx = 0x0000000000000000 rdi = 0x0000000000000005 rsi = 0x000000000000ffff rbp = 0x00007fffffffd760 rsp = 0x00007fffffffd738 r8 = 0x00005555556519e0 objects_history_test`folly::threadlocal_detail::PthreadKeyUnregister::instance_ r9 = 0x00007fffef6eea00 r10 = 0x00000000fffffffa r11 = 0x0000000000000000 r12 = 0x00007fffefcff718 r13 = 0x00000000000005f0 r14 = 0x00007fffefd04708 r15 = 0x0000555555716b60 rip = 0x00007ffff0c9a0d0 libpthread.so.0`pthread_key_delete rflags = 0x0000000000000257 cs = 0x0000000000000033 fs = 0x0000000000000000 gs = 0x0000000000000000 ss = 0x000000000000002b ds = 0x0000000000000000 es = 0x0000000000000000 (lldb) bt * thread #1, name = \u0026#39;objects_history\u0026#39;, stop reason = breakpoint 3.1 * frame #0: 0x00007ffff0c9a0d0 libpthread.so.0`pthread_key_delete frame #1: 0x0000555555643f92 objects_history_test`folly::threadlocal_detail::PthreadKeyUnregister::~PthreadKeyUnregister(this=0x00005555556519e0) at ThreadLocalDetail.h:266:7 frame #2: 0x00007fffef957161 libc.so.6`___lldb_unnamed_symbol109$$libc.so.6 + 369 frame #3: 0x00007fffef95725a libc.so.6`exit + 26 frame #4: 0x00007fffef935bfe libc.so.6`__libc_start_main + 238 frame #5: 0x00005555555e6b5a objects_history_test`_start + 42 ... (lldb) c Process 6522 resuming Process 6522 stopped * thread #2, name = \u0026#39;objects_history\u0026#39;, stop reason = breakpoint 1.1 frame #0: 0x00007ffff0c9a1a0 libpthread.so.0`__pthread_setspecific libpthread.so.0`__pthread_setspecific: -\u0026gt; 0x7ffff0c9a1a0 \u0026lt;+0\u0026gt;: pushq %r13 0x7ffff0c9a1a2 \u0026lt;+2\u0026gt;: pushq %r12 0x7ffff0c9a1a4 \u0026lt;+4\u0026gt;: pushq %rbp 0x7ffff0c9a1a5 \u0026lt;+5\u0026gt;: pushq %rbx (lldb) register read General Purpose Registers: rax = 0x00007fffeeceb560 rbx = 0x00005555556ef4f8 rcx = 0x00005555557151b0 rdx = 0x00005555556fe5c0 rdi = 0x0000000000000005 rsi = 0x00007fffeeceb560 rbp = 0x00007fffeeaea050 rsp = 0x00007fffeeaea018 r8 = 0x00000000620e53ab r9 = 0x00007fffeeae9d88 r10 = 0x00007fffeeae9d40 r11 = 0x0000000000000000 r12 = 0x00007fffeeaea880 r13 = 0x0000000000000000 r14 = 0x000055555571bc40 r15 = 0x00007fffffffc6a0 rip = 0x00007ffff0c9a1a0 libpthread.so.0`__pthread_setspecific rflags = 0x0000000000000202 cs = 0x0000000000000033 fs = 0x0000000000000000 gs = 0x0000000000000000 ss = 0x000000000000002b ds = 0x0000000000000000 es = 0x0000000000000000 (lldb) thread list Process 6522 stopped thread #1: tid = 6522, 0x00007ffff7deaf2b, name = \u0026#39;objects_history\u0026#39; * thread #2: tid = 7615, 0x00007ffff0c9a1a0 libpthread.so.0`__pthread_setspecific, name = \u0026#39;objects_history\u0026#39;, stop reason = breakpoint 1.1 (lldb) c Process 6522 resuming terminate called after throwing an instance of \u0026#39;std::system_error\u0026#39; what(): pthread_setspecific failed: Invalid argument Process 6522 stopped * thread #2, name = \u0026#39;objects_history\u0026#39;, stop reason = signal SIGABRT frame #0: 0x00007fffef952fb7 libc.so.6`raise + 199 libc.so.6`raise: -\u0026gt; 0x7fffef952fb7 \u0026lt;+199\u0026gt;: movq 0x108(%rsp), %rcx 0x7fffef952fbf \u0026lt;+207\u0026gt;: xorq %fs:0x28, %rcx 0x7fffef952fc8 \u0026lt;+216\u0026gt;: movl %r8d, %eax 0x7fffef952fcb \u0026lt;+219\u0026gt;: jne 0x7fffef952fec ; \u0026lt;+252\u0026gt; (lldb) (lldb) Process 11199 resuming Process 11199 stopped * thread #1, name = \u0026#39;objects_history\u0026#39;, stop reason = breakpoint 3.1 frame #0: 0x0000555555641c8b objects_history_test`folly::threadlocal_detail::PthreadKeyUnregister::registerKey(key=5) at ThreadLocalDetail.h:272:31 (lldb) bt * thread #1, name = \u0026#39;objects_history\u0026#39;, stop reason = breakpoint 3.1 * frame #0: 0x0000555555641c8b objects_history_test`folly::threadlocal_detail::PthreadKeyUnregister::registerKey(key=5) at ThreadLocalDetail.h:272:31 frame #1: 0x0000555555640d8d objects_history_test`folly::threadlocal_detail::StaticMetaBase::StaticMetaBase(this=0x00005555557151b0, threadEntry=(libonboard_Sglobal_Slibcounter.so`folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::getThreadEntrySlow() at ThreadLocalDetail.h:468), strict=false)(), bool) at ThreadLocalDetail.cpp:73:3 frame #2: 0x00007ffff55a525b libonboard_Sglobal_Slibcounter.so`folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::StaticMeta(this=0x00005555557151b0) at ThreadLocalDetail.h:420:9 frame #3: 0x00007ffff55a5138 libonboard_Sglobal_Slibcounter.so`void* folly::detail::StaticSingletonManagerWithRtti::make\u0026lt;folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt; \u0026gt;() at StaticSingletonManager.h:80:16 frame #4: 0x000055555563e3a9 objects_history_test`folly::detail::(anonymous namespace)::StaticSingletonManagerWithRttiImpl::Entry::get(this=0x00005555556ea1c0, make=0x00007ffff55a5110)()) at StaticSingletonManager.cpp:46:33 frame #5: 0x000055555563e121 objects_history_test`folly::detail::(anonymous namespace)::StaticSingletonManagerWithRttiImpl::create(this=0x0000555555728910, key=0x00007ffff55b6740, make=0x00007ffff55a5110, cache=0x00007ffff55b9f58)(), std::atomic\u0026lt;void*\u0026gt;\u0026amp;) at StaticSingletonManager.cpp:34:33 frame #6: 0x000055555563e098 objects_history_test`folly::detail::StaticSingletonManagerWithRtti::create_(arg=0x00007ffff55b9f58) at StaticSingletonManager.cpp:65:19 frame #7: 0x00007ffff55a5053 libonboard_Sglobal_Slibcounter.so`folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::instance() [inlined] void* folly::detail::StaticSingletonManagerWithRtti::create_\u0026lt;false\u0026gt;(arg=0x00007ffff55b9f58) at StaticSingletonManager.h:85:12 frame #8: 0x00007ffff55a504a libonboard_Sglobal_Slibcounter.so`folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::instance() [inlined] folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;\u0026amp; folly::detail::StaticSingletonManagerWithRtti::create\u0026lt;folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;, void\u0026gt;() at StaticSingletonManager.h:64 frame #9: 0x00007ffff55a5008 libonboard_Sglobal_Slibcounter.so`folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::instance() [inlined] folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;\u0026amp; folly::detail::createGlobal\u0026lt;folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;, void\u0026gt;() at StaticSingletonManager.h:97 frame #10: 0x00007ffff55a5008 libonboard_Sglobal_Slibcounter.so`folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::instance() at ThreadLocalDetail.h:433 frame #11: 0x00007ffff55a4f4d libonboard_Sglobal_Slibcounter.so`folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::getSlowReserveAndCache(ent=0x00005555556fbe30, id=0x00007fffffffc894, threadEntry=0x00007fffef2ee850, capacity=0x00007fffef2ee858) at ThreadLocalDetail.h:458:18 frame #12: 0x00007ffff55a4e2f libonboard_Sglobal_Slibcounter.so`folly::ThreadLocalPtr\u0026lt;qcraft::CounterImpl::CounterPerThread, qcraft::CounterImpl::CounterTag, void\u0026gt;::get() const [inlined] folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::get(ent=0x00005555556fbe30) at ThreadLocalDetail.h:448:7 frame #13: 0x00007ffff55a4dc4 libonboard_Sglobal_Slibcounter.so`folly::ThreadLocalPtr\u0026lt;qcraft::CounterImpl::CounterPerThread, qcraft::CounterImpl::CounterTag, void\u0026gt;::get(this=0x00005555556fbe30) const at ThreadLocal.h:158 frame #14: 0x00007ffff55941a1 libonboard_Sglobal_Slibcounter.so`folly::ThreadLocal\u0026lt;qcraft::CounterImpl::CounterPerThread, qcraft::CounterImpl::CounterTag, void\u0026gt;::operator-\u0026gt;() const [inlined] folly::ThreadLocal\u0026lt;qcraft::CounterImpl::CounterPerThread, qcraft::CounterImpl::CounterTag, void\u0026gt;::get(this=0x00005555556fbe30) const at ThreadLocal.h:68:27 frame #15: 0x00007ffff559419c libonboard_Sglobal_Slibcounter.so`folly::ThreadLocal\u0026lt;qcraft::CounterImpl::CounterPerThread, qcraft::CounterImpl::CounterTag, void\u0026gt;::operator-\u0026gt;(this=0x00005555556fbe30) const at ThreadLocal.h:73 frame #16: 0x00007ffff5588c39 libonboard_Sglobal_Slibcounter.so`qcraft::CounterImpl::AddCounterEvent(this=0x00005555556fbe30, name=\u0026#34;schedulefuture_callback_size\u0026#34;, val=1) at counter.cc:51:3 frame #17: 0x00007ffff558a23d libonboard_Sglobal_Slibcounter.so`qcraft::Counter::AddCounterEventInternal(this=0x0000555555711cd0, name=\u0026#34;schedulefuture_callback_size\u0026#34;, val=1) at counter.cc:191:10 frame #18: 0x00005555555f0745 objects_history_test`void qcraft::Counter::AddCounterEvent\u0026lt;long\u0026gt;(this=0x0000555555711cd0, name=\u0026#34;schedulefuture_callback_size\u0026#34;, val=1) at counter.h:70:5 frame #19: 0x00005555555e9fa7 objects_history_test`qcraft::Future\u0026lt;std::result_of\u0026lt;boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt; (void qcraft::DestroyContainerAsync\u0026lt;boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt; \u0026gt;(qcraft::ThreadPool*, boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt;)::\u0026#39;lambda\u0026#39;()...)\u0026gt;::type\u0026gt; qcraft::ThreadPool::Schedule\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt; \u0026gt;(this=0x000055555572ae70, f=0x00007fffffffcbb0)::\u0026#39;lambda\u0026#39;()\u0026gt;(boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt;\u0026amp;\u0026amp;, void qcraft::DestroyContainerAsync\u0026lt;boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt; \u0026gt;(qcraft::ThreadPool*, boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt;)::\u0026#39;lambda\u0026#39;()\u0026amp;\u0026amp;...) at thread_pool.h:88:5 frame #20: 0x00005555555e9951 objects_history_test`auto qcraft::ScheduleFuture\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt; \u0026gt;(qcraft::ThreadPool*, boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt;)::\u0026#39;lambda\u0026#39;()\u0026gt;(thread_pool=0x000055555572ae70, f=0x00007fffffffcbb0)::\u0026#39;lambda\u0026#39;()\u0026amp;\u0026amp;...) at async_util.h:24:23 frame #21: 0x00005555555e9835 objects_history_test`void qcraft::DestroyContainerAsync\u0026lt;boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt; \u0026gt;(thread_pool=0x000055555572ae70, container=\u0026lt;unavailable\u0026gt;) at async_util.h:38:3 frame #22: 0x00005555555e96fb objects_history_test`void qcraft::DestroyContainerAsync\u0026lt;boost::circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt; \u0026gt;(container=circular_buffer\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt;, std::allocator\u0026lt;qcraft::elements_history::Node\u0026lt;double, qcraft::prediction::PredictionObject\u0026gt; \u0026gt; \u0026gt; @ 0x00007fffffffcc80) at async_util.h:47:3 frame #23: 0x00005555555e9666 objects_history_test`qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;::~ElementHistory(this=0x000055555572ae30) at elements_history.h:103:23 frame #24: 0x00005555555e950b objects_history_test`std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt;::operator(this=0x000055555570f6c8, __ptr=0x000055555572ae30)(qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;*) const at unique_ptr.h:81:2 frame #25: 0x00005555555e9450 objects_history_test`std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt;::~unique_ptr(this=0x000055555570f6c8) at unique_ptr.h:292:4 frame #26: 0x00005555555e93dd objects_history_test`std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt;::~pair(this=0x000055555570f6a8) at stl_iterator.h:1283:12 frame #27: 0x00005555555e93b9 objects_history_test`void __gnu_cxx::new_allocator\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;::destroy\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;(this=0x00007fffffffd1b8, __p=0x000055555570f6a8) at new_allocator.h:152:10 frame #28: 0x00005555555e938d objects_history_test`void std::allocator_traits\u0026lt;std::allocator\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;::destroy\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;(__a=0x00007fffffffd1b8, __p=0x000055555570f6a8) at alloc_traits.h:496:8 frame #29: 0x00005555555e935d objects_history_test`void absl::lts_20210324::container_internal::map_slot_policy\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt;::destroy\u0026lt;std::allocator\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;(alloc=0x00007fffffffd1b8, slot=0x000055555570f6a8) at container_memory.h:408:7 frame #30: 0x00005555555e932d objects_history_test`void absl::lts_20210324::container_internal::FlatHashMapPolicy\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt;::destroy\u0026lt;std::allocator\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;(alloc=0x00007fffffffd1b8, slot=0x000055555570f6a8) at flat_hash_map.h:567:5 frame #31: 0x00005555555e914d objects_history_test`void absl::lts_20210324::container_internal::hash_policy_traits\u0026lt;absl::lts_20210324::container_internal::FlatHashMapPolicy\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt;, void\u0026gt;::destroy\u0026lt;std::allocator\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;(alloc=0x00007fffffffd1b8, slot=0x000055555570f6a8) at hash_policy_traits.h:101:5 frame #32: 0x00005555555e9040 objects_history_test`absl::lts_20210324::container_internal::raw_hash_set\u0026lt;absl::lts_20210324::container_internal::FlatHashMapPolicy\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt;, absl::lts_20210324::container_internal::StringHash, absl::lts_20210324::container_internal::StringHashEq::Eq, std::allocator\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;::destroy_slots(this=0x00007fffffffd198) at raw_hash_set.h:1565:9 frame #33: 0x00005555555e8f79 objects_history_test`absl::lts_20210324::container_internal::raw_hash_set\u0026lt;absl::lts_20210324::container_internal::FlatHashMapPolicy\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt;, absl::lts_20210324::container_internal::StringHash, absl::lts_20210324::container_internal::StringHashEq::Eq, std::allocator\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;::~raw_hash_set(this=0x00007fffffffd198) at raw_hash_set.h:970:21 frame #34: 0x00005555555e8f55 objects_history_test`absl::lts_20210324::container_internal::raw_hash_map\u0026lt;absl::lts_20210324::container_internal::FlatHashMapPolicy\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt;, absl::lts_20210324::container_internal::StringHash, absl::lts_20210324::container_internal::StringHashEq::Eq, std::allocator\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;::~raw_hash_map(this=0x00007fffffffd198) at raw_hash_map.h:31:7 frame #35: 0x00005555555e8b05 objects_history_test`absl::lts_20210324::flat_hash_map\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt;, absl::lts_20210324::container_internal::StringHash, absl::lts_20210324::container_internal::StringHashEq::Eq, std::allocator\u0026lt;std::pair\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const, std::unique_ptr\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt;, std::default_delete\u0026lt;qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt;::~flat_hash_map(this=0x00007fffffffd198) at flat_hash_map.h:108:7 frame #36: 0x00005555555f5f59 objects_history_test`qcraft::elements_history::ElementsHistory\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, double, qcraft::prediction::PredictionObject, qcraft::elements_history::ElementHistory\u0026lt;double, qcraft::prediction::PredictionObject, qcraft::prediction::ObjectHistorySpan\u0026gt; \u0026gt;::~ElementsHistory(this=0x00007fffffffd190) at elements_history.h:152:7 frame #37: 0x00005555555e81f5 objects_history_test`qcraft::prediction::ObjectsHistory::~ObjectsHistory(this=0x00007fffffffd190) at objects_history.h:11:7 frame #38: 0x00005555555e73ae objects_history_test`qcraft::prediction::ObjectsHistoryTest_Test_ObjectHistory_Push_Test::TestBody(this=0x000055555572b5c0) at objects_history_test.cc:13:1 frame #39: 0x00007ffff11d925b libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`void testing::internal::HandleSehExceptionsInMethodIfSupported\u0026lt;testing::Test, void\u0026gt;(object=0x000055555572b5c0, method=21 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00, location=\u0026#34;the test body\u0026#34;)(), char const*) at gtest.cc:2607:10 frame #40: 0x00007ffff11c6cad libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`void testing::internal::HandleExceptionsInMethodIfSupported\u0026lt;testing::Test, void\u0026gt;(object=0x000055555572b5c0, method=21 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00, location=\u0026#34;the test body\u0026#34;)(), char const*) at gtest.cc:2643:14 frame #41: 0x00007ffff11aafe3 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::Test::Run(this=0x000055555572b5c0) at gtest.cc:2682:5 frame #42: 0x00007ffff11abc19 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::TestInfo::Run(this=0x0000555555711b10) at gtest.cc:2861:11 frame #43: 0x00007ffff11ac474 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::TestSuite::Run(this=0x00005555556fc500) at gtest.cc:3015:28 frame #44: 0x00007ffff11be62b libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::internal::UnitTestImpl::RunAllTests(this=0x00005555557183f0) at gtest.cc:5855:44 frame #45: 0x00007ffff11dc0fb libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`bool testing::internal::HandleSehExceptionsInMethodIfSupported\u0026lt;testing::internal::UnitTestImpl, bool\u0026gt;(object=0x00005555557183f0, method=d0 e1 1b f1 ff 7f 00 00 00 00 00 00 00 00 00 00, location=\u0026#34;auxiliary test code (environments or event listeners)\u0026#34;)(), char const*) at gtest.cc:2607:10 frame #46: 0x00007ffff11c9243 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`bool testing::internal::HandleExceptionsInMethodIfSupported\u0026lt;testing::internal::UnitTestImpl, bool\u0026gt;(object=0x00005555557183f0, method=d0 e1 1b f1 ff 7f 00 00 00 00 00 00 00 00 00 00, location=\u0026#34;auxiliary test code (environments or event listeners)\u0026#34;)(), char const*) at gtest.cc:2643:14 frame #47: 0x00007ffff11be15e libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::UnitTest::Run(this=0x00007ffff11f80f8) at gtest.cc:5438:10 frame #48: 0x00007ffff11fcb01 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest_Umain.so`RUN_ALL_TESTS() at gtest.h:2490:46 frame #49: 0x00007ffff11fca9b libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest_Umain.so`main(argc=1, argv=0x00007fffffffd8a8) at gmock_main.cc:70:10 frame #50: 0x00007fffef935bf7 libc.so.6`__libc_start_main + 231 frame #51: 0x00005555555e6b5a objects_history_test`_start + 42 (lldb) thread list Process 11199 stopped * thread #1: tid = 11199, 0x0000555555641c8b objects_history_test`folly::threadlocal_detail::PthreadKeyUnregister::registerKey(key=5) at ThreadLocalDetail.h:272:31, name = \u0026#39;objects_history\u0026#39;, stop reason = breakpoint 3.1 thread #2: tid = 11202, 0x00007ffff7ddd4ab, name = \u0026#39;objects_history\u0026#39; (lldb) break list Current breakpoints: 1: name = \u0026#39;pthread_create\u0026#39;, locations = 1, resolved = 1, hit count = 2 1.1: where = libpthread.so.0`pthread_create@@GLIBC_2.2.5, address = 0x00007ffff0c929b0, resolved, hit count = 2 2: name = \u0026#39;pthread_setspecific\u0026#39;, locations = 1, resolved = 1, hit count = 8 2.1: where = libpthread.so.0`__pthread_setspecific, address = 0x00007ffff0c9a1a0, resolved, hit count = 8 3: name = \u0026#39;folly::threadlocal_detail::PthreadKeyUnregister::registerKey\u0026#39;, locations = 1, resolved = 1, hit count = 3 3.1: where = objects_history_test`folly::threadlocal_detail::PthreadKeyUnregister::registerKey(unsigned int) + 11 at ThreadLocalDetail.h:272:31, address = 0x0000555555641c8b, resolved, hit count = 3 (lldb) br d 2 ambiguous command \u0026#39;breakpoint d\u0026#39;. Possible completions: delete disable (lldb) br de 2 1 breakpoints deleted; 0 breakpoint locations disabled. (lldb) 写了一个段这个来测试删除pkey是不是会导致pthread_setsepcific返回22，符合了预期。主线程退出的时候destroy了pthread_pkey，导致的问题\n#include\u0026lt;stdio.h\u0026gt; #include\u0026lt;pthread.h\u0026gt; #include\u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; pthread_key_t p_key; void func1() { int *tmp = (int*)pthread_getspecific(p_key);//同一线程内的各个函数间共享数据。 printf(\u0026#34;%d is runing in %s\\n\u0026#34;,*tmp,__func__); } void *thread_func(void *args) { int ret = pthread_setspecific(p_key,args); printf(\u0026#34;ret is %d \\n\u0026#34;,ret); int *tmp = (int*)pthread_getspecific(p_key);//获得线程的私有空间 printf(\u0026#34;%d is runing in %s\\n\u0026#34;,*tmp,__func__); *tmp = (*tmp)*100;//修改私有变量的值 func1(); return (void*)0; } int main() { pthread_t pa, pb; int a=1; int b=2; pthread_key_create(\u0026amp;p_key,NULL); pthread_create(\u0026amp;pa, NULL,thread_func,\u0026amp;a); sleep(2); int ret = pthread_key_delete(p_key); printf(\u0026#34;pthread_key_delete ret is %d \\n\u0026#34;,ret); pthread_create(\u0026amp;pb, NULL,thread_func,\u0026amp;b); pthread_join(pa, NULL); pthread_join(pb, NULL); return 0; } qcraft@BJ-vgdog:~/code_test/pthread_key_delete_test$ ./a.out ret is 0 1 is runing in thread_func 100 is runing in func1 pthread_key_delete ret is 0 ret is 22 Segmentation fault 2023/03/21再探该问题，今天又遇到这个问题，同样是pthread_setspecific提示invalid argument，q公司内部实际上有一个曾经的分析，但是当时我没追踪这个问题，另外分析的过程臆想的部分过多，所以从新过滤思路，走了一遍debug。最终的思路如下：\n这个问题看起来似乎并不好调试，但是只需要确定是多线程的问题外加线程局部变量即可检查：因为主线程退出会导致静态变量析构，因此只需要在gtest结束之后调试主线程的时候断点断住pthread_key_delete和pthread_setspecific，令其他线程都暂停即set scheduler-locking on(这里注意，好几个thread local变量清理掉了)。之后打开其他线程继续调试即可。\n这个过程当中可以发现问题的整个过程如下\ngtest主线程调用一个planner的模块，该模块会启动线程2执行任务，执行任务的过程中会调用load地图的函数，注意这里面load地图的函数会传递一个析构函数到主线程。因此当planner的模块退出时，主线程调用析构函数。而该主线程在退出时调用的析构函数会再次创建一个新的线程去执行析构（DestroyContainerAsync，本质是ScheduleFuture一个对象到线程池）。换言之在主线程on_exit的时候，调用了ThreadPool::DisposalPool()去创建第三个线程，执行任务。\n实际上这里如果能够保证第三个线程管理的内存对象都释放掉，那么问题并不严重，但是我们的代码里面调用了folly的threadlocal类型对象，即folly::ThreadLocal\u0026lt;XXXPerThread, XXXTag\u0026gt; xxx_per_thread_;这个东西，它最终会进入下面的代码的pthread_setspecific从而抛出invalid argument，即key是invalid。那么问题就出现了pthread_getspecific没出错说明这个时候key是有效的，pthread_setspecific出错说明这个时候key无效，那么必然是key删除了，这个key为什么会删除，在哪里删除？\nFOLLY_EXPORT FOLLY_NOINLINE static ThreadEntry* getThreadEntrySlow() { auto\u0026amp; meta = instance(); auto key = meta.pthreadKey_; ThreadEntry* threadEntry = static_cast\u0026lt;ThreadEntry*\u0026gt;(pthread_getspecific(key)); if (!threadEntry) { ThreadEntryList* threadEntryList = StaticMeta::getThreadEntryList(); if (kUseThreadLocal) { static thread_local ThreadEntry threadEntrySingleton; threadEntry = \u0026amp;threadEntrySingleton; } else { threadEntry = new ThreadEntry(); } // if the ThreadEntry already exists // but pthread_getspecific returns NULL // do not add the same entry twice to the list // since this would create a loop in the list if (!threadEntry-\u0026gt;list) { threadEntry-\u0026gt;list = threadEntryList; threadEntry-\u0026gt;listNext = threadEntryList-\u0026gt;head; threadEntryList-\u0026gt;head = threadEntry; } threadEntry-\u0026gt;tid() = std::this_thread::get_id(); threadEntry-\u0026gt;tid_os = folly::getOSThreadID(); // if we\u0026#39;re adding a thread entry // we need to increment the list count // even if the entry is reused threadEntryList-\u0026gt;count++; threadEntry-\u0026gt;meta = \u0026amp;meta; int ret = pthread_setspecific(key, threadEntry); checkPosixError(ret, \u0026#34;pthread_setspecific failed\u0026#34;); 这里追踪就能发现folly::threadlocal_detail::PthreadKeyUnregister::~PthreadKeyUnregister()在析构的时候pthread_delete掉了pthread_key类型的变量，PthreadKeyUnregister是一个singleton，主线程退出会调用其析构删除pthread key对象，一旦在set之前析构掉了，那么就会报错pthread_setspecific invalid argument。参考这个实现就很清楚了（实际上注释也写的很清楚了，这个singleton是由析构顺序造成的问题的，其logic并不安全），PthreadKeyUnregister管理着全局的所有的pthread_key。每次新注册的pthread_local都会走这套去注册pthread_key到该类型中，而析构的时候并最终释放掉这些pthread keys。而另外一个新线程此时需要绑定一个局部tls到这个pthreadkey，从而导致这个问题。\nclass PthreadKeyUnregister { public: static constexpr size_t kMaxKeys = 1UL \u0026lt;\u0026lt; 16; ~PthreadKeyUnregister() { // If static constructor priorities are not supported then // ~PthreadKeyUnregister logic is not safe. #if !defined(__APPLE__) \u0026amp;\u0026amp; !defined(_MSC_VER) MSLGuard lg(lock_); // 最终考虑了下，once and for all还是直接注释掉下面三句话。。。。 while (size_) { pthread_key_delete(keys_[--size_]); } #endif } static void registerKey(pthread_key_t key) { instance_.registerKeyImpl(key); } private: /** * Only one global instance should exist, hence this is private. * See also the important note at the top of this class about `constexpr` * usage. */ constexpr PthreadKeyUnregister() : lock_(), size_(0), keys_() {} friend struct folly::threadlocal_detail::PthreadKeyUnregisterTester; void registerKeyImpl(pthread_key_t key) { MSLGuard lg(lock_); if (size_ == kMaxKeys) { throw_exception\u0026lt;std::logic_error\u0026gt;( \u0026#34;pthread_key limit has already been reached\u0026#34;); } keys_[size_++] = key; } MicroSpinLock lock_; size_t size_; pthread_key_t keys_[kMaxKeys]; static PthreadKeyUnregister instance_; }; 这里我们最终回归一下，为什么说程序开始的时候调用DestroyContainerAsync(std::move(x x x)); 强制初始化好ThreadLocal变量，只是虚假的解决了这个问题，而不是真正地解决，还是回到下面的代码，是因为如果强行构造std::move来程序正常运行时绑定了tls到pthread_key，之后这里的pthread_getspecific获取就不会出现threadEntry为空的情况，从而就不会调用的pthread_setspecific，所以不会出现pthread_setspecific的问题。其实际上并没有保证内存是正常的\nFOLLY_NOINLINE static void getSlowReserveAndCache( EntryID* ent, uint32_t\u0026amp; id, ThreadEntry*\u0026amp; threadEntry, size_t\u0026amp; capacity) { auto\u0026amp; inst = instance(); threadEntry = inst.threadEntry_(); \u0026lt;=== run here if (UNLIKELY(threadEntry-\u0026gt;getElementsCapacity() \u0026lt;= id)) { inst.reserve(ent); id = ent-\u0026gt;getOrInvalid(); } capacity = threadEntry-\u0026gt;getElementsCapacity(); assert(capacity \u0026gt; id); } FOLLY_EXPORT FOLLY_NOINLINE static ThreadEntry* getThreadEntrySlow() { // 拿到对应的staticMeta auto\u0026amp; meta = instance(); // 拿到对应的pthreadkey auto key = meta.pthreadKey_; // 获取对当前线程拿到的ThreadEntry ThreadEntry* threadEntry = static_cast\u0026lt;ThreadEntry*\u0026gt;(pthread_getspecific(key)); // 就是这里实际上不会返回null了 if (!threadEntry) { // threadEntry为空说明当前线程就没这个玩意，那么我们就得分配新的ThreadEntry开始用啦 // 这里注意ThreadEntryList是StaticMeta的东西 ThreadEntryList* threadEntryList = StaticMeta::getThreadEntryList(); if (kUseThreadLocal) { static thread_local ThreadEntry threadEntrySingleton; threadEntry = \u0026amp;threadEntrySingleton; } else { threadEntry = new ThreadEntry(); } // if the ThreadEntry already exists // but pthread_getspecific returns NULL // do not add the same entry twice to the list // since this would create a loop in the list // 刚才的新造出来的，当前线程的存储的局部ThreadEntry放到threadEntryList里面 if (!threadEntry-\u0026gt;list) { threadEntry-\u0026gt;list = threadEntryList; threadEntry-\u0026gt;listNext = threadEntryList-\u0026gt;head; threadEntryList-\u0026gt;head = threadEntry; } // 再存储下tid threadEntry-\u0026gt;tid() = std::this_thread::get_id(); threadEntry-\u0026gt;tid_os = folly::getOSThreadID(); // if we\u0026#39;re adding a thread entry // we need to increment the list count // even if the entry is reused threadEntryList-\u0026gt;count++; threadEntry-\u0026gt;meta = \u0026amp;meta; // 上面都加好了，现在可以设置绑定到当前线程啦 int ret = pthread_setspecific(key, threadEntry); \u0026lt;=== run here checkPosixError(ret, \u0026#34;pthread_setspecific failed\u0026#34;); } //不为空直接返回了拿到的当前线程的ThreadEntry return threadEntry; } 附上程序栈和部分代码的分析\n(gdb) bt #0 0x00007fffe8de1d50 in __GI___pthread_setspecific (key=9, value=0x7fffde552518) at pthread_setspecific.c:26 # 这里就到了有趣的地方了，解释看上面的部分 #1 0x00007fffee3dd94c in folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::getThreadEntrySlow() () at external/folly/folly/detail/ThreadLocalDetail.h:497 # frame 2 getSlowReserveAndCache这个的代码就不贴了，这里实际上是拿到staticmeta\u0026lt;Tag\u0026gt;的instance # 即只针对某一种类型的staticmeta的单例 #2 0x00007fffee3dd4ab in folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::getSlowReserveAndCache(folly::threadlocal_detail::StaticMetaBase::EntryID*, unsigned int\u0026amp;, folly::threadlocal_detail::ThreadEntry*\u0026amp;, unsigned long\u0026amp;) (ent=0x5555556eaa80, id=@0x7fffde550c64: 1, threadEntry=@0x7fffde552508: 0x0, capacity=@0x7fffde552510: 0) at external/folly/folly/detail/ThreadLocalDetail.h:459 # frame 3的代码如下 # FOLLY_EXPORT FOLLY_ALWAYS_INLINE static ElementWrapper\u0026amp; get(EntryID* ent) { # // Eliminate as many branches and as much extra code as possible in the # // cached fast path, leaving only one branch here and one indirection below. # uint32_t id = ent-\u0026gt;getOrInvalid(); ##ifdef FOLLY_TLD_USE_FOLLY_TLS # static FOLLY_TLS ThreadEntry* threadEntry{}; \u0026lt;== notice here， it\u0026#39;s a per thread static thing as well # static FOLLY_TLS size_t capacity{}; \u0026lt;== FOLLY_TLS is macro for _thread per thread as well ##else # ThreadEntry* threadEntry{}; # size_t capacity{}; ##endif # if (FOLLY_UNLIKELY(capacity \u0026lt;= id)) { # getSlowReserveAndCache(ent, id, threadEntry, capacity); \u0026lt;== run here # } # return threadEntry-\u0026gt;elements[id]; # } # 这次在做什么操作呢，实际上就是在给元素做cache缓存和分配。这里注意 # ThreadEntry* threadEntry{}是第一次分配的时候的事情，这时候这个东西实际上是空的指针！也就是说如果第一次过来会申请 # 但是如果已经走了一遍申请，因为静态变量不会多次初始化，所以只要它变了，它就是变了， # 下次再来访问这里的时候,id和capcity都是确定的，如果是新的那么id就增加了,capacity就会 # # # # #3 0x00007fffee3dd37f in folly::threadlocal_detail::StaticMeta\u0026lt;qcraft::CounterImpl::CounterTag, void\u0026gt;::get(folly::threadlocal_detail::StaticMetaBase::EntryID*) (ent=0x5555556eaa80) at external/folly/folly/detail/ThreadLocalDetail.h:448 # frame 4的代码如下 # T* get() const { # threadlocal_detail::ElementWrapper\u0026amp; w = StaticMeta::get(\u0026amp;id_); \u0026lt;== run here # return static_cast\u0026lt;T*\u0026gt;(w.ptr); # } # 所以可以清楚的看到，这个时候实际上是从StaticMeta当中通过id拿到真实元素的wrapper,StaticMeta是一个类型设定好了singleton # 对于整个程序而言，一种类型对应一种StaticMeta，用folly自己的话 # We have one of these per \u0026#34;Tag\u0026#34;, by default one for the whole system， # 在这里我们就能确定我们操作的是CounterTag的StaticMeta，但是这里的id_是什么？如果是默认构造函数，能够看到id_调用默认构造 # 由其他的ThreadLocalPtr那么就拿别人的id_ #4 0x00007fffee3dd37f in folly::ThreadLocalPtr\u0026lt;qcraft::CounterImpl::CounterPerThread, qcraft::CounterImpl::CounterTag, void\u0026gt;::get() const (this=0x5555556eaa80) at external/folly/folly/ThreadLocal.h:158 # frame 5 这里实际上就是获取对应的perthread的数据的过程,对应的代码如下 # FOLLY_ERASE T* get() const { # auto const ptr = tlp_.get(); \u0026lt;==运行到这里 # return FOLLY_LIKELY(!!ptr) ? ptr : makeTlp(); # } # 第一个问题就来了tlp_是个什么东西，其定义为mutable ThreadLocalPtr\u0026lt;T, Tag, AccessMode\u0026gt; tlp_ # 所以实际上就是一个ThreadLocalPtr类型，参考https://github.com/facebook/folly/blob/main/folly/docs/ThreadLocal.md # 所以实际上folly::ThreadLocal就是一成folly::ThreadLocalPtr的包裹，哈哈哈，这个具体干啥可以直接查询到 #5 0x00007fffee3ca7d1 in folly::ThreadLocal\u0026lt;qcraft::CounterImpl::CounterPerThread, qcraft::CounterImpl::CounterTag, void\u0026gt;::get() const (this=0x5555556eaa80) at external/folly/folly/ThreadLocal.h:68 # frame 6 真正开始调用operator-\u0026gt;()，因为其是一个threadlocal类型的变量，所以指针寻找的过程实际上重写了对应的过程 # 这里实际上就是把xxxx_per_thread_当成了一个指针 #6 0x00007fffee3ca7d1 in folly::ThreadLocal\u0026lt;qcraft::CounterImpl::CounterPerThread, qcraft::CounterImpl::CounterTag, void\u0026gt;::operator-\u0026gt;() const (this=0x5555556eaa80) at external/folly/folly/ThreadLocal.h:73 # frame 7 的代码实际上是个xxxx_per_thread_-\u0026gt;spin_lock.Lock(), # xxxx_per_thread_对应的类别是XXXPerThread，里面放了一个boost::circular_buffer和SpinLock #7 0x00007fffee3b90a4 in qcraft::CounterImpl::AddCounterEvent(char const*, long) (this=0x5555556eaa80, name=0x7fffee41e698 \u0026#34;AddTraceEvent\u0026#34;, val=12096) at onboard/global/counter.cc:70 #8 0x00007fffee3baa3d in qcraft::Counter::AddCounterEventInternal(char const*, long) (this=0x555555744ca0, name=0x7fffee41e698 \u0026#34;AddTraceEvent\u0026#34;, val=12096) at onboard/global/counter.cc:208 #9 0x00007ffff76a1d25 in qcraft::Counter::AddCounterEvent\u0026lt;long\u0026gt;(char const*, long) (this=0x555555744ca0, name=0x7fffee41e698 \u0026#34;AddTraceEvent\u0026#34;, val=12096) at ./onboard/global/counter.h:40 #10 0x00007ffff7668d3b in qcraft::CounterEventWrapper::~CounterEventWrapper() (this=0x7fffde550f18) at ./onboard/global/counter.h:64 #11 0x00007fffee440325 in qcraft::TraceImpl::AddTraceEvent(qcraft::TraceEvent const\u0026amp;) (this=0x7fffd901e0e0, trace_event=...) at onboard/global/trace.cc:75 #12 0x00007fffee42f675 in qcraft::Trace::AddTraceEvent(qcraft::TraceEvent const\u0026amp;) (this=0x7fffd901a0f0, trace_event=...) at onboard/global/trace.cc:342 #13 0x00007ffff7bc2a96 in qcraft::ScopedTrace::ScopedTrace(char const*, bool) (this=0x7fffde5510d0, name=0x7ffff3d3ab2b \u0026#34;DestroyContainerAsync\u0026#34;, use_ftrace=true) at ./onboard/global/trace.h:150 #14 0x00007ffff3dbeb76 in void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1}::operator()() (this=0x555555728d78) at ./onboard/async/async_util.h:40 #15 0x00007ffff3dc275d in std::__invoke_impl\u0026lt;void, void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1}\u0026amp;\u0026gt;(std::__invoke_other, void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1}\u0026amp;) (__f=...) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/invoke.h:60 #16 0x00007ffff3dc272d in std::__invoke\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1}\u0026amp;\u0026gt;(void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1}\u0026amp;, (std::__invoke_result\u0026amp;\u0026amp;)...) (__fn=...) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/invoke.h:95 #17 0x00007ffff3dc2709 in std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;::__call\u0026lt;void\u0026gt;(std::tuple\u0026lt;\u0026gt;\u0026amp;\u0026amp;, std::_Index_tuple\u0026lt;\u0026gt;) (this=0x555555728d78, __args=...) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/functional:400 #18 0x00007ffff3dc26e6 in std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;::operator()\u0026lt;, void\u0026gt;() (this=0x555555728d78) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/functional:482 #19 0x00007ffff3dc269d in std::__invoke_impl\u0026lt;void, std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;\u0026amp;\u0026gt;(std::__invoke_other, std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;\u0026amp;) (__f=...) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/invoke.h:60 #20 0x00007ffff3dc266d in std::__invoke\u0026lt;std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;\u0026amp;\u0026gt;(std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;\u0026amp;, (std::__invoke_result\u0026amp;\u0026amp;)...) (__fn=...) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/invoke.h:95 #21 0x00007ffff3dc263c in std::__future_base::_Task_state\u0026lt;std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;, std::allocator\u0026lt;int\u0026gt;, void ()\u0026gt;::_M_run()::{lambda()#1}::operator()() const (this=0x7fffde551660) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/future:1421 #22 0x00007ffff3dc251c in std::__future_base::_Task_setter\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result\u0026lt;void\u0026gt;, std::__future_base::_Result_base::_Deleter\u0026gt;, std::__future_base::_Task_state\u0026lt;std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;, std::allocator\u0026lt;int\u0026gt;, void ()\u0026gt;::_M_run()::{lambda()#1}, void\u0026gt;::operator()() const (this=0x7fffde551640) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/future:1362 #23 0x00007ffff3dc23b0 in std::_Function_handler\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; (), std::__future_base::_Task_setter\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result\u0026lt;void\u0026gt;, std::__future_base::_Result_base::_Deleter\u0026gt;, std::__future_base::_Task_state\u0026lt;std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;, std::allocator\u0026lt;int\u0026gt;, void ()\u0026gt;::_M_run()::{lambda()#1}, void\u0026gt; \u0026gt;::_M_invoke(std::_Any_data const\u0026amp;) (__functor=...) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:285 #24 0x00007ffff3dab658 in std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;::operator()() const (this=0x7fffde551640) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:688 #25 0x00007ffff3dab379 in std::__future_base::_State_baseV2::_M_do_set(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*) (this=0x555555728d50, __f=0x7fffde551640, __did_set=0x7fffde5515c6) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/future:561 #26 0x00007ffff3dab601 in std::__invoke_impl\u0026lt;void, void (std::__future_base::_State_baseV2::*)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*\u0026gt;(std::__invoke_memfun_deref, void (std::__future_base::_State_baseV2::*\u0026amp;\u0026amp;)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*\u0026amp;\u0026amp;, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*\u0026amp;\u0026amp;, bool*\u0026amp;\u0026amp;) (__f= @0x7fffde5515b0: (void (std::__future_base::_State_baseV2::*)(std::__future_base::_State_baseV2 * const, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt; *, bool *)) 0x7ffff3dab350 \u0026lt;std::__future_base::_State_baseV2::_M_do_set(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*)\u0026gt;, __t=@0x7fffde5515a8: 0x555555728d50, __args=@0x7fffde5515a0: 0x7fffde551640, __args=@0x7fffde551598: 0x7fffde5515c6) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/invoke.h:73 #27 0x00007ffff3dab50c in std::__invoke\u0026lt;void (std::__future_base::_State_baseV2::*)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*\u0026gt;(void (std::__future_base::_State_baseV2::*\u0026amp;\u0026amp;)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*\u0026amp;\u0026amp;, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*\u0026amp;\u0026amp;, bool*\u0026amp;\u0026amp;) (__fn= @0x7fffde5515b0: (void (std::__future_base::_State_baseV2::*)(std::__future_base::_State_baseV2 * const, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt; *, bool *)) 0x7ffff3dab350 \u0026lt;std::__future_base::_State_baseV2::_M_do_set(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*)\u0026gt;, __args=@0x7fffde5515a8: 0x555555728d50, __args=@0x7fffde5515a0: 0x7fffde551640, __args=@0x7fffde551598: 0x7fffde5515c6) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/invoke.h:95 #28 0x00007ffff3dab49c in void std::call_once\u0026lt;void (std::__future_base::_State_baseV2::*)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*\u0026gt;(std::once_flag\u0026amp;, void (std::__future_base::_State_baseV2::*\u0026amp;\u0026amp;)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*\u0026amp;\u0026amp;, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*\u0026amp;\u0026amp;, bool*\u0026amp;\u0026amp;)::{lambda()#1}::operator()() const (this=0x7fffde551518) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/mutex:671 #29 0x00007ffff3dab424 in void std::call_once\u0026lt;void (std::__future_base::_State_baseV2::*)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*\u0026gt;(std::once_flag\u0026amp;, void (std::__future_base::_State_baseV2::*\u0026amp;\u0026amp;)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*\u0026amp;\u0026amp;, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*\u0026amp;\u0026amp;, bool*\u0026amp;\u0026amp;)::{lambda()#2}::operator()() const (this=0x7ffff7e57758) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/mutex:676 #30 0x00007ffff3dab3f9 in void std::call_once\u0026lt;void (std::__future_base::_State_baseV2::*)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*\u0026gt;(std::once_flag\u0026amp;, void (std::__future_base::_State_baseV2::*\u0026amp;\u0026amp;)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*\u0026amp;\u0026amp;, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*\u0026amp;\u0026amp;, bool*\u0026amp;\u0026amp;)::{lambda()#2}::__invoke() () at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/mutex:676 #31 0x00007fffe8de24df in __pthread_once_slow (once_control=0x555555728d68, init_routine=0x7ffff7d51c20 \u0026lt;__once_proxy\u0026gt;) at pthread_once.c:116 #32 0x00007ffff3d938cb in __gthread_once(int*, void (*)()) (__once=0x555555728d68, __func=0x7ffff7d51c20 \u0026lt;__once_proxy\u0026gt;) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/x86_64-linux-gnu/c++/9/bits/gthr-default.h:700 #33 0x00007ffff3dab334 in std::call_once\u0026lt;void (std::__future_base::_State_baseV2::*)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*\u0026gt;(std::once_flag\u0026amp;, void (std::__future_base::_State_baseV2::*\u0026amp;\u0026amp;)(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*), std::__future_base::_State_baseV2*\u0026amp;\u0026amp;, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*\u0026amp;\u0026amp;, bool*\u0026amp;\u0026amp;) (__once=..., __f= ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- @0x7fffde5515b0: (void (std::__future_base::_State_baseV2::*)(std::__future_base::_State_baseV2 * const, std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt; *, bool *)) 0x7ffff3dab350 \u0026lt;std::__future_base::_State_baseV2::_M_do_set(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;*, bool*)\u0026gt;, __args=@0x7fffde5515a8: 0x555555728d50, __args=@0x7fffde5515a0: 0x7fffde551640, __args=@0x7fffde551598: 0x7fffde5515c6) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/mutex:683 #34 0x00007ffff3daae2e in std::__future_base::_State_baseV2::_M_set_result(std::function\u0026lt;std::unique_ptr\u0026lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter\u0026gt; ()\u0026gt;, bool) (this=0x555555728d50, __res=..., __ignore_failure=false) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/future:401 #35 0x00007ffff3dc1f71 in std::__future_base::_Task_state\u0026lt;std::_Bind\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;, std::allocator\u0026lt;int\u0026gt;, void ()\u0026gt;::_M_run() (this=0x555555728d50) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/future:1423 #36 0x00007ffff3dc0a7b in std::packaged_task\u0026lt;void ()\u0026gt;::operator()() (this=0x5555558181b0) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/future:1551 #37 0x00007ffff3dc388d in qcraft::Future\u0026lt;std::result_of\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;::type\u0026gt; qcraft::ThreadPool::Schedule\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1}\u0026gt;(void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1}\u0026amp;\u0026amp;, (std::result_of\u0026amp;\u0026amp;)...)::{lambda()#1}::operator()() const (this=0x5555557287e0) at ./onboard/async/thread_pool.h:118 #38 0x00007ffff3dc372d in std::_Function_handler\u0026lt;void (), qcraft::Future\u0026lt;std::result_of\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1} ()\u0026gt;::type\u0026gt; qcraft::ThreadPool::Schedule\u0026lt;void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1}\u0026gt;(void qcraft::DestroyContainerAsync\u0026lt;qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt; \u0026gt;(qcraft::ThreadPool*, qcraft::LockFileAndDelete\u0026lt;qcraft::mapping::v2::SemanticMapManager\u0026gt;)::{lambda()#1}\u0026amp;\u0026amp;, (std::result_of\u0026amp;\u0026amp;)...)::{lambda()#1}\u0026gt;::_M_invoke(std::_Any_data const\u0026amp;) (__functor=...) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:300 #39 0x00007ffff7668ad5 in std::function\u0026lt;void ()\u0026gt;::operator()() const (this=0x7fffde551748) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:688 #40 0x00007fffee4756bb in qcraft::ThreadPool::ThreadPool(int, std::function\u0026lt;void (int)\u0026gt; const\u0026amp;)::$_0::operator()() const (this=0x555555727e88) at onboard/async/thread_pool.cc:74 #41 0x00007fffee47542d in _ZSt13__invoke_implIvZN6qcraft10ThreadPoolC1EiRKSt8functionIFviEEE3$_0JEET_St14__invoke_otherOT0_DpOT1_ (__f=...) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/invoke.h:60 #42 0x00007fffee4753bd in _ZSt8__invokeIZN6qcraft10ThreadPoolC1EiRKSt8functionIFviEEE3$_0JEENSt15__invoke_resultIT_JDpT0_EE4typeEOS9_DpOSA_ (__fn=...) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/invoke.h:95 #43 0x00007fffee475395 in std::thread::_Invoker\u0026lt;std::tuple\u0026lt;qcraft::ThreadPool::ThreadPool(int, std::function\u0026lt;void (int)\u0026gt; const\u0026amp;)::$_0\u0026gt; \u0026gt;::_M_invoke\u0026lt;0ul\u0026gt;(std::_Index_tuple\u0026lt;0ul\u0026gt;) (this=0x555555727e88) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/thread:244 #44 0x00007fffee475365 in std::thread::_Invoker\u0026lt;std::tuple\u0026lt;qcraft::ThreadPool::ThreadPool(int, std::function\u0026lt;void (int)\u0026gt; const\u0026amp;)::$_0\u0026gt; \u0026gt;::operator()() (this=0x555555727e88) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/thread:251 #45 0x00007fffee475229 in std::thread::_State_impl\u0026lt;std::thread::_Invoker\u0026lt;std::tuple\u0026lt;qcraft::ThreadPool::ThreadPool(int, std::function\u0026lt;void (int)\u0026gt; const\u0026amp;)::$_0\u0026gt; \u0026gt; \u0026gt;::_M_run() (this=0x555555727e80) at /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/thread:195 #46 0x00007ffff7d52de4 in () at /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #47 0x00007fffe8dd9609 in start_thread (arg=\u0026lt;optimized out\u0026gt;) at pthread_create.c:477 #48 0x00007fffe858b133 in clone () at /lib/x86_64-linux-gnu/libc.so.6 到这里这个事情基本就结束了\n14 因为升级glog导致的问题 # 这几天维护代码库遇到一个问题，我们有一个Async的Logtest忽然开始bangbangbang出错了，代码大致如下\nTEST(AsyncLoggerTest, SetLoggerToGlog) { ... AsyncLogger logger(google::base::GetLogger(google::INFO)); google::base::SetLogger(FLAGS_minloglevel, \u0026amp;logger); ... google::ShutdownGoogleLogging(); } //gtest的报错信息 FAIL: //cyber/logger:async_logger_test ... INFO: From Testing //cyber/logger:async_logger_test: ==================== Test output for //cyber/logger:async_logger_test: Running main() from gmock_main.cc [==========] Running 2 tests from 1 test suite. [----------] Global test environment set-up. [----------] 2 tests from AsyncLoggerTest [ RUN ] AsyncLoggerTest.WriteAndFlush [ OK ] AsyncLoggerTest.WriteAndFlush (3 ms) [ RUN ] AsyncLoggerTest.SetLoggerToGlog E20220301 18:15:28.254946 8519 async_logger_test.cc:65] [AsyncLoggerTest2]test set async logger to glog free(): invalid pointer ================================================================================ Target //cyber/logger:async_logger_test up-to-date: bazel-bin/cyber/logger/async_logger_test INFO: Elapsed time: 1.325s, Critical Path: 1.09s INFO: 2 processes: 2 processwrapper-sandbox. INFO: Build completed, 1 test FAILED, 2 total actions Test cases: finished with 0 passing and 1 failing out of 1 test cases 然后我开始介入，基本上free报invalid pointer都是传入的指针不对，看了下就是logger的地址被传递给了free的参数，一开始没反应过来，以为是函数写越界地址写错了，然后后来忽然感觉不对劲：logger是个局部变量，明明是栈上的怎么就在ShutdownGoogleLogging里面给free了，然后看了下free函数寄存器等东西发现确实是free的这个地址！\nrdx = 0x0000555555664010 rdi = 0x00007fffffffd208 rsi = 0x0000000000000000 apollo::cyber::logger::AsyncLogger::AsyncLogger (lldb) register read General Purpose Registers: rax = 0x0000000000000000 rbx = 0x0000000000000000 rcx = 0x0000000000000002 rdx = 0x0000555555664010 rdi = 0x00007fffffffd208 rsi = 0x0000000000000000 rbp = 0x00007fffffffd0c0 rsp = 0x00007fffffffd0a8 r8 = 0x000055555567dd60 r9 = 0x00007fffffffcd10 r10 = 0x00007fffffffcd10 r11 = 0x0000000000000206 r12 = 0x000055555558edd0 async_logger_test`_start r13 = 0x00007fffffffd8f0 r14 = 0x0000000000000000 r15 = 0x0000000000000000 rip = 0x00007fffed33ca30 libc.so.6`cfree rflags = 0x0000000000000206 cs = 0x0000000000000033 fs = 0x0000000000000000 gs = 0x0000000000000000 ss = 0x000000000000002b ds = 0x0000000000000000 es = 0x0000000000000000 (lldb) br list Current breakpoints: 1: name = \u0026#39;apollo::cyber::logger::AsyncLogger::~AsyncLogger\u0026#39;, locations = 2, resolved = 2, hit count = 21 1.1: where = libcyber_Slogger_Slibasync_Ulogger.so`apollo::cyber::logger::AsyncLogger::~AsyncLogger() + 20 at async_logger.cc:39:29, address = 0x00007ffff7e5efd4, resolved, hit count = 7 1.2: where = libcyber_Slogger_Slibasync_Ulogger.so`apollo::cyber::logger::AsyncLogger::~AsyncLogger() + 20 at async_logger.cc:39:29, address = 0x00007ffff7e5eaf4, resolved, hit count = 14 5: name = \u0026#39;free\u0026#39;, locations = 3, resolved = 3, hit count = 16 5.1: where = ld-2.27.so`free, address = 0x00007ffff7dee800, resolved, hit count = 0 5.2: where = libexternal_Sboost_Slibasio.so`boost::asio::detail::object_pool\u0026lt;boost::asio::detail::epoll_reactor::descriptor_state\u0026gt;::free(boost::asio::detail::epoll_reactor::descriptor_state*) + 24 at object_pool.hpp:128:9, address = 0x00007ffff3317648, resolved, hit count = 0 5.3: where = libc.so.6`cfree, address = 0x00007fffed33ca30, resolved, hit count = 16 很有趣的一点，明明这个变量在栈上，为什么会送到free函数上？ 看下分配的函数 -\u0026gt; 0x55555558f5f7 \u0026lt;+87\u0026gt;: callq 0x5555555d9a80 ; symbol stub for: google::base::GetLogger(int) 0x55555558f5fc \u0026lt;+92\u0026gt;: movq %rax, %rsi 0x55555558f5ff \u0026lt;+95\u0026gt;: leaq -0x78(%rbp), %rdi 0x55555558f603 \u0026lt;+99\u0026gt;: movq %rdi, -0xc0(%rbp) 0x55555558f60a \u0026lt;+106\u0026gt;: callq 0x5555555d9a90 ; symbol stub for: apollo::cyber::logger::AsyncLogger::AsyncLogger(google::base::Logger*) 0x55555558f60f \u0026lt;+111\u0026gt;: movq -0xc0(%rbp), %rsi 0x55555558f616 \u0026lt;+118\u0026gt;: movq 0x4eb33(%rip), %rax 0x55555558f61d \u0026lt;+125\u0026gt;: movl (%rax), %edi 0x55555558f61f \u0026lt;+127\u0026gt;: callq 0x5555555d9bf0 ; symbol stub for: google::base::SetLogger(int, google::base::Logger*) 0x55555558f624 \u0026lt;+132\u0026gt;: jmp 0x55555558f629 ; \u0026lt;+137\u0026gt; at async_logger_test.cc 0x55555558f629 \u0026lt;+137\u0026gt;: leaq -0x78(%rbp), %rdi 0x55555558f62d \u0026lt;+141\u0026gt;: callq 0x5555555d9b60 ; symbol stub for: apollo::cyber::logger::AsyncLogger::Start() 0x55555558f632 \u0026lt;+146\u0026gt;: jmp 0x55555558f637 ; \u0026lt;+151\u0026gt; at async_logger_test.cc:63:3 非常清楚，调用apollo::cyber::logger::AsyncLogger::AsyncLogger的对象（实际上是rdi）是从栈上申请出来的地址，怎么最后就送到了free函数了呢？ 开始翻修改记录，发现同事把代码从glog 0.4升级到了0.5的代码，然后打了下断点看了下调用栈\nRunning main() from gmock_main.cc [==========] Running 2 tests from 1 test suite. [----------] Global test environment set-up. [----------] 2 tests from AsyncLoggerTest [ RUN ] AsyncLoggerTest.WriteAndFlush [ OK ] AsyncLoggerTest.WriteAndFlush (3 ms) [ RUN ] AsyncLoggerTest.SetLoggerToGlog E20220301 18:26:51.491030 15911 async_logger_test.cc:65] [AsyncLoggerTest2]test set async logger to glog free(): invalid pointer Process 15911 stopped * thread #1, name = \u0026#39;async_logger_te\u0026#39;, stop reason = signal SIGABRT frame #0: 0x00007fffed30dfb7 libc.so.6`raise + 199 libc.so.6`raise: -\u0026gt; 0x7fffed30dfb7 \u0026lt;+199\u0026gt;: movq 0x108(%rsp), %rcx 0x7fffed30dfbf \u0026lt;+207\u0026gt;: xorq %fs:0x28, %rcx 0x7fffed30dfc8 \u0026lt;+216\u0026gt;: movl %r8d, %eax 0x7fffed30dfcb \u0026lt;+219\u0026gt;: jne 0x7fffed30dfec ; \u0026lt;+252\u0026gt; (lldb) bt * thread #1, name = \u0026#39;async_logger_te\u0026#39;, stop reason = signal SIGABRT * frame #0: 0x00007fffed30dfb7 libc.so.6`raise + 199 frame #1: 0x00007fffed30f921 libc.so.6`abort + 321 frame #2: 0x00007fffed358967 libc.so.6`___lldb_unnamed_symbol237$$libc.so.6 + 631 frame #3: 0x00007fffed35f9da libc.so.6`___lldb_unnamed_symbol295$$libc.so.6 + 26 frame #4: 0x00007fffed366f0c libc.so.6`cfree + 1244 frame #5: 0x00007ffff7e5efe2 libcyber_Slogger_Slibasync_Ulogger.so`apollo::cyber::logger::AsyncLogger::~AsyncLogger(this=0x00007fffffffd218) at async_logger.cc:39:29 frame #6: 0x00007fffef39da79 libexternal_Scom_Ugithub_Ugoogle_Uglog_Slibglog.so`google::LogDestination::~LogDestination(this=0x0000555555691c70) at logging.cc:638:5 frame #7: 0x00007fffef39dbff libexternal_Scom_Ugithub_Ugoogle_Uglog_Slibglog.so`google::LogDestination::DeleteLogDestinations() at logging.cc:902:5 frame #8: 0x00007fffef3a3282 libexternal_Scom_Ugithub_Ugoogle_Uglog_Slibglog.so`google::ShutdownGoogleLogging() at logging.cc:2573:3 frame #9: 0x000055555558f838 async_logger_test`apollo::cyber::logger::AsyncLoggerTest_SetLoggerToGlog_Test::TestBody(this=0x00005555556b5180) at async_logger_test.cc:67:3 frame #10: 0x00007fffeeb94d9b libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`void testing::internal::HandleSehExceptionsInMethodIfSupported\u0026lt;testing::Test, void\u0026gt;(object=0x00005555556b5180, method=21 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00, location=\u0026#34;the test body\u0026#34;)(), char const*) at gtest.cc:2607:10 frame #11: 0x00007fffeeb82a0d libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`void testing::internal::HandleExceptionsInMethodIfSupported\u0026lt;testing::Test, void\u0026gt;(object=0x00005555556b5180, method=21 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00, location=\u0026#34;the test body\u0026#34;)(), char const*) at gtest.cc:2643:14 frame #12: 0x00007fffeeb673e3 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::Test::Run(this=0x00005555556b5180) at gtest.cc:2682:5 frame #13: 0x00007fffeeb67fc9 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::TestInfo::Run(this=0x00005555556c2080) at gtest.cc:2861:11 frame #14: 0x00007fffeeb68814 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::TestSuite::Run(this=0x000055555570f3b0) at gtest.cc:3015:28 frame #15: 0x00007fffeeb7a5d8 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::internal::UnitTestImpl::RunAllTests(this=0x0000555555707b20) at gtest.cc:5855:44 frame #16: 0x00007fffeeb97c2b libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`bool testing::internal::HandleSehExceptionsInMethodIfSupported\u0026lt;testing::internal::UnitTestImpl, bool\u0026gt;(object=0x0000555555707b20, method=80 a1 b7 ee ff 7f 00 00 00 00 00 00 00 00 00 00, location=\u0026#34;auxiliary test code (environments or event listeners)\u0026#34;)(), char const*) at gtest.cc:2607:10 frame #17: 0x00007fffeeb84f73 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`bool testing::internal::HandleExceptionsInMethodIfSupported\u0026lt;testing::internal::UnitTestImpl, bool\u0026gt;(object=0x0000555555707b20, method=80 a1 b7 ee ff 7f 00 00 00 00 00 00 00 00 00 00, location=\u0026#34;auxiliary test code (environments or event listeners)\u0026#34;)(), char const*) at gtest.cc:2643:14 frame #18: 0x00007fffeeb7a118 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so`testing::UnitTest::Run(this=0x00007fffeebb3b60) at gtest.cc:5438:10 frame #19: 0x00007fffeebb5a81 libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest_Umain.so`RUN_ALL_TESTS() at gtest.h:2490:46 frame #20: 0x00007fffeebb5a1b libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest_Umain.so`main(argc=1, argv=0x00007fffffffd908) at gmock_main.cc:70:10 frame #21: 0x00007fffed2f0bf7 libc.so.6`__libc_start_main + 231 frame #22: 0x000055555558edba async_logger_test`_start + 42 (lldb) 然后比较了一下glog 0.4和glog 0.5发现确实代码变了，还真是这个问题，然后查了一下glog的代码修改流程发现还真是这个事情，直接把整个logger的管理丢给了https://github.com/google/glog/commit/28321d8959574a8268de3ebe41d40cf65415fc9b\n//glog 0.4 ~LogDestination() { } //glog 0.5 LogDestination::~LogDestination() { if (logger_ \u0026amp;\u0026amp; logger_ != \u0026amp;fileobject_) { // Delete user-specified logger set via SetLogger(). delete logger_; } } 15奇怪的调度 # 这个问题说起来并不难查，但是因为很久没做过性能方面的优化和分析，本身又对k8s不熟悉，所以漏了怯了。。。。回头写一个单独如何做性能分析的文章来总结下问题查询的方法。轻舟做CI，目前在迁移仿真从aws到阿里云集群（这个背景要注意），有的时候仿真的集群运行忽然就很慢，往往跑个pod发现要跑一个多小时，然后因为pod超时被kill，这个场景的测试又多次重试，从而又失败了。加了几条代码打日志看了下，代码如下：\nstd::vector\u0026lt;std::vector\u0026lt;cv::Mat\u0026gt;\u0026gt; PanoNet::ClassifyImagePixels( const std::vector\u0026lt;cv::Mat\u0026gt;\u0026amp; images) { SCOPED_QTRACE_ARG1(\u0026#34;PanoNet::ClassifyImagePixels\u0026#34;, \u0026#34;gpu_id\u0026#34;, GpuId_Name(net_param_.gpu_id())); absl::Time start = absl::Now(); ..... if (SimCacheActive() \u0026amp;\u0026amp; !use_gpu_) { .... auto sim_cache = GlobalSimCache::GetSimCache(); if (!sim_cache-\u0026gt;GetResult(cache_key, \u0026amp;outputs)) { .... } int64_t into_check_latency_2 = absl::ToInt64Milliseconds(absl::Now() - start); LOG(INFO) \u0026lt;\u0026lt; \u0026#34;2 classify image pixels into check takes \u0026#34; \u0026lt;\u0026lt; into_check_latency_2 \u0026lt;\u0026lt; \u0026#34;ms\u0026#34; \u0026lt;\u0026lt; \u0026#34;cache key is \u0026#34; \u0026lt;\u0026lt; cache_key; tmp_cache_key = cache_key; } else { QCHECK(pano_net_-\u0026gt;GetOutputs(images, batch_size, \u0026amp;outputs)); } int64_t into_check_latency_3 = absl::ToInt64Milliseconds(absl::Now() - start); LOG(INFO) \u0026lt;\u0026lt; \u0026#34;3 classify image pixels into check takes \u0026#34; \u0026lt;\u0026lt; into_check_latency_3 \u0026lt;\u0026lt; \u0026#34;ms\u0026#34; \u0026lt;\u0026lt;\u0026#34; tmp cache key is \u0026#34; \u0026lt;\u0026lt; tmp_cache_key; .... } 发现在日志“2 classify image pixels xxx\u0026quot; 和 \u0026ldquo;3 classify image pixels xxx\u0026quot;之间竟然有一个长达4-10s的gap，而代码本身之间没东西。查仿真进程发现进程调度oncpu时间和整体运行时间比例相差极大，一开始以为是调度问题，呼叫阿里云介入，阿里云反应是读写bps导致cpu被打断，我表示不能理解，你一个读取完数据的cpu搁这里因为整体读写磁盘负载高被打断？现在cpu的负载也不重，这个解释有点牵强，仿佛逗我笑，但是当时忘了查进程状态，所以就搁置了，运维同学介入说换个跑pod数量少的node机器，降低并发磁盘读写。\n第二天换了机器问题还在，感觉不对劲，重新介入，查了下慢的simulator进程状态，是SLl也就是说等待事件，感觉不对，这不应该了。然后看了下主线程的pstack发现好几次都是在做sim-cache析构，然后往metric push消息。也就是说在阿里云的pod上往aws push metric，然后注释掉push metric的地方，重新触发仿真5分钟通过\n[root@sim-pipe241251spot ~]# ps -aux|grep 188359 root 188359 3.0 3.9 8693260 5077808 ? SLl 12:10 0:19 offboard/simulation/simulator_main --variation=0 --qevents_dir=/tmp/9f07-e87d-f912-f353 --qevents_whitelist=* --logtostderr --enable_run_analysis=false --run_analysis_config_file= --run_analysis_server_address= --use_run_map=1 --sim_cache_dir=/media/s3/sim_cache --prom_push_gateway_url=a57985cd13e064fa7a332ec0870f38ea-559580627.cn-north-1.elb.amazonaws.com.cn:9091 --prom_aggregation_gateway_url=ae1be9e5057a74bcd909c63b8f134e95-1323279091.cn-north-1.elb.amazonaws.com.cn --sim_cache_monitor_keys=scenario_test_presubmit_cn --vehicle_param_dir=onboard/params/run_params/vehicles --scenario_path=/tmp/b99d-d2a3-11eb-9dda --output_file=/tmp/0a6d-cb37-11ca-0793 --enable_localizer_gpu=false --cpu_image_codec --fen_use_gpu=false --pcn_use_gpu=false --tcn_use_gpu=false --knet_use_gpu=false --panonet_use_gpu=false --mof_net_use_gpu=false --disable_vantage_forwarding_module --undefok=variation,qevents_dir,qevents_whitelist,logtostderr,enable_run_analysis,run_analysis_config_file,run_analysis_server_address,use_run_map,sim_cache_dir,prom_push_gateway_url,prom_aggregation_gateway_url,sim_cache_monitor_keys,vehicle_param_dir,scenario_path,output_file,enable_localizer_gpu,cpu_image_codec,fen_use_gpu,pcn_use_gpu,tcn_use_gpu,knet_use_gpu,panonet_use_gpu,mof_net_use_gpu,disable_vantage_forwarding_module --sim_msg_dir=/tmp/dc5e-c1ab-58aa-441c --replace_with_icc_agent=true root 225817 0.0 0.0 112828 2344 pts/0 S+ 12:21 0:00 grep --color=auto 188359 [root@sim-pipe241251spot ~]# pstack 188359 Thread 1 (process 188359): #0 0x00007f562243c9cf in ?? () #1 0x0000000000000001 in ?? () #2 0x00007ffc30f1ccf0 in ?? () #3 0x0000000000000002 in ?? () #4 0x000003e800000000 in ?? () #5 0x0000000000000001 in ?? () #6 0x000055f858a6f0a5 in Curl_poll () #7 0x000055f858a62647 in Curl_multi_wait () #8 0x000055f858a628aa in curl_multi_poll () #9 0x000055f858a53f8f in curl_easy_perform () #10 0x000055f857b3e866 in curlpp::internal::CurlHandle::perform() () #11 0x000055f857b3c580 in qcraft::HttpClient::Post(std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026amp;, std::__cxx11::list\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;, std::allocator\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; \u0026gt; const\u0026amp;, std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026amp;, std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;*, int, int) () #12 0x000055f857b3b934 in qcraft::prometheus_gateway::PromGateWayClient::PushMetric(qcraft::prometheus_gateway::PromMetric const\u0026amp;) () #13 0x000055f857b37fe4 in qcraft::SimCache::~SimCache() () #14 0x000055f857b39831 in qcraft::SimFileCache::~SimFileCache() () ... #20 0x00007f5623db247f in ?? () #21 0x00007f5623db24d0 in ?? () 这次事件的反思是：\n代码里面if语句结束，不是直接就到下一句，if块里面的变量会析构，从而触发一些消耗，说实在的，这个虽然我大学的时候就知道，但是写C习惯了以后再看C++，我有的时候是真的想不起来。。。。一个variable的析构会触发一个curl，这说实在的也实在是神奇的代码。。。 应该在发现调度不上之后就确定进程的状态，通过ps -aux可以直接查看进程是不是处于SLl状态，即等待事件发生。这个单纯是那天太晚了，太困了，想不起来了。。。。 确定进程一直等待之后就可以调用pstack 188359查看进程的主线程的栈了，这个也是老方法了，当年查内存泄露用了好多次。。。 16 错误的ssh key # 这个问题坦白讲一般不会遇到，我们有台云上机器，需要后处理一些敏感数据，需要拉取git仓库，配置了私钥格式如下，\n-----BEGIN OPENSSH PRIVATE KEY----- ~~~~~~~~~~~~~~~~~~~~~~~ -----END OPENSSH PRIVATE KEY----- 但是仍然一直报错\nLoad key \u0026#34;xxx/.ssh/id_ed25519\u0026#34;: invalid format yyyyy: Permission denied (publickey). fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 最后发现是因为没有在私钥最后加一个newline。。。\n改成多一个newline即可。。。\n-----BEGIN OPENSSH PRIVATE KEY----- ~~~~~~~~~~~~~~~~~~~~~~~ -----END OPENSSH PRIVATE KEY----- \u0026lt;=== notice here 17 not support negative lookaround # 这俩天写正则，遇到一个问题，我们有些用户创建分支都已origin打头，比方说建立了什么origin/master，origin/dbet什么的，然而gitlab使用re2引擎，因此它不支持negative lookaround。为了避免这个问题只能写原始匹配，因为origin太长了，写起来太费劲，所以写了匹配orig，最后的命令如下\n^([^o].*$)|(o([^r].*$|$))|(or([^i].*$|$))|(ori([^g].*$|$)) 18 git push ref missing head # 这个问题，坦白讲我不知道root cause，也不知道解决原因为什么可以。简单来说我们有个巨大的git仓库放了很多的地图文件，每隔一段时间会遇到这种问题，即push代码会报错\ncreate mode 100644 zhuhai_1/semantic_map/4276747992/others.pb.bin create mode 100644 zhuhai_1/semantic_map/semantic_map_meta.pb.bin Locking support detected on remote \u0026#34;origin\u0026#34;. Consider enabling it with: $ git config lfs.https://china-map.qcraftai.com/qcraft/qcraft-maps-china-v2.git/info/lfs.locksverify true ref xxxxx:: missing object: 019e6b672af008e6873dcaec850c8c1fa5c63623 error: failed to push some refs to \u0026#39;china-map.qcraftai.com:qcraft/qcraft-maps-china-v2.git\u0026#39; 但是这个文件是实际上是lfs文件，而且文件也存在，而报错git missing，是不是意味着这个文件没有track在git的repo里面？而且后面操作\nqcrafter@runner-dghmx1qy-project-4-concurrent-09k7q5:/builds/DgHMx1qY/0/root/qcraft/qcraft-maps-china$ git cat-file -p 019e6b672af008e6873dcaec850c8c1fa5c63623 version https://git-lfs.github.com/spec/v1 oid sha256:5990808a372ce1ff02742a9557bc3312e6cddd7439e036f51acf019ea1ffb985 size 3003 qcrafter@runner-dghmx1qy-project-4-concurrent-09k7q5:/builds/DgHMx1qY/0/root/qcraft/qcraft-maps-china$ sha256sum beijing_yizhuang2nd/semantic_map/4283367543/sections.pb.bin 5990808a372ce1ff02742a9557bc3312e6cddd7439e036f51acf019ea1ffb985 beijing_yizhuang2nd/semantic_map/4283367543/sections.pb.bin qcrafter@runner-dghmx1qy-project-4-concurrent-09k7q5:/builds/DgHMx1qY/0/root/qcraft/qcraft-maps-china$ git cat-file -p 019e6b672af008e6873dcaec850c8c1fa5c63623 version https://git-lfs.github.com/spec/v1 oid sha256:5990808a372ce1ff02742a9557bc3312e6cddd7439e036f51acf019ea1ffb985 size 3003 看到一个了类似的issue，https://stackoverflow.com/questions/52612880/lfs-upload-missing-object-but-the-file-is-there\n还有一个现象很类似的issue，https://github.com/git-lfs/git-lfs/issues/3587\n19 奇怪的时间 # 写这个希望不会再有下一个倒霉蛋遇到这个事情了。。。。\n这两天写golang的gorm一个简单的crud程序，遇到一个有趣的问题，我们有两个数据库（都是oceanbase，线上和测试环境），里面有个表是datetime类型，gorm的model里面用的类型是time.Time，插入数据的时候直接插入了time.Time{}，就是0000-00-00 00:00:00，在测试环境数据库读取时间没什么问题，在生产环境就稳定出现问题，读取出来的时间是-0001-11-30 00:00:00 +0000，因为是用同一个环境的同一套代码同一个elf程序跑的，所以一直没理解咋回事，今天仔细看了一下程序里面的流程，栈如下，连接测试数据库和生产数据库都一样\n(dlv) bt 0 0x0000000001583232 in github.com/go-sql-driver/mysql.parseBinaryDateTime at /root/go/pkg/mod/github.com/go-sql-driver/mysql@v1.7.0/utils.go:230 1 0x000000000157cff0 in github.com/go-sql-driver/mysql.(*binaryRows).readRow at /root/go/pkg/mod/github.com/go-sql-driver/mysql@v1.7.0/packets.go:1314 2 0x000000000157ec37 in github.com/go-sql-driver/mysql.(*binaryRows).Next at /root/go/pkg/mod/github.com/go-sql-driver/mysql@v1.7.0/rows.go:198 3 0x0000000001555d0a in database/sql.(*Rows).nextLocked at /usr/local/go/src/database/sql/sql.go:2974 4 0x0000000001555ab4 in database/sql.(*Rows).Next.func1 at /usr/local/go/src/database/sql/sql.go:2952 5 0x0000000001559213 in database/sql.withLock at /usr/local/go/src/database/sql/sql.go:3405 6 0x0000000001555a2b in database/sql.(*Rows).Next at /usr/local/go/src/database/sql/sql.go:2951 7 0x00000000015fc622 in gorm.io/gorm.Scan at /root/go/pkg/mod/gorm.io/gorm@v1.25.2-0.20230530020048-26663ab9bf55/scan.go:327 8 0x0000000001643377 in gorm.io/gorm/callbacks.Query at /root/go/pkg/mod/gorm.io/gorm@v1.25.2-0.20230530020048-26663ab9bf55/callbacks/query.go:28 9 0x00000000015df4fe in gorm.io/gorm.(*processor).Execute at /root/go/pkg/mod/gorm.io/gorm@v1.25.2-0.20230530020048-26663ab9bf55/callbacks.go:130 10 0x00000000015e9708 in gorm.io/gorm.(*DB).First at /root/go/pkg/mod/gorm.io/gorm@v1.25.2-0.20230530020048-26663ab9bf55/finisher_api.go:129 11 0x000000000166505c in xxxxxxxx at xxxxxx 12 0x000000000167d2d4 in xxxxxxxxxx at xxxxx 13 0x000000000167ff56 in xxxxxxx at xxxxxx 14 0x0000000001681ff0 in main.main at ./cmd/datasource/main.go:105 15 0x00000000004affd3 in runtime.main at /usr/local/go/src/runtime/proc.go:250 16 0x00000000004e23a1 in runtime.goexit at /usr/local/go/src/runtime/asm_amd64.s:1598 然后打印了一下解析的内容，测试的环境回复的数据，日期部分（长度+内容）为[0\u0026hellip;]，也就是说长度为0，生产环境回复的数据里面日期的部分为[\u0026hellip;,11,0,0,0,0,0,0,0,0,0,0,0,\u0026hellip;+7 more]，也就是说长度是11，然后内容都是0。接下来调用parsetime的逻辑就是下面的东西，测试环境长度是0，所以直接返回了默认时间。生产环境长度是11，默认的空时间戳，走11的逻辑，写了个小程序（下面），跑了一下，出来了-0001-11-30 00:00:00 +0000。\n两个版本prod环境的oceanbase版本是3.2.3.1， test环境的oceanbase版本是 3.2.3.3\n我去看了一下mysql里面的bianry encode的标准：https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_binary_resultset.html，和golang mysql的driver的代码也是匹配的，包括长度就是0，4，7，11。但是按照标准，全0的时间应该是只返回一个表示0长度的byte。所以我理解这应该是oceanbase 3.2.3.1的bug\nfunc parseBinaryDateTime(num uint64, data []byte, loc *time.Location) (driver.Value, error) { switch num { case 0: return time.Time{}, nil case 4: return time.Date( int(binary.LittleEndian.Uint16(data[:2])), // year time.Month(data[2]), // month int(data[3]), // day 0, 0, 0, 0, loc, ), nil case 7: return time.Date( int(binary.LittleEndian.Uint16(data[:2])), // year time.Month(data[2]), // month int(data[3]), // day int(data[4]), // hour int(data[5]), // minutes int(data[6]), // seconds 0, loc, ), nil case 11: return time.Date( int(binary.LittleEndian.Uint16(data[:2])), // year time.Month(data[2]), // month int(data[3]), // day int(data[4]), // hour int(data[5]), // minutes int(data[6]), // seconds int(binary.LittleEndian.Uint32(data[7:11]))*1000, // nanoseconds loc, ), nil } return nil, fmt.Errorf(\u0026#34;invalid DATETIME packet length %d\u0026#34;, num) } package main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { data := []byte{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0} shot := time.Date( int(binary.LittleEndian.Uint16(data[:2])), // year time.Month(data[2]), // month int(data[3]), // day int(data[4]), // hour int(data[5]), // minutes int(data[6]), // seconds 0, time.UTC, ) invalidShot := time.Date( 0, // year 0, // month 0, // day 0, // hour 0, // minutes 0, // seconds 0, time.Local, ) fmt.Printf(\u0026#34;time is %v\\n\u0026#34;, shot) fmt.Printf(\u0026#34;checked time is %v\\n\u0026#34;, invalidShot) fmt.Printf(\u0026#34;year is %v\\n\u0026#34;, int(binary.LittleEndian.Uint16(data[:2]))) fmt.Printf(\u0026#34;month is %v\\n\u0026#34;, data[2]) fmt.Printf(\u0026#34;day is %v\\n\u0026#34;, data[3]) fmt.Printf(\u0026#34;hour is %v\\n\u0026#34;, data[4]) fmt.Printf(\u0026#34;minutes is %v\\n\u0026#34;, data[5]) fmt.Printf(\u0026#34;seconds is %v\\n\u0026#34;, data[6]) } 20 奇怪的卡顿 # 这几天做一个grpc的性能测试，忽然遇到一个奇怪的问题，有个同步模式的grpc服务器，然后不断地启动新的grpc client连接它，且不断开旧的grpc，然后发现请求一段时间以后新的grpc就会卡住，不被响应/调度。我一开始以为是代码问题，后来忽然想起来，grpc本身服务器支持的连接数量是有限的，毕竟是文件描述符嘛，一般会报错：error reading server preface: EOF，这个时候可以看下文件描述符是不是打满了,\n为了验证这一点，可以加上在服务端和client端执行的命令前面加上环境变量，如下所示\nGRPC_GO_LOG_VERBOSITY_LEVEL=99 GRPC_GO_LOG_SEVERITY_LEVEL=info /usr/sbin/xxx --config /etc/xxxx/config.yml client端执行后会看到下面的报错信息\n2023/12/20 17:20:11 INFO: [core] [Channel #149968 SubChannel #149969] Subchannel Connectivity change to IDLE, last error: connection error: desc = \u0026#34;error reading server preface: EOF\u0026#34; 2023/12/20 17:20:11 INFO: [core] pickfirstBalancer: UpdateSubConnState: 0xc1d0b88858, {IDLE connection error: desc = \u0026#34;error reading server preface: EOF\u0026#34;} 2023/12/20 17:20:11 INFO: [core] [Channel #149968] Channel Connectivity change to IDLE 2023/12/20 17:20:11 INFO: [core] [Channel #149968 SubChannel #149969] Subchannel Connectivity change to CONNECTING 2023/12/20 17:20:11 INFO: [core] [Channel #149968 SubChannel #149969] Subchannel picks a new address \u0026#34;172.21.208.11:5444\u0026#34; to connect 2023/12/20 17:20:11 INFO: [core] pickfirstBalancer: UpdateSubConnState: 0xc1d0b88858, {CONNECTING \u0026lt;nil\u0026gt;} 2023/12/20 17:20:11 INFO: [core] [Channel #149968] Channel Connectivity change to CONNECTING 2023/12/20 17:20:11 INFO: [transport] transport: closing: connection error: desc = \u0026#34;error reading server preface: EOF\u0026#34; 2023/12/20 17:20:11 INFO: [core] Creating new client transport to \u0026#34;{\\n \\\u0026#34;Addr\\\u0026#34;: \\\u0026#34;172.21.208.11:5444\\\u0026#34;,\\n \\\u0026#34;ServerName\\\u0026#34;: \\\u0026#34;172.21.208.11:5444\\\u0026#34;,\\n \\\u0026#34;Attributes\\\u0026#34;: null,\\n \\\u0026#34;BalancerAttributes\\\u0026#34;: null,\\n \\\u0026#34;Type\\\u0026#34;: 0,\\n \\\u0026#34;Metadata\\\u0026#34;: null\\n}\u0026#34;: connection error: desc = \u0026#34;error reading server preface: EOF\u0026#34; 2023/12/20 17:20:11 WARNING: [core] [Channel #149968 SubChannel #149969] grpc: addrConn.createTransport failed to connect to { \u0026#34;Addr\u0026#34;: \u0026#34;172.21.208.11:5444\u0026#34;, \u0026#34;ServerName\u0026#34;: \u0026#34;172.21.208.11:5444\u0026#34;, \u0026#34;Attributes\u0026#34;: null, \u0026#34;BalancerAttributes\u0026#34;: null, \u0026#34;Type\u0026#34;: 0, \u0026#34;Metadata\u0026#34;: null }. Err: connection error: desc = \u0026#34;error reading server preface: EOF\u0026#34; 2023/12/20 17:20:11 INFO: [core] [Channel #149968 SubChannel #149969] Subchannel Connectivity change to TRANSIENT_FAILURE, last error: connection error: desc = \u0026#34;error reading server preface: EOF\u0026#34; 2023/12/20 17:20:11 INFO: [transport] transport: loopyWriter exiting with error: transport closed by client 2023/12/20 17:20:11 INFO: [core] pickfirstBalancer: UpdateSubConnState: 0xc1d0b88858, {TRANSIENT_FAILURE connection error: desc = \u0026#34;error reading server preface: EOF\u0026#34;} 2023/12/20 17:20:11 INFO: [core] [Channel #149968] Channel Connectivity change to TRANSIENT_FAILURE 下面的代码是怎么对golang产生trace的代码，顺便做个附加了\nimport ( \u0026#34;context\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; + \u0026#34;os\u0026#34; + \u0026#34;os/signal\u0026#34; + \u0026#34;runtime/trace\u0026#34; .... func main() { flag.Parse() +\tf, err := os.Create(\u0026#34;/tmp/trace.out\u0026#34;) + if err != nil { + panic(err) + } + defer f.Close() + + // 启动trace + err = trace.Start(f) + if err != nil { + panic(err) + } + defer trace.Stop() if *versionFlag { fmt.Println(\u0026#34;pomerium:\u0026#34;, version.FullVersion()) fmt.Println(\u0026#34;envoy:\u0026#34;, files.FullVersion()) return } - if err := run(ctx); !errors.Is(err, context.Canceled) { - log.Fatal().Err(err).Msg(\u0026#34;error\u0026#34;) - } - log.Info(ctx).Msg(\u0026#34;cmd/command: exiting\u0026#34;) + go func() { + ctx := context.Background() + run(ctx) + }() + + signalChan := make(chan os.Signal, 1) + signal.Notify(signalChan, os.Interrupt) + \u0026lt;-signalChan 21 低性能的Unix Domain Socket # 这个问题出现有两个原因\n原因1（主要原因），k8s云环境配置的limit太小，线程数量很高导致都在互相抢占，上下文切换带来的性能问题很严重。这个最后看了统计里面的CPU throttling监控得到了验证。 原因2（次要原因），tokio的异步await轮询本身就是牺牲了时延的产物，因此会导致时延增高。请注意，尽管这是次要原因，但是如果使用了Tokio的容器k8s limit配置过低，它的线程触发了k8s的CPU throttling，无论服务端的处理速度有多快，那么它的异步线程调度会导致它那边看到的时延迅速增加！ 简单描述下上下文，同一个pod里面，两个不同k8s容器里面的程序通过UDS socket进行通信。服务端容器的k8s limit配置为1，是C语言，libevent+多线程痛处理UDS通信事件。另一个是客户端 Rust+Tokio发送数据，结果tokio经常提示UDS通信超时，超过了5ms。我自己在研发环境dev的时候平均时延并不高，显示处理UDS很快，也就几百us（我在dev进群没有配置k8s limit的限制，因此尽管CPU使用率最终显示为90%，但实际上程序还是并行的线程）。可能的原因\n猜想1，资源不足，k8s limit为1导致的上下文切换代价比较高。这个验证也很简单，如果不做限制改成大一些的值，那么应该时延会迅速下降，超时的比例会很低。\n猜想2，Rust客户端发送了，到了服务端进了backlog，最终超时了。在backlog里面待了一会，然后等待IO时间处理又等了一会，最终导致响应的很慢，也就是说超过了500us。这个并不可能，因为只要进入了backlog，不断溢出必然出错，但是并没有出错的日志。\n猜想3，Rust客户端多次await，这个导致多次异步轮询耽误了时间。这个验证直接看下异步下的时间延迟即可，\n关于猜想1的验证执行了两个操作\n查看k8s告警的CPU throttling监控，判断是否出现限流。从图片可以看出来确实有明显的限流。处于保密的原则，就不截图了。这个东西用户可以进入pod的container里面，通过cat /sys/fs/cgroup/cpu,cpuacct/cpu.stat来确定有没有触发限流。处于保密的缘故，我不能截图，但是我在我自己的dev环境做了复现，内容如下，可以看到有一半的周期都触发了CPU限流。\n# 配置k8s cpu limit 1时 root@hxn-debug-zslgf:/suricata# cat /sys/fs/cgroup/cpu,cpuacct/cpu.stat nr_periods 6227 nr_throttled 3038 throttled_time 3271452651481 nr_bursts 0 burst_time 0 # 配置k8s cpu limit 放到和线程数量相等甚至更大时 root@hxn-debug-zslgf:/suricata# cat /sys/fs/cgroup/cpu,cpuacct/cpu.stat nr_periods 721708 nr_throttled 0 throttled_time 0 修正limit为8，在压力测试下，看超时日志有没有减少。尽管后台的CPU throttling依然触发了限流，但是超时日志出现了明显的减少，从1w每分钟减少到了200每分钟（超时维持5ms，如果超时是1ms，那么超时会从1w每分钟降低到2k每分钟）\n关于猜想2直接放弃了验证，因为理论可能性太低。\n关于猜想3，我在客户端和服务端分别记录了接受和发送的时刻，结果如下。证明了纯异步确实对时延有一定的影响，在我当时测试的情况下，影响确实不如第一个方面更大。\nRust程序 ================================= 准备建立连接 时刻为 3982289 秒和 50986778 纳秒 尝试异步建连后，处理其它事情 ================================= C程序 ================================= 处理建立连接 时刻为 3982289 s, 51285037 ns 连接握手接受，分配资源 时刻为 3982289 s, 51328058 ns =================================\tRust程序 ================================= 发现连接建立完成，准备发送数据 时刻为 3982289 秒和 52508772 纳秒 尝试异步发送，先处理其它事情 ================================= Rust程序 ================================= 发现连接建立完成，准备发送数据 时刻为 3982289 秒和 52508772 纳秒 尝试异步发送，先处理其它事情 ================================= Rust程序 ================================= 发现发送数据完成，再次flush数据 时刻为 在3982289 秒和 52774571 纳秒 异步fluash完成，先处理其它事情 ================================= C程序 ==================================== 处理IO数据，接受数据 时刻为 3982289 s, 52787736 ns 处理结束，发送处理的结果 时刻为 3982289 s, 52940983 ns ==================================== Rust程序 ================================= 发现发送数据结束 时刻为 在3982289 秒和 52956091 纳秒 准备接受数据 ================================= ... 22 优雅地退出Libevent # 最近在写一个Libevent服务器，主线程启动多个IO子线程，每个IO子线程都有自己的Loop（Event Base），主线程监听Socket连接，建立连接会注册事件到子线程。现在遇到一个问题是说，希望在不会导致任何IO事件被丢弃的前提下，IO子线程可以被替换。初步解决的方案是：\n每个子线程内部置一个状态位，用于标识当前子线程是不是应该终止了。建立一个更新子线程，专门用于创建新的IO子线程并替换。 IO子线程会调用 event_base_loopexit(base, \u0026amp;one_minute);，然后调用event_base_dispatch(base);，如果没有注册IO事件就返回检查线程状态，如果状态为“准备终止”，就释放内存 更新子线程监听SIGHUP信号，每当收到SIGHUP信号，创建新的多子线程。锁住主线程的保护锁，替换主线程记录的子线程。 替换完成之后，更新子线程会把旧的IO子线程的状态置为“准备终止”，解析并等待旧的IO子线程的状态都被置为“终止完成”，到了终止完成之后。释放旧的IO线程的内存 但这个方案会导致莫名其妙地丢数据，然后反应过来有个这个情况。\n极端情况 ------------------------------- IO线程正好没事情做，工作状态还在Working 从event_base_dispatched返回 ------------------------------- ------------ 主线程分配任务到 ------------- ----------------------------- 更新线程执行替换操作 置IO线程状态为NeedTerminate ----------------------------- ----------------------------------- IO线程开始加载状态，发现是NeedTerminate 释放内存，但实际上此时是有未处理的事件的 ----------------------------------- 所以最终的修复方式很简单，IOWorker的工作函数改成\nwhile (1) { struct timeval one_minute = {kDefaultSleepDuration, 0}; int state = atomic_load(\u0026amp;context-\u0026gt;state_); if (state == kStateNeedTerminate) { // DCLP event_base_loopexit(base, \u0026amp;one_minute); event_base_dispatch(base); cleanupSuricataContext(context); break; } event_base_loopexit(base, \u0026amp;one_minute); event_base_dispatch(base); } 23 Suricata初始化 # 这两天该代码，会概率性出现报错\nError: misc: pcre2_substring_copy_bynumber failed [ParseSizeString:util-misc.c:101] Error: stream-tcp: Error parsing stream.memcap from conf file - 64mb. Killing engine [StreamTcpInitConfig:stream-tcp.c:400] 24 Protobuf糟糕的PROTOBUF_NAMESPACE_OPEN # 这两天在帮同事写一点东西，遇到一些莫名其妙的东西，一直报错PROTOBUF_NAMESPACE_OPEN这个宏未定义，即使已经引入了Protobuf的src源代码里面的相关定义，最后是直接定义了下面的宏。\n不过这里需要注意，最后的五个#define可能会和默认定义重合，出现报错，所以看情况注释掉\n#define PROTOBUF_NAMESPACE_OPEN \\ namespace google { \\ namespace protobuf \\ { #define PROTOBUF_NAMESPACE_CLOSE \\ } \\ } #define PROTOBUF_NAMESPACE_ID google::protobuf #define PROTOBUF_CONSTEXPR #define PROTOBUF_ATTRIBUTE_REINITIALIZES #define PROTOBUF_NODISCARD [[nodiscard]] #define PROTOBUF_ALWAYS_INLINE 25 Nginx的性能为啥加了我们代码就变差了 # 这两天在分析我们的代码为什么性能差，可以看性能分析那里提到MPMC的部分，但是有个很有趣的问题\nNginx不是性能非常好吗？加上我们的代码为啥会性能差呢？先看看Nginx本身的逻辑\nlinux部分用的epoll，初始化部分\nstatic ngx_event_module_t ngx_epoll_module_ctx = { \u0026amp;epoll_name, ngx_epoll_create_conf, /* create configuration */ ngx_epoll_init_conf, /* init configuration */ { ngx_epoll_add_event, /* add an event */ ngx_epoll_del_event, /* delete an event */ ngx_epoll_add_event, /* enable an event */ ngx_epoll_del_event, /* disable an event */ ngx_epoll_add_connection, /* add an connection */ ngx_epoll_del_connection, /* delete an connection */ #if (NGX_HAVE_EVENTFD) ngx_epoll_notify, /* trigger a notify */ #else NULL, /* trigger a notify */ #endif ngx_epoll_process_events, /* process the events */ ngx_epoll_init, /* init the events */ ngx_epoll_done, /* done the events */ } }; 处理部分\nngx_epoll_process_events { } 26 Hugo格式丢失 # diff --git a/themes/blowfish/layouts/partials/head.html b/themes/blowfish/layouts/partials/head.html index 43635eb..dfd8baf 100644 --- a/themes/blowfish/layouts/partials/head.html +++ b/themes/blowfish/layouts/partials/head.html @@ -48,7 +48,7 @@ {{ $bundleCSS := $assets.Get \u0026#34;css\u0026#34; | resources.Concat \u0026#34;css/main.bundle.css\u0026#34; | resources.Minify | resources.Fingerprint \u0026#34;sha512\u0026#34; }} \u0026lt;link type=\u0026#34;text/css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ $bundleCSS.RelPermalink }}\u0026#34; - integrity=\u0026#34;{{ $bundleCSS.Data.Integrity }}\u0026#34; /\u0026gt; + integrity=\u0026#34;\u0026#34; /\u0026gt; {{ $jsAppearance := resources.Get \u0026#34;js/appearance.js\u0026#34; }} {{ $jsAppearance = $jsAppearance | resources.ExecuteAsTemplate \u0026#34;js/appearance.js\u0026#34; . | resources.Minify | resources.Fingerprint \u0026#34;sha512\u0026#34; }} \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;{{ $jsAppearance.RelPermalink }}\u0026#34; 结尾 # 唉，尴尬\n","date":"2021 年 1 月 7 日","externalUrl":null,"permalink":"/posts/2021-01-07-%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E9%81%87%E8%A7%81%E7%9A%84%E6%9C%89%E8%B6%A3bug/","section":"Posts","summary":"","title":"记录一些遇见的有趣BUG","type":"posts"},{"content":" 从锁和RTE ring与KFIFO说起 # 前言 # 为什么写这篇博客？本质上是昨天大师和我讨论RTE ring的无锁操作，外加我在看KFIFO和《C++并发编程》，这个整理完成，我就可以转而去看《计算机体系结构xxxxx》的内容了。毕竟不能说东西整完了无所得。\n对关键数据/流程的保护 # 代码进入临界区，对关键数据做竞争修改，是导致恶性条件竞争的原因。三种解决方法：\n第一种很常见，就是锁，锁关键数据，保证不会同时多个进行操作。锁完了刷新所有CPU的缓存。 还有一种解决方法就是所谓的无锁编程，本质上就是追求修改的一系列操作不可细分的，有点原子操作那味儿了。 另一种就是将一系列的操作交给一个统一的操作者进行。由操作者判断能不能执行成功。有点类似操作数据库的味道了 下面分开来谈，先说锁，再说无锁，最后事务操作不说了，\n锁的保护 # 无论是C/C++操作对于关键数据的操作都是需要加锁的，因此必须小心某个函数在未获得锁的情况下，返回关键数据的引用或者指针。对于C++而言常见的关键数据共享还有个问题，函数调用传入了关键参数，但此时不在锁的保护范围。但是并不是说对关键数据加了个锁就会避免所有的竞争条件\u0026ndash;这里面藏着一个所谓“条件竞争”的问题，举个简单的例子，删除链表一个元素的时候需要同时获得三个指针，被删除指针+被删除之前指针+被删除之后指针，即使获取了其中单一一个指针的锁，仍然不能避免竞争的产生。这实际上就是常说的锁粒度问题，锁粒度太细就保护不力，锁粒度太粗性能有一塌糊涂。因此有人采用了多个互斥量竞争的情况，然后就产生了死锁。\n常见的死锁的条件每个人都清楚，互相等待，互相需求，都不会释放。似乎只要避免这三者问题就不会死锁。实际并非如此，前面条件成立有个前提：互相等待的锁是不同的锁！举个简单的例子，有一个函数swap(a, b)，每次都先获取a的锁，再获取b的锁，然后交换a，b。看上去似乎没什么问题？现在一个线程执行swap(obj_1, obj_2)，另一个线程执行swap(obj_2, obj_1)。照样GG，而且这东西还挺无解的。\nC++ 对于这东西的解决方案是一次锁两个对象，保证不会有第二个线程还能锁成功。至于C，我第一反应是对函数做个保护，然后转念反应过来锁应该保护数据，而不是保护函数。因此只需要第二次获得的时候如果失败就放弃。\n所以最终，如何避免死锁的结论是：\n要么就每次线程就只有一个锁，别同时上来申请二三四个锁。猜猜这里我想到了什么？mm_struct的读写信号量+页表的自旋锁。 锁的生命周期务必要短，别拿着锁的时候还来干一大堆脏活累活，这是一个避免出现问题的很有效的方法。 正确的申请锁的顺序，每个都一样，如果swap函数每次都是先申请小地址的锁，然后申请大地址的锁，那也没啥问题。这个申请锁顺序就需要参数顺序无关了 正确的使用分层锁， OK，那么如何设计一个有锁的并发数据结构呢？\n实际上就是，\n锁尽量少，锁尽量短。 对C++而言，不能再构造函数或者析构函数之后访问，对C而言就是不能访问已经释放的内存。这个让我想起来前几天别人问我的一个free地址出错，coredump失败的问题。因为那个函数是我写的，每个地方如果malloc内存失败，就会把指针改成0x0。最后定位到一个socket获取地址那里，应该是获取失败最后导致失败。 避免函数里面出现锁的争用，类比rw_sem的实现，读可以多多，写尽量少。 无锁或者说原子操作 # C++ 提供了std::atomic来进行无锁操作或者说原子操作，atomic除了进行原子修改操作之外，还要求明确的赋值必须完成之后才能发生，也就是说同时提供了内存屏障的操作。因此原子操作数常常作为flag进行操作。这里面伴随着两个概念先行(happens-before)和同发(synchronizes-with)。\n在《内存模型和缓存一致性》里，写原子性，指写完了其他核立刻可见，和这里的同步发生是一个理论，指的是线程A的原子写操作从执行的结果来看在线程B的原子读之前(这里的原子读之前，可能A的原子写操作已经被其他的线程所read_and_set了)，这里需要注意的点是同发，同步发生是个跨线程的概念。\n而先行，也就是“先行发生”是同一个线程里的事情，在源代码里A发生在B之前。操作同步发生的话，通常就没有先行关系了。这里需要引入一个线程之间的“先行发生”。可以理解为，线程里面的顺序在线程之间传递\n这里所谓的同发就是个蛋疼的概念，实际上就是一个先对原子变量写，另一个对原子变量读，虽然叫做同步发生关系，但是本质上是一先一后。还有一个先行关系，包括同一个线程的先行，线程间的先行。这里，C++整进来一个非常复杂的东西memory_order，我个人觉得就是闲的蛋疼。这里实际上就是原子操作的依赖性。这块说实话我觉得《C++并发实战》翻译的很糟糕，建议要么直接看英文，建议看C++内存模型 这篇文章。\n这时候就得说说内存模型的问题了，总共有六种内存模型：顺序一致性(sequentially consistent)，获取-释放序(memory_order_consume, memory_order_acquire, memory_order_release和memory_order_acq_rel)和自由序(memory_order_relaxed)。详细的内容看cpp reference\n那么C++中的内存序和我们平时看到的内存序有什么关系呢？C++的内存序提供了一种高于指令的抽象，但是这种抽象在我看来也比较失败。顺序序，我个人觉得更简单对于SEQ_CST的看法，不如理解为两个原子变量之间的操作是稳定的，不会发生重排序的。自由序，或者直接说弱内存序和《内存模型和缓存一致性入门》里不同的地方是，《XXX入门》里面，结果是固定的，即两个不同地址的（不同）对象A和B，看到的值变化的先后顺序是可能变化的，即可以是先A后B，或者先B后A，但是总能是一个固定的结果。而C++提供的弱内存序则不保证看到，每个线程看到的都是固定的结果，可能线程1看到A后B，线程2看到先B后A。这个东西实际上我觉得可以将之理解为不同核共享CACHE导致的，比方说共享L2级CACHE的写缓冲区导致两个核先看到A最后涉及到的获取-释放序，如果是分布在不同线程里的变量：A在线程1，B在线程2，那么结果观察到的和自由序是没有区别的。如果是在同一个线程里执行的操作，那么就不同了。\n这里最好按照书里面提供的例子，用公式的观点来进行观察，这样子能够简化思考。\n为了方便理解，在观察结果的线程里，可以认为atomic类型的变量观察的顺序是不会释放的。\n顺序一致性值得是两个原子操作先A后B，在其他线程看到的也是先A后B，这实际上就是当前线程跟新了其他线程的缓存。 非顺序一致性内存-自由序，看到这里大部分人都会虎躯一震，线程1原子操作是先A后B，线程2里看到的B已经做了，但A未必做。这tm也叫原子操作？按照《C++并发实战》解释来说是：唯一的要求是在访问同一线程中的单个原子变量不能重排序，当给定线程看到原子变量的值时，随后线程的读操作就不会去检索较早的那个值。实际上就是线程1没跟新线程2的缓存，后面跟了一个给数字的例子解释自由序，可以给你旧的缓存值，因此很可能看到和赋值顺序不一致的原子值。只保证线程里面看到新东西之不会在看到旧东西，不能保证线程外面看到新东西，另一个东西看到的也是新的。 非顺序一致性内存-获取/释放序，操作没有顺序，但是有同步。原子加载就是获取，原子存储就是释放，获取释放必然是成对的，也就是说，获取时发现已经释放了。那么释放之前的代码在获取时已经完成了。实际上，锁住锁就是获取，解开锁就是释放，这就保证了锁必然是线性执行的。\nOK，那么如何设计一个无锁的并发数据结构呢？\nRTE_ring的无锁实现 # 首先我们要清楚的明白，多消费，多生产的竞争来自两个方面。一方面是生产和生产的竞争，另一方面是生产和消费的竞争。RTE_ring怎么解决生产和生产的竞争？\n简单总结，RTE_ring的无所实现是先占一段距离，令head和tail来开距离。操作完成了，再把head和tail改成一个值。当tail和head一起的时候说明要么现在没人enqueue，要么已经enqueue完成了。\n仔细想想实际上这里面依靠的就是一个“圈地的原子性”。而对tail的操作则是不需要原子性的，所以按照C11的写法来说。我们只需要保证read是atomic，顺序一致即可。\nmp_enqueue的代码本质还是先占坑，后拉屎的行为。函数__rte_ring_move_prod_head中，每次生产者都尝试原子获取并移动r-\u0026gt;prod.head，因为每个线程都从r-\u0026gt;prod.head填写数据，这保证了每次都只有一个线程先把坑占好。接着__rte_ring_enqueue_elems把内容扔进去。\n最后调用update_tail函数，实际上update_tail是加了一个对前面操作的写屏障，然后尝试等待生产队列位到位置。\nstatic __rte_always_inline unsigned int __rte_ring_do_enqueue_elem(struct rte_ring *r, const void *obj_table, unsigned int esize, unsigned int n, enum rte_ring_queue_behavior behavior, unsigned int is_sp, unsigned int *free_space) { uint32_t prod_head, prod_next; uint32_t free_entries; n = __rte_ring_move_prod_head(r, is_sp, n, behavior, \u0026amp;prod_head, \u0026amp;prod_next, \u0026amp;free_entries); if (n == 0) goto end; __rte_ring_enqueue_elems(r, prod_head, obj_table, esize, n); update_tail(\u0026amp;r-\u0026gt;prod, prod_head, prod_next, is_sp, 1); end: if (free_space != NULL) *free_space = free_entries - n; return n; } static __rte_always_inline unsigned int __rte_ring_move_prod_head(struct rte_ring *r, unsigned int is_sp, unsigned int n, enum rte_ring_queue_behavior behavior, uint32_t *old_head, uint32_t *new_head, uint32_t *free_entries) { const uint32_t capacity = r-\u0026gt;capacity; unsigned int max = n; int success; do { /* Reset n to the initial burst count */ n = max; *old_head = r-\u0026gt;prod.head; /* add rmb barrier to avoid load/load reorder in weak * memory model. It is noop on x86 */ rte_smp_rmb(); /* * The subtraction is done between two unsigned 32bits value * (the result is always modulo 32 bits even if we have * *old_head \u0026gt; cons_tail). So \u0026#39;free_entries\u0026#39; is always between 0 * and capacity (which is \u0026lt; size). */ *free_entries = (capacity + r-\u0026gt;cons.tail - *old_head); /* check that we have enough room in ring */ if (unlikely(n \u0026gt; *free_entries)) n = (behavior == RTE_RING_QUEUE_FIXED) ? 0 : *free_entries; if (n == 0) return 0; *new_head = *old_head + n; if (is_sp) r-\u0026gt;prod.head = *new_head, success = 1; else success = rte_atomic32_cmpset(\u0026amp;r-\u0026gt;prod.head, *old_head, *new_head); } while (unlikely(success == 0)); return n; } static __rte_always_inline void update_tail(struct rte_ring_headtail *ht, uint32_t old_val, uint32_t new_val, uint32_t single, uint32_t enqueue) { if (enqueue) rte_smp_wmb(); else rte_smp_rmb(); /* * If there are other enqueues/dequeues in progress that preceded us, * we need to wait for them to complete */ if (!single) while (unlikely(ht-\u0026gt;tail != old_val)) rte_pause(); ht-\u0026gt;tail = new_val; } BOOST::SPSC_QUEUE的实现 # #ifdef BOOST_NO_CXX11_VARIADIC_TEMPLATES template \u0026lt;typename T, typename A0, typename A1\u0026gt; #else template \u0026lt;typename T, typename ...Options\u0026gt; #endif struct make_ringbuffer { #ifdef BOOST_NO_CXX11_VARIADIC_TEMPLATES typedef typename ringbuffer_signature::bind\u0026lt;A0, A1\u0026gt;::type bound_args; #else typedef typename ringbuffer_signature::bind\u0026lt;Options...\u0026gt;::type bound_args; #endif ... /* if_c是一个偏特化模板，如果runtime_sized为false，就使用第二个类型作为type。否则选择第一个类型作为type*/ /* 具体的意思是buffer的大小到底是运行时确定还是编译时确定，我们关注编译时确定的ringbuffer */ typedef typename mpl::if_c\u0026lt;runtime_sized, runtime_sized_ringbuffer\u0026lt;T, allocator\u0026gt;, compile_time_sized_ringbuffer\u0026lt;T, capacity\u0026gt; \u0026gt;::type ringbuffer_type; }; template \u0026lt;typename T, std::size_t MaxSize\u0026gt; class compile_time_sized_ringbuffer: public ringbuffer_base\u0026lt;T\u0026gt; { typedef std::size_t size_type; static const std::size_t max_size = MaxSize + 1; typedef typename boost::aligned_storage\u0026lt;max_size * sizeof(T), boost::alignment_of\u0026lt;T\u0026gt;::value \u0026gt;::type storage_type; storage_type storage_; ... /* 而aligned_storage到最后*/ struct aligned_storage_imp { union data_t { char buf[size_]; typename ::boost::type_with_alignment\u0026lt;alignment_\u0026gt;::type align_; } data_; void* address() const { return const_cast\u0026lt;aligned_storage_imp*\u0026gt;(this); } }; template \u0026lt;std::size_t size\u0026gt; struct aligned_storage_imp\u0026lt;size, std::size_t(-1)\u0026gt; { union data_t { char buf[size]; ::boost::detail::max_align align_; } data_; void* address() const { return const_cast\u0026lt;aligned_storage_imp*\u0026gt;(this); } }; template\u0026lt; std::size_t alignment_ \u0026gt; struct aligned_storage_imp\u0026lt;0u,alignment_\u0026gt; { /* intentionally empty */ void* address() const { return 0; } }; }} // namespace detail::aligned_storage template \u0026lt; std::size_t size_ , std::size_t alignment_ = std::size_t(-1) \u0026gt; class aligned_storage : #ifndef BOOST_BORLANDC private #else public #endif ::boost::detail::aligned_storage::aligned_storage_imp\u0026lt;size_, alignment_\u0026gt; { public: // constants typedef ::boost::detail::aligned_storage::aligned_storage_imp\u0026lt;size_, alignment_\u0026gt; type; BOOST_STATIC_CONSTANT( std::size_t , size = size_ ); BOOST_STATIC_CONSTANT( std::size_t , alignment = ( alignment_ == std::size_t(-1) ? ::boost::detail::aligned_storage::alignment_of_max_align : alignment_ ) ); private: // noncopyable aligned_storage(const aligned_storage\u0026amp;); aligned_storage\u0026amp; operator=(const aligned_storage\u0026amp;); public: // structors aligned_storage() { } ~aligned_storage() { } public: // accessors void* address() { return static_cast\u0026lt;type*\u0026gt;(this)-\u0026gt;address(); } kfifo的无锁实现 # 可以看到本质上就是一个先enqueue再挪动指针，保证数据先进去，再稳定挪动的操作。这个过程使用了内存屏障等多种操作。在ARM ustack atcp_rq就会出现问题。\nunsigned int kfifo_in(struct kfifo *fifo, const void *from, unsigned int len) { len = min(kfifo_avail(fifo), len); __kfifo_in_data(fifo, from, len, 0); __kfifo_add_in(fifo, len); return len; } static inline void __kfifo_in_data(struct kfifo *fifo, const void *from, unsigned int len, unsigned int off) { unsigned int l; /* * Ensure that we sample the fifo-\u0026gt;out index -before- we * start putting bytes into the kfifo. */ smp_mb(); off = __kfifo_off(fifo, fifo-\u0026gt;in + off); /* first put the data starting from fifo-\u0026gt;in to buffer end */ l = min(len, fifo-\u0026gt;size - off); memcpy(fifo-\u0026gt;buffer + off, from, l); /* then put the rest (if any) at the beginning of the buffer */ memcpy(fifo-\u0026gt;buffer, from + l, len - l); } static inline void __kfifo_add_in(struct kfifo *fifo, unsigned int off) { smp_wmb(); fifo-\u0026gt;in += off; } 结尾 # 唉，尴尬\n","date":"2021 年 1 月 3 日","externalUrl":null,"permalink":"/posts/2021-01-03-%E4%BB%8E%E9%94%81%E5%92%8Crte-ring%E4%B8%8Ekfifo%E8%AF%B4%E8%B5%B7/","section":"Posts","summary":"","title":"从锁和RTE ring与KFIFO说起","type":"posts"},{"content":" 阅读整理曾经做过的leetcode # 前言 # 原先做了不少中等难度和简单难度的leetcode题目，都上传到了github上。但是没有总结，现在面试需要的时候就发现很多都想不起来了。所以今天写一个整理总结的类型。\n常见数据结构和基本算法（摘抄自halfrost) # 数据结构见下，\n数据结构 变种 相关题目 讲解文章 顺序线性表：向量 Vector 单链表 Singly Linked List 1. 双向链表 Double Linked Lists 2. 静态链表 Static List 3. 对称矩阵 Symmetric Matrix 4. 稀疏矩阵 Sparse Matrix 哈希表 Hash Table 1. 散列函数 Hash Function 2. 解决碰撞/填充因子 Collision Resolution 栈和队列 Stack \u0026amp; Queue 1. 广义表 Generalized List/GList 2. 双端队列 Deque 队列 Queue 1. 链表实现 Linked List Implementation 2. 循环数组实现 ArrayQueue 3. 双端队列 Deque 4. 优先队列 Priority Queue 5. 循环队列 Circular Queue 字符串 String 1. KMP 算法 2. 有限状态自动机 3. 模式匹配有限状态自动机 4. BM 模式匹配算法 5. BM-KMP 算法 6. BF 算法 树 Tree 1. 二叉树 Binary Tree 2. 并查集 Union-Find 3. Huffman 树 数组实现的堆 Heap 1. 极大堆和极小堆 Max Heap and Min Heap 2. 极大极小堆 3. 双端堆 Deap 4. d 叉堆 树实现的堆 Heap 1. 左堆 Leftist Tree/Leftist Heap 2. 扁堆 3. 二项式堆 4. 斐波那契堆 Fibonacco Heap 5. 配对堆 Pairing Heap 查找 Search 1. 哈希表 Hash 2. 跳跃表 Skip List 3. 排序二叉树 Binary Sort Tree 4. AVL 树 5. B 树 / B+ 树 / B* 树 6. AA 树 7. 红黑树 Red Black Tree 8. 排序二叉堆 Binary Heap 9. Splay 树 10. 双链树 Double Chained Tree 11. Trie 树 12. R 树 ——————————————– ——————————————————————————————– ————————— ———————————– 常见的算法\n算法 具体类型 相关题目 讲解文章 排序算法 1. 冒泡排序\n2. 插入排序 3. 选择排序 4. 希尔 Shell 排序 5. 快速排序 6. 归并排序 7. 堆排序 8. 线性排序算法 9. 自省排序 10. 间接排序 11. 计数排序 12. 基数排序 13. 桶排序 14. 外部排序 - k 路归并败者树 15. 外部排序 - 最佳归并树 递归与分治 1. 二分搜索/查找 2. 大整数的乘法 3. Strassen 矩阵乘法 4. 棋盘覆盖 5. 合并排序 6. 快速排序 7. 线性时间选择 8. 最接近点对问题 9. 循环赛日程表 动态规划 1. 矩阵连乘问题 2. 最长公共子序列 3. 最大子段和 4. 凸多边形最优三角剖分 5. 多边形游戏 6. 图像压缩 7. 电路布线 8. 流水作业调度 9. 0-1 背包问题/背包九讲 10. 最优二叉搜索树 11. 动态规划加速原理 12. 树型 DP 贪心 1. 活动安排问题 2. 最优装载 3. 哈夫曼编码 4. 单源最短路径 5. 最小生成树 6. 多机调度问题 回溯法 1. 装载问题 2. 批处理作业调度 3. 符号三角形问题 4. n 后问题 5. 0-1 背包问题 6. 最大团问题 7. 图的 m 着色问题 8. 旅行售货员问题 9. 圆排列问题 10. 电路板排列问题 11. 连续邮资问题 搜索 1. 枚举 2. DFS 3. BFS 4. 启发式搜索 随机化 1. 随机数 2. 数值随机化算法 3. Sherwood 舍伍德算法 4. Las Vegas 拉斯维加斯算法 5. Monte Carlo 蒙特卡罗算法 1. 计算 π 值 2. 计算定积分 3. 解非线性方程组 4. 线性时间选择算法 5. 跳跃表 6. n 后问题 7. 整数因子分解 8. 主元素问题 9. 素数测试 图论 1. 遍历 DFS / BFS 2. AOV / AOE 网络 3. Kruskal 算法(最小生成树) 4. Prim 算法(最小生成树) 5. Boruvka 算法(最小生成树) 6. Dijkstra 算法(单源最短路径) 7. Bellman-Ford 算法(单源最短路径) 8. SPFA 算法(单源最短路径)9. Floyd 算法(多源最短路径) 10. Johnson 算法(多源最短路径) 11. Fleury 算法(欧拉回路) 12. Ford-Fulkerson 算法(最大网络流增广路) 13. Edmonds-Karp 算法(最大网络流) 14. Dinic 算法(最大网络流) 15. 一般预流推进算法 16. 最高标号预流推进 HLPP 算法 17. Primal-Dual 原始对偶算法(最小费用流)18. Kosaraju 算法(有向图强连通分量) 19. Tarjan 算法(有向图强连通分量) 20. Gabow 算法(有向图强连通分量) 21. 匈牙利算法(二分图匹配) 22. Hopcroft－Karp 算法(二分图匹配) 23. kuhn munkras 算法(二分图最佳匹配) 24. Edmonds’ Blossom-Contraction 算法(一般图匹配) 1. 图遍历 2. 有向图和无向图的强弱连通性 3. 割点/割边 3. AOV 网络和拓扑排序 4. AOE 网络和关键路径 5. 最小代价生成树/次小生成树 6. 最短路径问题/第 K 短路问题 7. 最大网络流问题 8. 最小费用流问题 9. 图着色问题 10. 差分约束系统 11. 欧拉回路 12. 中国邮递员问题 13. 汉密尔顿回路 14. 最佳边割集/最佳点割集/最小边割集/最小点割集/最小路径覆盖/最小点集覆盖 15. 边覆盖集 16. 二分图完美匹配和最大匹配问题 17. 仙人掌图 18. 弦图 19. 稳定婚姻问题 20. 最大团问题 数论 1. 最大公约数 2. 最小公倍数 3. 分解质因数 4. 素数判定 5. 进制转换 6. 高精度计算 7. 整除问题 8. 同余问题 9. 欧拉函数 10. 扩展欧几里得 11. 置换群 12. 母函数 13. 离散变换 14. 康托展开 15. 矩阵 16. 向量 17. 线性方程组 18. 线性规划 几何 1. 凸包 - Gift wrapping 2. 凸包 - Graham scan 3. 线段问题 4. 多边形和多面体相关问题 NP 完全 1. 计算模型 2. P 类与 NP 类问题 3. NP 完全问题 4. NP 完全问题的近似算法 1. 随机存取机 RAM 2. 随机存取存储程序机 RASP 3. 图灵机 4. 非确定性图灵机 5. P 类与 NP 类语言 6. 多项式时间验证 7. 多项式时间变换 8. Cook定理 9. 合取范式的可满足性问题 CNF-SAT 10. 3 元合取范式的可满足性问题 3-SAT 11. 团问题 CLIQUE 12. 顶点覆盖问题 VERTEX-COVER 13. 子集和问题 SUBSET-SUM 14. 哈密顿回路问题 HAM-CYCLE 15. 旅行售货员问题 TSP 16. 顶点覆盖问题的近似算法 17. 旅行售货员问题近似算法 18. 具有三角不等式性质的旅行售货员问题 19. 一般的旅行售货员问题 20. 集合覆盖问题的近似算法 21. 子集和问题的近似算法 22. 子集和问题的指数时间算法 23. 子集和问题的多项式时间近似格式 位运算 位操作包括： 1. 取反（NOT） 2. 按位或（OR） 3. 按位异或（XOR） 4. 按位与（AND） 5. 移位: 是一个二元运算符，用来将一个二进制数中的每一位全部都向一个方向移动指定位，溢出的部分将被舍弃，而空缺的部分填入一定的值。 1.数字范围按位与 2.UTF-8 编码验证 3.数字转换为十六进制数 4.找出最长的超赞子字符串 5.数组异或操作 6.幂集 7.位1的个数 8.二进制表示中质数个计算置位 9.子数组异或查询 力扣：位运算 ———— —————————————————————— —————————————————————– ——————– 针对每一种算法的具体实现\n针对具体类型的题目做的分类\nArray # 0001 Two Sum\n对常见数据结构的应用 # 指针的引用 # 盛最多水的容器 leetcode第11题\n给你 n 个非负整数 a1，a2，\u0026hellip;，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0) 。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水\n三数之和 leetcode第15题\n给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有满足条件且不重复的三元组。\n四数之和 leetcode第18题\n给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。\n树的应用 # 括号生成。 leetcode第22题\n数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。\n450. 删除二叉搜索树中的节点 # 给定一个二叉搜索树的根节点 root 和一个值 key，删除二叉搜索树中的 key 对应的节点，并保证二叉搜索树的性质不变。返回二叉搜索树（有可能被更新）的根节点的引用。\nhash表的应用 # 两数之和 leetcode第1题\n给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 的那 两个 整数，并返回它们的数组下标。\n无重复字符的最长子串 leetcode第3题\n给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。\n缺失的第一个正数 leetcode第41题\n给你一个未排序的整数数组 nums ，请你找出其中没有出现的最小的正整数。\n非常典型的原地hash\n数组中重复的数据 leetcode第442题\n给定一个整数数组 a，其中1 ≤ a[i] ≤ n （n为数组长度）, 其中有些元素出现两次而其他元素出现一次。找到所有出现两次的元素\n字母异位词分组。 leetcode第49题\n给定一个字符串数组，将字母异位词组合在一起。字母异位词指字母相同，但排列不同的字符串。\n423. 从英文中重建数字 # 给定一个非空字符串，其中包含字母顺序打乱的英文单词表示的数字0-9。按升序输出原始的数字。\n448. 找到所有数组中消失的数字 # 给定一个范围在 1 ≤ a[i] ≤ n ( n = 数组大小 ) 的 整型数组，数组中的元素一些出现了两次，另一些只出现一次。\n找到所有在 [1, n] 范围之间没有出现在数组中的数字。\n525. 连续数组 # 给定一个二进制数组, 找到含有相同数量的 0 和 1 的最长连续子数组（的长度）。\n栈的使用 # 有效的括号 leetcode第20题\n给定一个只包括 '('，')'，'{'，'}'，'['，']' 的字符串 s ，判断字符串是否有效。\n链表的操作 # 两数之和 leetcode第2题\n给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储一位数字。\n445. 两数相加 II # 给你两个 非空 链表来代表两个非负整数。数字最高位位于链表开始位置。它们的每个节点只存储一位数字。将这两数相加会返回一个新的链表。\n非常常见的栈的题目\n删除链表的倒数第N个节点 leetcode第19题\n给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。\n两两交换链表中的节点 leetcode第24题\n给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。\n旋转链表 leetcode第61题\n给定一个链表，旋转链表，将链表每个节点向右移动 k 个位置，其中 k 是非负数。\n删除排序链表中的重复元素 II leetcode第82题\n给定一个排序链表，删除所有含有重复数字的节点，只保留原始链表中 没有重复出现 的数字。\n分隔链表 leetcode第86题\n给定一个链表和一个特定值 x，对链表进行分隔，使得所有小于 x 的节点都在大于或等于 x 的节点之前。\n206. 反转链表 # 反转一个单链表。\n反转链表 II leetcode92题\n反转从位置 m 到 n 的链表。请使用一趟扫描完成反转。\n287. 寻找重复数 # 给定一个包含 n + 1 个整数的数组 nums ，其数字都在 1 到 n 之间（包括 1 和 n），可知至少存在一个重复的整数。\n假设 nums 只有 一个重复的整数 ，找出 这个重复的数 。\n和下面两个题目一样都是双指针\n141. 环形链表 # 给定一个链表，判断链表中是否有环。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。\n如果链表中存在环，则返回 true 。 否则，返回 false 。\n142. 环形链表 II # 给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。\n328. 奇偶链表 # 给定一个单链表，把所有的奇数节点和偶数节点分别排在一起。请注意，这里的奇数节点和偶数节点指的是节点编号的奇偶性，而不是节点的值的奇偶性。\n常见算法的应用 # 动态规划 # 最长回文子串。 leetcode第5题\n给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。 实际上本质上就是减少检查的次数，利用原先推到过的结果。\n最大子序和。 leetcode第53题\n给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。\n简单难度，你竟然没想到。。。。失败啊。\n不同路径。 leetcode第62题\n一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish” ）。问总共有多少条不同的路径？\n实际上是个组合数学问题\n不同路径2。 leetcode第63题\n一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为“Start” ）。机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？\n滚动数组问题需要学习\n最小路径和。 leetcode第64题\n给定一个包含非负整数的 m x n 网格 grid ，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。每次只能向下或者向右移动一步。\n解码方法。 leetcode第91题\n给定一个只包含数字的非空字符串，请计算解码方法的总数。题目数据保证答案肯定是一个 32 位的整数。\n1277. 统计全为 1 的正方形子矩阵 # 给你一个 m * n 的矩阵，矩阵中的元素不是 0 就是 1，请你统计并返回其中完全由 1 组成的 正方形 子矩阵的个数。\n最大正方形 leetcode221题 # 在一个由 '0' 和 '1' 组成的二维矩阵内，找到只包含 '1' 的最大正方形，并返回其面积\n打家劫舍 leetcode198题 # 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。\n给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。\n打家劫舍 II leetcode213 # 你是一个专业的小偷，计划偷窃沿街的房屋，每间房内都藏有一定的现金。这个地方所有的房屋都 围成一圈 ，这意味着第一个房屋和最后一个房屋是紧挨着的。同时，相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警 。\n给定一个代表每个房屋存放金额的非负整数数组，计算你 在不触动警报装置的情况下 ，能够偷窃到的最高金额。\n279. 完全平方数 # 给定正整数 n，找到若干个完全平方数（比如 1, 4, 9, 16, \u0026hellip;）使得它们的和等于 n。你需要让组成和的完全平方数的个数最少。\n给你一个整数 n ，返回和为 n 的完全平方数的 最少数量 。\n背包问题还要再研究一下\n300. 最长递增子序列 # 给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。\n子序列是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。\n第二种方法很有趣，值得再次阅读\n322. 零钱兑换 # 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。\n你可以认为每种硬币的数量是无限的。\n338. 比特位计数 # 给定一个非负整数 num。对于 0 ≤ i ≤ num 范围中的每个数字 i ，计算其二进制数中的 1 的数目并将它们作为数组返回。\n由此可见，正整数 y 是 2的整数次幂，当且仅当y\u0026amp;(y−1)=0。这个规律很有趣。而且有一个关于1的数目很有趣的特点：\nbits[x]=bits[x\u0026amp;(x−1)]+1\n375. 猜数字大小 II # 我们正在玩一个猜数游戏，游戏规则如下：\n我从 1 到 n 之间选择一个数字，你来猜我选了哪个数字。\n每次你猜错了，我都会告诉你，我选的数字比你的大了或者小了。\n然而，当你猜了数字 x 并且猜错了的时候，你需要支付金额为 x 的现金。直到你猜到我选的数字，你才算赢得了这个游戏。\n396. 旋转函数 # 给定一个长度为 n 的整数数组 A 。\n假设 Bk 是数组 A 顺时针旋转 k 个位置后的数组，我们定义 A 的“旋转函数” F 为：\nF(k) = 0 * Bk[0] + 1 * Bk[1] + \u0026hellip; + (n-1) * Bk[n-1]。\n计算F(0), F(1), \u0026hellip;, F(n-1)中的最大值。\n这个应该说规律非常明显，难度只有简单才合适\n397. 整数替换 # 给定一个正整数 n ，你可以做如下操作：\n如果 n 是偶数，则用 n / 2替换 n 。 如果 n 是奇数，则可以用 n + 1或n - 1替换 n 。 n 变为 1 所需的最小替换次数是多少？\n实际上也是很基本的对数字的考察\n413. 等差数列划分 # 如果一个数列至少有三个元素，并且任意两个相邻元素之差相同，则称该数列为等差数列。\n如果满足以下条件，则称子数组(P, Q)为等差数组：\n元素 A[P], A[p + 1], \u0026hellip;, A[Q - 1], A[Q] 是等差的。并且 P + 1 \u0026lt; Q 。\n函数要返回数组 A 中所有为等差数组的子数组个数。\n486. 预测赢家 # 给定一个表示分数的非负整数数组。 玩家 1 从数组任意一端拿取一个分数，随后玩家 2 继续从剩余数组任意一端拿取分数，然后玩家 1 拿，…… 。每次一个玩家只能拿取一个分数，分数被拿取之后不再可取。直到没有剩余分数可取时游戏结束。最终获得分数总和最多的玩家获胜。\n给定一个表示分数的数组，预测玩家1是否会成为赢家。你可以假设每个玩家的玩法都会使他的分数最大化。\n背包问题 # 虽然背包问题一般要么搜索，要么动规，但是出于检索目的单独把背包问题拆出来了。\n416. 分割等和子集 # 给定一个只包含正整数的非空数组。是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。\n光看题目非常居有迷惑性，但是想明白两个子集的元素和相等就明白这个实际上是个背包问题了。很有趣也很值得关注的一道题，务必搜索“背包九讲”\n474. 一和零 # 给你一个二进制字符串数组 strs 和两个整数 m 和 n 。\n请你找出并返回 strs 的最大子集的大小，该子集中 最多 有 m 个 0 和 n 个 1 。\n如果 x 的所有元素也是 y 的元素，集合 x 是集合 y 的 子集 。\n494. 目标和 # 给定一个非负整数数组，a1, a2, \u0026hellip;, an, 和一个目标数，S。现在你有两个符号 + 和 -。对于数组中的任意一个整数，你都可以从 + 或 -中选择一个符号添加在前面。\n返回可以使最终数组和为目标数 S 的所有添加符号的方法数。\n322. 零钱兑换 # 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。\n你可以认为每种硬币的数量是无限的。\n518. 零钱兑换 II # 给定不同面额的硬币和一个总金额。写出函数来计算可以凑成总金额的硬币组合数。假设每一种面额的硬币有无限个。\n递归 # 从前序与中序遍历序列构造二叉树 leetcode第105题\n根据一棵树的前序遍历与中序遍历构造二叉树。\n从中序与后序遍历序列构造二叉树 leetcode第106题\n根据一棵树的中序遍历与后序遍历构造二叉树。\n有序链表转换二叉搜索树 leetcode第109题\n给定一个单链表，其中的元素按升序排序，将其转换为高度平衡的二叉搜索树。\n264. 丑数 II # 编写一个程序，找出第 n 个丑数。\n丑数就是质因数只包含 2, 3, 5 的正整数。\n三指针法的想法得明白咋回事\n390. 消除游戏 # 给定一个从1 到 n 排序的整数列表。 首先，从左到右，从第一个数字开始，每隔一个数字进行删除，直到列表的末尾。 第二步，在剩下的数字中，从右到左，从倒数第一个数字开始，每隔一个数字进行删除，直到列表开头。 我们不断重复这两步，从左到右和从右到左交替进行，直到只剩下一个数字。 返回长度为 n 的列表中，最后剩下的数字。\n剑指 Offer 62. 圆圈中最后剩下的数字 # 0,1,···,n-1这n个数字排成一个圆圈，从数字0开始，每次从这个圆圈里删除第m个数字（删除后从下一个数字开始计数）。求出这个圆圈里剩下的最后一个数字。\n例如，0、1、2、3、4这5个数字组成一个圆圈，从数字0开始每次删除第3个数字，则删除的前4个数字依次是2、0、4、1，因此最后剩下的数字是3。\n上面两个题目本质是约瑟夫环，得学习下\n深度搜索(或者说回溯) # 这里把深度搜索的算法写下来，方便以后回想\nstruct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) {} }; 括号生成。 leetcode第22题\n给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。\n关于这种生成字符串种类的题目通通可以这样子计算，找到了生成的字符串的限制规律，然后让计算机去搜索在规律限制之下能够生成的子串的集合，这东西就是深搜。\n组合总和。 leetcode第39题\n给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的数字可以无限制重复被选取。\n这种问题实际上就是搜索。\n组合总和2。 leetcode第40题\n给定一个数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的每个数字在每个组合中只能使用一次。\n电话号码的字母组合。 leetcode第17题\n给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。\n全排列。 leetcode第46题\n给定一个 没有重复 数字的序列，返回其所有可能的全排列。\n回溯实际上就是个不断撞南墙回来的过程，此外这题目的解答里面，有个哥们给了给非常详尽的回溯搜索的见解和相关题目，建议阅读\n全排列2。 leetcode第47题\n给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。\n排列序列。 leetcode第60题\n给出集合 [1,2,3,\u0026hellip;,n]，其所有元素共有 n! 种排列。按大小顺序列出所有排列情况。给定 n 和 k，返回第 k 个排列。\n组合。 leetcode第77题\n给定两个整数 n 和 k，返回 1 \u0026hellip; n 中所有可能的 k 个数的组合。\n子集。 leetcode第78题\n给你一个整数数组 nums ，返回该数组所有可能的子集（幂集）。解集不能包含重复的子集。\n这题有个“DFS 和回溯算法区别”写的挺不错，建议看看，当然，这里需要。\n子集2。 leetcode第90题\n给你一个整数数组 nums ，其中可能包含重复元素，请你返回该数组所有可能的 子集（幂集）。\n解集 不能 包含重复的子集。返回的解集中，子集可以按 任意顺序 排列。\n单词搜索。 leetcode第79题\n给定一个二维网格和一个单词，找出该单词是否存在于网格中。\n复原IP地址。 leetcode第93题\n给定一个只包含数字的字符串，复原它并返回所有可能的 IP 地址格式。\n二叉树的中序遍历。 leetcode第94题\n给定一个二叉树的根节点 root ，返回它的 中序 遍历。\n不同的二叉搜索树 II。 leetcode第95题\n给定一个整数 n，生成所有由 1 \u0026hellip; n 为节点所组成的 二叉搜索树 。\n路径总和 II。 leetcode第113题\n给定一个二叉树和一个目标和，找到所有从根节点到叶子节点路径总和等于给定目标和的路径。\n二叉树展开为链表。 leetcode第114题\n给你二叉树的根结点 root ，请你将它展开为一个单链表： 展开后的单链表应该和先序遍历一致\n组合总和 III leetcode216题 # 找出所有相加之和为 n 的 k 个数的组合。组合中只允许含有 1 - 9 的正整数，并且每种组合中不存在重复的数字。\n说明：\n所有数字都是正整数。 解集不能包含重复的组合\n完全二叉树的节点个数 leetcode222 # 给你一棵 完全二叉树 的根节点 root ，求出该树的节点个数。\n利用完全二叉树的结构和递归的想法\n二叉搜索树中第K小的元素 leetcode 230 # 给定一个二叉搜索树的根节点 root ，和一个整数 k ，请你设计一个算法查找其中第 k 个最小元素（从 1 开始计数）。\n二叉树的最近公共祖先 leetcode236 # 给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。\n331. 验证二叉树的前序序列化 # 存疑\n357. 计算各个位数不同的数字个数 # 给定一个非负整数 n，计算各位数字都不同的数字 x 的个数，其中 0 ≤ x \u0026lt; 10n 。(就是组合数学)\n377. 组合总和 Ⅳ # 给定一个由正整数组成且不存在重复数字的数组，找出和为给定目标正整数的组合的个数。\n实际是背包问题，看这个https://leetcode-cn.com/problems/combination-sum-iv/solution/xi-wang-yong-yi-chong-gui-lu-gao-ding-bei-bao-wen-/\n386. 字典序排数 # 给定一个整数 n, 返回从 1 到 n 的字典顺序。\n394. 字符串解码 # 给定一个经过编码的字符串，返回它解码后的字符串。\n编码规则为: k[encoded_string]，表示其中方括号内部的 encoded_string 正好重复 k 次。注意 k 保证为正整数。\n可以说是栈，也可以说是深搜。\n491. 递增子序列 # 给定一个整型数组, 你的任务是找到所有该数组的递增子序列，递增子序列的长度至少是2。\n508. 出现次数最多的子树元素和 # 给你一个二叉树的根结点，请你找出现次数最多的子树元素和。一个结点的「子树元素和」定义为以该结点为根的二叉树上所有结点的元素之和（包括结点本身）。\n你需要返回出现次数最多的子树元素和。如果有多个元素出现的次数相同，返回所有出现次数最多的子树元素和（不限顺序）。\n513. 找树左下角的值 # 给定一个二叉树，在树的最后一行找到最左边的值\n广度搜索 # void bfs(TreeNode* root) { if (root == nullptr) { return; } queue\u0026lt;TreeNode*\u0026gt; nodeQueue; nodeQueue.push(root); while (!nodeQueue.empty()) { TreeNode* node = nodeQueue.front(); nodeQueue.pop(); cout \u0026lt;\u0026lt; node-\u0026gt;val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; if (node-\u0026gt;left != nullptr) { nodeQueue.push(node-\u0026gt;left); } if (node-\u0026gt;right != nullptr) { nodeQueue.push(node-\u0026gt;right); } } } 二叉树的层序遍历 leetcode第102题\n给你一个二叉树，请你返回其按 层序遍历 得到的节点值。 （即逐层地，从左到右访问所有节点）。\n典型的广度搜索\n二叉树的锯齿形层序遍历 leetcode第103题\n给定一个二叉树，返回其节点值的锯齿形层序遍历。（即先从左往右，再从右往左进行下一层遍历，以此类推，层与层之间交替进行）。\n二叉树的右视图 leetcode199题 # 给定一棵二叉树，想象自己站在它的右侧，按照从顶部到底部的顺序，返回从右侧所能看到的节点值。\n419. 甲板上的战舰 # 给定一个二维的甲板， 请计算其中有多少艘战舰。 战舰用 \u0026lsquo;X\u0026rsquo;表示，空位用 \u0026lsquo;.\u0026lsquo;表示。 你需要遵守以下规则：\n给你一个有效的甲板，仅由战舰或者空位组成。 战舰只能水平或者垂直放置。换句话说,战舰只能由 1xN (1 行, N 列)组成，或者 Nx1 (N 行, 1 列)组成，其中N可以是任意大小。 两艘战舰之间至少有一个水平或垂直的空位分隔 - 即没有相邻的战舰。\n515. 在每个树行中找最大值 # 您需要在二叉树的每一行中找到最大的值。\n542. 01 矩阵 # 给定一个由 0 和 1 组成的矩阵，找出每个元素到最近的 0 的距离。\n两个相邻元素间的距离为 1 。\n贪心算法 # 跳跃游戏。 leetcode第55题\n给定一个非负整数数组，你最初位于数组的第一个位置。数组中的每个元素代表你在该位置可以跳跃的最大长度。判断你是否能够到达最后一个位置。\n跳跃游戏 II。 leetcode第45题\n给定一个非负整数数组，你最初位于数组的第一个位置。数组中的每个元素代表你在该位置可以跳跃的最大长度。你的目标是使用最少的跳跃次数到达数组的最后一个位置。\n392. 判断子序列 # 给定字符串 s 和 t ，判断 s 是否为 t 的子序列。\n字符串的一个子序列是原始字符串删除一些（也可以不删除）字符而不改变剩余字符相对位置形成的新字符串。（例如，\u0026ldquo;ace\u0026quot;是\u0026quot;abcde\u0026quot;的一个子序列，而\u0026quot;aec\u0026quot;不是）。\n贪心或者动规？\n402. 移掉K位数字 # 给定一个以字符串表示的非负整数 num，移除这个数中的 k 位数字，使得剩下的数字最小。\n注意:\nnum 的长度小于 10002 且 ≥ k。 num 不会包含任何前导零。\n非常简单的贪心，使用单调栈的想法很有趣。\n473. 火柴拼正方形 # 435. 无重叠区间 # 图算法 # 课程表 leetcode207 # 你这个学期必须选修 numCourses 门课程，记为 0 到 numCourses - 1 。\n在选修某些课程之前需要一些先修课程。 先修课程按数组 prerequisites 给出，其中 prerequisites[i] = [ai, bi] ，表示如果要学习课程 ai 则 必须 先学习课程 bi 。\n例如，先修课程对 [0, 1] 表示：想要学习课程 0 ，你需要先完成课程 1 。 请你判断是否可能完成所有课程的学习？如果可以，返回 true ；否则，返回 false\n其他 # 下一个排列。 leetcode第31题\n实现获取 下一个排列 的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。\n排序问题的非常正常的解法，实际上就是个所谓的升序找最小。降低的顺序变为升顺序。\n旋转图像。 leetcode第48题\n给定一个 n × n 的二维矩阵表示一个图像。将图像顺时针旋转 90 度。\n螺旋矩阵。 leetcode第54题\n给定一个包含 m x n 个元素的矩阵（m 行, n 列），请按照顺时针螺旋顺序，返回矩阵中的所有元素。\n螺旋矩阵2。 leetcode第59题\n给定一个正整数 n，生成一个包含 1 到 n2 所有元素，且元素按顺时针顺序螺旋排列的正方形矩阵。\n多数元素。 leetcode第169题\n给定一个大小为 n 的数组，找到其中的多数元素。多数元素是指在数组中出现次数 大于 ⌊ n/2 ⌋ 的元素。\n你可以假设数组是非空的，并且给定的数组总是存在多数元素。\n[颠倒二进制位]。 leetcode第190题\n颠倒给定的 32 位无符号整数的二进制位。\n本质就是诸位颠倒\n位1的个数。 leetcode第191题\n编写一个函数，输入是一个无符号整数（以二进制串的形式），返回其二进制表达式中数字位数为 \u0026lsquo;1\u0026rsquo; 的个数（也被称为汉明重量）\n[LRU 缓存机制]。 leetcode第146题\n运用你所掌握的数据结构，设计和实现一个 LRU (最近最少使用) 缓存机制 。\n从本质来说是hash表和双向链表，因为这个题目很有趣，所以给出代码实现。\nclass LRUCache { public: LRUCache(int capacity) : cap(capacity) { } int get(int key) { if (map.find(key) == map.end()) return -1; auto key_value = *map[key]; cache.erase(map[key]); cache.push_front(key_value); map[key] = cache.begin(); return key_value.second; } void put(int key, int value) { if (map.find(key) == map.end()) { if (cache.size() == cap) { map.erase(cache.back().first); cache.pop_back(); } } else { cache.erase(map[key]); } cache.push_front({key, value}); map[key] = cache.begin(); } private: int cap; list\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; cache; unordered_map\u0026lt;int, list\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;::iterator\u0026gt; map; }; 下面还需要把linux的lru+last chance实现出来。\n315. 计算右侧小于当前元素的个数 # 给定一个整数数组 nums，按要求返回一个新数组 counts。数组 counts 有该性质： counts[i] 的值是 nums[i] 右侧小于 nums[i] 的元素的数量。\n逆序数\n矩形面积 leetcode223 # 在二维平面上计算出两个由直线构成的矩形重叠后形成的总面积。\n260. 只出现一次的数字 III # 给定一个整数数组 nums，其中恰好有两个元素只出现一次，其余所有元素均出现两次。 找出只出现一次的那两个元素。你可以按 任意顺序 返回答案。\n数学的思想，异或\n268. 丢失的数字 # 给定一个包含 [0, n] 中 n 个数的数组 nums ，找出 [0, n] 这个范围内没有出现在数组中的那个数。\n289. 生命游戏 # 根据 百度百科 ，生命游戏，简称为生命，是英国数学家约翰·何顿·康威在 1970 年发明的细胞自动机。\n给定一个包含 m × n 个格子的面板，每一个格子都可以看成是一个细胞。每个细胞都具有一个初始状态：1 即为活细胞（live），或 0 即为死细胞（dead）。每个细胞与其八个相邻位置（水平，垂直，对角线）的细胞都遵循以下四条生存定律：\n如果活细胞周围八个位置的活细胞数少于两个，则该位置活细胞死亡； 如果活细胞周围八个位置有两个或三个活细胞，则该位置活细胞仍然存活； 如果活细胞周围八个位置有超过三个活细胞，则该位置活细胞死亡； 如果死细胞周围正好有三个活细胞，则该位置死细胞复活； 下一个状态是通过将上述规则同时应用于当前状态下的每个细胞所形成的，其中细胞的出生和死亡是同时发生的。给你 m x n 网格面板 board 的当前状态，返回下一个状态。\n319. 灯泡开关 # 初始时有 n 个灯泡关闭。\n第 1 轮，你打开所有的灯泡。 第 2 轮，每两个灯泡你关闭一次。 第 3 轮，每三个灯泡切换一次开关（如果关闭则开启，如果开启则关闭）。\n第 i 轮，每 i 个灯泡切换一次开关。 对于第 n 轮，你只切换最后一个灯泡的开关。\n找出 n 轮后有多少个亮着的灯泡。\n334. 递增的三元子序列 # 给你一个整数数组 nums ，判断这个数组中是否存在长度为 3 的递增子序列。\n如果存在这样的三元组下标 (i, j, k) 且满足 i \u0026lt; j \u0026lt; k ，使得 nums[i] \u0026lt; nums[j] \u0026lt; nums[k] ，返回 true ；否则，返回 false 。\n双指针法\n343. 整数拆分 # 给定一个正整数 n，将其拆分为至少两个正整数的和，并使这些整数的乘积最大化。 返回你可以获得的最大乘积。\n344. 反转字符串 # 编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 char[] 的形式给出。\n372. 超级次方 # 你的任务是计算 ab 对 1337 取模，a 是一个正整数，b 是一个非常大的正整数且会以数组形式给出。\n382. 链表随机节点 # 给定一个单链表，随机选择链表的一个节点，并返回相应的节点值。保证每个节点被选的概率一样。\n一个随机的想法，值得一看。\n389. 找不同 # 给定两个字符串 s 和 t，它们只包含小写字母。\n字符串 *t* 由字符串 *s* 随机重排，然后在随机位置添加一个字母。\n请找出在 t 中被添加的字母。\n421. 数组中两个数的最大异或值 # 本质还是数学\n451. 根据字符出现频率排序 # 本质还是数学\n461. 汉明距离 # 二进制，数学\n476. 数字的补数 # 二进制，数学\n477. 汉明距离总和 # 两个整数的 汉明距离 指的是这两个数字的二进制数对应位不同的数量。\n计算一个数组中，任意两个数之间汉明距离的总和。\n498. 对角线遍历 # 给定一个含有 M x N 个元素的矩阵（M 行，N 列），请以对角线遍历的顺序返回这个矩阵中的所有元素，对角线遍历如下图所示。\n二分 # 搜索旋转排序数组。 leetcode第33题\n升序排列的整数数组 nums 在预先未知的某个点上进行了旋转（例如， [0,1,2,4,5,6,7] 经旋转后可能变为 [4,5,6,7,0,1,2] ）。请你在数组中搜索 target ，如果数组中存在这个目标值，则返回它的索引，否则返回 -1 。\n在排序数组中查找元素的第一个和最后一个位置。 leetcode第34题\n给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。如果数组中不存在目标值 target，返回 [-1, -1]。\n搜索二维矩阵。 leetcode第74题\n编写一个高效的算法来判断 m x n 矩阵中，是否存在一个目标值。该矩阵具有如下特性： 每行中的整数从左到右按升序排列。 每行的第一个整数大于前一行的最后一个整数。\n[ 寻找旋转排序数组中的最小值 leetcode第153题\n假设按照升序排序的数组在预先未知的某个点上进行了旋转。例如，数组 [0,1,2,4,5,6,7] 可能变为 [4,5,6,7,0,1,2] 。\n请找出其中最小的元素。\n寻找峰值。 leetcode第162题\n峰值元素是指其值大于左右相邻值的元素。\n给你一个输入数组 nums，找到峰值元素并返回其索引。数组可能包含多个峰值，在这种情况下，返回 任何一个峰值 所在位置即可。\n你可以假设 nums[-1] = nums[n] = -∞ 。\n数组中的第K个最大元素 leetcode215题 # 在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。\n2的幂 leetcode231 # 给定一个整数，编写一个函数来判断它是否是 2 的幂次方\n搜索二维矩阵 II leetcode240 # 编写一个高效的算法来搜索 m x n 矩阵 matrix 中的一个目标值 target 。该矩阵具有以下特性：\n每行的元素从左到右升序排列。 每列的元素从上到下升序排列。\n241. 为运算表达式设计优先级 # 给定一个含有数字和运算符的字符串，为表达式添加括号，改变其运算优先级以求出不同的结果。你需要给出所有可能的组合的结果。有效的运算符号包含 +, - 以及 * 。\n378. 有序矩阵中第 K 小的元素 # 给你一个 n x n 矩阵 matrix ，其中每行和每列元素均按升序排序，找到矩阵中第 k 小的元素。 请注意，它是 排序后 的第 k 小元素，而不是第 k 个 不同 的元素。\n排序 # 合并区间。 leetcode第56题\n给出一个区间的集合，请合并所有重叠的区间。\n颜色分类。 leetcode第75题\n给定一个包含红色、白色和蓝色，一共 n 个元素的数组，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。\n274. H 指数 # 给定一位研究者论文被引用次数的数组（被引用次数是非负整数）。编写一个方法，计算出研究者的 h 指数。\nh 指数的定义：h 代表“高引用次数”（high citations），一名科研人员的 h 指数是指他（她）的 （N 篇论文中）总共有 h 篇论文分别被引用了至少 h 次。且其余的 N - h 篇论文每篇被引用次数 不超过 h 次。\n324. 摆动排序 II # 给你一个整数数组 nums，将它重新排列成 nums[0] \u0026lt; nums[1] \u0026gt; nums[2] \u0026lt; nums[3]\u0026hellip; 的顺序。\n你可以假设所有输入数组都可以得到满足题目要求的结果。\n347. 前 K 个高频元素 # 给定一个非空的整数数组，返回其中出现频率前 *k* 高的元素。\n373. 查找和最小的K对数字 # 给定两个以升序排列的整形数组 nums1 和 nums2, 以及一个整数 k。\n定义一对值 (u,v)，其中第一个元素来自 nums1，第二个元素来自 nums2。\n找到和最小的 k 对数字 (u1,v1), (u2,v2) \u0026hellip; (uk,vk)。\n看这个网址https://blog.csdn.net/u013317445/article/details/89680330或者用双指针来做\n462. 最少移动次数使数组元素相等 II # 给定一个非空整数数组，找到使所有数组元素相等所需的最小移动数，其中每次移动可将选定的一个元素加1或减1。 您可以假设数组的长度最多为10000。\n致谢 # 感谢halfrost同学，\n参考资料 # https://books.halfrost.com/leetcode/ChapterOne/\n结尾 # ","date":"2021 年 1 月 2 日","externalUrl":null,"permalink":"/posts/2021-01-02-%E9%98%85%E8%AF%BB%E6%95%B4%E7%90%86%E6%9B%BE%E7%BB%8F%E5%81%9A%E8%BF%87%E7%9A%84leetcode/","section":"Posts","summary":"","title":"阅读整理曾经做过的leetcode","type":"posts"},{"content":" 如何进行性能分析和诊断 # 0 前言和性能测试综述 # 为什么写这个呢，毕竟性能分析往往是整个系统的最后一环，而且目前很多时候像什么cpu/内存往往都可以拓展的情况下，性能分析的意义不再像原先那么大。但是现在做CI，CI运行的稳定，对CI中每个测试都有一定的依赖，以目前轻舟的实例来说：如果format test 或者仿真测试scenario-test-presubmit-cn运行过久，那么就会占用大量的CI运算资源，从而干扰其他的测试。我们目前虽然启用了buildfarm来加速编译和测试过程，但是仿真测试在编译完成之后就在云端运行，就脱离了编译的范畴了。\n这里面揉杂着三个方面的内容和经历：\n在华耀排查内存泄露的问题，到底是哪里花了太多cpu？malloc的linux内存？还是直接接管的hugepage内存？ 轻舟排查CI运行的性能问题，比方说为什么仿真运行过久，占用了太多的ci资源 《性能之巅》+《bpf之巅》等很多东西，估计写起来会比较复杂 linux性能优化实战 。。。 可能第一遍写也会比较乱，慢慢写吧。\n0.1 性能测试综述 # 我下面先简单对性能测试做个分类，再介绍性能测试挑战性的来源，之后给出性能测试的方法和套路，最后给出性能测试可视化的常见手段。这里需要说下，很多内容都是抄的《性能之巅》这本书，我建议直接阅读这本书（已经捐到了图书角），先对xxx表示感谢\n0.1.1 性能测试的分类 # 按照我个人习惯，我将性能测试按照阶段和复杂度进行分类。按照测试场景可以分为下面几种：\n软件开发阶段 设置性能目标和建立基本的性能模型：做简单的性能测试，定性分析。 针对软件发布后的基准测试：理想情况下的软件综合性能测试，定量分析。 真实集成阶段 目标环境的概念测试：集成环境或者说ontest环境的性能测试，定量分析。依赖的数据源可能成为受限因素。 特定问题的性能分析：针对实际生产环境性能不达标所做的分析。故障分析 按照复杂度将测试分为两种单一测试和集成测试\n单一测试一般只测试单一模块，其它的资源（网络，IO。。。）是充足的，属于设置性能目标和性能建模阶段做的测试。 集成测试，对应软件发布后的基准测试，是理想情况下一个软件系统所能提供的性能的量化 因为测试阶段的不同，其常用的方法和手段都是不同。针对单一测试，抽象出关键资源的性能指标，然后做资源USE分析即可估算出性能模型，提供性能参考。而集成测试需要以单一测试为起点，对工作负载做分析，最终量化性能数据。\n0.1.2 性能测试挑战性的来源 # 性能测试是一个具有挑战性的话题，其挑战性来源于标准的主观性，系统结构的复杂，和系统多问题并存的可能性。\n主观：之所以说性能测试是主观的，是因为性能问题是否存在的判断标准往往是模糊的：响应时间或者说是延时虽然是比较清楚的衡量标准之一，如果只说延迟1ms，实际上并不能确定是否存在性能问题。简单来说如果不明确最终用户的性能预期，那这个性能评测往往就是主观的。这个问题的解决方法可以通过定义清晰的目标，或者对落进一定响应延时范围内的请求统计百分比可以将主观的性能变得客观化。 复杂：系统的复杂性导致我们往往缺少一个明确的分析起点，即使子系统隔离时表现得都很好，也可能因为故障连锁（出故障的组件导致其它组件出现性能问题）。这种问题的解决往往要不同角色的工程师通力合作，有时还需要子系统隔离做性能分析 多问题并存：做软件测试 因此当我们做性能测试的时候，需要明确地针对上面三种问题，给出前提条件，从而论证性能测试时合理有效的，\n0.1.3 性能测试的常见方法 # 无论哪种性能测试，都需要明确具体的测试目的，测试用例和前提假设\n首先我们需要明确一些术语，这些一致的术语能够帮我们讨论性能问题时快速地统一背景。讨论性能测试时第一步就是明确哪些是关键指标，如何衡量这些指标\nIOPS：每秒进行读写(I/O)操作的次数，多用于数据库等场合 响应时间：在网络上，指从空载到负载发生一个步进值的变化时，举个简单例子是TLS握手的服务端返回ServerHello报文时间。 延时：延迟是指某个操作从开始到结束所经过的时间 使用率：使用率可以认为是资源所占的比例，一般常说的都是CPU使用率，IO使用率 性能测试常见方法可以分成三种\n最常见的就是我直接benchmark工具做压测，什么线程模型，软件模型一把梭！这种方法术语“死道友不死贫道”的性能测试，即我就测试请求，至于可靠性啥的完全不管，只要数字。 从上到下-工作负载分析法：工作负载法往往是用来对外给出定量分析使用，常用来衡量QPS，延时等指标 从下到上-资源分析法：资源负载重点考察资源是否已经处于极限或者接近极限，一些资源负载分析的关键指标为IOPS，吞吐量，使用率 后两种方法是相辅相成的，工作负载测试出来的数据需要有合理性的论证，这时就需要做资源分析；做工作负载分析时，要明确具体的工作负载是什么，除了工作负载之外假定的前提的是什么，注意这里的前提是需要重点展示的。但是无论如何都要对软件应用场景有充分的理解\n下面针对性的聊下这几个方法\n0.1.3.1 USE法 # USE 方法可以概括为：检查所有的资源（服务器功能性的物理组成硬件（CPU， 硬盘, 总线））的利用率（资源执行某工作的平均时间），饱和度（衡量资源超载工作的程度，往往会被塞入队列），和错误信息。\n其流程如下\n先列出资源列表，比方说下面的资源类型\nCPUs： sockets, cores, hardware threads (virtual CPUs) 内存： 容量 网络接口 存储设备： I/O, 容量 控制器： 存储, 网卡 通道： CPUs, memory, I/O 绘制数据流图，利用数据流图做瓶颈分析。确定数据流转的关键流程。比方说编解码是主要的功耗，那么我就直接拿CPU的资源做估算即可评估QPS。\n我一般用USE法的时候不会直接对着CPU或者网络做资源分析，因为那样子过于基础。相反一般是先用benchmark测试几个关键路径qps等数据，之后利用排队理论里面的little law做性能估测。这个little law的内容为L = *λW。*即：一个排队系统在稳定状态下，在系统里面的个体的数量的平均值 L， 等于平均个体到达率λ （单位是 个每单位时间）乘以 个体的平均逗留时间W。这里有一个点，如果系统是串行的，那么可以参考CPU发射，将他们的L累加；如果是并行的，需要取最小的L作为结果。\n举个简单的例子，分析一个负载均衡的TLS Offload系统的性能，首先分析数据是通过轮询网卡直接拷贝到用户态，然后CPU做解码分包，再之后送入SSL硬件卡做加ECC计算。因此硬件负载均衡网卡，CPU的数据普遍都强于加解密卡，就能直接从理论确定上，这里新建的性能瓶颈是来自加解密卡的性能，那加解密卡做性能建模即可。\n如果想计算延时，那么little law就派上了用场，就拿上面的例子来说，网卡的qps是1000，延时是2ms；cpu的qps是10000，延时是1ms；加解密卡的qps是100，延时是1ms，那么系统的并发总量可以计算为1000*2+10000*1+100*1，并发度就算出来了，接下来我们非常清楚qps是100，那么延时就可以用这个值直接除以100计算得出。\n这里面可能有一些要正常研发注意的地方，对于延时而言，普通的C++程序延迟内部延迟（从进程收到消息到进程发出消息）做到几百微秒（即亚毫秒级）是不需要特殊的努力的。而最有效的优化方式是“强度消减”，即不在于怎么做得快，而在于怎么做得少。有三个实际注意点要看到：\n延迟和吞吐量是矛盾的，通常吞吐量上去了延迟也会跟着飚上去，因此控制负载是控制延迟的重要手段。延迟跟吞吐量的关系通常是个U型曲线。负载低延迟高；负载中，延迟低；负载高，延迟高 延迟和资源使用率是矛盾的，做高吞吐的服务程序，恨不得把CPU和IO都跑满，资源都用完。而低延迟的服务程序的资源占用率通常低得可怜，让人认为闲着没干什么事，可以再“加码”，要抵住这种压力。就算系统到了前面说的“发烫”的程度，其资源使用率也远没有到 100%。实际上平时资源使用率低是为了准备应付突发请求，请求或消息一来就可以立刻得到处理，尽量少排队，“排队”就意味着等待，等待就意味着长延迟。消除等待是最直接有效的降低延迟的办法，靠的就是富裕的容量。 延迟和可靠传输也是矛盾的，TCP做到可靠传输的办法是超时重传，一旦发生重传，几百毫秒的延迟就搭进去了，因此保持网络随时畅通，避免拥塞也是控制延迟的必要手段 0.1.3.3 工作负载特征归纳法 # 工作负载特征归纳法，从上到下进行分析，它需要开发者对实际场景有非常深入的了解。不断提问下面的问题来进行特征归纳，进而设计测试场景。\n负载时谁产生的？可以参考进程ID，用户ID，进程名 负载为什么会产生？是哪个代码路径，怎么样子的调用链 负载的组成是什么？是IO？是吞吐？ 负载有什么的特点？这种问题一般需要用泛性的方法去分析 我是用工作负载特征法的时候，一般只用来设计测试场景，就拿RPC的测试为例，RPC框架的工作主要是IO线程做发送+送到对应的计算线程编解码，其流量特征为部分长尾数据长度及其长，那么测试场景就可以设计为10%的数据为长尾数据，这些数据随机发出，测试响应时间/延时。\n工作负载特征归纳法的问题是用户很多时候并不知道负载是从哪里来的：简单的echo程序，处理一个请求只需要200-300纳秒，单个线程可以达到300-500万的吞吐。但如果多个线程协作，即使在极其流畅的系统中，也要付出3-5微秒的上下文切换代价和1微秒的cache同步代价，这种代价对开发者往往是透明的，因此这种时候我的建议还是直接对着函数做个benchmark，测一下，然后二分式地找一下工作负载来自哪里。\n0.1.3.4 性能测试的一般套路 # 上面的两种方法说起来还是比较粗糙和抽象的，下面给通用一些套路。\n首先\n确定好性能基线。使用资源分析法，明确响应时间，吞吐量以及资源利用率等性能测试中的关键指标。 可以直接用gbenchmark跑一下理想情况的关键路径，以关键路径作为理论性能的基准 设计测试用例，使用工作负载特征归纳法逐层分析，重点是需要分析清楚负载有什么样子的特点，或者说用户的真实使用场景是什么样子的。 对于部分场景，请求的平均qps很低，但是瞬时冲击很高，那么做性能测试就需要针对性地测试瞬时冲击。 REVIEW测试用例合理性，对比软件测试模型是否一致，并评估测试模型是否合理。需要计算机体系结构的基础知识。 执行具体的测试，明确性能测试中的关键指标后，选择具有统计意义的数据进行测试。如果做定量测试或者对比测试，需要给出自变量和因变量的测试结果。 这里要注意，展示结果的时候需要明确地给出测试环境的前提假设。比方说依赖数据库，那么就需要确保数据库的吞吐和延时是正常的。 我们以原先的自定义RPC框架为例模拟一下定量测试。\n确定性能基线：因为网络属于不可控因素，先假设网络为理想情况，网络延时为0。接下来对protobuf编解码做benchmark评估延时和QPS等数据的量级，这个结果可以作为理论性能的上限，最终测试出的系统性能偏差20%都算正常。 设计测试用例：PC框架的工作主要是IO线程做发送+送到对应的计算线程编解码，其流量特征为部分长尾数据长度极其长，那么测试场景就可以设计为10%的数据为长尾数据，这些数据随机发出，我们需要测试正常的请求响应时间/延时，是不是受到影响。 REVIEW测试用例合理性：这个就可以写文档论述软件模型是什么样子的，测试写的程序架构是什么如何如何 执行具体测试并展示结果：这里要确定自变量和因变量是什么，比方说认为网络情况理想，自变量可以是发送线程的数量，因变量可以为QPS。或者自变量是发送数据包的大小，因变量是请求的QPS。如果对比不同框架的RPC，在固定QPS的情况下，可以自变量是延时，因变量是百分比等等 最后\n1 性能分析总览 # 性能分析是一个很复杂的事情，可能是多个方面造成的后果。性能问题很可能出在多个子系统复杂的联系上，即便是这些子系统隔离的时候表现很好，也可能由于连锁故障产生性能问题。要理解这些问题最重要的是搞清楚各个系统下的联系。因此要求对整个系统的理解就要深刻\n在轻舟做CI我们重点针对的测试就是仿真测试，而仿真测试的代码非常复杂，揉杂着cache/bazel等一堆东西。它不单纯涉及到编译的耗时，还有仿真测试load cache的延时，另外还有cpu计算的耗时，也就是说它不单纯是个计算密集型还是个io密集型，而且它往往是多个问题的集合体，同时可能有多个瓶颈问题的存在\n对这种东西的性能分析，往往要集合很多人才能做分析，诸如pod数量不够，或者存储pvc/oss挂载失败的问题浅层还能直接确定并解决，一旦深入到逻辑里比方说跑的慢，那么就手足无措了。\n1.1 性能分析的起步和大致的方法 # 一般分析的时候先考虑程序是什么类型，在华耀做的负载均衡系统就是io密集型，而轻舟的仿真就是io密集+cpu密集型：它又能把cpu吃慢，还吃网络io来load cache（这种两者兼有的极为蛋疼）。之后，就需要衡量程序的性能，改进性能首先要研究评测哪些方面，如何评价，比方说吞吐量，响应时间，延时，并发，使用率，饱和度等等。最后就是针对性的采用各种方法。\n1.1.1 资源分析法 # 资源分析分析是内部哪个资源达到了极限，从而导致问题的出现。我们目前可以简单地将资源分类为下面几个类别，内容是具体的术语来表明关注点。实际上针对性地我们就是在提问比方说使用率，饱和度，错误\n网络IO iops：每秒发生的输入/输出的次数 响应时间：一次操作完成的时间（比方说load cache） 延时：等待服务的时间，这里面实际上藏着很多问题，因为网络延时设计的范围很广：dns延时，tcp三次握手延时，数据传输延时等等 磁盘IO iops：如上面，就不赘述了 响应时间 延时： 使用率： CPU： 负载：这里又暗藏一个东西，负载可能不是说任务太多了，而是说任务跑的太久了 内存： 使用率 文件系统： 响应时间： 1.1.2 工作负载法 # 工作负载分析则分析是内部哪个部分在疯狂占用负载，从而导致问题。这个东西实际上就有点类似perf火焰图了，这里面藏着一个问题就是负载重的不一定就是导致延时增加的东西。比方说阿里云的人就是典型的工作负载法，直接查负载，哪里不对就往哪里blame。\n业务负载画像需要直接理解实际运行的业务复杂， “消除不必要的工作”就往往是优化的起点，这要求用户了解\n负载时谁产生的？可以参考进程ID，用户ID，进程名 负载为什么会产生？是哪个代码路径，怎么样子的调用链 负载的组成是什么？是IO？是吞吐？ 负载有什么的特点？这种问题一般需要用泛性的方法去分析 这里要重点提出来一个60s观察法， 这个是在bpf之巅里面提到的分析，可以帮助我们建立一个直观的最初的印象，确定排查的方向。即先执行一些简单的命令看看有什么问题：\nuptime\ndmesg|tail\nvmstat 1，r的列表示cpu上正在执行和等待执行的进程数量，这个不包含IO，标准来说Average number of kernel threads that are runnable, which includes threads that are running and threads that are waiting for the CPU.。而b指的是被block的进程，一般是被IO阻塞，Average number of kernel threads in the VMM wait queue per second. This includes threads that are waiting on filesystem I/O or threads that have been suspended due to memory load control，free指空闲内存，si和so指示页换入和换出，这些值不为0，说明系统内存紧张。us,sy,id,wa,st都是cpu的运行时间戏份，st是指被窃取时间，主要针对虚拟化环境。cs代表每秒上下文切换次数，一般如果超过10000就意味着上下文过量了。此时一般祭出pidstat -w 5查看上下文抢占的情况。下面是我一次调试runner问题的记录，pidstat的使用看下面，有写 mpstat -P ALL 1，如果usr出现100的占用，一般是单个线程阻塞，如果是iowait高就得看看io，如果sys高就得看看系统调用\npidstat 1，针对进程显示cpu占用情况，-w显示上下文抢占情况，-w的结果重点关注下面两列。安装命令为apt-get install sysstat 或者是sudo yum install sysstat\ncswch：自愿上下文切换，进程运行时由于系统资源不足，如IO,内存等原因不得不进行切换。 nvcswch：非自愿上下文切换，比如时间片用完，系统调度让其他任务运行，或者竞争CPU的时候也会发生。 iostat -xz 1，r/s,w/s,rkB/s,wkB/s是指每秒向设备发出的读写次数，读写字节数。使用这些指标对业务负载画像即可察觉问题。await：IO的平均响应时间以ms为单位，超过预期的平均响应时间可以视为设备已经饱和或者设备层面有问题的表征。%util代表设备利用率，一般大于60代表性能变差\nfree -m\nsar -n DEV 1\nsar -n TCP,ETCP 1\ntop\n1.1.3 延时分析法 # 对于延时的分析方法存在延时分析法，这个方法就非常直接了，就是针对延时的二分法：\n存在请求延时吗？（有的） 请求时间花在cpu上吗？（不在） 不花在cpu的时间花在哪里了？（文件系统i/o） 文件系统的io花在了磁盘io/还是锁竞争？（磁盘io） 1.2 性能分析的工具 # 我们现在可以使用的工具已经非常多了，这给我们带来很多的方便。\n1.2.1 计数器类型工具 # 针对系统级别：\nvmstat mpstat iostat netstat sar 针对进程级别：\nps：用来查进程状态，延时分析的时候可以调研进程处于哪几种状态。\n可以用这个命令来判断进程（线程）on-cpu占wallclock总的时间比例：\nps -eo time,pid,etime | grep [PID] 进程状态的汇总：on-cpu（执行）；off-cpu（可运行；匿名换页；睡眠：等待包括网络，块设备和数据/文本页换入在内的io；锁：等待获取同步锁，或者等待其它线程；空闲：等待工作）\n针对各个cpu状态可以做更细分工作\n执行：检查执行的是用户态还是内核态，确定哪些代码路径消耗cpu，消耗了多少 可运行：检查整个系统的cpu负载，可能是系统的资源不足？ 匿名换页：检查整个系统的内存使用情况和限制 睡眠：分析阻塞应用程序的资源是什么，下面给一些具体的工具 pidstat -d ：判断在等待磁盘io还是睡眠 pstack，这个一般是针对睡眠达到s级别的，这次对仿真运行过久的排查就是用pstack确定的 锁：识别锁和持有锁过久线程，确定为什么花了那么久 top：top往往用来分析进程占用cpu的比例，对于cpu密集型程序，如果占用cpu很少，那明显确定有问题。\ntop将执行时间汇报为%CPU，即 pmap\n/proc/[pid]下的各种进程信息的汇总\nstat进程状态和统计，直接看这个https://man7.org/linux/man-pages/man5/proc.5.html，里面有每个列的汇总 limits实际的资源限制 pstack：直接打印线程栈，显示线程在干什么，如果几次打印线程都阻塞在curl上，那么大概率网络io有点问题\n1.2.2 追踪类型工具 # 追踪方面的工具相比较而言可以给我们更直接的观察\ndtrace bpftrace perf dtrace：针对dtrace我觉得不用多看了，毕竟bpftrace都出来那么久了，感觉没必要再坚持老黄历了。\n1.2.2.1 bpftrace # bpftrace：bpftrace，比较新的内核都支持，注意这里比较新的是指4.19之后的linux kernel，所以目前实际上我们都可以做分析了，下面给出来几个简单的例子，这里注意我不会过多的纠结于语法，也就是说重点是介绍某个工具可用，给个简单的例子，然后继续\nfunccount，统计内核态或者用户态函数是否被调用过，该函数被调用过几次。方向明确的时候，针对具体函数可以做分析。 stackcount，负责对内核态或者用户态函数发生调用链分析，比方说我们认为某个函数被调用是有问题，想查查到底是哪几个地方大量调用就可以使用这个函数。方向明确的时候，针对具体函数可以做分析 trace，trace函数是多用途函数。它可以用来显示包括：1某个函数被调用的时候，参数是什么？2函数的返回值是什么？3函数的调用链是什么？这个功能对于内存泄漏问题排查会有比较大的帮助。比方说我可以直接同时记录申请内存 \u0026amp; 释放内存的函数，然后查询哪些函数路径里面的内存没被释放掉。当然，这也是需要自己手动去比较的。方向明确的时候，针对具体函数可以做分析 perf：具体的如何用perf做分析的就直接看这个链接好了https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance\n2 针对具体方面的分析 # 2.1 CPU # 2.1.0 关于CPU # CPU和硬件资源直接的管理者是kernel，kernel决定了cpu的调度和状态的切换。这里的状态值得是用户态和内核态，用户态程序进入内核态有两种情况：发起syscall就会显式地进入内核态；如果有缺页中断会隐式地进入内核态。这里面藏着一点，如果有大量的中断，确实可能导致CPU上的进程被打断，在华耀的时候就见过网卡大量中断，中断上半段必须立刻执行从而干扰了进程执行。但是这种情况的确定是明显能从数据当中看出来的，会打断所有的程序。软件发起的中断一般是软中断，而硬件发起的中断是硬中断\n从上面的描述可以看出来，使线程脱离cpu执行的情况有：\n主动脱离，线程阻塞于IO，锁或者主动休眠sleep 被动脱离，线程运行时长超过了调度器分配的时间片，或者高优先的任务抢占。 这种线程的切换实际上要保存包括栈，页表等信息被称为上线问切换。\n2.1.1 CPU分析的方法 # 方法，对cpu做性能分析的方法如此之多，可以分析的指标又如此之多，所以中断关注什么呢？可以看看系统负载是否均衡，cpu是不是调度的均匀：\n工具法：实际上就是可用的工具全用一遍，检查是不是有什么明显的问题。但是这个有个问题就是，工具爆出来的问题可能只是个红鲱鱼，真正的问题不在这里。而且这种排查方式往往占用大量的时间。针对工具法的流程如下，是一个从全程到细节的分析过程： uptime：检查负载平均数来确认cpu负载时随时间上升还是下降，负载平均数超过了cpu数量通常代表cpu饱和 vmstat：每秒运行vmstat，然后检查空余列 mpstat：检查单个热点cpu，挑出来可能的线程拓展性问题 top/prstat：看哪个进程和用户是cpu消耗大户。需要多赘述一句，top命令有很多种显示方法，默认情况下， top 显示单CPU的使用率结果. 在多核心操作系统上，使用shift+i可以让操作系统显示占整个进程的百分比个数。切换模式的结果如下。这引发了一个下面的问题，在云环境下，如果配置k8s的limit为1，那么每时每刻容器里面真正在CPU上面执行的确实只有一个线程（尽管它使用了时间片来显示多个进程/线程在同时运行） Irix mode：进程的CPU使用率是基于单个CPU核心的，所有核心的使用率可以累加，因此可以超过100%。 Solaris mode：进程的CPU使用率是针对整个系统的，不论有多少个CPU核心被使用，最多显示为100%。 pidstat/prstat：把cpu消耗大户分解为用户和系统时间 Perf/dtrace/stap/cpustat:profile 负载特征归纳：这个重点就是分析平均负载；用户时间和系统时间的比例；系统调用频率；中断频率；如果程序花了大量的时间在系统调用中，那么就可以用这个方法来确定到底为什么慢。 profiling：这个就是拿dtrace/perf等方面一点一点去看，究竟哪些path的频率高 优先级调优：这个说白了就是调整nice值，正的nice代表降低进程优先级，而负值代表提高优先级。 2.1.2 CPU分析的工具 # 工具：\nuptime：用来显示系统的平均负载，如果认为是性能不足负载过重，可以用这个来检查。平均负载表示了对cpu资源的需求，通过汇总正在运行的线程数和正在排队等待运行的线程数计算得出。如果平均负载大于CPU数量，那么说明CPU不足以服务线程\nqcraft@BJ-vgdog:~$ uptime\r#最后三个值分别代表1min，5min，15min的平均负载\r16:12:45 up 4 days, 3:22, 2 users, load average: 1.14, 1.65, 1.46 vmstat：\nmpstat: mpstatl报告每个cpu的统计信息，参考这个：https://man7.org/linux/man-pages/man1/mpstat.1.html，列CPU表示cpu号，%usr代表用户态，%sys为内核态，%iowait：io等待，%irq，硬件中断，%soft软件中断，%idle空闲；\nqcraft@BJ-vgdog:~$ mpstat -P ALL 1\rLinux 5.4.0-42-generic (BJ-vgdog) 2022年06月05日 _x86_64_\t(24 CPU)\r16时23分21秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle\r16时23分22秒 all 0.00 0.00 0.08 0.00 0.00 0.00 0.00 0.00 0.00 99.92\r16时23分22秒 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00\r16时23分22秒 1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00\r16时23分22秒 2 0.99 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.01\r16时23分22秒 3 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 ps：这个不用多说\ngdb: 也不用多说\npidstat：这个命令按照进程或者线程数量打印CPU用量，很直接的结果，实际上\ntime \u0026amp; ptime:这个也不用多说了，输出运行用户态时间+sys时间+wallclock时间\n来说说怎么使用bpftrace做分析，\n2.1.3 分析CPU的几种具体方法 # 我们来看下面几种重点的分析案例中的具体手段，注意，这下面都是给出工具，从工具出发的具体手段。这里使用的工具是bpf\n2.1.3.0 通用分析 # 通用分析的时候一般第一步是分析到底是什么问题，一般入手就是两种情况：\n目的非常明确，我知道我想分析的程序是什么，比方说就是仿真的主程序simulator_main跑得慢，那么直接针对性的用pidstat/pstack看花费时间在哪里，进而查询到底是本身在文件系统、io(磁盘，网络)上。还是单纯的cpu没抢到。 我不知道我要分析什么，我需要首先查询负载，检查每个cpu的状态mpstat。检查io的状态。如果能找到可疑的程序，那么检查这个程序的耗时等东西。 通用分析的工具包括CPU分析的工具里面提到的东西，和下面的bpf的工具。\nexecsnoop：这个工具会列出来新创建出来的进程，分析负载方面的问题。试想这样子的场景，pod启动失败，对应于一个docker进程，根据日志/启动时间+execsnoop的日志我们就能找到对应的进程号，然后就可以不断的看top里面该进程的状态是D？S？R？一个良好的起点就出现了。\ngdb：gdb \u0026ndash;q \u0026ndash;n \u0026ndash;ex bt \u0026ndash;batch \u0026ndash;pid xxx 使用这个命令打印出栈在干啥，有的时候发现进程不知道在干啥就可以打印出来具体的栈，看看到底在干啥\nexitsnoop：这个工具可以列出来pid，ppid运行时长和退出码，分析进程之间的关系和它们所耗费的时间的时候是个非常有效的提示点\nopensnoop：这个工具用来分析\nprofile：和perf一样，直接进行采样，设想这样的用法：我们使用profile发现某个函数比方说~SIM_CACHE花了大量时间，那么到底是跑的慢还是跑的次数很多呢？调用前面的functount算下调用多少次，就可以排查了。profile会以49hz的频率记录用户态和内核态的调用栈。除了在不知道咋回事的时候用profile看调用栈，使用profile也可以针对一两个函数做分析，比方说想分析malloc都是哪里申请的，那就调用profile查看到malloc的调用栈啥的。\noffcputime：offcputime会打印出来进程阻塞时候的栈，或者说调用链。我们可以用火焰图进行分析。这里很有用的是火焰图片svg，可以点击进去继续进行分析\noffcputime -f -p $(pgrep mysqld) 10 \u0026gt; out.offcputime.txt flamegraph.pl --width=800 --color=io --title=\u0026#34;Off-CPU Time Flame Graph\u0026#34; \\ --countname=us \u0026lt; out.offcputime.txt \u0026gt; out.offcputim.svg /opt/homebrew/Cellar/flamegraph/1.0_1/bin/flamegraph.pl --width=800 --color=io --title=\u0026#34;Off-CPU Time Flame Graph\u0026#34; --countname=us \u0026lt; out.offcputime.txt \u0026gt; out.offcputim.svg 2.1.3.1 分析锁 # 一般认为锁是导致程序睡眠的原因的话属于大部分问题分析的最后一步了，这种锁的争用要么及其冥想，要么很令人迷惑所幸bpf里面也有分析的软件\npmlock：会显示出来调用锁的路径和等待的延迟，输出的格式一般是：先是锁的地址，然后具体的调用路径，最后是等待的时间\npmheld：显示某些路径持有锁和持有的时间\ndeadlock：显示死锁，这个说起来是显示锁的调用顺序\n2.1.3.2 分析负载或者进程/线程睡眠 # 线程/进程睡眠的时间原因就几种：\n负载重，进程优先级不高，被其它线程抢占了。可以看看uptime，runqlat，runqlen 本身代码的问题，有网络io/很重的磁盘io。这个针对具体进程分析cpudist 系统有大量的磁盘io/中断，强行打断了。调用mpstat看irqs，或者看下一小节。 确认是不是负载重的问题，分析可以使用下面的工具进行分析。\nrunqlat：当cpu负载很重，我们想证明这一点的时候，除了使用uptime的后三列来论证。也可以使用该工具，该工具统计的信息是每个线程（任务）等待CPU的耗时。这个工具有什么用呢？我们都知道编译的时候是clang多线程编译的，如果编译的线程数量设置的不对，可能就会发生资源利用不充分的情况。CPU超载的情况下就会发生下图，这样子就是明显的离群点。当然使用sar也能发现这样子的问题。下面的图片显示了线程等待时间的微秒是多少，可以看到0-\u0026gt;15s有很多，16384 -\u0026gt; 32767有一个明显的离群点，这就证明了配置的错误，或者说是性能不足。\n# runqlat\rTracing run queue latency... Hit Ctrl-C to end.\r^C\rusecs : count distribution\r0 -\u0026gt; 1 : 233 |*********** |\r2 -\u0026gt; 3 : 742 |************************************ |\r4 -\u0026gt; 7 : 203 |********** |\r8 -\u0026gt; 15 : 173 |******** |\r16 -\u0026gt; 31 : 24 |* |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 30 |* |\r128 -\u0026gt; 255 : 6 | |\r256 -\u0026gt; 511 : 3 | |\r512 -\u0026gt; 1023 : 5 | |\r1024 -\u0026gt; 2047 : 27 |* |\r2048 -\u0026gt; 4095 : 30 |* |\r4096 -\u0026gt; 8191 : 20 | |\r8192 -\u0026gt; 16383 : 29 |* |\r16384 -\u0026gt; 32767 : 809 |****************************************|\r32768 -\u0026gt; 65535 : 64 |*** | runqlen：另一个显示性能是否繁忙的工具，显示有多少个线程在等待运行，显示等待队列的信息，同样可以确定负载。但是显示运行等待队列并不如显示运行等待时间靠谱，等待时间是一等指标，等待队列是二等指标，想想看超市排队的时候排队时间是关注重点，排队人数是稍次级的工具。那么为什么需要runqlen呢？因为它可以从侧面反映问题，而且它对性能造成的影响低。\ncpudist：这个工具的作用是统计每次线程唤醒后在cpu上执行的时长分布，它可以针对具体的进程执行分析，只需要制定pid。我们实际上是希望某些程序能够尽量多占用cpu的，这个工具不用直接去查/proc/[pid]/stat里面的信息。设想我们某天保存了一个仿真测试正常执行的oncpu分布，过了两天仿真测试忽然变慢了，我们可以对比下看看到底是哪里的变化。下面是我在台式机上做分析的时候给出的统计，可以看到每个线程执行的时间很短。但整体还是一个正态分布的效果。\nroot@BJ-vgdog:/# /usr/share/bcc/tools/cpudist 10 1\rTracing on-CPU time... Hit Ctrl-C to end.\rusecs : count distribution\r0 -\u0026gt; 1 : 1095 |** |\r2 -\u0026gt; 3 : 5130 |********** |\r4 -\u0026gt; 7 : 6286 |************ |\r8 -\u0026gt; 15 : 7448 |************** |\r16 -\u0026gt; 31 : 20146 |****************************************|\r32 -\u0026gt; 63 : 7442 |************** |\r64 -\u0026gt; 127 : 2461 |**** |\r128 -\u0026gt; 255 : 527 |* |\r256 -\u0026gt; 511 : 152 | |\r512 -\u0026gt; 1023 : 112 | |\r1024 -\u0026gt; 2047 : 59 | |\r2048 -\u0026gt; 4095 : 40 | |\r4096 -\u0026gt; 8191 : 47 | |\r8192 -\u0026gt; 16383 : 28 | |\rroot@BJ-vgdog:/# 对于任务很重的情况，可能会有线程超过了CPU调度器分配的运行失常，从而导致了被动的上下文切换的情况，下面的图有非常明显的离群点，4-15ms，\nroot@BJ-vgdog:/# /usr/share/bcc/tools/cpudist 10 1\rTracing on-CPU time... Hit Ctrl-C to end.\rusecs : count distribution\r0 -\u0026gt; 1 : 1095 |****************************************|\r2 -\u0026gt; 3 : 5130 |**** |\r4 -\u0026gt; 7 : 6286 |***************************** |\r8 -\u0026gt; 15 : 7448 |******************************* |\r16 -\u0026gt; 31 : 20146 |******** |\r32 -\u0026gt; 63 : 7442 |****** |\r64 -\u0026gt; 127 : 2461 |**** |\r128 -\u0026gt; 255 : 527 |* |\rroot@BJ-vgdog:/#\nthreaded：很多时候，我们分析的软件时多线程的，那么这些线程多久使用一次cpu就需要采样分析，使用threaded.bt就能做这样子的事情\noffcputime：虽然上面已经说过一次了，不过还是要专门提一下offcputime因为它确实好用，offcputime会统计并输出线程offcpu的原因和时间，换言之会给出来栈，因此可以分析为什么线程没在cpu上运行，这个工具可以用来分析为什么线程没在cpu上运行。如果是有睡眠或者syscall的原因可以用这个看出来。\n2.1.3.3 分析软中断soft interrupt（syscall）/和硬中断 # 一般直观的可以用pstack或者软中断上去看下线程在干什么，然后调用相应的工具。\nsyscount：这个工具用来调查syscall占用时间长的问题，它会打印出来系统调用的排行表。然后我们可以用profile发现到底是什么慢了 softirqs \u0026amp; hardirqs：mpstat工具用%soft \u0026amp; %irq来显示软中断，硬中断，也可以用这两个工具来做分析 argdist： trace： bpftrace： 2.2 内存 # 对于内存方面，我发现有些人认识并不清楚，性能差了就往缺页终端，内存swap了方面去猜测，这种如果是内存引起的性能问题是需要明确数据证明的，不能靠猜测。按照bpf之巅的方法，一般排查流程是：\n实际上这段时间我们遇到内存的问题并不多，一次是内存泄露的排查，最后用memleak查了出来；另一次是没有内存泄露，用memleak确定了一下，最后强制malloc把释放的内存还给了操作系统解决。\n2.2.1 内存排查的工具 # 工具还是以bpf的为主：\noomkill，用来追踪是什么程序需要内存从而触发的oom kill，和谁被oomkill掉了。同时还会显示当前系统的负载 memleak，用来排查没释放的内存，但这个工具依然只是调试工具，可能会导致性能降低到十分之一的级别 mmapsnoop，跟踪mmap系统调用， brkstack，跟踪brk系统调用 faults，跟踪缺页中断触发时候的系统路径，会打印出来调用栈。这个时候可以用来解释进程内存的增长。这个是有火焰图可以用来统计具体是哪里触发的。 swapin 2.3 文件系统 # 当问题出到文件系统和IO的时候，问题往往就不是那么好分析了。需要开发人员对于操作系统有基本的认识：\n一般来说，应用程序向文件系统发送的请求是逻辑IO，如果这些逻辑IO最终由磁盘设备服务，那么就会变成物理IO\u0026mdash;应用程序通过posxi到系统库，然后到系统调用。到了系统调用之后要么直接裸io，要么走文件系统io:用vfs一点一点到磁盘设备。linux为了应对性能的挑战，启用了多种缓存技术这些缓存包括：\n页缓存：页缓存是缓存的虚拟内存页，包括文件的内容和IO穿冲的信息，简单来说就是page cache。注意linux支持写回模式处理文件系统写操作，仙还村脏页，再写回，避免阻塞IO inode缓存：索引节点是文件系统用来描述所需对象的一个数据结构体，linux维持这个是因为检查权限或者读取其他数据的时候，这个经常用到 目录缓存：dcache，这个缓存了从目录元素名到VFS inode之间的映射关系，这可以提高路径名查找的速度。 针对文件系统，我们通常需要解答很多细节的问题，比方说：\n发往文件系统的请求有哪些？按照类型计数 文件系统的读请求多少？ 有多少写IO是同步请求？ 文件系统的延迟来自哪里？磁盘？调用路径？还是锁？ 文件系统延迟的分布情况如何？ Dcache和Icache的命中率和命空率是多少？ 下面给一种通用的IO排查方法：\n首先识别挂载了哪些盘，df/fdisk啥的 检查文件系统的容量，看看磁盘是不是满了。之后找个空闲的机器看看IO Usage多少 使用opensnoop查看正在打开那些文件，使用filelife查找是否存在短期稳健 查找非常慢的文件系统操作，按照进程和文件名观察，可以用ext4slower,btrfsslower,zfsslower 检查文件系统的延迟分布，比方说ext4dist，btrfsdist，zfsdist等 检查页缓存命中率 使用vfsstat比较逻辑IO和物理IO的命中率和数量的区别 可用的BPF工具：\n因为linux传统工具分析文件系统的不多，所以我直接写BPF工具了\nopensnoop，这个就不多赘述了\nstatsnoop，stat用来获取文件信息，这个东西过多也可能造成性能问题\nfmapfault：用来跟踪内存映射文件的时候的缺页错误\nfilelife：显示文件的生命周期\nvfsstat：这个是针对VFS调用，用来统计VFS调用，比方说读、写、创建、打开、的次数。文件打开是相对较慢的操作，需要进行路径查找，创建文件描述符啥的\nvfscount：这个是用来显示vfs函数的次数的\nvfssize：用直方图的方式统计VFS读取尺寸和写入尺寸，并且按照进程名，VFS文件名和操作类型分类\nfileslower：显示延迟超过某个阈值的同步模式文件读取和写入，下面的命令可以看到写入了大量的源代码文件，其延迟非常恐怖，竟然达到了200甚至4000ms的级别\nroot@hangzhou-arm03:/usr/share/bcc/tools# ./fileslower -p 24959\rTracing sync read/writes slower than 10 ms\rTIME(s) COMM TID D BYTES LAT(ms) FILENAME\r0.261 skyframe-evalu 18233 W 1535 200.59 central_b_splines.svg\r0.261 skyframe-evalu 18248 W 4279 201.55 AccessKey.cpp\r0.464 skyframe-evalu 18233 W 1559 203.51 central_b_splines.svg\r0.464 skyframe-evalu 18248 W 989 203.48 AttachGroupPolicyRequest.cpp\r0.668 skyframe-evalu 18233 W 1606 203.55 central_b_splines.svg\r0.668 skyframe-evalu 18248 W 1283 203.42 ContextKeyTypeEnum.cpp\r4.968 skyframe-evalu 18233 W 1521 4299.95 central_b_splines.svg\r4.976 skyframe-evalu 18248 W 3424 4307.99 ContextKeyTypeEnum.cpp\r5.176 skyframe-evalu 18233 W 466 201.83 differential_entropy.svg\r5.184 skyframe-evalu 18248 W 1612 202.68 GetPolicyVersionResult.cpp\r5.380 skyframe-evalu 18233 W 3936 202.40 digamma____float128.svg\r5.388 skyframe-evalu 18248 W 4364 202.50 InstanceProfile.cpp filetop，关注读写最频繁的文件，这个可以用来找热点文件\nwritesync\ncachestat：用来显示页缓存的命中率，一般来说页缓存命中率应该很高才对，如果命中率能达到100%，那么这个效率就很高了\nwriteback：显示页缓存的协会操作，包括：页扫描的时间，脏页写入磁盘的时间，写回时间的类型，持续的时间\ndcstat和dcsnoop\nxfsslower:跟踪xfs文件系统操作，对超过阈值的慢速操作打印出来每个事件的详细信息，跟踪的操作有read/write/open/fsync\nxfsdist：以直方图的方式，统计操作的延迟read/write/open/fsync\next4dist\next4slower:用来追踪ext4比较慢的操作\nroot@hangzhou-arm03:/usr/share/bcc/tools# ./ext4slower\rTracing ext4 operations slower than 10 ms\rTIME COMM PID T BYTES OFF_KB LAT(ms) FILENAME\r13:37:03 skyframe-evalu 27776 W 8192 110456 203.52 boost_1_76_0.tar.gz\r13:37:03 skyframe-evalu 26315 W 6929 1 203.96 Recommendation.h\r13:37:03 skyframe-evalu 25278 W 508 0 200.85 DescribeMapRequest.cpp\r13:37:03 skyframe-evalu 24408 W 6204 16 206.56 brent_minima.html\r13:37:03 skyframe-evalu 25278 W 2259 5 201.86 test_gcd.cpp\r13:37:03 skyframe-evalu 27439 W 8192 19 201.58 reverse_128.hpp\r13:37:03 skyframe-evalu 27439 W 2391 0 204.91 test_read_format_zip_encryption_\r13:37:03 skyframe-evalu 24959 W 2575 0 206.25 DeleteLogGroupRequest.h\r13:37:03 skyframe-evalu 27439 W 5428 0 206.37 UpdateVpcLinkRequest.h\r13:37:03 skyframe-evalu 26315 W 8192 427 207.77 pcl_horz_large_pos.bmp\r13:37:03 skyframe-evalu 28681 W 8192 86528 207.81 boost_1_76_0.tar.gz\r13:37:03 skyframe-evalu 26315 W 8192 3744 207.81 libxml2-2.9.12.tar.gz\r13:37:03 skyframe-evalu 27439 W 8192 20592 203.83 pcl-1d3622c1e624994bc013e3e66bc5\r13:37:03 skyframe-evalu 26315 W 884 0 202.81 bind.hpp\r13:37:03 skyframe-evalu 29981 W 2898 26 203.15 tokenizer.cc\r13:37:03 skyframe-evalu 24959 W 3825 296 207.59 hypergeometric_1f1_log_large.ipp\r13:37:03 skyframe-evalu 26315 W 422 0 202.99 UntagResourceRequest.h\r13:37:03 skyframe-evalu 25278 W 587 0 202.62 GetMapGlyphsRequest.cpp\r13:37:03 skyframe-evalu 24408 W 4754 90 207.67 brent_minima.html\r13:37:03 skyframe-evalu 25278 W 715 0 202.98 test_kn.cpp\r13:37:03 skyframe-evalu 27439 W 8192 7 207.62 reverse_256.hpp\r13:37:03 skyframe-evalu 27439 W 391 0 207.12 test_read_format_zip_filename_cp\r13:37:03 skyframe-evalu 24959 W 5520 0 207.10 DescribeLogGroupsRequest.h\r13:37:03 skyframe-evalu 26315 W 8192 3816 207.81 libxml2-2.9.12.tar.gz\r13:37:03 skyframe-evalu 27439 W 8192 20656 203.84 pcl-1d3622c1e624994bc013e3e66bc5\r13:37:08 skyframe-evalu 26315 W 8192 493 4715.70 pcl_horz_large_pos.bmp\r13:37:08 skyframe-evalu 27439 W 4462 3 4723.10 APIGatewayClient.cpp\r13:37:08 skyframe-evalu 28681 W 8192 86600 4723.81 boost_1_76_0.tar.gz\r13:37:08 skyframe-evalu 26315 W 8192 3824 4515.97 libxml2-2.9.12.tar.gz icstat：跟踪inode缓存的查找操作\nbufgrow：查看换从缓存的内部情况，展示页缓存里面的块也增长情况\n2.4 IO # 我个人对io的认识并不深刻，前几天实际上就分析遇到过xavier（arm64）机器io占用极高的问题，大概四个核的iowait高达90%，但是无论使用iotop还是iftop都没看到什么可疑的东西。最后我重启了系统，恢复正常。但是这个事情算是无疾而终，实际上我后来回想出问题的地方，觉得我的分析有两大谬误：\niowait高是起因还是结果？如何分析这个事情？iowait高智能说明操作延时很高 磁盘或者网络io只是外因，重点应该分析文件系统，只关注磁盘/网络往往是错误的。 2.3.1 IO的基本知识 # 这里的IO和文件系统拆开说了，我们只说IO了。IO操作在块IO层会进入一个队列，由调度器进行调度，传统调度器使用一个全局共享请求队列，这个队列有单独的锁保护，在高IO的情况下就有性能瓶颈。新的IO调度器拆分为不同的CPU不同的队列，但是总体来讲，等待时长是在块服务层调度器队列和设备分发队列中等待的时间。服务时长是从设备发布请求到请求完成的时间。\n现在的IO设备往往自己还有一个缓存，所以这个是时候的问题分析就变得复杂，总之\n所以实际上我们分析的事情应该针对\n2.3.2 IO分析的方法 # 分析的时候一般需要先分析一些基础信息：\n操作频率和操作类型 文件io吞吐量：需要考虑文件系统缓存有多大？ 文件io大小 读写比例 同步读写比例 文件随机读写 2.3.3 磁盘io分析的工具 # 传统工具部分，观察\niostat，最常用的工具一般是iostat -dxz 1使用，其中rrqm/s是每秒进入对了和被合并的读请求，wrqm/s是每秒进入对了和被合并的写请求。当系统发现一个新的io读写请求和另一个io读写请求位置相邻的时候，两个io就会被合并。r/s和w/s是合并一哦呼每秒完成的读或者写请求。这里面对于同步io，我们要管线r_await或者w_await，await是平均IO请求市场，也就是设备的响应时间，包括在驱动队列中的等待时间和设备的实际响应时长，单位为ms\nDevice r/s w/s rkB/s wkB/s rrqm/s wrqm/s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %util\rloop0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 2.50 0.00 0.00 0.00\rvda 6.61 1021.96 136.05 25014.27 0.00 2482.40 0.06 70.84 0.43 0.41 0.37 20.58 24.48 0.05 4.86\rDevice r/s w/s rkB/s wkB/s rrqm/s wrqm/s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %util\rvda 1.00 8.00 8.00 360.00 0.00 82.00 0.00 91.11 0.00 0.00 0.00 8.00 45.00 0.00 0.00 blktrace\n上面都是传统工具，我们重点看bpf的工具了，针对磁盘IO发生的性能诊断工具其应用的层次如下\nbiolatency。该工具用直方图统计块IO设备的延迟信息，这里的设备延迟是从向设备发出请求到请求完成的全部时间，包括了在操作系统内部的派对时间。给一个简单例子，下面按照10s来统计写入./biolatency -Q -F 10，这个会包括操作系统的排队时间（-Q，A -Q option can be used to include time queued in the kernel.），按照IO操作的类型区分（-F），从而区分同步写等flag的区别。下面的图片，同步写有明显的双峰\nroot@hangzhou-arm03:/usr/share/bcc/tools# ./biolatency -Q -F 10\rTracing block device I/O... Hit Ctrl-C to end.\rflags = Write\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 0 | |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 0 | |\r128 -\u0026gt; 255 : 18 |****** |\r256 -\u0026gt; 511 : 35 |*********** |\r512 -\u0026gt; 1023 : 111 |************************************* |\r1024 -\u0026gt; 2047 : 120 |****************************************|\r2048 -\u0026gt; 4095 : 67 |********************** |\r4096 -\u0026gt; 8191 : 9 |*** |\rflags = Sync-Write\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 0 | |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 0 | |\r128 -\u0026gt; 255 : 10 |****************************************|\r256 -\u0026gt; 511 : 1 |**** |\r512 -\u0026gt; 1023 : 0 | |\r1024 -\u0026gt; 2047 : 4 |**************** |\rflags = NoMerge-Write\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 0 | |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 0 | |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 0 | |\r512 -\u0026gt; 1023 : 20 |******************************** |\r1024 -\u0026gt; 2047 : 25 |****************************************|\r2048 -\u0026gt; 4095 : 9 |************** |\r4096 -\u0026gt; 8191 : 1 |* |\rflags = NoMerge-Sync-Write\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 0 | |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 0 | |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 0 | |\r512 -\u0026gt; 1023 : 19 |****************************************|\r1024 -\u0026gt; 2047 : 18 |************************************* | biosnoop，biosnoop用来针对每个磁盘IO打印一行信息，可以方便地确定写入的延迟。下面的例子发现一只在写入jbd2/vda3-8的进程的写操作。\n30.954642 jbd2/vda3-8 471 vda W 17496216 65536 3.16\r30.954707 jbd2/vda3-8 471 vda W 17499928 65536 2.30\r30.954861 jbd2/vda3-8 471 vda W 17500056 65536 2.43\r30.954873 jbd2/vda3-8 471 vda W 17496344 65536 3.38 biotop，可以认为是iotop的现代版本，用来显示正在操作的io行为\nbitesize\nseeksize\nbiopattern\nbiostacks：跟踪完整io栈，一些后台进程可以被追踪\nbioerr\niosched：跟踪io请求在io调度器里面排队的时间，并且安装调度器名称分组显示\nscsilatency：跟踪scsi命令以及对应的延迟分布的工具\nnvmelatency：\n2.5 网络 # 或许有点奇怪，实际上网络的问题我查的不多，因为很多时候网络的问题都是直接看统计报表即可\n常用工具\nss Ip 2.5 安全 # 作为新兴工具，bpf在安全方面还是很先进的。bpf可以协助检查正在执行进程，检查网络连接和系统权限，检查正在被调用系统内核。此外bpf也可以用来追踪检查软件漏洞\n常用工具：\nelfsnoop modsnoop bashreadline：跟踪bash交互的命令 shellsnoop：镜像另一个shell会话的输出 ttysnoop eperm：舰艇permission失败，但是在具有高IO的系统里，开销可能会很高 tcpreset：跟踪tcp发送重置数据包 capable：检查线程能力模型（参考零信任学习）的进程，会显示安全能力号，安全能力代码名称， 2 性能分析的案例和常见的调优手段 # 2.1 git慢的问题排查 # 我为啥写这个事情呢？因为这个过程当中我一开始以为是性能问题，后来发现似乎和性能无关，最后还是发现性能问题。这个属于第二类性能问题，即一开始没有明确目标，需要先找到问题是啥然后再解决。\n2022年6月的时候，我们的gitlab出现两个问题：1 push代码忽然很慢，2 提交代码经常报错500\n这里面两个问题同时出现，以至于我们以为这是同一个问题，实际上是两个问题，提交代码报错500，经过追踪是gitlab内部ruby报的错误。然后开始查push慢的问题，一开始以为是gitaly和gitlab-workhorse的东西（这两个干啥的可以直接搜索下），在机器负载重的情况下这两个占用cpu能占到5个cpu，负载重的时候uptime显示的负载能到60多（我们机器才32c），但是后来发现及时是负载清的时候，push代码也很慢，Nmmmm，换个思路。排查下push代码的时候发生了什么\n启动execsnoop监控启动的进程和参数，exec log可以清晰的看到参数和具体启动的时间戳，看了下发现似乎29307也就是git rev-list花了好长的时间啊，那么到底是这样子吗？还是说启动的早，退出的早？\nexec.log 10:37:21 git 28706 2005 0 /opt/gitlab/embedded/bin/git -c core.fsyncObjectFiles=true -c gc.auto=0 -c core.autocrlf=input -c core.alternateRefsCommand=exit 0 # -c receive.fsckObjects=true -c receive.fsck.badTimezone=ignore -c receive.advertisePushOptions=true -c receive.hideRefs=refs/environments/ -c receive.hideRefs=refs/keep-around/ -c ... 10:37:33 git 29306 28706 0 /opt/gitlab/embedded/libexec/git-core/git unpack-objects --pack_header=2,5 --strict=badtimezone=ignore 10:37:33 ps 29307 1975 0 /bin/ps -o rss= -p 1975 #为什么你这个慢？你到底干了什么？这时候它还是个黑盒 10:37:33 git 29309 28706 0 /opt/gitlab/embedded/libexec/git-core/git rev-list --objects --stdin --not --all --quiet --alternate-refs --progress=Checking connectivity 10:37:57 pre-receive 30076 28706 0 /opt/gitlab/embedded/service/gitaly-ruby/git-hooks/pre-receive 10:37:57 gitaly-hooks 30076 28706 0 /opt/gitlab/embedded/bin/gitaly-hooks pre-receive 10:37:58 update 30116 28706 0 /opt/gitlab/embedded/service/gitaly-ruby/git-hooks/update refs/heads/x x x x x/y y y y y y/z z z z z 051676603877ed329f2e525227dc46a71ff4987f 2e2d1501e78d1ac69cc1072d4d9dd5a14e245fdf 启动exitsnoop监控启动的进程运行的时常，发现这个29309确实很慢，花了23.36s，那么它干啥了呢？\nexit.log 10:37:33.790 git 29306 28706 29306 0.03 0 10:37:57.156 git 29309 28706 29309 23.36 0 10:37:58.384 gitaly-hooks 30076 28706 30076 1.23 0 10:37:58.395 gitaly-hooks 30116 28706 30116 0.01 0 10:37:58.474 git 28706 2005 28706 36.70 0 启动opensnoop看看开了哪些文件，我猜测git就是个版本管理（文件管理）所以超时可能和文件有关。打开以后一看，时间非常均匀的分布在遍历gitlab的objects目录下，它检索了所有的文件，使用ls -laR ｜ wc -l看看多少个文件，哇，286313个，看起来是文件太多导致的，奇怪了git gc哪里去了？\n我们的代码库曾经出现过几次bad object大型事故，因此直接执行git gc会出错，会不会是这个原因导致文件越来越多，越来越慢呢？首先执行fsck找到broken link，然后删除掉这些坏掉的ref，大部分是keep-around/xxxxxx，然后执行git gc，看了下文件数量减少到3万多，重新git rev-list，时间减少为4s，bingo\n# --name-objects是需要的，找到broken的ref git fsck --full --name-objects #多次操作 git update-ref -d broken_ref_0 git update-ref -d broken_ref_1 git update-ref -d broken_ref_3 ... # 最后操作 git gc 2.2 cassandra连接内存泄露 # 这几天在排查仿真运行过慢的时候，发现我们的一部分服务器会出现严重的内存的泄露，这些服务的共同点都是连接cassandra服务器。然后开始协助排查，本来想祭出ebpf排查，发现线上环境的linux kernel是3.10.xxx，是个阿里云的内部kernel，装不了perf也装不了ebpf，Nmmmm，本地起了个虚拟机，然后同事写了个MR加了一个test发送数据来测试，观测到明显的内存增长。这时候祭出ebpf memleak：\n#这个路径是我在宿主机用源码装的memleak路径\r# -a, --show-allocs show allocation addresses and sizes as well as callstacks，显示调用次数，申请的大小，返回的地址和调用栈\r# -p 指定pid，就是那个79xxxx\r# 最后的500，interval in seconds to print outstanding allocations，就是显示malloc 和 free没有抵消掉的地址，\r/usr/share/bcc/tools/memleak -ap 79xxxx 500 使用ebpf的memleak的时候要注意两点：\nrecord一次的时间要比较长，最好保证一个测试连接的完整完成，从而去除那些智能指针引起的内存泄漏错误判断，我这里设置的是500，bazel test small size 300 s，这里放了500s record的时候，最好加上-a来显示call stack，会有很大帮助 最后发现Session::prepare大量调用malloc没释放，按照这个函数的名字找了一下我们调用cassandra sdk的代码，发现里面犯了一个经典的内存错误，一个变量存储一块必须被释放的内存地址，这个变量后来又直接赋值了新的内存地址，没释放这个老得内存，总之就是申请的内存地址直接覆盖了，然后第一次申请的内存没释放导致的。\n36696 bytes in 1529 allocations from stack xxxxx datastax::internal::core::Session::prepare(char const*, unsigned long)+0x219 [libcassandra.so.2.14.1] 210744 bytes in 8781 allocations from stack xxxxx datastax::internal::core::Session::prepare(char const*, unsigned long)+0x219 [libcassandra.so.2.14.1] 600000 bytes in 25000 allocations from stack xxxxx datastax::internal::core::SimpleDataTypeCache::by_value_type(unsigned short)+0x3f [libcassandra.so.2.14.1] 3000000 bytes in 12500 allocations from stack datastax::internal::core::Session::prepare(char const*, unsigned long)+0x4f [libcassandra.so.2.14.1] 0x000000000000005f [unknown] 0x65766571204f544e [unknown] 3299736 bytes in 12499 allocations from stack xxxxx datastax::internal::core::Session::prepare(char const*, unsigned long)+0x1ac [libcassandra.so.2.14.1] 0x000000000000005f [unknown] 0x00007fdc600008d0 [unknown] 9400000 bytes in 12500 allocations from stack 2.3 crypto_c++ 慢 # 事情的起因是这几天（在美团的时候）在开发给网关用的auth sdk，功能性测试通过了，然后给出性能测试时候发现性能低的令人发指，数据如下：\nCrypto++算法 签发QPS 验签QPS HMAC 15475 ECDSA 358 RSA 206 我本来是想用perf的，但是不知道为啥一直收不到数据，就切换成了gperftools。对签名/验签算法优化是不能更进一步了，因此注释掉代码里面的编码解码部分，然后用gbenchmark测试，发现结果为编码需要44054ns。我傻了，这也太长了！\n---------------------------------------------------------------------\rBenchmark Time CPU Iterations\r---------------------------------------------------------------------\rBM_MultiThreaded/threads:1 44054 ns 43773 ns 15721\rLoad Average: 0.31, 0.12, 0.03\r---------------------------------------------------------------------\rBenchmark Time CPU Iterations\r---------------------------------------------------------------------\rBM_MultiThreaded/threads:1 28770 ns 28596 ns 24289 使用gperftool分析调用时长，发现cryptopp库的base64编解码性能太差了！所以再次修改base64/base64 url safe编码的实现，从新测试性能得到上面第二个benchamark结果。\nTotal: 85 samples\r/*使用了过多的临时对象并释放，对内存消耗比较大 */\r7 8.2% 8.2% 7 8.2% _int_free //整数释放,具体的调用链\r6 7.1% 22.4% 6 7.1% _int_malloc //整数申请\r5 5.9% 28.2% 11 12.9% __GI___libc_malloc\r/* cryptopp库性能太低，消耗太大直接拖慢了性能 */\r4 4.7% 38.8% 7 8.2% CryptoPP::BaseN_Encoder::Put2\r2 2.4% 61.2% 2 2.4% CryptoPP::AlgorithmParametersTemplate::~AlgorithmParametersTemplate\r1 1.2% 75.3% 2 2.4% CryptoPP::Filter::AttachedTransformation\r1 1.2% 76.5% 1 1.2% CryptoPP::SecBlock::New\r1 1.2% 77.6% 1 1.2% CryptoPP::StringSinkTemplate::Put2\r1 1.2% 78.8% 1 1.2% CryptoPP::member_ptr::get\r1 1.2% 94.1% 1 1.2% boost::any_cast\r1 1.2% 96.5% 1 1.2% operator delete 再次使用gperf分析得到：\nTotal: 28 samples\r2 7.1% 7.1% 2 7.1% _int_free\r2 7.1% 14.3% 2 7.1% _int_malloc\r2 7.1% 21.4% 4 14.3% std::unique_ptr::reset\r1 3.6% 25.0% 4 14.3% AuthBasicClaim::AuthBasicClaim\r1 3.6% 28.6% 1 3.6% AuthBasicClaim::InputParamType\r1 3.6% 32.1% 5 17.9% AuthClaim::AuthClaim@684c54\r1 3.6% 35.7% 1 3.6% AuthClaim::operator\u0026lt;\r1 3.6% 39.3% 1 3.6% AuthToken::SetAud\r1 3.6% 42.9% 3 10.7% __GI___libc_malloc\r1 3.6% 46.4% 1 3.6% __gnu_cxx::__normal_iterator::operator++\r1 3.6% 50.0% 1 3.6% __gnu_cxx::__ops::_Iter_equals_val::operator\r1 3.6% 53.6% 1 3.6% __gnu_cxx::operator!=\r1 3.6% 57.1% 1 3.6% std::_Head_base::_M_head\r1 3.6% 60.7% 5 17.9% std::_Rb_tree::_M_create_node\r1 3.6% 64.3% 8 28.6% std::_Rb_tree::_M_insert_unique\r1 3.6% 67.9% 1 3.6% std::_Tuple_impl::_Tuple_impl\r1 3.6% 71.4% 3 10.7% std::__find_if\r1 3.6% 75.0% 1 3.6% std::allocator_traits::select_on_container_copy_construction\r1 3.6% 78.6% 1 3.6% std::forward\r1 3.6% 82.1% 2 7.1% std::get\r1 3.6% 85.7% 2 7.1% std::replace\r1 3.6% 89.3% 1 3.6% std::string::assign\r1 3.6% 92.9% 1 3.6% std::swap\r1 3.6% 96.4% 2 7.1% std::unique_ptr::operator bool\r1 3.6% 100.0% 2 7.1% std::unique_ptr::unique_ptr\r0 0.0% 100.0% 3 10.7% AuthBasicClaim::AuthBasicClaim@68872c 优化之后的sample结果，有大量的内存申请和释放，这很正常，内部编码没开启优化，有大量的临时变量分配之后再释放。修改成O3级别的优化，再benchmark一次看下\n---------------------------------------------------------------------\rBenchmark Time CPU Iterations\r---------------------------------------------------------------------\rBM_MultiThreaded/threads:1 9402 ns 9348 ns 74714 还有一些问题，比方说使用shared_ptr从而避免申请释放内存，会不会比unique_ptr的效果好呢？这个优化以后发现性能提高了1/20，算是比较小就暂时不再考虑了。\n2.4 分析git仓库corrupt问题 # 仓库经常性的崩溃，我目前有一个怀疑这是个by design git corrupted issue，我查明白之后会总结线索\n2.5 gitlab runner崩溃问题 # 有一天我们的gitlab runner经常莫名其妙的被unregistered，从具体的操作来看就是runner自己cancel了自己的pod，奇特！简单看了下syslog发现提示探活失败\nApr 13 23:23:57 ack-ci-172 kubelet: E0413 23:23:57.435661 1786 remote_runtime.go:394] \u0026#34;ExecSync cmd from runtime service failed\u0026#34; err=\u0026#34;rpc error: code = DeadlineExceeded desc = context deadline exceeded\u0026#34; containerID=\u0026#34;b7afd8d170b2542888f710fce5f6f994da5c40fdb9d943c0d779058250b49415\u0026#34; cmd=[/usr/bin/pgrep gitlab.*runner] ... 莫名其妙，感觉不太正常重新开始检查，IT的同学给了一个探活超时的issue，感觉有点可能，到宿主机上开始找相关信息，dmesg没有关键信息，然后如下：！四核cpu负载高出来这么多！太tm离谱了\n[root@ack-ci-172 ~]# uptime 00:30:11 up 1:49, 1 user, load average: 24.28, 22.19, 21.74 [root@ack-ci-172 ~]# cat /proc/cpuinfo| grep \u0026#34;processor\u0026#34;| wc -l 4 [root@ack-ci-172 ~]# 直接关闭\n2.6 Buildfarm Worker 构建问题分析 # CI后台编译服务性能下降，机器并没有减配，但是速度确实减慢了，找了一个满负载的机器，buildfarm-worker-868bs（100%功率运转），先把环境装上\n[root@ack-ci-172 ~]# lsb_release -a LSB Version:\t:core-4.1-amd64:core-4.1-noarch Distributor ID:\tCentOS Description:\tCentOS Linux release 7.9.2009 (Core) Release:\t7.9.2009 Codename:\tCore [root@ack-ci-172 ~]# uname -a Linux ack-ci-172.20.6.26-online-buildfarm-worker 3.10.0-1160.76.1.el7.x86_64 #1 SMP Wed Aug 10 16:21:17 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux [root@ack-ci-172 ~]# yum -y install bcc-tools vmstat的结果显示还好，但是看clang有比较明显的非自愿切换。做出猜测，是不是clang确实编译速度减慢了？clang被抢占是直接原因，或者说也还只是结果，而不是根本原因\n[root@ack-ci-172 ~]# vmstat 1 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 25 0 0 1608516 73508 65077532 0 0 24 154 0 0 7 4 89 0 0 27 0 0 1164052 73504 64969344 0 0 4564 235986 76844 62002 34 10 56 0 0 29 0 0 934664 73432 64629188 0 0 1664 67045 84336 72251 35 17 48 0 0 27 0 0 1246500 73364 64221360 0 0 2256 125096 96714 87624 36 11 53 0 0 24 0 0 2644012 73372 64221348 0 0 2352 824785 96807 65267 35 13 51 1 0 27 0 0 1990800 73372 64227796 0 0 3840 13154 90636 88460 33 14 53 0 0 25 0 0 1572856 73336 64037344 0 0 2288 14159 100520 97671 34 18 48 0 0 23 0 0 3231344 73312 63839116 0 0 5736 171691 85444 82650 34 17 49 0 0 30 0 0 2974904 73320 63843980 0 0 2540 6776 67446 46092 33 10 57 0 0 05:50:02 UID PID cswch/s nvcswch/s Command 05:50:03 0 1 1.00 0.00 tini 05:50:03 0 654787 0.00 14.00 clang 05:50:03 0 654842 0.00 10.00 clang 05:50:03 0 654892 0.00 2.00 clang 05:50:03 0 654920 0.00 10.00 clang 05:50:03 0 654929 0.00 2.00 clang 05:50:03 0 655140 0.00 4.00 clang 05:50:03 0 655157 1.00 0.00 pidstat 05:50:03 0 655163 1.00 7.00 clang 05:50:03 0 655186 157.00 2.00 multi_camera_fu 05:50:03 0 655195 0.00 2.00 clang 05:50:03 0 655205 0.00 3.00 clang 05:50:03 0 655214 0.00 18.00 clang 05:50:03 0 655220 0.00 4.00 clang 05:50:03 0 655246 0.00 17.00 clang 05:50:03 0 655322 0.00 15.00 clang 05:50:03 0 655360 1.00 15.00 clang 开始考虑查找是不是进程被非自愿地抢占了，使用命令/usr/share/bcc/tools/cpudist -P就能够针对每个进程查看在CPU上运行的时间，（偶尔）可以非常明显地可以看到java的运行非常不规律，针对clang同样发现了同样非常明显的离群点\npid = 3034488 java\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 19 |*** |\r16 -\u0026gt; 31 : 169 |********************************** |\r32 -\u0026gt; 63 : 194 |****************************************|\r64 -\u0026gt; 127 : 58 |*********** |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 29 |***** |\r512 -\u0026gt; 1023 : 0 | |\r1024 -\u0026gt; 2047 : 25 |***** |\r2048 -\u0026gt; 4095 : 33 |****** |\r4096 -\u0026gt; 8191 : 0 | |\r8192 -\u0026gt; 16383 : 123 |************************* |\r16384 -\u0026gt; 32767 : 88 |****************** |\rpid = 3180430 clang\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 5 |*********** |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 0 | |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 4 |********* |\r512 -\u0026gt; 1023 : 0 | |\r1024 -\u0026gt; 2047 : 1 |** |\r2048 -\u0026gt; 4095 : 3 |******* |\r4096 -\u0026gt; 8191 : 0 | |\r8192 -\u0026gt; 16383 : 0 | |\r16384 -\u0026gt; 32767 : 0 | |\r32768 -\u0026gt; 65535 : 0 | |\r65536 -\u0026gt; 131071 : 0 | |\r131072 -\u0026gt; 262143 : 17 |****************************************| 再随便找一个针对具体的clang作分析，明显地看到clang被中断了好几次。所以需要查找为什么clang被中断\n[root@ack-ci-172 ~]# pidstat -w 1 | grep clang\r02:30:57 PM 0 3268780 0.00 36.00 clang\r^C[root@ack-ci-172 ~]# /usr/share/bcc/tools/cpudist -p 3268780\rTracing on-CPU time... Hit Ctrl-C to end.\r^C\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 5 |****************************************|\r32 -\u0026gt; 63 : 1 |******** |\r64 -\u0026gt; 127 : 0 | |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 3 |************************ |\r512 -\u0026gt; 1023 : 1 |******** |\r1024 -\u0026gt; 2047 : 1 |******** |\r2048 -\u0026gt; 4095 : 3 |************************ |\r4096 -\u0026gt; 8191 : 0 | |\r8192 -\u0026gt; 16383 : 0 | |\r16384 -\u0026gt; 32767 : 0 | |\r32768 -\u0026gt; 65535 : 0 | |\r65536 -\u0026gt; 131071 : 0 | |\r131072 -\u0026gt; 262143 : 1 |******** |\r262144 -\u0026gt; 524287 : 1 |******** |\r524288 -\u0026gt; 1048575 : 1 |******** |\r1048576 -\u0026gt; 2097151 : 0 | |\r2097152 -\u0026gt; 4194303 : 1 |******** | 从统计的角度进行一些分析，下面的部分会从两个bazel的profile文件提取出来同样的cpp编译文件，这两个profile文件内部的编译数量是基本一致的（注意，这依然不是严格证明，因为黑盒太多，无法严格对比）之后对比两个文件执行控制流里面cpp编译的时间。bazel的编译是并行运行的，但是总体依然是反映了单“执行线程”的规律。从下面的结果可以看出来，单纯执行阶段clang的编译速度确实下降了一倍左右\n# 第一个比较慢，remote编译4329个target，耗时132min。第二个快不少，remote编译4301个target，耗时66min\rmv 455610-27325538.profile slow.profile\rmv 458377-27662235.profile fast.profile\r# 提取编译的C++目标\rcat slow.profile | grep CppCompile \u0026gt; slow.cppcompile\rcat fast.profile | grep CppCompile \u0026gt; fast.cppcompile\r# 提取C++目标的编译文件和时间\rcat slow.cppcompile| awk -F \u0026#39;,\u0026#39; \u0026#39;{print $2,$5}\u0026#39; \u0026gt; slow_simple.cppcompile\rcat fast.cppcompile| awk -F \u0026#39;,\u0026#39; \u0026#39;{print $2,$5}\u0026#39; \u0026gt; fast_simple.cppcompile\r# 提取C++目标的编译文件， 本次分析slow目标共3472个，fast目标共3502个\rcat fast.cppcompile| awk -F \u0026#39;,\u0026#39; \u0026#39;{print $2}\u0026#39; \u0026gt; fast_targets.cppcompile\rcat slow.cppcompile| awk -F \u0026#39;,\u0026#39; \u0026#39;{print $2}\u0026#39; \u0026gt; slow_targets.cppcompile\r# 找到共同的编译文件, 共同编译的对象共2798个\rcat slow_targets.cppcompile fast_targets.cppcompile| sort | uniq -d \u0026gt; common_targets.cppcompile\r# 从慢和快的profile提取共同编译的文件\rcat common_targets.cppcompile| while read line; do cat slow_simple.cppcompile|grep $line \u0026gt;\u0026gt; slow_common.cppcompile; done\rcat common_targets.cppcompile| while read line; do cat fast_simple.cppcompile|grep $line \u0026gt;\u0026gt; fast_common.cppcompile; done\r# 检索慢的编译平均速度\rcat slow_common.cppcompile| awk -F \u0026#39;:\u0026#39; \u0026#39;{print $3}\u0026#39; \u0026gt; slow_time.cppcompile\rcat slow_common.cppcompile| awk -F \u0026#39;:\u0026#39; \u0026#39;{print $3}\u0026#39; \u0026gt; slow_time.cppcompile\r# 求和，看下累加起来的总c++编译的时间是多少，慢的编译时间是快的1.7倍，符合我对应bazel编译慢的猜想\rawk \u0026#39;BEGIN{sum=0}{sum+=$1}END{print sum}\u0026#39; slow_time.cppcompile\r168695103574\rawk \u0026#39;BEGIN{sum=0}{sum+=$1}END{print sum}\u0026#39; fast_time.cppcompile\r97473692742 那么问题就需要进一步排查，为什么clang的编译变慢了？对这一步的分析会非常麻烦，因为缺乏环境+有很多外部因素的干扰。\n使用ps -eLfc可以在CLS一栏中查看进程的调度策略，clang用的是TS即SCHED_OTHER，SCHED_OTHER也被称为SCHED_NORMAL，下面的一些东西是我的猜想，机器使用的是3.10的linux kernel，SCHED_NORMAL基本上默认的linux进程调度算法，而sched_nomal实际上是倾向于优先处理io bound的进程的，所以是否会由于受到IO密集型ld.ldd的flto的影响呢？\n（非完备）测试方法很简单，空闲状态下跟踪一个clang进程的cpudist，之后启动大量flto的进程做测试，再次跟踪。不启动flto的时候按照5s的频率跟踪，clang基本都是 524288 -\u0026gt; 1048575长时间运行，出现明显离群点的比例统计为3/121。启动flto任务之后，等待ld.ldd启用flto操作之后再去检查clang的cpudist发现出现大量下面的类型，比例为5/13（分母比较小是因为ld.ldd停止了我就退出了统计）。尽管不能证明历史原因就是因为ld.ldd引起的，不过也找到了一个影响因素。\npid = 1429291 clang\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 0 | |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 2 |************************** |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 0 | |\r512 -\u0026gt; 1023 : 1 |************* |\r1024 -\u0026gt; 2047 : 1 |************* |\r2048 -\u0026gt; 4095 : 1 |************* |\r4096 -\u0026gt; 8191 : 2 |************************** |\r8192 -\u0026gt; 16383 : 0 | |\r16384 -\u0026gt; 32767 : 0 | |\r32768 -\u0026gt; 65535 : 1 |************* |\r65536 -\u0026gt; 131071 : 0 | |\r131072 -\u0026gt; 262143 : 0 | |\r262144 -\u0026gt; 524287 : 3 |****************************************|\rpid = 1429010 clang\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 2 |************************** |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 0 | |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 3 |****************************************|\r512 -\u0026gt; 1023 : 0 | |\r1024 -\u0026gt; 2047 : 0 | |\r2048 -\u0026gt; 4095 : 2 |************************** |\r4096 -\u0026gt; 8191 : 0 | |\r8192 -\u0026gt; 16383 : 0 | |\r16384 -\u0026gt; 32767 : 0 | |\r32768 -\u0026gt; 65535 : 0 | |\r65536 -\u0026gt; 131071 : 1 |************* |\r131072 -\u0026gt; 262143 : 3 |****************************************|\rpid = 1429010 clang #还是上面那个clang进程，可以看到它被打断多次\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 2 |************************** |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 0 | |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 3 |****************************************|\r512 -\u0026gt; 1023 : 0 | |\r1024 -\u0026gt; 2047 : 0 | |\r2048 -\u0026gt; 4095 : 2 |************************** |\r4096 -\u0026gt; 8191 : 0 | |\r8192 -\u0026gt; 16383 : 0 | |\r16384 -\u0026gt; 32767 : 0 | |\r32768 -\u0026gt; 65535 : 0 | |\r65536 -\u0026gt; 131071 : 1 |************* |\r131072 -\u0026gt; 262143 : 3 |****************************************|\rpid = 1427996 clang\rusecs : count distribution\r0 -\u0026gt; 1 : 0 | |\r2 -\u0026gt; 3 : 0 | |\r4 -\u0026gt; 7 : 0 | |\r8 -\u0026gt; 15 : 0 | |\r16 -\u0026gt; 31 : 0 | |\r32 -\u0026gt; 63 : 0 | |\r64 -\u0026gt; 127 : 0 | |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 0 | |\r512 -\u0026gt; 1023 : 0 | |\r1024 -\u0026gt; 2047 : 0 | |\r2048 -\u0026gt; 4095 : 0 | |\r4096 -\u0026gt; 8191 : 0 | |\r8192 -\u0026gt; 16383 : 1 |****************************************|\r16384 -\u0026gt; 32767 : 1 |****************************************|\r32768 -\u0026gt; 65535 : 0 | |\r65536 -\u0026gt; 131071 : 0 | |\r131072 -\u0026gt; 262143 : 0 | |\r262144 -\u0026gt; 524287 : 0 | |\r524288 -\u0026gt; 1048575 : 1 |****************************************| 2.7 Xavier机器的IO问题 # 依然是多个个核存在非常高的iowait，\nAverage: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle\rAverage: all 2.50 0.03 1.21 38.81 0.00 0.00 0.00 0.00 0.00 57.46\rAverage: 0 0.61 0.40 3.43 34.55 0.00 0.00 0.00 0.00 0.00 61.01\rAverage: 1 0.80 0.00 1.20 34.27 0.00 0.00 0.00 0.00 0.00 63.73\rAverage: 2 2.01 0.00 1.61 33.53 0.00 0.00 0.00 0.00 0.00 62.85\rAverage: 3 0.80 0.00 2.21 15.86 0.00 0.00 0.00 0.00 0.00 81.12\rAverage: 4 9.72 0.00 2.02 54.45 0.00 0.00 0.00 0.00 0.00 33.81\rAverage: 5 7.24 0.00 0.80 31.39 0.00 0.00 0.00 0.00 0.00 60.56\rAverage: 6 1.20 0.00 0.40 32.53 0.00 0.00 0.00 0.00 0.00 65.86\rAverage: 7 1.80 0.00 1.40 0.20 0.00 0.00 0.00 0.00 0.00 96.60\rAverage: 8 1.21 0.00 0.20 98.59 0.00 0.00 0.00 0.00 0.00 0.00\rAverage: 9 0.80 0.00 0.40 98.80 0.00 0.00 0.00 0.00 0.00 0.00\rAverage: 10 0.80 0.00 0.40 43.06 0.00 0.00 0.00 0.00 0.00 55.73\rAverage: 11 5.21 0.00 1.00 27.86 0.00 0.00 0.00 0.00 0.00 65.93\rAverage: 12 0.80 0.00 0.40 20.24 0.00 0.00 0.00 0.00 0.00 78.56\rAverage: 13 3.81 0.00 0.40 0.00 0.00 0.00 0.00 0.00 0.00 95.79\rAverage: 14 1.81 0.00 1.01 78.67 0.00 0.00 0.00 0.00 0.00 18.51\rAverage: 15 1.60 0.00 2.00 17.64 0.00 0.00 0.00 0.00 0.00 78.76 针对一个bazel进程做分析，发现等待的时间有点久\n1000 29057 1.6 0.6 26199204 429660 ? Ssl 00:44 0:17 bazel(qcraft) --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED -Xverify:none -Djava.util.logging.config.file=/home/qcrafter/.cache/bazel/_bazel_qcrafter/c418f5acab2a0d971f0829ca9f48d1c3/javalog.properties -Dcom.google.devtools.build.lib.util.LogHandlerQuerier.class=com.google.devtools.build.lib.util.SimpleLogHandler$HandlerQuerier -XX:-MaxFDLimit -Djava.library.path=/home/qcrafter/.cache/bazel/_bazel_qcrafter/install/0f213247804519331681f5a8469944bb/embedded_tools/jdk/lib/jli:/home/qcrafter/.cache/bazel/_bazel_qcrafter/install/0f213247804519331681f5a8469944bb/embedded_tools/jdk/lib:/home/qcrafter/.cache/bazel/_bazel_qcrafter/install/0f213247804519331681f5a8469944bb/embedded_tools/jdk/lib/server:/home/qcrafter/.cache/bazel/_bazel_qcrafter/install/0f213247804519331681f5a8469944bb/ -Dfile.encoding=ISO-8859-1 -jar /home/qcrafter/.cache/bazel/_bazel_qcrafter/install/0f213247804519331681f5a8469944bb/A-server.jar --max_idle_secs=10800 --noshutdown_on_low_sys_mem --connect_timeout_secs=30 --output_user_root=/home/qcrafter/.cache/bazel/_bazel_qcrafter --install_base=/home/qcrafter/.cache/bazel/_bazel_qcrafter/install/0f213247804519331681f5a8469944bb --install_md5=0f213247804519331681f5a8469944bb --output_base=/home/qcrafter/.cache/bazel/_bazel_qcrafter/c418f5acab2a0d971f0829ca9f48d1c3 --workspace_directory=/builds/root/qcraft --default_system_javabase= --failure_detail_out=/home/qcrafter/.cache/bazel/_bazel_qcrafter/c418f5acab2a0d971f0829ca9f48d1c3/failure_detail.rawproto --expand_configs_in_place --idle_server_tasks --write_command_log --nowatchfs --nofatal_event_bus_exceptions --nowindows_enable_symlinks --client_debug=false --product_name=Bazel --option_sources=\rroot@hangzhou-arm03:~# ps -eo time,pid,etime | grep 29057\r00:00:17 29057 18:20 针对性地去看vmstat的结果，发现b那一列明显数量大，也就是说被(IO)阻塞的进程很多\nroot@hangzhou-arm03:~# vmstat 1\rprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\rr b swpd free buff cache si so bi bo in cs us sy id wa st\r2 16 0 3457712 13946072 38106688 0 0 8 1574 0 0 15 2 82 1 0\r1 17 0 3458236 13946072 38106692 0 0 0 0 6445 10341 10 1 31 59 0\r1 17 0 3458508 13946072 38106692 0 0 0 0 5005 8231 7 0 38 55 0\r0 13 0 3442008 13946440 38122648 0 0 0 15836 18856 33676 2 2 47 49 0\r0 15 0 3442112 13946440 38122648 0 0 0 356 3911 6790 0 0 43 57 0\r1 16 0 3442452 13946440 38122648 0 0 0 0 7766 13444 1 2 29 68 0\r0 17 0 3443040 13946440 38122656 0 0 0 0 4313 7236 0 0 24 75 0\r0 18 0 3441648 13946440 38122660 0 0 0 0 7302 12236 0 2 21 77 0\r1 19 0 3441072 13946440 38122660 0 0 0 20 4924 8226 4 1 25 71 0\r0 19 0 3440940 13946440 38122660 0 0 0 128 4747 8105 2 1 41 57 0\r1 19 0 3438976 13946440 38122660 0 0 0 0 4615 7832 1 1 40 59 0\r0 19 0 3441968 13946440 38122660 0 0 0 0 5105 8807 0 0 34 65 0\r0 19 0 3441712 13946440 38122660 0 0 0 0 4047 7055 1 0 29 71 0\r1 19 0 3441024 13946440 38122660 0 0 0 44 6129 9746 7 1 32 60 0\rroot@hangzhou-arm03:~# dstat\rYou did not select any stats, using -cdngy by default.\r--total-cpu-usage-- -dsk/total- -net/total- ---paging-- ---system--\rusr sys idl wai stl| read writ| recv send| in out | int csw\r15 2 82 1 0| 136k 25M| 0 0 | 0 0 |6964 10k\r0 0 18 81 0| 0 0 | 362B 2974B| 0 0 |4228 7259\r0 1 8 91 0| 0 0 | 218k 3841B| 0 0 |5665 9887\r7 1 6 87 0| 344k 0 | 118B 424B| 0 0 |5220 8267\r3 1 8 88 0| 56k 4096B|1919B 4682B| 0 0 |5440 9258\r1 1 12 86 0| 0 0 |3501B 58k| 0 0 |5478 9222\r0 0 14 86 0| 0 136k| 118B 424B| 0 0 |4487 7801\r1 1 12 86 0| 0 0 | 803B 1057B| 0 0 |5172 8713\r0 0 1 98 0| 0 0 | 118B 424B| 0 0 |4651 8057\r2 2 7 89 0| 0 2796k| 43k 2207B| 0 0 | 11k 19k\r5 4 6 85 0|8192B 0 | 73k 2623B| 0 0 |7246 12k^C 又看了下文件的写入延迟，这也太离谱了。。。\nroot@hangzhou-arm03:/usr/share/bcc/tools# ./fileslower -p 27439\rTracing sync read/writes slower than 10 ms\rTIME(s) COMM TID D BYTES LAT(ms) FILENAME\r47.455 skyframe-evalu 29133 W 3317 202.95 unicode_iterator.hpp\r52.190 skyframe-evalu 29151 W 8192 34993.71 pcl-1d3622c1e624994bc013e3e66...\r52.194 skyframe-evalu 29137 W 4735 34995.38 ComputeEnvironmentOrder.h\r52.402 skyframe-evalu 29151 W 8192 207.66 pcl-1d3622c1e624994bc013e3e66...\r52.414 skyframe-evalu 29137 W 2860 206.61 LinuxParameters.cpp\r82.242 skyframe-evalu 29133 W 1013 34787.80 w32_regex_traits.hpp\r82.458 skyframe-evalu 29133 W 400 206.21 integer.hpp 然而，查看biolatency的结果发现实际上，QUEUE，就是倒数第二列（操作系统队列的排队时间），(从IO创建到发送到设备的时间并不长)，那么问题是这么回事？\n110.154892 skyframe-evalu 25278 vda R 113660304 4096 0.00 0.69\r110.180021 skyframe-evalu 29981 vda R 908345936 4096 0.01 0.16\r110.180148 skyframe-evalu 29981 vda R 908345944 16384 0.00 0.09\r110.180447 skyframe-evalu 29981 vda R 908345976 32768 0.00 0.28\r110.180936 skyframe-evalu 29981 vda R 908345800 16384 0.01 0.26\r110.181238 skyframe-evalu 29981 vda R 908345832 32768 0.00 0.26\r110.181454 skyframe-evalu 29981 vda R 908345896 20480 0.00 0.46\r110.182545 skyframe-evalu 29981 vda R 908346040 45056 0.01 0.15\r110.183457 skyframe-evalu 29981 vda R 908148672 4096 0.00 0.28\r110.183700 skyframe-evalu 29981 vda R 908148680 16384 0.00 0.22\r110.184168 skyframe-evalu 29981 vda R 908148712 4096 0.00 0.09\r110.184338 skyframe-evalu 29981 vda R 908148728 8192 0.01 0.25\r110.184377 skyframe-evalu 29981 vda R 908148752 4096 0.00 0.29\r110.187430 skyframe-evalu 29981 vda R 908148968 16384 0.01 0.11\r110.187906 skyframe-evalu 29981 vda R 908149088 4096 0.01 0.08 然后针对bazel统计下每5s的io操作强度，pidstat -dl 5，发现最慢的bazel进程也就写个4kb，一个文件解压前170MB，需要花170*1024/4*5/60 = 60h。。。这明显超时，所以io这么慢的根本原因是什么？\n2.8 丢包的原因 # 在理想，有一天接入层往WAF建立连接报了大量错误\n查看ss发现tcp连接为6033个\n2.9 优化检测程序性能 # 这两天写一个libevent+Suricata的检测程序，libevent是通信框架，Suricata是检测框架。遇到一个问题，程序性能打不上去，每个线程撑死4k的QPS，配置的Limits是8，CPU才不到200，这不是浪费了（公司收费竟然算limit收费。。。），perf暂时无法运行，先用pidstat排查，发现system很高。\n一半system比较高原因有如下几种：\nI/O 密集任务: 该进程正在执行大量的 I/O 操作，如频繁的磁盘读写或网络通信。 系统调用频繁: 该进程频繁地调用系统函数，例如文件操作、网络功能、或进程间通信。 进程调度频繁: 该进程可能引发了频繁的上下文切换。 中断处理: 该进程可能与设备驱动程序或硬件密切交互，导致高频率的中断处理。 root@cloud-proxy-uds-test-5488b8f6c9-qxxnn:/suricata# pidstat -p 1 1\rLinux 5.10.0-3.0.1.5 (cloud-proxy-uds-test-5488b8f6c9-qxxnn) 06/18/24 _x86_64_ (32 CPU)\r11:48:11 UID PID %usr %system %guest %wait %CPU CPU Command\r11:48:12 0 1 62.00 88.00 0.00 0.00 150.00 28 Suricata-Main\r11:48:13 0 1 82.00 84.00 0.00 0.00 166.00 0 Suricata-Main\r11:48:14 0 1 70.00 77.00 0.00 0.00 147.00 12 Suricata-Main\r11:48:15 0 1 73.00 78.00 0.00 0.00 151.00 0 Suricata-Main\r11:48:16 0 1 64.00 87.00 0.00 0.00 151.00 16 Suricata-Main\r11:48:17 0 1 75.00 79.00 0.00 0.00 154.00 10 Suricata-Main\r11:48:18 0 1 72.00 89.00 0.00 0.00 161.00 24 Suricata-Main\r11:48:19 0 1 88.00 77.00 0.00 0.00 165.00 4 Suricata-Main\r11:48:20 0 1 76.00 74.00 0.00 0.00 150.00 12 Suricata-Main\r11:48:21 0 1 73.00 75.00 0.00 0.00 148.00 30 Suricata-Main\r11:48:22 0 1 70.00 77.00 0.00 1.00 147.00 24 Suricata-Main\r11:48:23 0 1 70.00 81.00 0.00 0.00 151.00 2 Suricata-Main\r11:48:24 0 1 76.00 89.00 0.00 0.00 165.00 22 Suricata-Main\r11:48:25 0 1 90.00 77.00 0.00 0.00 167.00 6 Suricata-Main\r11:48:26 0 1 76.00 93.00 0.00 0.00 169.00 6 Suricata-Main\r11:48:27 0 1 66.00 83.00 0.00 0.00 149.00 18 Suricata-Main\r11:48:28 0 1 65.00 73.00 0.00 0.00 138.00 26 Suricata-Main\r^C\rAverage: 0 1 73.41 81.24 0.00 0.06 154.65 - Suricata-Main\rroot@cloud-proxy-uds-test-5488b8f6c9-qxxnn:/suricata# 看看进程是不是自愿发生的切换比较，使用pidstat -w -p 1，卧槽，每秒钟切换出现了几千次，这有点狠呀。第一反应是IO导致了频繁的上下文切换。\nAverage: 0 1 - 3816.67 0.33 Suricata-Main\rAverage: 0 - 1 3817.00 0.33 |__Suricata-Main\rAverage: 0 - 7 1090.33 0.00 |__Suricata-Main\rAverage: 0 - 8 15931.33 0.00 |__Suricata-Main\rAverage: 0 - 9 1107.33 0.00 |__Suricata-Main\rAverage: 0 - 10 15287.00 0.00 |__Suricata-Main\rAverage: 0 - 11 1091.33 0.00 |__Suricata-Main\rAverage: 0 - 12 15859.67 0.00 |__Suricata-Main\rAverage: 0 - 13 1103.33 0.00 |__Suricata-Main\rAverage: 0 - 14 15358.33 0.00 |__Suricata-Main\rAverage: 0 - 15 1092.00 0.00 |__Suricata-Main\rAverage: 0 - 16 15860.33 0.00 |__Suricata-Main\rAverage: 0 - 17 1110.00 0.00 |__Suricata-Main\rAverage: 0 - 18 15172.67 0.00 |__Suricata-Main\rAverage: 0 - 19 1090.33 0.00 |__Suricata-Main\rAverage: 0 - 20 15924.00 0.00 |__Suricata-Main\rAverage: 0 - 21 1105.67 0.00 |__Suricata-Main\rAverage: 0 - 22 15319.67 0.00 |__Suricata-Main\rAverage: 0 - 23 1090.33 0.00 |__Suricata-Main\rAverage: 0 - 24 15974.33 0.00 |__Suricata-Main\rAverage: 0 - 25 1107.67 0.00 |__Suricata-Main\rAverage: 0 - 26 15347.67 0.00 |__Suricata-Main\rAverage: 0 - 27 1091.00 0.00 |__Suricata-Main\rAverage: 0 - 28 15839.33 0.00 |__Suricata-Main\rAverage: 0 - 29 1111.67 0.00 |__Suricata-Main\rAverage: 0 - 30 15391.33 0.00 |__Suricata-Main\rAverage: 0 - 31 1092.33 0.00 |__Suricata-Main\rAverage: 0 - 32 15854.67 0.00 |__Suricata-Main\rAverage: 0 - 33 1115.00 0.00 |__Suricata-Main\rAverage: 0 - 34 15314.00 0.00 |__Suricata-Main\rAverage: 0 - 35 1091.00 0.00 |__Suricata-Main\rAverage: 0 - 36 15922.67 0.00 |__Suricata-Main\rAverage: 0 - 37 1109.00 0.00 |__Suricata-Main\rAverage: 0 - 38 15271.33 0.00 |__Suricata-Main\rAverage: 0 - 39 0.00 0.00 |__Suricata-Main strace看下系统调用，epoll_wait占用的比例最高\nroot@cloud-proxy-uds-test-5488b8f6c9-qxxnn:/suricata# strace -c -p 1\rstrace: Process 1 attached\r^Cstrace: Process 1 detached\r% time seconds usecs/call calls errors syscall\r------ ----------- ----------- --------- --------- ----------------\r94.58 17.637016 3498 5042 epoll_wait\r1.37 0.255808 8 30627 write\r0.84 0.157116 7 20416 openat\r0.79 0.147240 9 15250 5042 accept4\r0.72 0.133498 6 20416 newfstatat\r0.65 0.120828 5 20416 close\r0.43 0.080023 7 10208 epoll_ctl\r0.32 0.059370 5 10208 setsockopt\r0.30 0.056014 7 7689 futex\r------ ----------- ----------- --------- --------- ----------------\r100.00 18.646913 132 140272 5042 total\rroot@cloud-proxy-uds-test-5488b8f6c9-qxxnn:/suricata# 第一次修改，2IO，4检测线程\nAverage: 0 1 - 4699.60 0.00 Suricata-Main\rAverage: 0 - 1 4699.40 0.00 |__Suricata-Main\rAverage: 0 - 7 9740.40 0.00 |__Suricata-Main\rAverage: 0 - 8 11321.80 0.00 |__Suricata-Main\rAverage: 0 - 9 13638.20 0.20 |__Suricata-Main\rAverage: 0 - 10 13704.60 0.20 |__Suricata-Main\rAverage: 0 - 11 13730.00 0.20 |__Suricata-Main\rAverage: 0 - 12 13689.20 0.00 |__Suricata-Main\rAverage: 0 - 13 0.00 0.00 |__Suricata-Main 第二次修改，1IO，1检测线程\n2.10 排查超时 # 这几天盯一个超时的问题，发现每次准点CPU的使用率不高但是有大量超时，怀疑是工作负载上来处理来不及。但是只看CPU使用率很难解释，开始收集统计数据，发现一些奇怪的点\npidstat查看进程非自助切换\n# 平时没有问题，进程的非自愿切换比较少\r10:46:48 UID PID cswch/s nvcswch/s Command\r10:46:49 0 26 65.00 0.00 openresty\r10:46:49 0 27 60.00 0.00 openresty\r10:46:49 0 28 43.00 0.00 openresty\r10:46:49 0 29 66.00 0.00 openresty\r10:46:49 0 30 53.00 0.00 openresty\r10:46:49 0 31 58.00 0.00 openresty\r10:46:49 0 32 63.00 0.00 openresty\r10:46:49 0 33 65.00 0.00 openresty\r10:46:49 0 34 51.00 0.00 openresty\r10:46:49 0 35 54.00 0.00 openresty\r10:46:49 0 36 61.00 0.00 openresty\r10:46:49 0 37 54.00 0.00 openresty\r10:46:49 0 38 50.00 0.00 openresty\r10:46:49 0 39 57.00 0.00 openresty\r10:46:49 0 40 59.00 0.00 openresty # 10:59出现一波明显的非自助切换\r10:58:59 UID PID cswch/s nvcswch/s Command 10:59:00 0 26 101.00 2.00 openresty\r10:59:00 0 27 119.00 3.00 openresty\r10:59:00 0 28 134.00 0.00 openresty\r10:59:00 0 29 112.00 5.00 openresty\r10:59:00 0 30 134.00 1.00 openresty\r10:59:00 0 31 142.00 0.00 openresty\r10:59:00 0 32 132.00 2.00 openresty\r10:59:00 0 33 137.00 0.00 openresty\r10:59:00 0 34 119.00 0.00 openresty\r10:59:00 0 35 124.00 1.00 openresty\r10:59:00 0 36 113.00 2.00 openresty\r10:59:00 0 37 113.00 1.00 openresty\r10:59:00 0 38 95.00 1.00 openresty\r10:59:00 0 39 111.00 4.00 openresty\r10:59:00 0 40 138.00 1.00 openresty\r10:59:00 0 43 120.00 3.00 openresty\r10:59:00 0 44 122.00 2.00 openresty\r10:59:00 0 45 131.00 1.00 openresty\r10:59:00 0 46 110.00 6.00 openresty\r10:59:00 0 47 128.00 1.00 openresty\r10:59:00 0 48 112.00 2.00 openresty\r10:59:00 0 49 139.00 1.00 openresty\r10:59:00 0 50 114.00 2.00 openresty\r10:59:00 0 51 136.00 1.00 openresty\r10:59:00 0 52 108.00 2.00 openresty\r10:59:00 0 53 131.00 1.00 openresty\r10:59:00 0 54 109.00 2.00 openresty\r10:59:00 0 55 134.00 1.00 openresty\r10:59:00 0 56 110.00 1.00 openresty\r10:59:00 0 57 124.00 0.00 openresty\r10:59:00 0 58 3.00 0.00 openresty\r10:59:00 0 1648 119.00 2.00 openresty\r10:59:00 0 1937 100.00 1.00 openresty 11点一波冲击，出现大量的非自愿context switch\n10:59:59 UID PID cswch/s nvcswch/s Command\r11:00:00 0 25 1.00 0.00 openresty\r11:00:00 0 26 14.00 42.00 openresty\r11:00:00 0 27 14.00 49.00 openresty\r11:00:00 0 28 13.00 47.00 openresty\r11:00:00 0 29 3.00 60.00 openresty\r11:00:00 0 30 27.00 52.00 openresty\r11:00:00 0 31 17.00 61.00 openresty\r11:00:00 0 32 17.00 62.00 openresty\r11:00:00 0 33 43.00 72.00 openresty\r11:00:00 0 34 34.00 72.00 openresty\r11:00:00 0 35 20.00 46.00 openresty\r11:00:00 0 36 13.00 46.00 openresty\r11:00:00 0 37 7.00 48.00 openresty\r11:00:00 0 38 18.00 70.00 openresty\r11:00:00 0 39 9.00 64.00 openresty\r11:00:00 0 40 24.00 80.00 openresty\r11:00:00 0 43 1.00 51.00 openresty\r11:00:00 0 44 20.00 45.00 openresty\r11:00:00 0 45 17.00 56.00 openresty\r11:00:00 0 46 26.00 60.00 openresty\r11:00:00 0 47 19.00 46.00 openresty\r11:00:00 0 48 11.00 56.00 openresty\r11:00:00 0 49 20.00 60.00 openresty\r11:00:00 0 50 9.00 63.00 openresty\r11:00:00 0 51 23.00 49.00 openresty\r11:00:00 0 52 23.00 81.00 openresty\r11:00:00 0 53 10.00 49.00 openresty\r11:00:00 0 54 30.00 70.00 openresty\r11:00:00 0 55 24.00 57.00 openresty\r11:00:00 0 56 22.00 58.00 openresty\r11:00:00 0 57 22.00 49.00 openresty\r11:00:00 0 58 3.00 0.00 openresty\r11:00:00 0 1648 55.00 61.00 openresty\r11:00:00 0 1937 4.00 59.00 openresty\r11:00:00 UID PID cswch/s nvcswch/s Command\r11:00:01 0 26 76.00 8.00 openresty\r11:00:01 0 27 75.00 11.00 openresty\r11:00:01 0 28 80.00 9.00 openresty\r11:00:01 0 29 78.00 12.00 openresty\r11:00:01 0 30 77.00 8.00 openresty\r11:00:01 0 31 63.00 8.00 openresty\r11:00:01 0 32 51.00 12.00 openresty\r11:00:01 0 33 59.00 23.00 openresty\r11:00:01 0 34 59.00 12.00 openresty\r11:00:01 0 35 105.00 7.00 openresty\r11:00:01 0 36 27.00 13.00 openresty\r11:00:01 0 37 52.00 9.00 openresty\r11:00:01 0 38 23.00 17.00 openresty\r11:00:01 0 39 68.00 14.00 openresty\r11:00:01 0 40 91.00 7.00 openresty\r11:00:01 0 43 51.00 9.00 openresty\r11:00:01 0 44 54.00 12.00 openresty\r11:00:01 0 45 36.00 8.00 openresty\r11:00:01 0 46 60.00 13.00 openresty\r11:00:01 0 47 61.00 9.00 openresty\r11:00:01 0 48 67.00 17.00 openresty\r11:00:01 0 49 51.00 11.00 openresty\r11:00:01 0 50 61.00 11.00 openresty\r11:00:01 0 51 74.00 7.00 openresty\r11:00:01 0 52 40.00 26.00 openresty\r11:00:01 0 53 45.00 11.00 openresty\r11:00:01 0 54 56.00 16.00 openresty\r11:00:01 0 55 40.00 11.00 openresty\r11:00:01 0 56 69.00 11.00 openresty\r11:00:01 0 57 32.00 13.00 openresty\r11:00:01 0 58 5.00 0.00 openresty\r11:00:01 0 1648 83.00 12.00 openresty\r11:00:01 0 1937 41.00 11.00 openresty runqlat查看\nusecs : count distribution\r0 -\u0026gt; 1 : 1284 |*********** |\r2 -\u0026gt; 3 : 4408 |****************************************|\r4 -\u0026gt; 7 : 4381 |*************************************** |\r8 -\u0026gt; 15 : 1074 |********* |\r16 -\u0026gt; 31 : 156 |* |\r32 -\u0026gt; 63 : 13 | |\r64 -\u0026gt; 127 : 9 | |\r128 -\u0026gt; 255 : 5 | |\r256 -\u0026gt; 511 : 2 | |\r512 -\u0026gt; 1023 : 22 | |\r1024 -\u0026gt; 2047 : 2 | |\r2048 -\u0026gt; 4095 : 12 | |\r4096 -\u0026gt; 8191 : 10 | |\r8192 -\u0026gt; 16383 : 6 | |\rusecs : count distribution\r0 -\u0026gt; 1 : 984 |******* |\r2 -\u0026gt; 3 : 5580 |****************************************|\r4 -\u0026gt; 7 : 4297 |****************************** |\r8 -\u0026gt; 15 : 1505 |********** |\r16 -\u0026gt; 31 : 248 |* |\r32 -\u0026gt; 63 : 30 | |\r64 -\u0026gt; 127 : 6 | |\r128 -\u0026gt; 255 : 1 | |\r256 -\u0026gt; 511 : 2 | |\r512 -\u0026gt; 1023 : 19 | |\r1024 -\u0026gt; 2047 : 5 | |\r2048 -\u0026gt; 4095 : 6 | |\r4096 -\u0026gt; 8191 : 5 | |\r8192 -\u0026gt; 16383 : 3 | |\r16384 -\u0026gt; 32767 : 1 | |\r# 12:00整点几秒数据\rusecs : count distribution\r0 -\u0026gt; 1 : 560 |****** |\r2 -\u0026gt; 3 : 3542 |****************************************|\r4 -\u0026gt; 7 : 3087 |********************************** |\r8 -\u0026gt; 15 : 993 |*********** |\r16 -\u0026gt; 31 : 486 |***** |\r32 -\u0026gt; 63 : 363 |**** |\r64 -\u0026gt; 127 : 453 |***** |\r128 -\u0026gt; 255 : 246 |** |\r256 -\u0026gt; 511 : 129 |* |\r512 -\u0026gt; 1023 : 316 |*** |\r1024 -\u0026gt; 2047 : 153 |* |\r2048 -\u0026gt; 4095 : 493 |***** |\r4096 -\u0026gt; 8191 : 828 |********* |\r8192 -\u0026gt; 16383 : 232 |** |\r16384 -\u0026gt; 32767 : 4 | |\rusecs : count distribution\r0 -\u0026gt; 1 : 571 |***** |\r2 -\u0026gt; 3 : 3946 |************************************ |\r4 -\u0026gt; 7 : 4279 |****************************************|\r8 -\u0026gt; 15 : 1136 |********** |\r16 -\u0026gt; 31 : 695 |****** |\r32 -\u0026gt; 63 : 606 |***** |\r64 -\u0026gt; 127 : 638 |***** |\r128 -\u0026gt; 255 : 424 |*** |\r256 -\u0026gt; 511 : 271 |** |\r512 -\u0026gt; 1023 : 580 |***** |\r1024 -\u0026gt; 2047 : 277 |** |\r2048 -\u0026gt; 4095 : 674 |****** |\r4096 -\u0026gt; 8191 : 979 |********* |\r8192 -\u0026gt; 16383 : 347 |*** |\r16384 -\u0026gt; 32767 : 18 | |\r32768 -\u0026gt; 65535 : 6 | |\r65536 -\u0026gt; 131071 : 0 | |\r131072 -\u0026gt; 262143 : 1 | |\r262144 -\u0026gt; 524287 : 1 | |\rusecs : count distribution\r0 -\u0026gt; 1 : 1270 |********** |\r2 -\u0026gt; 3 : 3429 |***************************** |\r4 -\u0026gt; 7 : 4695 |****************************************|\r8 -\u0026gt; 15 : 1138 |********* |\r16 -\u0026gt; 31 : 124 |* |\r32 -\u0026gt; 63 : 7 | |\r64 -\u0026gt; 127 : 2 | |\r128 -\u0026gt; 255 : 5 | |\r256 -\u0026gt; 511 : 8 | |\r512 -\u0026gt; 1023 : 4 | |\r1024 -\u0026gt; 2047 : 4 | |\r2048 -\u0026gt; 4095 : 5 | |\r4096 -\u0026gt; 8191 : 6 | |\r8192 -\u0026gt; 16383 : 4 | |\r16384 -\u0026gt; 32767 : 1 | |\rusecs : count distribution\r0 -\u0026gt; 1 : 1419 |********* |\r2 -\u0026gt; 3 : 3267 |********************** |\r4 -\u0026gt; 7 : 5819 |****************************************|\r8 -\u0026gt; 15 : 1138 |******* |\r16 -\u0026gt; 31 : 100 | |\r32 -\u0026gt; 63 : 22 | |\r64 -\u0026gt; 127 : 11 | |\r128 -\u0026gt; 255 : 2 | |\r256 -\u0026gt; 511 : 35 | |\r512 -\u0026gt; 1023 : 11 | |\r1024 -\u0026gt; 2047 : 2 | |\r2048 -\u0026gt; 4095 : 3 | |\r4096 -\u0026gt; 8191 : 4 | |\r8192 -\u0026gt; 16383 : 3 | |\rusecs : count distribution\r0 -\u0026gt; 1 : 1090 |********** |\r2 -\u0026gt; 3 : 2792 |************************** |\r4 -\u0026gt; 7 : 4143 |****************************************|\r8 -\u0026gt; 15 : 778 |******* |\r16 -\u0026gt; 31 : 64 | |\r32 -\u0026gt; 63 : 3 | |\r64 -\u0026gt; 127 : 6 | |\r128 -\u0026gt; 255 : 0 | |\r256 -\u0026gt; 511 : 0 | |\r512 -\u0026gt; 1023 : 1 | |\r1024 -\u0026gt; 2047 : 3 | |\r2048 -\u0026gt; 4095 : 3 | |\r4096 -\u0026gt; 8191 : 1 | |\r8192 -\u0026gt; 16383 : 3 | | 等待队列异常，等待时间过久。\n之后对程序从CPU剥离的函数栈进行统计，发现函数并没有固定在某个地方被剥离CPU，换言之没有固定点。最终结论\n直接原因：基于Nginx做的二次开发，本身上层应用是一个耗时很长的任务，还不会有抢占，如果在某个时刻忽然受到了大量任务的冲击，一个CPU上同时排队100个任务，最后一个任务的等待时间就是100*但个任务的耗时，从而超时。而此时，其它的CPU可能只有两个任务，所以CPU使用率不均匀。 根本问题：计算时间花费时间过久，本身每次计算耗时都要花费4-5ms，这个时间对于时间敏感型程序是不可接受的 这种属于哪哪都不行，就是慢，就很尴尬。\n可以参考的链接 # https://huataihuang.gitbooks.io/cloud-atlas/content/os/linux/kernel/tracing/diagnose_high_sys_cpu.html\nhttps://cloud.tencent.com/developer/article/1876605\n2.11 优化后分析慢的原因 # 参考工具库的12 MPMC \u0026amp; SPSC 和上面的2.10慢的原因分析，针对认为时任务调度到不同CPU，导致CPU使用率不均匀，超时设计了新的通信模型后，重新使用自定义的工具和线上软件（可以理解为Nginx）进行测试：\n自定义工具维持200/300个连接，测试，超时请求只有0.24% 线上工具测试发现结果不稳定，好的时候一个超时没有，差的时候10%都超时 重新分析，按照如下步骤\n新的通信模型可以记录每毫秒来的请求个数，打出来每毫秒创建的任务数量\n以每个请求的超时时延作为滑动窗口，将这个滑动窗口之内的创建请求数量累加，相当于原先的请求数量*滑动窗口的个数。需要绘制两种情况\n绘制线上工具测试超时很多的情况 绘制线上工具测试超时的情况 计算每个窗口内能处理的请求个数，简单来说就是\n1/每个请求计算时延*CPU核心数量*超时时延$\n将第二个拿到的图和第三个拿到的图对比一下发现，红色是超时很多的情况，绿色是超时很少的情况，红色确实出现了很多超过处理请求能力的时刻，绿色则没有达到。\n最终得出的结论，线上工具打请求冲击过快。。。\n2 Half 云环境的资源限制 # 和常规的CPU使用不同，在云环境下，出现了很多新问题，因为k8s limit关键字的出现，很多新的问题爆发出来。错误地配置CPU limit，导致程序响应不及时，触发了大量的限流。可以参考有趣的BUG内容里面的21 低性能的Unix Domain Socket（一个BUG水了一堆字）。\n通过cat /sys/fs/cgroup/cpu,cpuacct/cpu.stat来确定有没有触发限流\n今天主要是想解决一个问题，TOP显示的CPU使用率能不能作为配置K8S的CPU limit的限制呢？\n3 （附加）如何安装bcc工具包到ubuntu18.04 # 安装方式有两种，一种是直接安装binary，另一种从源码编译安装。我选择从源码编译。主要是出了问题也好修复。使用源代码编译的时候还有一点要注意，首先，安装的实际上是python3的bcc，而默认安装到/usr/share/bcc/tool下面之后的各种工具，指明的语言版本都是python，需要手动更改为python3，这可能是个小坑。另外用户必须是root才能正常启用。\n一种方法是安装最新版的llvm，和最新版的github上面的bcc，这种方法要求能连接github\n安装llvm-13，之所以选择llvm 13是因为14安装的很多依赖过新，所以装llvm13。而且很多编译的工具平时开发也用，所以全安装\nwget https://apt.llvm.org/llvm.sh\rchmod +x llvm.sh\rsudo ./llvm.sh 13 all 安装bcc需要的依赖，命令如下，一部分llvm的东西已经装上了\nsudo apt install -y bison build-essential cmake flex git libedit-dev \\\rlibllvm13 llvm-13-dev libclang-13-dev python3 zlib1g-dev libelf-dev libfl-dev python3-distutils 最后从源头编译bcc，直接安装bcc binary的方式只会安装上老旧的版本，缺失部分工具\ngit clone https://github.com/iovisor/bcc.git\rmkdir bcc/build; cd bcc/build\rcmake ..\rmake\rsudo make install\rcmake -DPYTHON_CMD=python3 .. # build python3 binding\rpushd src/python/\rmake\rsudo make install\rpopd 另一种方法适用于连接不上github，只能用gitee的情况下，因为代码兼容性的问题，需要切换到旧的版本。如果能连接github，那么不需要用gitee，直接安装然后切换到v0.24.0也可以\n首先安装依赖\n# For Bionic (18.04 LTS)\rsudo apt-get -y install bison build-essential cmake flex git libedit-dev \\\rlibllvm6.0 llvm-6.0-dev libclang-6.0-dev python zlib1g-dev libelf-dev libfl-dev 接着clone bcc的代码，如果是只能连接gitee，需要把git配置内部的submodule都替换为gitee的网址。因为submodule会下载\n#git clone https://gitee.com/ershou10/bcc.git\rgit clone https://github.com/iovisor/bcc.git\r# 切换到0.24.0的版本是为了避免兼容性的问题\rcd bcc\rgit checkout v0.24.0\rmkdir bcc/build; cd bcc/build\rcmake ..\rmake\rsudo make install\rcmake -DPYTHON_CMD=python3 .. # build python3 binding\rpushd src/python/\rmake\rsudo make install\rpopd CENTOS7 的安装\nyum -y install bcc-tools\ryum -y install kernel-devel-$(uname -r) 4 BPF的学习 # 实际上上面是纯应用，但是除了纯应用的方面，我们还需要关注更基本的东西\nBPF是什么不写了，网上一堆抄来抄去\n4.1 BPF支持的插桩 # 支持动态插桩和静态插桩\n动态插桩，动态性地插桩，但是需要用户对软件函数有所了解，且不会被编译器内联处理\nkprobes 工作原理： 对于krpobe插桩，首先复制插桩地址的字节码 单步中断指令覆盖目标地址，x86_64是int3 指令执行到断点，断电处理函数检查是不是kprobe插桩。 kprobe插桩是的话就执行krpobe函数 原始指令继续执行。当不需要kprobe时，再把原始的字节内容放回去 对于kretprobe 对入口做kprobe插桩，如果入口命中，将返回地址保存并替换为蹦床函数 在返回的时候，跳到蹦床函数。如果不需要就移除蹦床 uprobes：用户态动态插桩 工作原理：和krpobe基本一致 静态插桩，静态插桩需要由开发者维护，就比较麻烦，一般是推荐用户优先用静态\ntracepoint USDT 工作原理，在USDT探针的地址放置了一个not指令。插桩的事哦呼这个地址会被内核修改为一个端点指令，so damned genius 4.2 bcc和bpftrace # 一般来说，当真正使用bpf相关观测工具的时候，我推荐用户直接根据问题的需要去看bpftools来查阅相关工具。所以下面的内容实际上更针对性一种学习。\n4.1 BCC内部实现和调试 # 内部实现\n调试\n4.2 bpftrace工具的内部实现和调试 # bpf前端用lex和yacc对bpftrace编程语言做语法和此法分析，然后交给clang解析，最后丢给bpftrace程序编译成llvm中间形式，并最终编译为bpf程序。\nbpf支持很多种事件源，比方说动态插桩，静态插桩，定期事件采样，周期事件PMC事件，合成事件。目前已经存在的bpftrace工具如下图\n4.2.1 bpftrace一行编程 # 参考文档参考bpftrace one-liner tutorial和bpftrrace reference guide\n# 执行bpf程序，直到退出。所以后年的program可以是单行程序，也可以是一个.bt，即bpf执行程序\rbpftrace -e program\r#程序的内部结构往往是探针加对应的动作\rprobes { actions }\r# 可以在前面加上一些filter，类似awk的匹配替换一样\rprobes /filter/ { actions }\r# 可以通过// 添加单行主食，或者/* */添加多行主食，类似c++\r#探针格式以类型名启动，然后以冒号分割的标识符\rtype:identifier1[:identifier2[...]]\r# 举个例子\r# krpobe探针对内核太函数插桩，只用一个标识符：内核函数名字\r# uprobe探针对用户态函数插桩，需要两个标识符，文件名字和函数名\rkprobe:vfs_read\ruprobe:/bin/bash:readline\r# 过滤器\r# 变量，内置变量，临时变量，映射表变量以@前缀可以用作全局存储，在不通动作之间同步。可以提供由多个或者耽搁元素组成的ekey，将映射表作为hash表使用\r@start[tid] = nsecs;\r# 内置变量有pid,tid,uid,username,nsecs,elapsed,cpu,comm（进程名）,kstack,ustak内核调用栈和用户态调用栈，retval函数返回值，func被跟踪的函数名称，cgroup，cgroup的ID，\r# 映射表函数\r# bpftrace的探针类型\r# tracepoint内核静态插桩点，usdt用户态静态定义插桩点，kprobe，kretprobe内核动态插转和返回插桩，uprobe和ureteprobe，用户态动态插桩和返回插桩\r# profile，cpu采样，interval，周期性报告\r# bpftrace的函数\r# 给一个简单的例子\n工作原理，如何内部运作\n5 如何做性能优化 # 理解CPU架构 # 理解CPU架构就理解CPU为了加速做了哪些操作，进而就可以知道系统的性能问题出在哪里了，CPU执行指令一般分为如下几步\n取指(Instruction Fetch，IF)。 译码(Instruction Decode，ID)。 执行(EXE)。 访存(MEM)。 回写(Write Back，WB)。 这几步使用流水线的方式拆解以后，CPU会同时运行多个指令，这里流水线的性能制约为流水线冒险(Pipeline Hazards)，从而导致停顿。这三种冒险分别是\n结构冒险 数据冒险 写后读(Read-After-Write，RAW） 读后写(Write-After-Read，WAR) 写后写(Write-After-Write，WAW) 控制冒险。 为了能够起到加速的作用，现代CPU启用如下手段\n乱序执行：支持乱序执行的CPU仍必须给出相同的结果，就好像所有指令都是按程序顺序执行一样。指令在最终执行时称为退休，其结 超标量：它们可以在一个时钟周期内发射多条指令 投机执行： 控制冒险可能会导致流水线中显著的性能损失。硬件分支预测逻辑是一种避免这种性能损失的技术，用于预测分支的可能方向并从预测路径执行指令（投机执行） 为了支撑指令快速运行（避免因为访问内存造成的性能延时），CPU还会启用高速缓存，现代CPU中典型的缓存行大小是64字节。最接近执行流水线的高速缓存大小通常在8KiB到32KiB之间。在现代CPU中，层次结构中更远的高速缓存可以在64KiB到16MiB。任何层级的高速缓存的架构都由以下四个属性定义。\n高速缓存的映射方法有：\n直接映射 全关联高速缓存 组关联高速缓存 到这里我们就可以给出CPU的架构图了\nCPU前端\nCPU前端由许多数据结构构成，其主要目的是有效地从内存中获取指令并解码。步骤如下 从L1缓存获取16字节X86指令，解码转换为微操作并进入指令解码队列(Instruction Decode Queue，IDQ)。 CPU后段\n乱序(Out-Of-Order)引擎来执行指令并存储结果。 如何测量性能-通用方法 # 性能是一个很难测量的东西，因为环境噪声和“生产环境”隔离的原因，有时候测试是非常不准确的。有几种非常愚蠢的方式做自动化测量\n第一个办法是安排人员看图来比较结果，愚蠢在于人很容易因注意力不集中而错过性能退化缺陷，只会关注大的退化 第二个办法是设定一个简单的阈值门限，比低一点好一些，这个主要糟糕在门限很难确定 一些开源软件使用了一些其它方法做限制，比方说mongodb的evergreen或者autoperf使用pmc\n因为自动化的问题，导致我们常常需要使用手动化测试，手动化测试问题也很多需要多次运行基准测试，这样基线程序有N个测量值，改动过的程序也有N个测量值。这样子画出统计图能够发现基准测试的问题，比方说双峰问题代表缓存或者锁。一般我们也会采用箱形图。\n测量性能时有两种计时器\n系统级高分辨率计时器 它是一个系统计时器，通过统计自某任意时间（称为Epoch）起开始流逝的嘀嗒数而实现。该时钟是单调递增的。系统计时器的分辨率是纳秒级的，这个运行比较慢，访问一次需要200个CPU Clock 时间戳计时器(Time Stamp Counter，TSC)这是一个通过硬件寄存器实现的硬件计时器。TSC也是单调递增的，并且以固定速率增长，也就是说它与频率无关。这个运行比较快，访问一次也就20个CPU Clock 因此，我们的测量说白了就是利用多种计时器来针对性的分析，常见的技术手段为\n代码插桩：让开发者观察应用程序的整体架构和流程，但它不能提供进程调度执行的频率（可从操作系统获得）或发生了多少次分支预测错误（可从CPU获得）的信息。另外插桩本身就会造成性能影响。常用软件为Intel Pin，eBPF， Trace：依赖现有的插桩，适合黑盒 负载表征：负载表征是通过量化参数和函数来描述负载的过程，它的目标是定义负载的行为及主要特征，比方说自顶向下的微架构分析(TMA)方法，它试图通过将应用程序划分为4种特征中的一类，4种特征分别为前端绑定(Front End Bound)、后端绑定(BackEnd Bound)、退休(Retiring)和错误投机(BadSpeculation) 采样：用于查找热点 发现问题 # 这里我们来到了具体的方法\n自顶向下微架构分析技术\n使用\nperf就可以分析这种问题，简单来说就是加topdown，步骤可以立即为 perf stat --topdown -a -- taskset -c 0 ./7zip-1benchmark b retiring bad speculat FE bound BE bound 首先使用perf对上层进行分析，确定具体出现在哪一端的哪个类型 确定类型之后，使用perf record记录CPU事件发生的函数时哪个，产生统计。再调用perf report \u0026amp; perf annotatie，查找具体的符号。 根据类型加解决方案，比方说预取 LBR最后分支记录。LBR可以直接在不插桩的情况下分析性能，针对基本块可以画出概率密度函数曲线，确定如何优化。另外LBR可以帮助分析热路径，即最经常执行的路径\nLBR分支记录的目的是最后跳转的路径，利用该特性可以持续地记录大量已经执行的分支跳转指令。这种方法可以快速确定调用的基本块。可以使用LBR对分支跳转指令进行采样，但是每次采样期间都需要查看LBR栈中已执行过的分支跳转指令。这可以实现比较合理的热点代码路径控制流覆盖度，并且也不会采集太多无用的信息，因为所有分支跳转指令中只有很小的一部分会被检查。使用dmesg | grep -i lbr来查看是否支持lbr。采集方法如下 perf record -b。注意及时编译的时候没有启用（通过编译选项-fomit-frame-pointer控制，默认开启）或调试信息 从Skylake架构开始，LBR条目有了Cycle Count信息，这个新增字段记录了两个被选中的分支之间的时钟周期计数。如果前一个LBR条目中的目标地址是某个基本块(BB)的开始，而当前LBR条目中的源地址是该基本块中的最后一个指令，那么时钟周期计数就是该基本块的时延。 处理器事件采样\nIntel处理器跟踪技术\n编译器优化报告：比方说clang加上参数-Rpass*参数。看看报告写的未执行的优化是怎么回事\nclang -03 -Rpass-analysis=.* -Rpass=.* -Rpass-missed=.* a.c -c 静态分析工具：比方说clang-sanitanzer\n前面了解\n定向优化 # 前面了解了相关的分析手段，下面给出一些优化的方法。指导方法请参考下图\n优化方法：\nCPU前端优化：CPU前端优化一般集中在如何确保微指令不会被丢弃上。绝大部分的真实应用程序都会有非零的“前端绑定”指标，该指标通常小于10%。如果看到“前端绑定”指标在20%左右，那么绝对值得花时间分析一下 针对hot path，将cold path标记为UNLIKELY，确保编译器优化 基本块对齐：确保循环指令（经常执行的指令）不会垮缓存行 函数拆分：等同于拆分cold path PGO：反馈式编译或者使用BOLT，这个就不多赘述了，非常经典。对llvm编译器而言，使用-fprofile-instr-generate选项编译程序，这样会告诉编译器生成插桩代码，这些插桩会在运行时采集剖析信息 TLB：大页，减少对TLB造成的miss CPU后段优化：后端优化往往是后端资源不足导致 内存绑定：当应用程序执行大量的内存访问并且花比较长的时间等待内存访问完成时，那么该应用程序会被表征为内存绑定。利用缓存空间局部性的最佳方法是按顺序访问内存。 绑核： 优化错误投机：对于常规应用程序，有5%～10%的“错误投机”率是正常的。建议是当该指标超过10%时才关注它。 用查表法替代繁多ifelse：如果有多个ifelse，比方说一个数字所在的范围，那么可能因为分支过多导致预测失败，这种建议转换为加载一个数组，对应地址直接返回数组的值，会加快速度。于在超过CPU缓存大小的大数组搜索的场景，基于分支的二分搜索版本表现得更好，因为分支预测错误导致的性能损耗相比内存访问延迟（由于缓存未命中延迟比较高）造成的更小。对于能够全部填充到CPU缓存中的小数组，情况正好相反 用断言替代分支：这里的断言是指同时执行ifelse的两条结果，直接都执行。但是这个跟执行的代价强相关。如果不行的话考虑区分likely和unlikely啥的 其它调优： 编译时计算：实际上就是直接提前计算 缓存预热： 减少慢浮点数运算 系统调优 优化多线程程序 锁争用：锁争用可以通过perf -s探查到， MESI 真共享：真共享可能会造成互相干扰，解决手段有1 使用atomic 2 使用TLS 伪共享：伪共享是因为MESI互相干扰使得县城互相打扰，因此通过内存对象对齐/填充可能会消除伪共享。参考https://joemario.github.io/blog/2016/09/01/c2c-blog/ 总结，一般思路如下\n业务架构层面 系统层优化 缓存 减少中断和系统调用 减少不必要的中断在我们写安全网关的时候是非常重要的一点：减少系统调用和缺页中断的次数！系统调用会导致上下文切换外加一些耗时的操作。举一个简单的例子：启用hugepage减少缺页中断，另一个方面很多小对象的分配和回收会导致内存空洞，这种情况下小对象应当使用slab的管理方式进行管理，减少不必要的操作。（我见过一部分的go的内存管理就是直接抄袭的slab的实现） 应用层优化 STL容器和算法性能比较与选择 去掉全局变量 受限指针 - 别名优化 条件编译和编译时优化 比方说浮点数运算等指令的“使用”是多余的，但是这种优化一般不推荐个人用户随便使用，一个很简单的例子，写代码写的是inline，只是对编译器的建议。具体是不是转换为inline代码是编译器的行为。这种情况下，自己对最终行为做出诸多假设往往不如启用编译器官方的优化：也就是 The BOLT + LTO + PGO 选择正确的第三方库 另外一种减少不必要的指令级操作指具有一定专业性的操作：举一个简单的例子，对于大数除法或者大整数求分解的问题（这种一般都是数学上的NP问题）最简单的优化方法不是自己去翻翻数论里面的理论，自己实现一套。而是使用正确的第三方库，比方说openssl而不是cryptopp，openssl的大部分除法运算都是直接参考的理论论文，做汇编级别的运算。其效率会比自己写的效率高起码十几倍。 一些竞争频繁数据结构，使用无锁的结果可能会带来一定的性能提升 使用正确的序列化，反序列化库 函数层优化 减少拷贝 针对C++而言： 函数调用参数 内联函数，inline是建议层面，优化力度也要看编译器 C++ Devirtualization，解决方法还是LTO等操作， 选择正确的数据结构 比较细枝末节的效率了，比方说boost any的效率就是比C的void*效率低。但是这种优化往往属于最末端才会考虑的优化。 还有就是参考上面给的CPU前端/后端优化 参考资料：\nhttps://juejin.cn/post/7102235375724625928\n","date":"2020 年 12 月 15 日","externalUrl":null,"permalink":"/posts/2020-12-15-%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%92%8C%E8%AF%8A%E6%96%AD/","section":"Posts","summary":"","title":"如何进行性能分析和诊断","type":"posts"},{"content":" 异步程序编写时候的一些小教训 # 前言 # 写博客是为了什么？放松脑子，构建自己的模型\n针对通俗事件的教训 # 开会的时候，应当提前就确定好：1要讨论的点，2 自己的观点，3基本观点必须遵守的原则。将无用的思考/争论时间去掉。如果必然发生讨论，那么要注意基本原则的有效和一致性。 代码的研发/BUG的报告要遵循一惯性的观点，不应当想到啥是啥。 绕开难度大的东西，去做简单的事情是一种非常取巧的事情。这种追求简单的东西看上去似乎效率高，但实际上是一种懦弱的行为。正如同\u0026quot;你面前有两条路，选择荆棘丛生的那条\u0026quot; 做事应该包含三个层面，本身层面：熟悉这东西的方方面面，横向对比和理念对比，纵向的观点 判断事情是不是要做应当包含一个对边际效应的考虑，是不是值得做，有没有效益做需要考虑，但是这个效益要怎么考虑呢？ 思考问题的方法是自顶向下还是自底向上的呢?要避免手里是个锤子，看啥都是钉子 单独针对异步的教训 # 任何内存申请，或者说明显的状态转换，乃至大的标记的转移，都需要在外部明显的标识出来，不要藏在犄角旮旯里。 对于任何说出来的结论，都要进行论证，“不理智的人扭曲事实来适应理论，而不是改变理论来适应事实”，不要过早的得出结论，要找到足够的证据证明你的猜测。 凡是参与到运算，或者说要多次采用的东西，都要保证其值不能在中间的时候发生改变，如果可能有其他线程修改，那就需要自己保存下来。 如果类似内存申请的操作，需要好几个参与，其中一个失败了，剩下的几个务必也要释放。不要留着，否则重入可能造成内存leak 针对通用程序的教训 # 程序在进行设计开发的时候应该进行良好的抽象与设计：模块化，层次化最好在一开始就保持。在进行后续代码的开发时，同样要求层次和模块的开发。层次的划分和模块的划分是重点与难点，建议看看《代码大全》 对程序的测试应当经过充分的考虑，很多时候参数的有效性是否开放是要经过考虑的。 下面三条都是看《多处理器编程的艺术》时候的教训，代码逻辑\u0026amp;现实逻辑，具体的原有看第七章TAS \u0026amp; TTAS设计实现的感想：\n代码层面我们认为逻辑一致性的东西，已经在一定程度上避免了问题的出现，但是这种层面只是问题设计的第一层面 因为代码是需要跑的，所以在实现的时候不但要考虑上层层面，还要考虑底层层面的实现，对锁而言就是缓存协议，同步等的代价 最后一个就是要养成一个从上向下，看到底层的习惯了。还得尝试提出，实现方面的抽象。 代码整洁相关的教训直接看《代码整洁之道》里面总结的代码规范，\n对代码的熟悉程度 # 什么叫做对代码的很熟悉？从我个人的角度来看，一般是以下几个方面：\n自动机中功能性的划分，能迅速找到功能划分的位置。 针对某些异常情况的处理，能迅速找到在不同步骤出异常或问题时的处理流程。 系统竞争和瓶颈所在地，能迅速找到可能导致并发 /新建问题出现的地方。 多线程或多进程同步的地方，能迅速分析清楚具体是哪种同步模型。 能够将模块中可拆分 /变化的部分迅速找到，并零件化 附加一个学习thrift的时候的经验，应当熟悉并排查常见的运用该工具所遇见的错误和导致的问题，简单来说就是编程的时候需要遵守某种规范，那么如果不遵守这种规范，会出现什么错误和问题。 类比代码，可以得出对CI/CD环境的教训\n写程序的时候要注意的 # 写一个函数，要注意把每个覆盖的路径都正确，不能只保证一部分路径\n要注意层次，每层尽量只干一件事情，同时减少只出现一次的东西被单独拿出来初始化，比方说\nconst std::string test_sets = request-\u0026gt;test_sets(); if else不要出现太多条件，如果条件超过三个，建议成为函数\n分层，拆成一层一层的观点，逐步的减少复杂度\n接口，接口尽量明确，不要出现一个string打掉所有的情况，尽量明确到具体的比方说MAP\u0026lt;Key/value\u0026gt;\n对于一些新加的函数/接口/实现，不要追求和过去完全一致，可以改变数据结构的选择，使用map等，最直接的例子就是\nmessage ListScenariosRequest { optional string filter = 1; optional string page_token = 2; optional int32 page_size = 3; optional bool trace_history = 4; optional bool include_original_scenarios = 5; // test set filter optional string test_sets = 6; // experimental scenario test filter optional bool include_experimental = 7; // scenario name regex filter optional string scenario_re = 8; // china mode filter optional bool china_mode = 9; // match labels filter optional string match_labels = 10; //这个地方就应该转换为map\u0026lt;string, string\u0026gt;来做，而不应该继续使用现在的string } 接口设计的时候要考虑数据类型的匹配，比方说map里面有key:country，value为 China/US，如果使用bool值那么只能表示中国或美国一种，但是有一种情况是map里面没有country这个key。换言之直接条件崩了，所以这个时候选择bool表示国家并不好，它表示的是中国或者不是中国，这种设计很糟糕\n针对多线程编程的教训 # 看这个链接https://www.quora.com/How-does-STL-vector-map-etc-work-in-multithreading-environments-in-C++和这个链接https://en.cppreference.com/w/cpp/container#Thread_safety。敲黑板，记住：\n读写安全但是添加删除是不安全的。实际上某个数据结构是不是线程安全的就在于可不可以将数据结构的修改/删除/插入linerable 任何使得iterator无效的操作都必须同步化，但是push_back这种倒是对前面的操作无所谓。 针对需求合理性 # 写这个是因为需求合理性经常被CHALLENGE，所以给出一个综合性的需求文档的设计。\n首先需要明确客户是谁，客户的场景是什么样子的，明确客户是谁非常重要， 这个需求究竟是客户提出来的，还是只是顺嘴提一句，SE随手加上的？很多时候SE根本就不懂这个功能，就是胡说八道，因此需要确认是不是真正的需求。（去了qcraft又一次遇到了这个问题，目前遇到的事情是要写一个qsim cache，但是qsim cache具体需要什么功能不确定） 需要明确一点，需求往往是高层的，而具体的解决方案是开发做的，要区分开这两个层面 这个需求是不是SPECIAL的呢？换言之是一个通用性FEATURE还是单独的FEATURE（就这个客户用？），通用性再考虑做。 这个需求是抄谁的？或者参考谁的？原本的场景和现在的场景哪些相同，哪些不同。是不是可以原样复制原本的解决方案？ 和我们目前的功能有没有一致性？有没有连续性方面的东西考虑？ 从实现角度考虑\n细化需求的实现难度，按照实现难度和效益进行排序。过于难/不合理的实现直接拒绝。 对于领导而言，更喜欢更简单，更直接的解决方式 从真实实现角度，在确定需求之前\n如果太难解决，就将客户的需求条列化以后和leader讨论一下 和不同的人聊天，看看这个功能有没有类似的，究竟做不做，如果做，从哪个方面做起？为什么不做？ 和QA讨论\n一个功能，对客户而言应该足够简单，简单才能有人用。 相对应的，这个网址https://www.pmcaff.com/discuss/439444879874112上面的例子很不错，下面截取了一些具体的回复。\nCarriePisces的回复\n我们不能随意抛弃任何一个需求，不管是否合理，这是基本原则。\n拿到这些需求后，做如下步骤：\n1、首先看该需求当前的版本是否满足？如果可以满足，是否比当前更优？不能满足是否有替代功能可以满足？如果满足是否可以更优？\n2、当前版本功能均不能满足的情况下，一定要跟需求提出者进行一次深入沟通（千万不要一口回绝，即使你觉得非常十分以及特别不合理），了解他提出这个需求的原因、使用场景、带来的意义等，经过反复沟通，你也许会发现有些人的需求跟第一次告诉你会有差异，这是正常的，所以需要沟通沟通再沟通，究其原因。\n3、沟通后，你大致有了自己的看法。是否要做，你这时可以结合市场分析、自身产品定位、资源配置等进行整理资料，去说服对方，并且讲明为什么现在不做这样需求。当然了，话不能讲得太满，比如“这个需求经过以下情况分析，balabala不合理，所以不做”，可以稍微改动下“这个需求经过以下情况分析，balabala目前看来是不适合做入产品的，但是这是一个好的想法，我们先纳入需求池，根据后期产品发展情况做进一步考虑，只是暂时搁置~”。毕竟，直接否决别人伤和气，再者，有些需求其实只是目前不合理，后期怎样就不一定咯~\n4、如果还是不能说服对方的话，23333333，先反省自己，分析得是否合理，语言表达是否清楚，是否有完善的数据支撑。。。如果还是不行的话，没有什么是请吃一顿火锅解决不了的，如果有，那就请吃两顿。#经费自己掏腰包哈#\n最后，作为一个产品人，真的不用轻易抛弃和鄙视任何一个需求呀，深挖出实际需求，毕竟，肯给你提需求的是关注你产品的人，不关注的人才懒得理你呢~\n嗯，瞎扯完毕。#说的不对的地方指出来哈，一起进步#\n知乎的网址也给出了具体的例子，https://www.zhihu.com/question/19804178/answer/274824703\nStep1.有效性分析\n面向哪些用户（用户有效）？ 针对哪些特定的场景（场景有效）？ 解决什么问题（痛点有效）？ Step2.可行性分析\n与产品先前的设定不出现大的反差 核心功能不能受到影响或者回退 .性价比不能太低(这个实际上就对应了成本) Step3.对比分析\n对比竞争对手 对比主流价值观 对比用户行为 这个网址也给出了一些细节https://zhuanlan.zhihu.com/p/23223059。关于具体决定需求对不对使用了一种投票的手段，很不错。\n如何编写文档 # 无论是廖雪峰还是外网的文档，都是从具体规范和格式角度编写文档，而我总结的文档规范主要从内容角度出发。下面给出文档编写流程中的常见考虑方法\n首先需要标准化技术术语，避免出现由于中文互联网的不准确性和语义的复杂性导致的错误意义（举个简单的例子，HASH算法中的压缩函数本来应该只是参与计算的一个流程，而有人把HASH本身成为压缩函数）\n对文档阅读者建模，主要从以下几个角度来考虑：谁阅读这篇文档，阅读者的教育水平（对专业知识的了解），因此哪些部分要详细？\n如果文档当中有客户的需求，要说出来客户最开始的原始需求是什么，需求经过了什么变化，为什么会有这种变化，多方需求要写清楚每一方的变化。\n如果文档中有原有功能的局限性，这个需要写具体局限性体现在哪个方面，该功能处于哪一层，为什么要在本层做，便利和优势有哪些，灵活性为什么这样子考虑。\n如果文档为设计文档，当中需要有detailed description，务必写清楚我们解决的问题是什么，功能实现的手段，我们做的工作是什么。为了能够方便快速地理解，需要文档编写者遵循一定地框架进行描述：1 分层描述，每层具体提供了什么功能，可以依托现有协议地层次，或者依托功能划分地层次进行描述；2 给出每一层我们依赖地第三方/基础功能，并说明每层对上层提供地保证和利用的下层的依赖。层次之间的够通也需要说清楚。\n如果文档针对QA，那么需要给出TestConsiderration，如果是针对开发，要写清楚连贯的逻辑和准则，如果是针对用户，需要给出详尽的使用流程。这里使用流程要说明白，包括详尽的命令提示信息，帮助信息，测试CASE覆盖等多个方面。\n上面的部分覆盖了编写的思路，具体的内容我觉得我司的文档模板就写的很不错，包括以下部分：1.1. Problem Statement：；1.1. High Level Overview of this Feature/Function；2. External Requirement；2.1. Customer Requirement；2.1. Usage Scenario；3. Competitor Analysis；4. Function Specification；4.1. Detailed Description of this Feature/Function；4.21.1. Scalability and Performance Target；4.3 Dependencies and Considerations 4.4 Future Enhancements (Optional)；5. User Interface 6 Backward Compatibility 7 Platform Support (Optional) 8 Packaging Consideration 9 Security Consideration 10 1. Testing Consideration 11. Troubleshooting Consideration 12 . Issue and Limitation Reference主要是参考\n下面的各个部分并不单独针对需求/设计文档，是通用的文档内容。下面列出来详尽的每个部分该写些什么内容。\n1.1. Problem Statement: 1. Is there any background information for this problem? 2. What is the problem we are trying to solve? 3. Is there any specific information from customers? 1.2.\tHigh Level Overview of this Feature/Function : [This section should cover the high-level function description.] 2.1 Customer Requirement:[This section should cover the details of the customer requirements.] 2.2. Usage Scenario : [This section should cover the usage/configuration steps from the user perspective.] 3.1 Competitor Analysis:\\1. Which competitors to compete with?\\2. What is the developing status of the industry and competitors?\\3. What have the competitors done to meet the same or similar customer requirement?\\4. What are their solution’s advantages and disadvantages? 4.1.\tDetailed Description of this Feature/Function: [This section should cover the following contents: issues with system integration, memory, reliability, forward and/or backward compatibility, etc.] 4.2. Scalability and Performance Target \\1. Does this feature have any scalability or performance target?\\2. What are the settings of external parameters and limits for this requirement? 4.3.\tDependencies and Considerations: \\1. What versions of ArrayOS need to support this feature?\\2. Does this feature have a client component, and what are the supported client OS? 3. Does this feature require any integration with HA, Clustering, Webwall, Client Security, etc,? 4.4.\tFuture Enhancements (Optional)\\1. What is still missing for a complete solution? \\2What needs to be done to improve the usability or performance? 5.1 System Administrator [This section should cover the following contents:What does the end user see/experience, for example Array Client UI, Authorization, Portal theme, etc.] 6.1 Backward Compatibility 7.1 Platform Support (Optional)[This section should cover the following contents: Feature Matrix for clients or servers, etc.] 8.1 Packaging Consideration[This section should cover the following contents: How the software can be delivered to the target machine. Is feature control, additional or special HW required? If no, input “None” here.] 9.1 Security Consideration 10.1 Testing Consideration [This section should cover the following contents: Test requirement, equipment, setup, and test scenarios for black box testing. If no, input “None” here.] 11.1 Troubleshooting Consideration [This section should cover the troubleshooting methods or tools, etc.] 12.1 Issue and Limitation [This section should cover the existing issues and known limitations from the external perspective.] 13.1 Reference 各种RFC之类的资料 如果是设计文档，那么在detailed description里面还得加上：[Input the text here.\nThis section describes the high-level software architecture design/implementation of the internal and detailed external programming interface (API), even with ported codes.\n*In addition, the following information MUST be provided if any:*\n*1. Platform:* List which platforms this feature/function will be supported on.\n*2. Boundary conditions:* Should list some maximum numbers related to this feature/function, such as the maximum number of users.\n*3. Error handling:* Should state how errors are handled.\n*4. Security:* Security considerations are an important part of a project. We should detail possibilities of abuse of the system.]\n*A separate* *Design Document for more detailed internal design can be referenced in case more design details is required,* *such as internal data structure, flow chart, algorithm used, exact* *code, etc.*]\n# 一些学习到的常见的小技巧 # 位运算 # 最常见的例子应该是linux内核的GFP_ZONE_TABLE，如果ZONES的个数小于8，那么GFP_ZONES_SHIFT为3。具体的看代码每一个OPT_ZONE_XXX实际上就是存在情况下的ZONE_XXX，因此我们能看出来，那么我们可以看到，每个___GFP_XXX对应了一个左移的次数，不同的ZONE对应不同的左移的位数，当找需要计算的GFP_ZONE的时候，需要先获取GFP_FLAGS的低四位。 低四位就是计算的时候想要的___GFP_XXX然后将GFP_ZONE_TABLE右移bit*GFP_ZONES_SHIFT位，最后用(1 \u0026lt;\u0026lt; GFP_ZONES_SHIFT) - 1将具体的ZONE的个数的为都置为1。然后取出来一样的。如果还有不明白的建议看这个网页https://richardweiyang-2.gitbook.io/kernel-exploring/00-memory_a_bottom_up_view/12-gfp_usage\nZONE_XXX VALUE ZONE_DMA 0 ZONE_DMA32 1 ZONE_NORMAL 2 ZONE_HIGHMEM 3 ZONE_MOVABLE 4 ZONE_DEVICE 5 #define GFP_ZONE_TABLE ( \\ (ZONE_NORMAL \u0026lt;\u0026lt; 0 * GFP_ZONES_SHIFT)\t\\ | (OPT_ZONE_DMA \u0026lt;\u0026lt; ___GFP_DMA * GFP_ZONES_SHIFT)\t\\ | (OPT_ZONE_HIGHMEM \u0026lt;\u0026lt; ___GFP_HIGHMEM * GFP_ZONES_SHIFT)\t\\ | (OPT_ZONE_DMA32 \u0026lt;\u0026lt; ___GFP_DMA32 * GFP_ZONES_SHIFT)\t\\ | (ZONE_NORMAL \u0026lt;\u0026lt; ___GFP_MOVABLE * GFP_ZONES_SHIFT)\t\\ | (OPT_ZONE_DMA \u0026lt;\u0026lt; (___GFP_MOVABLE | ___GFP_DMA) * GFP_ZONES_SHIFT) \\ | (ZONE_MOVABLE \u0026lt;\u0026lt; (___GFP_MOVABLE | ___GFP_HIGHMEM) * GFP_ZONES_SHIFT)\\ | (OPT_ZONE_DMA32 \u0026lt;\u0026lt; (___GFP_MOVABLE | ___GFP_DMA32) * GFP_ZONES_SHIFT)\\ ) 优先级 # linux的实时程序和普通进程的优先级很有趣，用了一种超级简单的方式来区分这两种进程的优先级：\n实时程序用的优先级是weight = 1000 + p-\u0026gt;rt_priority; 而普通程序就是简单的weight = p-\u0026gt;counter;if (!weight) goto out; weight += 20 - p-\u0026gt;nice;。所以如果该进程的时间片耗尽，那么就讲优先级置成0，在本轮调度中没有机会了。这个方法实际上在《现代操作系统》里面有说。 现在让我们回忆一下操作系统几种常见的调度方式：\n最短作业方法 FIFO 最短剩余时间 结尾 # 唉，尴尬\n","date":"2020 年 12 月 15 日","externalUrl":null,"permalink":"/posts/2020-12-15-%E5%BC%82%E6%AD%A5%E7%A8%8B%E5%BA%8F%E7%BC%96%E5%86%99%E6%97%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%95%99%E8%AE%AD/","section":"Posts","summary":"","title":"异步程序编写时候的一些小教训","type":"posts"},{"content":"","date":"2020 年 12 月 9 日","externalUrl":null,"permalink":"/tags/%E5%86%85%E5%AD%98/","section":"Tags","summary":"","title":"内存","type":"tags"},{"content":" 阅读内核程序员的smp技术 # 前言 # 这本书实际上叫做《现代体系结构上的UNIX系统-内核程序员的对称多处理和缓存技术(修订版)》这本书我才刚刚看完，下面打算看电子版书籍《内存模型和缓存一致性》与《多处理器编程的艺术》。我第一次看的时候没注意第一三部分，主要注意了第二部分。\n第一部分\u0026ndash;高速缓存系统 # 第一部分讲解了两种高速缓存系统和其写策略：直接映射高速缓存和N路组相连高速缓存系统，与常用的写策略：写直通，写回和写分配。接着通过介绍纯虚拟高速缓存，到键虚拟高速缓存再到物理高速缓存系统执行上下文切换/fork/exec等操作时候的困难和优势，介绍了为什么目前常见的硬件都是讲虚拟高速缓存和物理高速缓存相结合的策略-避免出现重名和歧义的问题，而且物理高速缓存有总线监视等搞笑手段。最后指出了三种提高高速缓存效率的方法：地址空间布局，延迟高速缓存无效和缓存对其的数据结构。最后一种方法是对应用程序最直接的方法，前两种实际上对应用程序是透明的。\n映射相关的基础知识：\n直接映射高速缓存指的是：在保存高速缓存的地址中，以散列算法计算地址只能算出来每行仅拥有且仅有一个索引（换言之直接映射地址）。由于高速缓存有限，因此会出现多个地址命中的情况，因此还需要标记位+地址来表示是否命中 直接映射高速缓存的散列算法：最常用的散列算法就是取模，一般会将一个地址拆成三个部分：1 低地址为选择行中的字节，选择行的字节个数和高速缓存每行（块）的大小一致 2 高速缓存行号，连着选择行的地址为高速缓存行号，个数和高速缓存行的个数一致 3 剩下的高地址没什么直接用处 所谓高速缓存着色，指的是不同的地址映射到相同的高速缓存行上。如果高速缓存发生了缺失，那么就会触发突发模式（burst mode)读取一个高速缓存行。但是索引命中比较聚集，多个不同地址，被映射到同一个缓存行，触发频繁的读写就会导致高速缓存颠簸。 写策略：\n写直通：是当cache写命中时，cache与主存同时发生写修改。 写回：当CPU对cache写命中时，只修改cache的内容不立即写入主存，只当此行被换出时才写回主存 上面的简介都是单台机器上的缓存概念，那么到了多处理机，换言之SMP，问题就发生了改变。\n这种情况下就出现了一个问题，多处理机\n第二部分\u0026ndash;多处理器系统 # 这一部分考虑了主从系统内核，支持自旋锁的内核，采用信号量的内核等面对争用的解决方式，我个人觉得这部分实际上已经可以不看了。因为很多只要看linux内核里面的锁，互斥量等东西就能理解到。\n第三部分\u0026ndash;带有高速缓存的多处理器系统 # 第三部分讲述了在SMP体系下，面对缓存不一致问题的解决。并介绍了缓存一致性和顺序一致性协议，实际上这部分同样也不是很值得看，不如直接看《A Primer onMemory Consistencyand Cache Coherence》\n结语 # 这本书作为一本入门书籍比较合适，其他方面可能比《C++并发实战》还是要差一些，对于内存的解释相比较而言还是并发实战更好一些。\n多处理机系统概述的一些要点 # 临界区，竞争条件的概念就不多说了。在书籍《linux内核设计与实现》上说过了。 单机系统下，也会出现竞争条件，比方说“短期互斥”，“中断互斥”，“长期互斥”。对于unix内核而言，因为不存在内核抢占，所以短期互斥很难出现，但是linux内核可以内核抢占，如果内核操作同一数据结构，就会出现短期互斥。中断互斥指的是中断跟新了非中断代码（基准代码），对于这种东西我们在内核里就该直接关中断，可以参照缺页中断的处理。长期互斥，一般是指文件操作，因为文件IO一般比较长，因此文件IO的时候，会让出CPU。即CPU会调用sleep和wakeup函数。这块让我想起来了虚拟内存了。 SMP系统可就没有UP系统(单机系统)那么简单了，短期互斥UP系统的同一时刻只有一个进程运行的条件自动被破坏了，中断互斥也被破坏 下面三章提出的方法都是非抢占式内核针对SMP系统的解决方式 主从处理机内核的一些要点 # 主从处理机将关键代码放到主处理器执行，这些操作包括缺页中断，算数异常。\n两个或两个以上处理器彼此享有对方需要的资源，又彼此等待不可抢占就会触发死锁。比方说一个数据结构的两个元素在两个不同的自旋锁上，这就是AB-BA死锁。值得注意的是，对于非抢占式内核，在已经有一个cpu占有自旋锁的情况下，所有cpu再次竞争自旋锁也可能触发死锁。因为忙等不可释放 这种模式下，性能很容易出现瓶颈 采用自旋锁的内核的一些要点 # 锁的粒度是个值得争论的东西，一方面要考虑性能，另一方面要考虑语意的简洁名了。如果CPU的数量很少，那么一个巨大的自旋锁可能和多个自旋锁的情况一致。也得考虑系统是IO密集还是计算密集 在多处理机上因为使用sleep/wakeup导致的多进程对锁的争夺和颠簸，称为惊群效应，这种操作可以通过使用wakeup_one来解决。 采用信号量的内核的一些要点 # 为什么信号量比sleep/wakeup更高级？因为信号量阻塞的决定和阻塞进程的操作都是原子操作，也支持一次仅唤醒一个进程的操作。 为什么中断不能使用信号量，因为中断处理程序没有进程现场，P操作是无法阻塞进程的 同一个信号量多次P，并不一定会死锁，因为V由其他进程执行。但是如果试图一次预留多份资源，会触发死锁。两个进程都想获取四分资源里面的三分，每个都获取两个，那么获取第三个时候就会死锁。一般都是通过每个进程释放它占用的那部分资源来避免死锁。银行家算法。 内核的部分基础知识 # 造成并发执行的原因，很多：\n如何防止死锁？\n内核同步方法，务必注意，锁保护的是数据而不是代码：\n自旋锁，持有自旋锁的时间最好小于信号量带来的问题即两次上下文切换的耗时。自旋锁可以用在中断处理程序里，中断处理程序在获取锁之前，务必禁止本地（也就是这个CPU上）中断，否则中断处理程序会打断持有锁的内核代码，而中断程序如果尝试抢占这个锁的话，那么中断程序就会自旋，从而导致死锁。如果中断发生在别的处理器上没问题。按照知乎的答案，两个上下文切换的时间消耗大概是7微妙，微妙是10的负六次方，而系统调用是200ns。注意！自旋锁是禁止抢占的！单处理器下同样需要自旋锁保护关键数据。 信号量，信号量的问题是带来两次明显的上下文切换，被阻塞的线程要执行换出和换入。因此信号量适合等待时间比较长的进程 互斥量，互斥量就是值为1的信号量。 BLK大内核锁： 顺序锁： 顺序/屏障 中断\n缺页中断流程\n结尾 # 唉，尴尬\n","date":"2020 年 12 月 9 日","externalUrl":null,"permalink":"/posts/2020-12-09-%E9%98%85%E8%AF%BB%E5%86%85%E6%A0%B8%E7%A8%8B%E5%BA%8F%E5%91%98smp%E7%9A%84%E4%BF%AE%E5%85%BB/","section":"Posts","summary":"","title":"阅读内核程序员的smp修养","type":"posts"},{"content":"","date":"2020 年 12 月 8 日","externalUrl":null,"permalink":"/tags/libevent/","section":"Tags","summary":"","title":"Libevent","type":"tags"},{"content":" USTACK系统是怎么做到高性能的 # 前言 # 这东西写起来实际上并不简单，但是毕竟都做这个了，难免得研究研究。就好像评价一台电脑，不是单纯说显示器好，那这台电脑就无与伦比了。需要多个方面来评价，还要综合各种类别。\n总述 USTACK是个什么系统 # USTACK系统本质来说就是个综合Reactor和Proactor模式的服务器，以下几个方面的东西只针对TLS层面和系统层面，不能保证面面俱到，点列好以后，下面会一条条的说。\n缓存 缓存包含两个层面，一个是数据层面:常用数据驻留内存，计算或者拷贝时直接利用，SSL证书和90x错误页面为典型例子。避免频繁的读取或者写入内存。另一方面是内存层面：常用数据结构缓存，或者以SLAB结构存取在系统内部，方便使用。每个CPU还绑核，减少缓存颠簸。 系统拆分 系统根据网络协议层或者任务功能划分成不同部分，比方说四层TLS层握手功能，和负载均衡服务器的选择分属不同模块。使用的时候，每个层面遵从最快服务原则，即尽快返回结果或者\u0026quot;在计算\u0026quot;状态。 计算/Verify任务拆分 系统尽量不去进行耗时过长的计算/verify任务，比方说对OCSP服务器的访问，对CLIENT cert的验证，都是放在了单独的进程CERTM里进行。CERTM进程的执行目前实际上还有问题。 计算层面简洁操作 这个计算层面简介操作实际指，采用最快的计算方式/trick减少自动机的状态转换，简化自动机流程。 尽量减少上下文切换 常见的上下文切换比方说用户态/内核态切换，中断上下文切换。USTACK系统两个层面都遇到了，用户态/内核态切换通过用户态DPDK使用。中断上下文切换的解决以SSL硬件卡支持为例，系统采用轮训方式去检查数据计算请求是否完成，从而将任务挪出队列。 尽量减少锁竞争 尽量减少锁竞争存在两个方面，每个线程尽量使用自己内部数据结构，如果必须要多线程同时操作，那么采用细粒度锁。前者例子是负载均衡模块的各种算法比方说RR，就是单线程内部检查。后者以TLS SESSION链表为例。 缓存层面 # 数据缓存层面比较直接，诸如证书OCSP_STAPLING结果之类的内容直接以M_BUF形式存储于vhost的数据结构中。\nstruct mbuf *ocsp_stapling[MAX_DOMAIN_NAMES+1]; struct mbuf *ocsp_stapling_ecc[MAX_DOMAIN_NAMES+1]; 内存缓存就得看ATCP_ZONE的实现了，要考虑的问题是不同线程怎么申请释放，碰撞如何解决，还有SLAB着色问题如何解决。这部分不多说了，看ATCP ZONE设计就可得。\n系统拆分 # 系统拆分是一个非常常见的方法，SSL层计算椭圆曲线点乘最慢，因此送卡之后就直接返回让系统去做别的事情。前面VS握手结束，选择后台RS，调用负载均衡模块进行算法选择。每次都以最快恢复为第一目标。\n计算/Verify任务拆分 # 这部分以CERTM进程例子最为显著，无论访问OCSP服务器还是查询OCSP STAPLING消息亦或验证证书有效性，都会拆分出来，实现简单是一方面，另一方面一个进程出错不会干扰另一个进程，CERTM的CORE我也修过好几个了。目前CERTM还是功能太复杂，仍需要简化。\n尽量减少上下文切换 # 这个以SSL card交互为例子最合适，SSL卡频繁中断会打断当前进程的上下文，干扰进程执行。最终我们决定通过采用轮训方式检测卡是否运转完成。enqueue请求时会将item的回调函数赋值为ssl_hw_out，然后把请求扔到per atcp的队列里。然后大循环会每次检测每个命令是不是需要poll_out，调用顺序为clicktcpintr_real==\u0026gt;ssl_card_poll_smp();==\u0026gt;ssl_card_poll_generic==\u0026gt;SslHw_PollResult\n尽量减少锁竞争 # 锁竞争以SESSION CACHE为立即比较合适，锁共#define SSL_SC_LOCK_GRAIN_SIZE ATCP_MAXTHREADS个，每个SESSION CACHE和session_id一样#define SESSION_CACHE_KEY(sp) (*((uint32_t *)((sp)-\u0026gt;session_id)))。哈希表同样由LOCK保护，只不过此时找的锁稍微大一些#define SSL_SC_KEY(sp) ((SESSION_CACHE_KEY(sp) \u0026amp; SSL_SC_HASH_SIZE ) % SSL_SC_LOCK_GRAIN_SIZE)，然后把新的HASH值插入hash表。如果L4_atcp数量少于锁的数量，实际上碰撞会继续减少。\n下面看看负载均衡的链表，\n结尾 # 唉，尴尬\n","date":"2020 年 12 月 8 日","externalUrl":null,"permalink":"/posts/2020-12-08-ustack%E7%B3%BB%E7%BB%9F%E6%98%AF%E6%80%8E%E4%B9%88%E5%81%9A%E5%88%B0%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84/","section":"Posts","summary":"","title":"USTACK系统是怎么做到高性能的","type":"posts"},{"content":" 阅读Libevent/libuv源码 # 前言 # libevent 阅读的文档是：\n这篇讲的很简陋https://github.com/libevent/libevent.git 讲的很不错的文档：https://github.com/balloonwj/CppGuide/tree/master/articles/libevent%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90 官方文档：http://www.wangafu.net/~nickm/libevent-book/ 这篇入门文档讲的很不错http://senlinzhan.github.io/2017/08/12/libevent/ libevent是reactor模式代码的静态库，使用的时候需要先将reactor即struct event_base *event_base_new(void);初始化，然后初始化对应的event并挂到event_base上，然后执行的线程再执行event_base_loop不断检索是否有注册事件触发，如果有事件再调用相应的回调并触发。需要注意的是，eventloop只能在一个线程执行检查是否有事件ready的loop，如果想多线程执行loop只能每个线程一个eventbase。event_base_dispatch() 和event_base_loop()一样，只不过没设置flag。Thus, it keeps running until there are no more registered events or until event_base_loopbreak() or event_base_loopexit() is called.\n#define EVLOOP_ONCE 0x01 //event_base_loop会等待激活事件，然后处理当前批次的激活事件，然后返回，也就是说只执行一次 #define EVLOOP_NONBLOCK 0x02\t//event_base_loop不会等待激活事件，而是每次执行的时候检查是不是有事情就绪，如果有就执行相对应事件的回调函数。完成工作后,如果正常退出, event_base_loop()返回0;如果因为后端中的某些未处理 错误而退出,则返回 -1。 #define EVLOOP_NO_EXIT_ON_EMPTY 0x04 int event_base_loop(struct event_base *base, int flags) { while (any events are registered with the loop, or EVLOOP_NO_EXIT_ON_EMPTY was set) { if (EVLOOP_NONBLOCK was set, or any events are already active) If any registered events have triggered, mark them active. else Wait until at least one event has triggered, and mark it active. for (p = 0; p \u0026lt; n_priorities; ++p) { if (any event with priority of p is active) { Run all active events with priority of p. break; /* Do not run any events of a less important priority */ } } if (EVLOOP_ONCE was set or EVLOOP_NONBLOCK was set) break; } } 具体的操作对象是struct event，Events have similar lifecycles. Once you call a Libevent function to set up an event and associate it with an event base, it becomes initialized. At this point, you can add, which makes it pending in the base. When the event is pending, if the conditions that would trigger an event occur (e.g., its file descriptor changes state or its timeout expires), the event becomes active, and its (user-provided) callback function is run. If the event is configured persistent, it remains pending. If it is not persistent, it stops being pending when its callback runs. You can make a pending event non-pending by deleting it, and you can add a non-pending event to make it pending again。\nlibuv的文档为：\nhttps://luohaha.github.io/Chinese-uvbook/source/introduction.html 中文文档 http://docs.libuv.org/en/v1.x/ 官方文档 结尾 # 唉，尴尬\n","date":"2020 年 12 月 8 日","externalUrl":null,"permalink":"/posts/2020-12-08-%E9%98%85%E8%AF%BBlibevent%E7%BD%91%E7%BB%9C%E5%BA%93/","section":"Posts","summary":"","title":"阅读Libevent网络库","type":"posts"},{"content":"","date":"2020 年 10 月 27 日","externalUrl":null,"permalink":"/tags/linux-kernel/","section":"Tags","summary":"","title":"Linux Kernel","type":"tags"},{"content":" 内存学习(3) # 内存过程的锁(们) # 我们今天来看看do_page_fault中的锁，为什么要看这东西？平时老说什么死锁，互相抢占，不释放如何如何。我们来看看linux怎么避免了死锁的出现，这里我们假设面对的是SMP机器，我记得最早开始看的时候就很疑惑，首先每个线程如果都申请一块内存，怎么操作的？然后就是说页表是怎么同步的？这都是我当时的问题。\n一开始预取mm-\u0026gt;mmap_sem(信号量说白了也就是个内存里的值，所以预取是没问题的)，然后判断是不是user_mode_vm或者(regs-\u0026gt;flags \u0026amp; X86_EFLAGS_IF异常开中断。这里需要注意这里如果是不同的不同的线程，那么获取的task_struct是不同的，但是所指向的mm_struct是相同的。同一个自旋锁的入口，总能保证只能有一个抢到，但是这里是读写信号量，可以进来多个读尝试。这里保证了可以有多个任务(task)进来。对于页表的保护必须必须通过自旋锁。 尝试获取读写信号量(为什么使用？确保当前进程获取写锁没有已经抢占了该信号量)，如果直接获取了长生命周期的信号量，调用might_sleep函数，检查可不可以发生内核抢占，这里内核抢占的条件和《linux内核设计与实现》P53完全一致，检查need_resched函数，同时检查检查preempt_count的值，也就是当前使用锁的个数是否为0。如果锁争用失败，而且当前地址是系统调用的地址，那么直接调用down_read函数去等待。为什么要检测这个东西？这是因为down_read_trylock函数成功的情况下可能是已经获得了锁。这里还有个很有意思的事情，这里是read_lock，为什么要read_lock？立刻让尽量多的task进来修改不同的vma，只需要保护vma，没什么问题。那么什么时候对mmap_sem做写抢占呢？munmap就会做这种事情，为什么munmap要做这事？倒是不难理解，毕竟大块操作可能涉及到很多vma。 从当前函数调用expand_stack===\u0026gt;expand_downwards，中调用anon_vma_lock(vma);锁住vma的自旋锁，操作完毕释放再释放自旋锁，保护vma。这里要修改所以加了锁，前面查找的时候加锁了吗？并没有。有没有同时两个进程修改vma呢？不可能，那么为什么vma还要加锁呢？实际上点进去看，可以发现这个锁操作实际上是vma-\u0026gt;anon_vma-\u0026gt;root-\u0026gt;lock，保证同时只有一个修改这东西。 从expand_stack返回之后，释放掉了vma的锁。然后alloc_pud \u0026amp; alloc_pmd中都锁住mm的保护线性区和页表的自旋锁，spin_lock(\u0026amp;mm-\u0026gt;page_table_lock)。这里注意，这几个都存在内存屏障smp_wmb，这里为什么需要写内存屏障？SMP系统，缓存一致性协议保证每个CPU看到的缓存是一样的，但是即使分配操作成功，对于new的赋值很可能不会立即发生，pgtable_t new = pte_alloc_one(mm, address)，这里使用内存屏障保证所有的CPU看到的缓存和内存是一致的。rmb和wmb的是两种不同的内存屏障，分别对应于load和存储。这里需要注意的是，锁只能保证顺序执行，不能保证锁之外，返回值被写回内存立刻发生。后面还得再多赘述一句volatile。 最后__alloc_pages_nodemask，这里锁的情况比较复杂。如果是split_lock，那就使用page的lock，否则使用mm-\u0026gt;page_table_lock，锁住这个自旋锁。注意此时我们可以对当前vma做修改。分配出来anon_vma之后，立刻锁住改anon_vma-\u0026gt;lock，如果!(flags \u0026amp; FAULT_FLAG_WRITE)，那一开始不会抢锁，回去抢zone的lock。 mm = tsk-\u0026gt;mm; prefetchw(\u0026amp;mm-\u0026gt;mmap_sem); /* struct rw_semaphore mmap_sem 也就是说这是在预取一个读写信号量 */ if (user_mode_vm(regs)) { local_irq_enable(); /* 开中断 */ error_code |= PF_USER; } else { if (regs-\u0026gt;flags \u0026amp; X86_EFLAGS_IF) local_irq_enable(); /* 开中断 */ } ... if (unlikely(!down_read_trylock(\u0026amp;mm-\u0026gt;mmap_sem))) { /* 如果此时，锁被征用，返回0。成功获得放回非0值*/ if ((error_code \u0026amp; PF_USER) == 0 \u0026amp;\u0026amp; !search_exception_tables(regs-\u0026gt;ip)) { bad_area_nosemaphore(regs, error_code, address); return; } down_read(\u0026amp;mm-\u0026gt;mmap_sem); /* 如果锁征用失败了，回到这里来 , } else { /* * The above down_read_trylock() might have succeeded in * which case we\u0026#39;ll have missed the might_sleep() from * down_read(): */ might_sleep(); } 说点内存屏障和voliate # 多线程环境下，类似下面的条件并不能保证flag被不被优化掉，编译器优化可能把单线程执行的flag判断为不会变化，也就是说很可能if (flag == true)会直接被优化成死循环。此外如果多线程环境下，其他线程做了什么事情，再修改flag，并不能保证flag之前的指令先执行(没错我说的就是乱序执行)。\nflag = false; while (true) { if (flag == true) { apply(value); break; } } 说说小结论 # 这块内存申请简直是多锁操作的典范，用锁来保护关键数据，用内存屏障来保证有依赖的执行顺序。每个锁只在自己的最小范围内进行操作。使用内存屏障保证关键操作不会出现缓存和内存不一致的情况。这里典型的锁之内的顺序不用担心，锁之外的指令如果有明显的顺序依赖最好加个内存屏障。\n结尾的闲言碎语 # 写到这里差不多就可以结束了，就不多说了。 ","date":"2020 年 10 月 27 日","externalUrl":null,"permalink":"/posts/2020-10-27-%E5%86%85%E5%AD%98%E5%AD%A6%E4%B9%A03--%E9%94%81%E4%BB%AC/","section":"Posts","summary":"","title":"内存学习(3)--锁(们)","type":"posts"},{"content":"","date":"2020 年 10 月 15 日","externalUrl":null,"permalink":"/tags/openssl/","section":"Tags","summary":"","title":"OPENSSL","type":"tags"},{"content":" OPENSSL源码阅读 # 前言 # 原先写的几个都只是写了自动机，今天来看看多线程和异步。我们今天重点就是看看OPENSSL怎么做，这么做的好处与问题，锁的粒度等问题。实际上服务端s_server并不支持多线程，libcrypto支持多线程，所以对于S_SERVER我们重点看异步的做法，看libcrypto的多线程到底做了些什么。\n前置知识 # OPENSSL的ASYNC JOB就是使用协程+per thread局部变量的概念实现的，我们需要理解协程的基本概念，协程是个什么东西？\n# 多线程是怎么竞争的，竞争哪些内容？ 异步是怎么做的？我们以S_SERVER为例，启动的选项为-nbio_test和-nbio。nbio的socket type为SOCK_STREAM 任务队列是怎么做的？(因为异步就是一个事情发现没法直接做完，那就先去做别的事情。这就是任务队列) OPENSSL大量使用per-thread内部局部变量，即调用函数phread_key_create创建pthread_key_t类型数值，每个线程再调用pthread_setspcific()和pthread_getspecific()去初始化线程内局部变量。OPENSSL调用ossl_init_get_thread_local函数去获取per线程局部变量，根据参数决定是不是分配。\nossl_init_thread_start函数调用ossl_init_get_thread_local初始化per thread的数据，初始化成功返回1，\n说说OPENSSL的异步 # OPENSSL的异步需要调用函数ASYNC_start_job，去注册一个函数做异步操作。这里的异步操作需要返回“per 线程局部变量”ctxkey，每个线程运行时都会有自己的任务(工作)，分配器和判阻塞。每个线程调用async_fibre_swapcontext去切换当前的任务到设置好的函数，使得函数继续。ASYNC_start_job的分析我们等会再说。\nstruct async_ctx_st { async_fibre dispatcher; ASYNC_JOB *currjob; unsigned int blocked; }; struct async_job_st { async_fibre fibrectx; int (*func) (void *); void *funcargs; int ret; int status; ASYNC_WAIT_CTX *waitctx; }; async_ctx *async_get_ctx(void) { return (async_ctx *)CRYPTO_THREAD_get_local(\u0026amp;ctxkey); } 函数ASYNC_init_thread分配POOL，并初始化线程的局部变量。\n函数ossl_init_thread_start初始化并分配当前线程的per thread的本地状态thread_local_inits_st数据结构地址和空间。\n函数ASYNC_start_job首先获取当前线程的async_ctx结构，如果SSL当前有JOB，那就初始化当前ctx的运行JOB为SSL的JOB，然后判断当前JOB的状态，结束ASYNC_JOB_STOPPING，正在暂停ASYNC_JOB_PAUSING还是已暂停ASYNC_JOB_PAUSED，为什么区分这三种状态？如果当前为已暂停，往往意味着刚才是因为等待网络IO/卡的计算，再次进来是因为网络IO/卡的计算结果有数据了，要继续向下运行了。如果当前为正在暂停，意味着是某个流程调用ASYNC_pause_job来暂停当前进行的函数，比方说送卡请求，等着结果了。而结束往往是指JOB已经结束了，没必要再维持了，已经拿到结果了。\n好，继续说，判断完JOB的三种状态，就调用async_fibre_swapcontext去切换协议栈了，我们这里一般是切换到async_start_func函数，去调用我们在ASYNC_start_job传入的函数指针。这里注意啊ctx-\u0026gt;currjob-\u0026gt;func = func;传入的函数并不直接被调用，而是在函数async_start_func被交换回来。\nint ASYNC_start_job(ASYNC_JOB **job, ASYNC_WAIT_CTX *wctx, int *ret, int (*func)(void *), void *args, size_t size) { async_ctx *ctx; if (!OPENSSL_init_crypto(OPENSSL_INIT_ASYNC, NULL)) return ASYNC_ERR; ctx = async_get_ctx(); if (ctx == NULL) ctx = async_ctx_new(); if (ctx == NULL) return ASYNC_ERR; if (*job) ctx-\u0026gt;currjob = *job; for (;;) { if (ctx-\u0026gt;currjob != NULL) { if (ctx-\u0026gt;currjob-\u0026gt;status == ASYNC_JOB_STOPPING) { *ret = ctx-\u0026gt;currjob-\u0026gt;ret; ctx-\u0026gt;currjob-\u0026gt;waitctx = NULL; async_release_job(ctx-\u0026gt;currjob); ctx-\u0026gt;currjob = NULL; *job = NULL; return ASYNC_FINISH; } if (ctx-\u0026gt;currjob-\u0026gt;status == ASYNC_JOB_PAUSING) { *job = ctx-\u0026gt;currjob; ctx-\u0026gt;currjob-\u0026gt;status = ASYNC_JOB_PAUSED; ctx-\u0026gt;currjob = NULL; return ASYNC_PAUSE; } if (ctx-\u0026gt;currjob-\u0026gt;status == ASYNC_JOB_PAUSED) { ctx-\u0026gt;currjob = *job; /* Resume previous job */ if (!async_fibre_swapcontext(\u0026amp;ctx-\u0026gt;dispatcher, \u0026amp;ctx-\u0026gt;currjob-\u0026gt;fibrectx, 1)) { ASYNCerr(ASYNC_F_ASYNC_START_JOB, ASYNC_R_FAILED_TO_SWAP_CONTEXT); goto err; } continue; } /* Should not happen */ ASYNCerr(ASYNC_F_ASYNC_START_JOB, ERR_R_INTERNAL_ERROR); async_release_job(ctx-\u0026gt;currjob); ctx-\u0026gt;currjob = NULL; *job = NULL; return ASYNC_ERR; } /* Start a new job */ if ((ctx-\u0026gt;currjob = async_get_pool_job()) == NULL) return ASYNC_NO_JOBS; if (args != NULL) { ctx-\u0026gt;currjob-\u0026gt;funcargs = OPENSSL_malloc(size); if (ctx-\u0026gt;currjob-\u0026gt;funcargs == NULL) { ASYNCerr(ASYNC_F_ASYNC_START_JOB, ERR_R_MALLOC_FAILURE); async_release_job(ctx-\u0026gt;currjob); ctx-\u0026gt;currjob = NULL; return ASYNC_ERR; } memcpy(ctx-\u0026gt;currjob-\u0026gt;funcargs, args, size); } else { ctx-\u0026gt;currjob-\u0026gt;funcargs = NULL; } ctx-\u0026gt;currjob-\u0026gt;func = func; ctx-\u0026gt;currjob-\u0026gt;waitctx = wctx; if (!async_fibre_swapcontext(\u0026amp;ctx-\u0026gt;dispatcher, \u0026amp;ctx-\u0026gt;currjob-\u0026gt;fibrectx, 1)) { ASYNCerr(ASYNC_F_ASYNC_START_JOB, ASYNC_R_FAILED_TO_SWAP_CONTEXT); goto err; } } err: async_release_job(ctx-\u0026gt;currjob); ctx-\u0026gt;currjob = NULL; *job = NULL; return ASYNC_ERR; } 函数async_ctx_new初始化并分配当前线程的per thread的本地状态，调用ossl_init_thread_start初始化thread_local_inits_st数据结构地址和空间。之后初始化per thread的async_ctx_st结构，每个ctx的结构。\n函数async_get_pool_job从pool里获取一个job，获取本地pool，如果pool为空还要再分配per thread的工作pool。从pool中pop出最后进栈的job，如果没有job，就调用async_job_new分配一个新工作，然后调用async_fibre_makecontext初始化协程的调用栈，这里重点注意async_fibre_makecontext函数，该函数先分配一个堆栈出来，该堆栈长度为32768字节(小吧，省事省资源啊)，然后调用makecontext函数切换调用栈到函数async_start_func中，async_start_func的功能下面再说。\nstatic ASYNC_JOB *async_get_pool_job(void) { ASYNC_JOB *job; async_pool *pool; pool = (async_pool *)CRYPTO_THREAD_get_local(\u0026amp;poolkey); if (pool == NULL) { /* * Pool has not been initialised, so init with the defaults, i.e. * no max size and no pre-created jobs */ if (ASYNC_init_thread(0, 0) == 0) return NULL; pool = (async_pool *)CRYPTO_THREAD_get_local(\u0026amp;poolkey); } job = sk_ASYNC_JOB_pop(pool-\u0026gt;jobs); if (job == NULL) { /* Pool is empty */ if ((pool-\u0026gt;max_size != 0) \u0026amp;\u0026amp; (pool-\u0026gt;curr_size \u0026gt;= pool-\u0026gt;max_size)) return NULL; job = async_job_new(); if (job != NULL) { if (! async_fibre_makecontext(\u0026amp;job-\u0026gt;fibrectx)) { async_job_free(job); return NULL; } pool-\u0026gt;curr_size++; } } return job; } int async_fibre_makecontext(async_fibre *fibre) { fibre-\u0026gt;env_init = 0; if (getcontext(\u0026amp;fibre-\u0026gt;fibre) == 0) { fibre-\u0026gt;fibre.uc_stack.ss_sp = OPENSSL_malloc(STACKSIZE); if (fibre-\u0026gt;fibre.uc_stack.ss_sp != NULL) { fibre-\u0026gt;fibre.uc_stack.ss_size = STACKSIZE; fibre-\u0026gt;fibre.uc_link = NULL; makecontext(\u0026amp;fibre-\u0026gt;fibre, async_start_func, 0); return 1; } } else { fibre-\u0026gt;fibre.uc_stack.ss_sp = NULL; } return 0; } 函数async_start_func该函数负责调用传入的JOB所指向的函数，函数终止以后调用async_fibre_swapcontext来交出控制栈并返回到ctx-\u0026gt;dispatcher中\nvoid async_start_func(void) { ASYNC_JOB *job; async_ctx *ctx = async_get_ctx(); while (1) { /* Run the job */ job = ctx-\u0026gt;currjob; job-\u0026gt;ret = job-\u0026gt;func(job-\u0026gt;funcargs); /* Stop the job */ job-\u0026gt;status = ASYNC_JOB_STOPPING; if (!async_fibre_swapcontext(\u0026amp;job-\u0026gt;fibrectx, \u0026amp;ctx-\u0026gt;dispatcher, 1)) { /* * Should not happen. Getting here will close the thread...can\u0026#39;t do * much about it */ ASYNCerr(ASYNC_F_ASYNC_START_FUNC, ASYNC_R_FAILED_TO_SWAP_CONTEXT); } } } 函数SSL_get_all_async_fds负责获取当前SSL* s的wait_ctx所关联的所有文件描述符，获取之后我们就可以对其调用epoll或者select函数来监控通信。对于每个S-\u0026gt;wait_ctx，需要调用函数ASYNC_WAIT_CTX_set_wait_fd去给S-\u0026gt;wait_ctx注册上这个描述符。一般来说只有异步的时候这个函数才会被调用，函数wait_for_async会调用它，而sv_body函数会调用wait_for_async等待网络异步IO事件。这里再赘述两局，OPENSSL的异步事件需要调用底层的ENGINE实现，底层的ENGINE有很多种，比方说AF_ALG，DUMMY，GM等等，这些ENGINE由我们实现并提供。\n函数async_fibre_swapcontext切换线程栈，注意这里面的o-\u0026gt;env_init = 1，第一次从o到n的时候调用setcontext函数，此时还没有调用过n，所以用setcontext函数。从n回到o的时候调用_longjmp。下次再从o到n的时候，就还是用_longjmp了。\nstatic ossl_inline int async_fibre_swapcontext(async_fibre *o, async_fibre *n, int r) { o-\u0026gt;env_init = 1; if (!r || !_setjmp(o-\u0026gt;env)) { if (n-\u0026gt;env_init) _longjmp(n-\u0026gt;env, 1); else setcontext(\u0026amp;n-\u0026gt;fibre); } return 1; } 函数dummy_pause_job这个函数非常有趣，我们这里要注意这个dummy_pause_job只是个假的异步唤醒函数。该函数先对异步ctxS-\u0026gt;wait_ctx注册了一个管道pipefd，并把writefd注册到了wait_ctx中，注册完了向管道写入一个字符\u0026quot;x\u0026quot;来表示唤醒，然后调用ASYNC_pause_job函数继续执行从而切换协程。然后自己再从管道当中把那个X读出来，相当于假装通知+假装唤醒。\nstatic void dummy_pause_job(void) { ASYNC_JOB *job; ASYNC_WAIT_CTX *waitctx; OSSL_ASYNC_FD pipefds[2] = {0, 0}; OSSL_ASYNC_FD *writefd; #if defined(ASYNC_WIN) DWORD numwritten, numread; char buf = DUMMY_CHAR; #elif defined(ASYNC_POSIX) char buf = DUMMY_CHAR; #endif if ((job = ASYNC_get_current_job()) == NULL) return; waitctx = ASYNC_get_wait_ctx(job); if (ASYNC_WAIT_CTX_get_fd(waitctx, engine_dasync_id, \u0026amp;pipefds[0], (void **)\u0026amp;writefd)) { pipefds[1] = *writefd; } else { writefd = OPENSSL_malloc(sizeof(*writefd)); if (writefd == NULL) return; #if defined(ASYNC_WIN) if (CreatePipe(\u0026amp;pipefds[0], \u0026amp;pipefds[1], NULL, 256) == 0) { OPENSSL_free(writefd); return; } #elif defined(ASYNC_POSIX) if (pipe(pipefds) != 0) { OPENSSL_free(writefd); return; } #endif *writefd = pipefds[1]; if (!ASYNC_WAIT_CTX_set_wait_fd(waitctx, engine_dasync_id, pipefds[0], writefd, wait_cleanup)) { wait_cleanup(waitctx, engine_dasync_id, pipefds[0], writefd); return; } } /* * In the Dummy async engine we are cheating. We signal that the job * is complete by waking it before the call to ASYNC_pause_job(). A real * async engine would only wake when the job was actually complete */ #if defined(ASYNC_WIN) WriteFile(pipefds[1], \u0026amp;buf, 1, \u0026amp;numwritten, NULL); #elif defined(ASYNC_POSIX) if (write(pipefds[1], \u0026amp;buf, 1) \u0026lt; 0) return; #endif /* Ignore errors - we carry on anyway */ ASYNC_pause_job(); /* Clear the wake signal */ #if defined(ASYNC_WIN) ReadFile(pipefds[0], \u0026amp;buf, 1, \u0026amp;numread, NULL); #elif defined(ASYNC_POSIX) if (read(pipefds[0], \u0026amp;buf, 1) \u0026lt; 0) return; #endif } 从锁说起 # 我们重点关注对openssl对linux系统下pthread的支持，具体的文件为threads_pthread.c，该文件位于crypto文件夹中，使用的锁为读写锁。初始化锁的函数为CRYPTO_THREAD_lock_new，实现非常简单，就是分配并初始化读写锁。我们重点是要看哪里使用了读写锁。异步的操作文件为async.c\nCRYPTO_RWLOCK *CRYPTO_THREAD_lock_new(void) { # ifdef USE_RWLOCK CRYPTO_RWLOCK *lock; if ((lock = OPENSSL_zalloc(sizeof(pthread_rwlock_t))) == NULL) { /* Don\u0026#39;t set error, to avoid recursion blowup. */ return NULL; } if (pthread_rwlock_init(lock, NULL) != 0) { OPENSSL_free(lock); return NULL; } ... return lock; } 在函数BIO_new会调用CRYPTO_THREAD_lock_new，初始化bio-\u0026gt;lock 函数BN_BLINDING_new中，生成一个BN_BLINDING，初始化其-\u0026gt;lock 函数context_init中，会初始化OPENSSL_CTX的lock,oncelock和ctx-\u0026gt;index_locks[OPENSSL_CTX_MAX_INDEXES] 函数dh_new_intern中会初始化DH* ret-\u0026gt;lock 函数evp_md_new 函数各种key，evp_cipher_new等等`` 函数CRYPTO_secure_malloc_init 函数ssl_cert_new和ssl_cert_dup 函数SSL_CTX_new_with_xxx和SSL_new，查询session的时候，可以看到会对SSL_CTX加锁保护，查找session会进行检索。 函数X509_STORE_new和一些其他的函数 我们可以看到对证书，BIO，SSL_CTX，SSL_st，DH/各种曲线/CIPHER都分配了锁结构。\n我们重点关注下session是怎么存储的，OPENSSL查找session的函数为ssl_get_prev_session，核心的查找函数是lookup_sess_in_cache，该函数的几个查找函数直接看是看不到的，这几个函数都是通过宏定义DEFINE_LHASH_OF获得的。所以我们实际上是对每个LHASH_OF(SSL_SESSION) s-\u0026gt;session_ctx-\u0026gt;sessions进行查找，调用的核心函数实际上是OPENSSL_LH_retrieve。此时使用读锁来获取SSL_CTX，因为指向的SESSION CTX都是一个，这样子操作实际上比较糟糕。\nvoid *OPENSSL_LH_retrieve(OPENSSL_LHASH *lh, const void *data) { unsigned long hash; OPENSSL_LH_NODE **rn; void *ret; tsan_store((TSAN_QUALIFIER int *)\u0026amp;lh-\u0026gt;error, 0); rn = getrn(lh, data, \u0026amp;hash); if (*rn == NULL) { tsan_counter(\u0026amp;lh-\u0026gt;num_retrieve_miss); return NULL; } else { ret = (*rn)-\u0026gt;data; tsan_counter(\u0026amp;lh-\u0026gt;num_retrieve); } return ret; } static OPENSSL_LH_NODE **getrn(OPENSSL_LHASH *lh, const void *data, unsigned long *rhash) { OPENSSL_LH_NODE **ret, *n1; unsigned long hash, nn; OPENSSL_LH_COMPFUNC cf; hash = (*(lh-\u0026gt;hash)) (data); tsan_counter(\u0026amp;lh-\u0026gt;num_hash_calls); *rhash = hash; nn = hash % lh-\u0026gt;pmax; if (nn \u0026lt; lh-\u0026gt;p) nn = hash % lh-\u0026gt;num_alloc_nodes; cf = lh-\u0026gt;comp; ret = \u0026amp;(lh-\u0026gt;b[(int)nn]); for (n1 = *ret; n1 != NULL; n1 = n1-\u0026gt;next) { tsan_counter(\u0026amp;lh-\u0026gt;num_hash_comps); if (n1-\u0026gt;hash != hash) { ret = \u0026amp;(n1-\u0026gt;next); continue; } tsan_counter(\u0026amp;lh-\u0026gt;num_comp_calls); if (cf(n1-\u0026gt;data, data) == 0) break; ret = \u0026amp;(n1-\u0026gt;next); } return ret; } 结束 # 结尾的闲言碎语 # 写到这里差不多就可以结束了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 10 月 15 日","externalUrl":null,"permalink":"/posts/2020-10-15-openssl%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB9/","section":"Posts","summary":"","title":"OPENSSL源码阅读","type":"posts"},{"content":"","date":"2020 年 9 月 16 日","externalUrl":null,"permalink":"/tags/fsm/","section":"Tags","summary":"","title":"FSM","type":"tags"},{"content":" TLS自动机实现时一些不错地方 # 前言 # 实现TLS自动机的时候我们实际上做了不少东西，有不少地方都挺巧的。2020/12/9更新了一下，因为忘得差不多了，补充下自动机的代码。\n# SESSION方面 # 对于SESSION方面的优化我们做了两点\nTLS1.3 VS方面我们直接放弃了SESSION ID的做法，直接用SESSION TICKET，这样子服务端的存储大大缓解，只需要每次客户端服务端做个校验即可。 TLS1.3之前的版本，我们设计的数据模型为：一个大的hash表用于参与到查找，每个vhost存有等同于最大线程数的cache entry用来存储cache，每个cache entry由锁来保护，本身每个L4线程绑核。使用SESSION ID的前四字节#define SESSION_CACHE_KEY(sp) (*((uint32_t *)((sp)-\u0026gt;session_id)))计算hp，使用#define SSL_SC_KEY(sp) ((SESSION_CACHE_KEY(sp) \u0026amp; SSL_SC_HASH_SIZE ) % SSL_SC_LOCK_GRAIN_SIZE)计算添加的cache entry。简单来说，我们使用了细粒度锁，锁粒度为最大线程数。会出现多个不通hp存储到同一个cache entry的情况。至于hash表的结构就一句话带过了：数组下面挂一个二叉树 typedef struct ssl_vhost { TAILQ_ENTRY(ssl_vhost) next_vhost; /* session cache entries */ vh_schead_smp_t session_cache[SSL_SC_LOCK_GRAIN_SIZE]; }... struct mtx\tssl_session_lock[SSL_SC_LOCK_GRAIN_SIZE]; TLS1.3方面 # 自动机综述 # Record自动机 # TLS自动机本质是分层的，下层为RECORD LAYER，上层为HANDSHAKE LAYER。这种设计方式是反直觉的，但是本质上还是简化了研发和DEBUG的难度，\nRecord Layer和Handshake Layer是相互嵌套的，Record Layer不断的转，当收集到足够的信息或者上层自动机足够的消息发完了会不断继续转。从本质来说Record Layer就是做加解密的事情的，但是需要注意的是，Record Layer 会多转一次，直到遇见当前卡/SOFTSSL正在计算的flag才会退出。\nwhile (!done) { if (ssl_record_state[sslp-\u0026gt;rstate].rfunc == NULL) { sslstats.ssls_record_null_state++; if (sslp-\u0026gt;error_code == 0) { sslp-\u0026gt;error_code = RST_ID_FROM_SSL_20; } ssl_error(sslp); return SSL_ERROR; } action = (*ssl_record_state[sslp-\u0026gt;rstate].rfunc)(sslp); switch (action) { case RECORD_ACTION_ERROR: /* Bug 23415, chenyl, 20090824 */ if (sslp-\u0026gt;error_code == 0) { sslp-\u0026gt;error_code = RST_ID_FROM_SSL_9d; } /* Bug 23415, end */ ssl_error(sslp); done = 1; break; case RECORD_ACTION_CLOSE: if (ssl_close(sslp) == SSL_OK \u0026amp;\u0026amp; sslp-\u0026gt;tcp) { conn_insert_event(sslp-\u0026gt;tcp); } done = 1; break; case RECORD_ACTION_END: done = 1; break; case RECORD_ACTION_CONTINUE: continue; case RECORD_ACTION_NOTIFY_SSL: if (sslp-\u0026gt;flags \u0026amp; (SSL_FLAG_CLOSE_PENDING | SSL_FLAG_SENDANDCLOSE)) { /* upper layer isn\u0026#39;t interested anymore */ continue; } if (ssl_state_continue(sslp) != SSL_OK) { done = 1; } break; default: sslstats.ssls_record_bad_action++; if (sslp-\u0026gt;error_code == 0) { sslp-\u0026gt;error_code = RST_ID_FROM_SSL_21; } ssl_error(sslp); return SSL_ERROR; } } 来看看TLS1.3的Record Layer，首先判断是不是在卡/softssl里面做计算，如果是的话直接退出。否则继续，然后就是一个饥饿阻止的操作：因为可能同时有数据要加密和解密，如果上次做的是解密，那么本次就加密。避免服务端的数据被\u0026quot;饿死\u0026quot;。\n如果不是饥饿阻止的情况，那么检查报文是否为SSLv3报文，然后检查报文最外层的合法性。之后进入新状态，等待下层送上来足够的报文。等待完整报文阶段也检查是否在做加解密。首先检查当前报文的种类，握手报文/应用数据报文，决定是否做加解密操作，然后根据当前握手自动机的状态和SSLP是否有cipher，选择不同的解密Context，比方说当前是硬件接收0-RTT数据，就需要调用n5_early_context。如果是软加解密情况，指教调用pending_context即可。加解密的单位是一整个RECORD报文，\n这里需要加个特殊的地方，如果context为NULL，且该报文是个应用数据报文，说明这是一个我们不接受的0-RTT数据，这个时候直接destroy这个数据包，因为客户端可能不清楚我们不该接收这个数据包，而发了很多0-RTT数据，接着回到等待报文也就是SSL_RECORD_START阶段。\n我们接着说，上面如果是应用数据，那么我们送卡做解密，RECORD 自动机进入DECRYPT阶段，DECRYPT阶段并不是解密，解密是卡做的，DECRYPT阶段是解密完之后的处理。如果是握手报文，调用handle_data做分类，确定是不是上送。解密和握手报文最终调用handle_data来上送。\nHANDSHAKE自动机 # 我做的是REUSE和0-RTT自动机，握手自动机还是非常简单的说起来。检查ClientHello是不是有PSK拓展，有的话做PSK verify，我拆成了hmac verify + ticket identity decrypt + ticket lifetime chekc \u0026amp; sni check \u0026amp; ticket lifettime mismatch + compute hmac \u0026amp; binder key + handshake hash + binder verify。后面的计算不需要赘述\n对于0-RTT来说，发送完了finished消息之后(这里先发送finished是正常的，因为客户端可以一直发0-RTT数据直到收到服务端的finished报文)就需要计算early secret，此时还是在handshake自动机里转。 接收early data的阶段我称为TLSV13S_S_PRE_ESTABLISHED状态，实际上和ESTABLISHED阶段没区别的，函数是一个。对于END_OF_EARLY_DATA的判断实在ESTABLISHED函数里面判断的，0-RTT\nTLS1.3的0-RTT数据 # 对于VS端的0-RTT是个比较麻烦的问题，即使后面是HTTPS的连接，你也得等0-RTT收完了才能发送，贼蛋疼。这个地方我们做了很多东西\nsoft/hard context的分配和管理，这个地方存在的问题是，完整握手情况下计算了key share才会分配context，而0-RTT数据必须立刻算出early_context并存储early_secret，当受到END_OF_EARLY_DATA时也有必要立刻释放early_context\n如果客户端带了0-rtt数据，我们接受，两边都不是TCPS，那么我们直接调用向后端建立连接，也就是立刻向后端建立pipe，所谓的建立pipe并不是只建管道，而是pipe_open调用后面的握手函数，开始握手并建立连接。也就是说此刻vs端的record layer本质上就是个解密的操作，解密完了丢到后面去，没有直接关系了。可能由问题，如果服务端数据来了，这时候怎么办？没啥问题，是可以发送服务端回送的数据的，完整性虽然没保证，但是还是可以的。参照TLS1.3 RFC Page17的流程图。\n建立连接\n如果两边都是TCPS，我们决定接受0-RTT数据那就需要缓存客户端0-RTT数据再发送到后端，我们先缓存0-RTT数据，直到我们验证了客户端的finished报文再通知后面可以发送early_data了。前面开PIPE的时候我们就不会直接让后面客户端握手，而是让客户端进入TLSV13S_C_WAIT_CLIENT_EARLY_DATA_END状态，然后直接让这个握手函数先暂停，等vs这边的消息。我们会将消息放到user_event队列。每个ATCP线程处理完当前的业务之后会调用clicktcp_process_events 处理user_event队列，从而使得rs端连接继续进行。\n对于TCPS2TCPS的0-RTT模式，TLSV13S_C_WAIT_COMPUTED_EARLY_DATA_FIN状态下必须等待RECORD LAYER的数据发送完，record layer和handshake layer的交互是交替进行。因为finished必须由handshake secret保护，而不是early secret。\n无论是VS还是RS端的0-RTT数据都要注意secret的变化，因为序号变化了。\nTLS1.3的KEY UPDATE流程 # 收到KEY UPDATE的时候，需要判断更新哪端的握手环境，是只需要更新对端还是同时需要更新本端？为了解决更新本端的问题，我添加了一个新状态TLSV13_S_PREPARE_KEY_UPDATE，该状态负责清空本地的发送缓存，简单来说是让握手自动机停止运转，而record layer一直加密，直到加密完成。\nTLS1.3的SESSION TICKET设计 # RECORD LAYER和 HANDSHAKE LAYER的交互 # OPENSSL实现自动机的时候没有将record layer和handshake layer分开，这样子的好处是简单，问题在于过于追求通用性，可读性和理解很差。而USTACK系统拆分了record layer和handshake layer好处是好理解，问题是因为是异步自动机，两个自动机怎么协调，包括状态的变化等等怎么做合适？需要分析下TLS的驱动\nTLS1.3之前的版本 # TLS的驱动来自两个方面，下层送上来数据和卡/soft context送过来数据(本质上是加解密操作)。record_in存储下层协议栈，record_out存储要发送的明文。\n客户端先送来明文CLIENTHELLO，我们解析CLIENTHELLO，此时record_out必然为空，好，此时要送CLIENTHELLO报文进handshake layer。 handshake layer拼凑好了，Server hello，Certificate，ServerKeyExchange，和ServerHelloDone，都放到了record_out里，等待客户端消息，但是此时都是明文。然后等待客户端明文。 客户端消息ClientKeyExchange还是明文，发送FINSIEHD并等待FINISHED 整个流程可见，到了发送应用数据的时候必然是先接受加密数据A0，从而有回复待加密数据B1，此时即使有已接受的加密数据A1，也得先把B1加密发出去。\nTLS1.3版本数据 # TLS1.3的驱动来自三个方面，下层送上来数据，卡/soft context送过来数据(本质上是加解密操作)与自动机自发的触发。record_in存储下层协议栈，record_out存储要发送的明文。\n如果是完整的握手流程本身是必须本地算完才会有对端数据的，但是如果客户端发送了0-rtt数据和end_of_early_data数据。那么必然是record_in和record_out同时有数据，且需要先发record_out的明文，因此我们能得出record layer和handshake layer的交互必须满足下面几个条件\n进入handshake layer之前必须进入record layer，record layer必然是handshake layer的下层。 每次进入record layer只有两种情况，等待某某消息加密完成并写到pcb里，或者从起始状态启动，等待明文/密文消息做加密/解密 如果同时由加密和解密要做，上一次做的是解密，那么这次就一定要做加密。这个地方要简单的解释解释， TLS协议栈和卡的交互 # 这部分也值得好好说道说道，每个L4线程都会调用ssl_card_poll_generic，尝试判断卡是不是算完了数据。这里判断的方法为轮询每个atcp线程自己的入队列，校验任务是否完成，之所以使用轮询是因为中断会侵犯切换上下文，打扰性能。如果卡刚入栈ticks间隔小于2，那就直接返回。否则继续轮询队列。注意，这里我们需要区分异步队列和同步队列，同步队列运算非常快，异步队列运算非常慢。 每个卡在入队列和出队列的时候都是用的是？ 内存方面 # 内存方面是一个需要注意的问题，slab管理器。\n结尾的闲言碎语 # 写到这里差不多就可以结束了，就不多说了。 ","date":"2020 年 9 月 16 日","externalUrl":null,"permalink":"/posts/2020-10-13-tls%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%AE%9E%E7%8E%B0%E6%97%B6%E4%B8%80%E4%BA%9B%E4%B8%8D%E9%94%99%E5%9C%B0%E6%96%B9/","section":"Posts","summary":"","title":"TLS自动机实现时一些不错地方","type":"posts"},{"content":" 如何写TLS自动机？ # 0 前言 # 前段时间这个写一半嫌累，就暂停了，今天补上。这里的TLS自动机设计和总结不会设计加到线程安全，因为那个纯属于实现级别。我同样附加上了安全开发和安全运营的内容，如果还有大量的总结和拓展，那么我会拆成单独的文章。\n1 TLS自动机设计理念 # 1.1 理念 # 设计时，我们的理念就三种：\n简单 分层 安全 这三条理念说起来都很短的，但是实际上的理念是高度集成的，我们一条一条分开说：\n1.1.1简单 # 简单的概念包含三种：\n自动机的设计要足够简单，没有用或者说能节省掉的流程，在保证安全的同时，一定要省略掉。这里千万不要忽视掉“保证安全”四个字，openssh曾经有个CVE(CVE-2018-15473)就是因为简单了，但是没考虑安全导致的。复杂的步骤除了带来计算的复杂度，也带来了安全的风险；而简单的状态实现一方面减少了实现的难度和麻烦，另一方面带来了可读性和吞吐性能的改善。这里需要注意的是，自动机的设计并不等同于RFC里面的状态机，这点是需要自动机设计者搞明白的。 自动机的状态转换，语义和可读性要足够简单，好理解。：任何涉及到大/小的状态转换，标记变化必须在明处写明白，能用一种变量表明的状态不要使用两种来做。就以TLS1.3的EARLYDATA的状态而言，这个状态EARLY_DATA_NONE表示没有0-RTT请求，不要用EARLY_DATA_NONE来表示拒绝了0-RTT请求。这一条“可读，语义简单”并不一定完全执行，有的时候处于内存申请的考虑是需要 最后一个简单的意思就是要减少复杂的操作，这里复杂的操作主要指就是系统调用：我司系统里面就是减少了malloc的申请（毕竟又是系统调用，又是缺页中断）能用uma_zone/slab管理器的地方，绝对不要用malloc来做，虽然对于TLS握手流程而言，非对称密钥的计算才是时间消耗的大头，但是内存的申请利用这块也要减少！ 1.1.2 分层 # 相比较简单而言，分层的概念简单多了，就两种：\n协议本身的分层是“分层理念”的基础，这点最直接就提现到了TLS的协议分层：外层为RECORD LAYER，内层为HANDSHAKE LAYER，内外层尽量减少干涉。但这种分层实际上并没有提现到OPENSSL的自动机里，或者说体现的不够明显，这也是我对OPENSSL自动机的主要不满之处。 实现层面的分层，举个操作系统的简单例子，分配内存时候只是分配虚拟内存，物理内存未必可以分配出来，真正需要的时候再进行缺页中断。这种方式主要是为了提高吞吐量。 1.1.3 安全 # TLS状态机设计里面实际上安全是最难实现的，安全的原则说简单也简单，说难也难，抽象起来就两种：\n不要对下层协议释放过多的信息。这个设计到的攻击主要是针对信息泄露，任何时刻都需要对输入输出做边界检查（心脏滴血漏洞），对不同的行为但是相同的后果不要做出不同的回应（CVE(CVE-2018-15473)）。 上层协议的资源不要和下层保持同样的生命周期。这种设计理念主要是针对拒绝服务攻击，常见的拒绝服务攻击记大多都是由于资源错误释放时间。 2 TLS自动机实现时候的困难和问题 # 下面针对性的给出我们做自动机的时候遇到的困难和问题，并简单描述我们给出的解决方案。这里需要注意的是里面一部分问题是理念导致的，一部分是实现导致的，在写代码的时候要区分开抽象和具体的区别。\n2.1 简单理念 # 问题1，冗余的状态：TLS1.3里在客户端复用的流程下的psk ==\u0026gt; binder_key ==\u0026gt; hmac_key状态切换冗余而且麻烦，会降低复用的性能。出于简单理念，我将状态机的从psk ==\u0026gt; binder_key ==\u0026gt; hmac_key的状态切分压缩到一步，并且将hmac_key计算流程放在了服务端，使得客户端可以直接利用hmac_key(加密存储在ticket identity里) 问题2，TLS1.2自动机里隐晦的状态转换：我在写TLS1.3自动机之前，参与了我司对TLS1.2的状态机优化，除了代码层面的优化，也修改了TLS1.2里面一部分隐晦状态的改变问题，TLS1.2的验签藏在一个非常深的函数里，因为验签涉及到跨进程通信，因此这个地方的修改非常不显眼，及其容易引起误解！我改了两次：第一次只是加了注释，第二次将跨进程通信的flag打在了明处。 问题3，session identity的lazy delete，当一个session identity失效的时候我们不会直接调用释放函数（在CPP里面是析构函数），相反我们只是打上一个flag表示无效，当new不出来的时候就遍历一遍链表查找失效的identity然后复用。这种方法很简单，效率高。但是带来了问题即多线程的争用，读写和无效化，解决方式很多，不多赘述。 2.2 分层理念 # 分层理念带来了逻辑的简单，但也带来了一些比较麻烦的问题。\n问题1，Record Layer层的饿死：和handshake layer不同，record layer实际上是无状态的，因此如果有报文加密又有报文解密的时候record layer应当向上驱动还是向下驱动呢？OPENSSL将record layer包含在handshakel layer里解决这个问题，我的解决方法是如果上次是解密，此时有加密就先做加密。\n问题2，上下层的通信：通常来说层与层之间只有依赖，而没有通信，但TLS1.3里的0-RTT导致1record layer和handshake layer需要通信决定lazy alloc enc/dec ctx 2 0-RTT加密/解密失败时候需要丢弃数据，而不是丢弃自动机，这两个情况就需要设计两个层的通信。我目前没有给出这个问题的规整解决，只是看EARLY_DATA_STATUE，如果复杂化了再建立通信机制。\n问题3，0-RTT的自驱动：TLS1.3之前，自动机都是由数据驱动的，因此都是RECORD LAYER驱动了HANDSHAKE LAYER，但是0-RTT导致了一个自驱动。正是这个自驱动导致TLS自动机的RECORD LAYER和HANDSHAKE LAYER分层复杂化，解决方法也不难，在handshake layer添加一个自己触发自己的状态，该状态会频繁触发record layer的自驱动（这里面隐藏着一个问题1）。\n2.3 安全理念 # 问题1，错误的NST颁发：NST(Session Identity)的颁发需要握手完成，但是握手完成不代表对端可信，必须是单转双之后才能发送NST。我最早的逻辑是只要发送了finish报文就发送NST，后来我发现这个安全（逻辑）漏洞。 问题2，错误的证书授权者：这个问题实际上是个协议+实现导致的问题，比方说我是一个黑客，我可以在某个不靠谱的CA申请了GITHUB的网站证书，然后我就可以假冒GITHUB了。关于这点我们提供了严格的CA校验，就是对于特定的访问只能通过特定的CA，以此来对抗此类攻击。 问题3，错误的证书验证（黑白名单功能）：这个问题和实现没关系，是设计的缺陷。CRL记录的是吊销证书，也就是黑名单，如果在crl里面找不到的证书会验证通过。这个缺陷我最后实现的时候改成了白名单模式，如果没找到就直接拒绝连接。如果采用了公钥钉扎，那么就不需要担心这个问题了。但目前看起来钉扎做的还不是那么到位 3 不遵守三种理念导致的问题 # 下面我会列出一些CVE，这些CVE就是由于不遵守相应的理念导致的问题，作为一个安全协议的实现人员（分析人员），一定不要忽视小小的问题。有一点需要注意，我并不只列出OPENSSL的cve，其他软件也会有，不过基本都是我修过/探究过的。除此之外，我写过很多好玩的东西，比方说假SNI做代理，但这些都不属于标准行为，不具备任何参考价值。\n臭名昭著的心脏滴血漏洞（CVE-2014-0160），该问题就是由于安全理念考虑不到位，对拷贝边界/信息校验没做到位。因此在实现的时候，我们对边界坐了严格的校验。实际上我们在实现的时候有一部分可以上送/下移的功能出于安全考虑的角度也没做，因为多做实际上就意味着可攻击。 因为区分存在用户名和不存在用户名导致的攻击（CVE-2018-15473），该问题是由于将存在的用户名校验流程和不存在的用户名校验流程的步骤可区分导致的信息泄漏，我当时修复就是把两个流程改一致。在平时的代码实现的时候，这个问题可能是不可避免的，也就是说，可能存在的用户名和不存在的用户名处理流程不同是客户想要的，尤其以银行为首的一部分企业。 弱hash算法（CVE-2004-2761），这个问题没啥好说的，现代计算机算力增强了，木的办法。再赘述一句，我国很多企业（还是以银行为首）使用的包括ATM，内部网关，内部数据的通信还是以弱TLS为主，这是一个很可怕的事情。某些基本不存在任何安全可言的CIPHER还在使用。 因为校验没到位导致的（CVE-2015-4458）和不安全重协商攻击，对消息的mac没包含足量信息导致。这里考虑的东西实际上是一种信任关系的拓展和层与层之间的关联，加密过的信息必须是经过上一步加密过的信息保证保密性和关联。有一个很有意思（很蛋疼）的东西，这种关联在设计不合理的时候反而会成为被攻击点，就好比HKDF应该包含EXPAND+EXTRACT，如果只有一个那么可能反而是不安全的。 因为校验没做到位（ Zombie POODLE），最常见的填充攻击就是针对这个，很巧妙，因此我们在实现的时候，对于任何参与的信息都坐了加密，划重点：参与了计算最好就加密！ 证书链校验攻击（Microsoft CryptoAPI错误等多种），这种问题在代码实现时很难被发现，因为人们对证书链校验的不完备导致。因此我们实现的时候改了逻辑，做了最严格的校验，发现一层无效，链式就无效。 随机数范围过小攻击，这个问题实际上是因为random种子需要随机导致的，我们只是规定了必须有种子，没详细规定种子的来源。 BEAST攻击，我当时看这个攻击看的是一愣一愣的，感觉就是俩字，牛逼，真正的协议攻击。该问题就是因为IV可见了。TLS协议本身避开了这个问题，TLS1.2使用了EXPLICT IV来解决这个问题。 4 针对三种理念做的优化 # 这里的优化并不是单纯针对三种理念的，是一种杂糅的优化策略，有的优化访问速度，有的优化安全性能。\n不要将证书过于绑定，安全方面的角度，不需要过多解释。 部署OCSP STAPLING，这个东西实际上是减少访问时延的措施，比较有效。 性能转移，将一部分的计算操作放到客户端让复用减少性能消耗是一种非常常见的方法，这个不展开说了，需要具体情况而定。 5 再谈安全开发 # 提到安全开发头头是道，真到开发的时候抓瞎了。身为一个从预研到开发的程序工程师，我来简单说说我所认识到的安全开发。由于我是单纯从开发干起，很多东西都是（我自己总结的）从开发的角度来谈的，因此难免有局限性。\n5.1 安全开发流程初期 # 安全开发名字高大上，但是实际上是个苦差事，因为安全并不是水桶，而是一个气球：哪里扎破一个洞，立刻整个就崩了。因此初期把握好安全开发就很重要，我比较喜欢从下面几个方面来分析：\n目的是提供一款什么样子的安全产品？是提供端到端的加密？认证服务不可抵赖？秘钥管理？权限管理？安全监测？每种不同的属性对应着不同的功能。project leader还常常需要进行产品的横向对比，从而能够保证功能的灵活性和创造性。 需要保护哪些敏感信息，等级分为几种？比方说身份信息，权限信息，支付信息，爱好信息等等方面都可以被划归为敏感信息。 可能遭受哪些攻击？相比上两种，这个问题是最具体的攻击，常见的攻击很多种：供应链攻击，SQL注入 可以复用哪些已有的安全工具和代码块？不要老去造轮子，要学会组合而不是创造。 上面几个问题实际上是安全开发当中大的目标，分析好上面几个问题之后，最大的问题就来了，怎么落地？说起来也不难：\n第一步 培训：培训的目的包含三个方面：使得每个参与者（不限于开发者，测试者，经理，审计\u0026hellip;.）了解产品提供的安全属性，安全准则和具体功能，尤其是要对产品经理培训使得其明白安全不是个绝对概念，是有选择倾向的，总要做出抉择；对每个参与进来的开发者培训，使得其清楚常见的安全知识，比方说对称加密的安全性由秘钥保证，hash不是加密，什么方法提供认证功能等基础知识；对核心开发者明确产品的核心逻辑和模块的设计（不一定是高速开发者，而是让核心开发者设计），必须达成对功能和安全的共识！我们在做TLS自动机的时候核心就三个人，每个人都可以相互替换对面的功能，TLS1.3新功能REUSE和0-RTT的核心逻辑也是我设计完了，争论了几次才确定的，我们的测试完全参与不到我们的培训里，因为听不懂。。。 第二步 需求和功能划分：确定需求是个很有趣，却不困难的工作。因为核心逻辑是围绕关键信息的，所以基本确定了敏感信息和核心逻辑之后，需求划分就比较简单了。但功能划分是个很麻烦的事情，一方面核心逻辑可能并不复杂，但是边界错误和细枝末节可能会出现大量问题，因此每个细微的工程都需要有人把关；另一方面，安全开发产品有很强的连续性，安全经常是成环的，因此要确保具体的代码开发者是了解开发的模块的输入/输出/隐喻/保障的，因此需要保证开发者是真的懂怎么回事，而不是似是而非模棱两可。这里注意，划分功能意味着划分责任，有的开发爱甩锅，有的QA爱甩锅，这时候就看project leader的功力了。 第三步 颁发安全准则：培训了，需求确定了，功能划分了，到了写代码的时候新的问题就来了，怎么保证代码是安全的呢？针对TLS可以看我写过TLS三理念，更具体的一般是：第三方安全性，很多安全问题是由第三方安全保证的，开发工程师精力不够，找QA啊；函数安全；工具安全。 多赘述一点东西：安全属性不是隔离的，端到端加密是很多功能的保证，但是奥卡姆的剃刀原则务必不要忘记，如无必要勿增实体，不要把其他层的东西放到本层来做！\n5.2 安全开发流程中 # 安全开发流程中期实际上是个工程师埋头干活，抬头开会报进度的流程，这阶段的关注点在于project leader上。project leader不但要对项目进度做好把握还要把握好需求变更的问题。project leader还需要检查行为变化，细化安全规范。这就需要project leader能够明确安全的行为，并且能够根据具体的功能黑盒灵活的改变行为。\n坦白讲，做TLS自动机研发的时候，虽然复用和0-RTT是我负责，但是关于排期这事我没咋催，主力是我，小功能分出去的时候我会提前培训开发的同事；每天问问进度和问题；明确行为规范。所以没啥排期的变更，行为这块一开始三个核心争了很久，也很确定，所以没遇到啥大问题。\n5.3 安全开发流程后期 # 安全开发流程后期实际上主要的关注点不再开发工程师上了，在于QA和运营人员：运营人员要执行静态检测和动态监测；QA要执行模糊测试，输入测试等多种功能，这都不是问题。问题在于：project leader和开发者要在开发前期和开发后期以高度透明的角度，参与QA的测试CASE制定！换言之QA和开发必须都审核过测试CASE，从而避免出现什么“现实不可能发生，测试不全面”的扯皮。\n此外，需要记录开发过程当中遇到的实际问题和BUG，并且将这些问题归类，加入到安全规范中。一方面能够给工程师提供具体的案例分析，另一方面能够很明确的细化规范和经验。实际上关于0-RTT的DDOS攻击我在分析OPENSSL的时候虽然想到了但是没明确，是后来QA参与进来我们才定性规定这是个问题的。\n最后，最蛋疼的收尾工作来了：\n如果出现问题，如何应对？project leader需要根据具体的威胁制定针对补足方案，开发需要明确出现某种问题时，谁第一阶段参与，谁来参与追责。 如果在具体的安全规范出现问题，依据什么原则，听谁的？ 开发和测试当中的资料归档在哪里？值得商榷的行为和安全保证的细节必须高度透明的写出来，并且能够被明确归档。 可复用的工具，代码和属性是哪些？哪些应当成为标准组件？这些（第三方，第一方）工具，代码安全吗？实际上这里我最直接想到的就是HKDF-EXTRACT \u0026amp; HKDF-EXPAND，一个安全并且规范化的灵活伪随机码产生工具。实际上这个工作是需要一线开发工程师一起参与的。当然TLS研发完了，也就我自己想了想这块。。。。。 5.4 遇到的安全开发中的问题 # 简单说说我们在开发过程当中遇到的一些实际问题：\n人力不充足：人员短缺的问题很蛋疼，核心三人组是又订规范，又商量行为，光研究RFC就花了很久，更别提给其他人培训了。虽然能力增加了不少，但是确实很蛋疼。 需求的变更：我对需求变更实在是太烦了，小的需求比方说拓展的支持还好说，解析的时候多花点功夫即可。如果大的属性变了，那排期就得大变。 项目周期紧：这个对我们来说还好，虽然我们设计阶段功夫很多，但是设计好了我们的开发还是很快的。 6 再提安全运营 # 我只所以写这个有两个原因，一个是因为昨天晚上11点，我们的SE忽然给我打电话，说了一个卡顿的问题，然后说是必须明天10点给回复，然后我去看了下BUGZILLA对应的页面，前几天我在里面回复的要查询测试的点一个都没做/然后说好的统计数据和日志也没有上传。另一个事情是看FREEBUF上安全甲方群的讨论，里面的几个回复有所感慨，还是以开发的角度来聊聊技术支持和安全运营。\n从我的观点来看，安全运营实际上分为两个方向：对内\u0026ndash;针对开发和测试，对外\u0026mdash;对客户。这两点说完了，再写一点对SE的建议。\n6.1 对客户 # 对客户而言，SE是问题的解决者，在解决问题的时候应当：\n正视漏洞（问题）存在的客观性，不要去抵赖或者无视问题，但是要明白安全是有所选择的。 能够明白具体问题是什么，出在哪个层面，不要乱承诺。 和服务商进行沟通，确保有业务保障的应急方案。应急方案是必须得有的，怎么能没有应急方案呢？应对策略 和运维团队（如果可能的话）一起评估风险，并制定紧急干预措施（如果可行） 事后复盘，评估服务商的综合能力。 保证高效的解决方案的能力，不能磨蹭，尤其是不能在低效的沟通上磨蹭时间。 除此之外，由于我们是TOB的，漏洞的发现往往会早于客户环境遇到，因此应该：\n积极关注客户的方案和环境，如果产品出现了问题或漏洞，要第一时间通知客户 6.2 对内 # 对内，或者说对开发和测试工程师而言，SE是寻求帮助的人，SE应当：\n了解产品，了解基本的技术。至少和开发/测试够通的时候能够说明白具体问题出在哪个组件上。 能够清晰的够通具体问题和针对现象，对开发/测试给出的探查方向和原因要能搞明白，要做一道桥，而不是做一堵墙。 解决问题，给出测试等流程要块，务必不要11号发现，18号截至，然后17号忽然电话打过来说赶紧给解决方案，然后一看啥分析数据都没有。 6.3 SE的自我修养 # 我不是SE，但是我想所有的问题都是一致的。\nSE要去学习技术，不说精通，至少得熟悉模块/功能/划分 SE应当提炼工作手段，将可利用的部分组件化，而不是每次都抓瞎 SE应当适当的利用自动化技术，不要老是手动操作，尝试安全高效的解决问题。 7 自动机的闲言碎语 # 过几天要说说自动机的东西，今天说一点有限状态自动机的内容：\n自动机的作用：自动机是多状态/多输入情况下有效减少考虑问题复杂度的方法，之所以用自动机是因为对单个状态的输入是有限的，但是总的输入很多 自动机的目标：可靠性和简单，越简单越好。尽量状态少一些，避免出现很多状态，状态多了可能死锁 自动机问题1 死锁，两种情况触发死锁：a没有条件跳出当前状态。b跳出条件不会触发 自动机问题2 无法到达特定状态：a没有条件到达这个状态。b有条件，但是条件无法被触发 自动机问题3 livelock活锁： 怎么检测自动机死锁/活锁： 结尾的闲言碎语 # 写到这里差不多就可以结束了，就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 16 日","externalUrl":null,"permalink":"/posts/2020-09-16-%E5%88%B0%E5%BA%95%E8%AF%A5%E6%80%8E%E4%B9%88%E5%86%99%E8%87%AA%E5%8A%A8%E6%9C%BA/","section":"Posts","summary":"","title":"到底该怎么写自动机","type":"posts"},{"content":" 内存学习(1) # 前言 # 内存这块我很早之前看过，但是一直没怎么做记录。这次姑且记录下这次的阅读的书籍分别为：《Linux内核0.11完全注释》，《Linux内核源代码情景分析》，《ATCP内存实现》(这个是我司的代码管理)。啊，对了，这次我同时在看SICP的东西，希望顺便打打基础。当然，纸上得来终觉浅，绝知此事要躬行，还是从已经分配好的内存看起吧，从用户态的开始看。\n絮叨几句 # 简单来说linux2.6的内存管理方式并不能说麻烦，来来去去东西就那么多，但是有很多东西属于前置知识，也就是说你知道它是为了解决什么问题才可能理解为什么会有这种解决方式，单纯的看代码只会觉得仿佛是看天书。我第一次看《深入详解linux内核》只感觉是天书，毕竟毕业好多年，操作系统的东西差不多都还给老师了，后来为了学习就买了一本《操作系统真象还原》然后哆哆嗦嗦看完了，再看《深入理解linux内核》才大致明白是什么回事，可是内核庞大，经常前面的东西裹挟着后面的内容，所以经常会看看忽然看不懂，暂且释怀，总会明白，无非多看几次。\n内存管理小前言 # linux2.6的内存管理，总结来说分为下面两块\n虚拟内存管理 物理内存管理 这其中，虚拟内存管理分为 应用层虚拟内存管理(0-3GB的内存管理) kernel虚拟内存管理(3-4GB的内存管理) 虚拟内存的初始化 这里面无论是0-3GB还是3-4GB都是虚拟内存的概念，每个程序都认为自己有四GB的空间，但是实际使用的时候会根据需求进行调页。虚拟内存初始化讲道理和前两种分类并不一致，但是又没多少其他合适的地方放，所以姑且放到一起 物理内存管理层面分为 物理内存的分配管理 物理内存的回收和置换 物理内存管理方式之slab管理器 严格来说，slab管理器实际上属于物理内存的分配管理，但是由于其管理方式非常常见也很重要所以单独拿出来了。下面我会一边捋思路，一边记录多种数据结构。因为这两者都互相影响，所以虚拟内存和物理内存的管理会穿插着来。 从页框说起\u0026ndash;基本的物理内存管理 # 大部分书籍说起内存管理，都先说什么线性地址，可是每个人都知道什么是线性地址，也不需要我多少。我们从页框(Page Frame)说起，假设我们有个12KB的内存，我们认为一个4k是一个页框，第一个4k，我们称为第一页，第二个4k我们称为第二页，第三个4k我们称为第三页，简单而言每4k大小的物理内存我们称为一页。为了管理每个页框，我们为每个页框生成一个管理单元，该数据结构称为“页描述符”(以后我们page也指一页，也指对应的页描述符)，数据结构写在下面了。\nunsigned long flags用于表明page目前正处在哪种类型，用该标志来表示该页框的状态，常见的标志为\nPG_locked\t//页被锁定，比方说在做I/O操作，这几次对内存的梳理我们都不会涉及到 PG_referenced\t//该页刚刚被访问过，我们等到“物理内存的回收和置换”再讨论 PG_active\t//该页在活动或者非活动链表里，我们等到“物理内存的回收和置换”再讨论 PG_reserved\t//该页给内存保留使用，或者无法使用 PG_reclaim\t//该页将要写入内存 PG_swapcache\t//该页属于兑换高速缓存 PG_private\t//该页的private字段有用，是有特殊含义的(比方说伙伴系统用这个记录位阶) atomic_t _count字段说明该页框当前有有几个进程使用，比方说多个fork出来的进程同样拥有一个页框 atomic_t _mapcount 字段说明该页框当中有多少个页表项，如果一个没有为-1\nstruct address_space *mapping 如果该PAGE属于匿名区，那么mapping用于指向某个还没涉及到的数据结构，从而找到页表项。如果属于页高速缓存\nunsigned long index\nstruct list_head lru 非常好玩的东西，只要是个list_head的链表都能挂，当然最常见的是挂在物理内存伙伴算法和活动链表和非活动链表上。\n剩下的几个结构要么涉及不到，要么我暂时不想理。略过了。\nstruct page { unsigned long flags;\t/* Atomic flags, some possibly * updated asynchronously */ atomic_t _count;\t/* Usage count, see below. */ union { atomic_t _mapcount;\t/* Count of ptes mapped in mms, * to show when page is mapped * \u0026amp; limit reverse map searches. */ struct {\t/* SLUB */ u16 inuse; u16 objects; }; }; union { struct { unsigned long private;\t/* Mapping-private opaque data: * usually used for buffer_heads * if PagePrivate set; used for * swp_entry_t if PageSwapCache; * indicates order in the buddy * system if PG_buddy is set. */ struct address_space *mapping;\t/* If low bit clear, points to * inode address_space, or NULL. * If page mapped as anonymous * memory, low bit is set, and * it points to anon_vma object: * see PAGE_MAPPING_ANON below. */ }; #if USE_SPLIT_PTLOCKS spinlock_t ptl; #endif struct kmem_cache *slab;\t/* SLUB: Pointer to slab */ struct page *first_page;\t/* Compound tail pages */ }; union { pgoff_t index;\t/* Our offset within mapping. */ void *freelist;\t/* SLUB: freelist req. slab lock */ }; struct list_head lru;\t/* Pageout list, eg. active_list * protected by zone-\u0026gt;lru_lock ! */ /* * On machines where all RAM is mapped into kernel address space, * we can simply calculate the virtual address. On machines with * highmem some memory is mapped into kernel virtual memory * dynamically, so we need a place to store that address. * Note that this field could be 16 bits on x86 ... ;) * * Architectures with slow multiplication can define * WANT_PAGE_VIRTUAL in asm/page.h */ #if defined(WANT_PAGE_VIRTUAL) void *virtual;\t/* Kernel virtual address (NULL if not kmapped, ie. highmem) */ #endif /* WANT_PAGE_VIRTUAL */ #ifdef CONFIG_WANT_PAGE_DEBUG_FLAGS unsigned long debug_flags;\t/* Use atomic bitops on this */ #endif #ifdef CONFIG_KMEMCHECK /* * kmemcheck wants to track the status of each byte in a page; this * is a pointer to such a status block. NULL if not tracked. */ void *shadow; #endif }; 数据结构列在上面了，这样一个结构大概40字节，用来表示4k字节，也就是说用1的内存来表示大小为100的内存，似乎还可以？好，我们继续向下说。管理那么多的物理内存，不可能都临时管理，肯定都是初始化好的，所以操作系统中会有一个全局的page数组，称为mem_map数组。平时页表或者页目录项里面存储的也是页帧号Page Frame Number。\n对于X86系统，我们人为的将内存划成几个管理区：\nZONE_DMA包含低于16MB的内存页框 ZONE_NORMAL包含高于16MB且低于896MB的内存页框 ZONE_HIGHMEEM包含高于896MB的内存 让我们直接看内核里面的ZONE_TYPE的意思：\nZONE_DMA是给设备用的，因为不能直接对所有的可寻址地址做DMA操作，\u0026ldquo;that are not able to do DMA to all of addressable memory\u0026rdquo; ZONE_DMA32是给X86_64用的，因为有设备只能对32bit地址下做DMA ZONE_NORMAL真正的可寻址范围 ZONE_HIGHMEM是高端地址，不过X86_64是不需要用的 ZONE_MOVABLE 这部分建议直接看英文原版https://lwn.net/Articles/224829/，不会出现理解错误 我在公司的电脑，就三个ZONE，ZONE_DMA，ZONE_DMA32和ZONE_NORMAL\nenum zone_type { #ifdef CONFIG_ZONE_DMA /* * ZONE_DMA is used when there are devices that are not able * to do DMA to all of addressable memory (ZONE_NORMAL). Then we * carve out the portion of memory that is needed for these devices. * The range is arch specific. * * Some examples * * Architecture\tLimit * --------------------------- * parisc, ia64, sparc\t\u0026lt;4G * s390, powerpc\t\u0026lt;2G * arm\tVarious * alpha\tUnlimited or 0-16MB. * * i386, x86_64 and multiple other arches * \u0026lt;16M. */ ZONE_DMA, #endif #ifdef CONFIG_ZONE_DMA32 /* * x86_64 needs two ZONE_DMAs because it supports devices that are * only able to do DMA to the lower 16M but also 32 bit devices that * can only do DMA areas below 4G. */ ZONE_DMA32, #endif /* * Normal addressable memory is in ZONE_NORMAL. DMA operations can be * performed on pages in ZONE_NORMAL if the DMA devices support * transfers to all addressable memory. */ ZONE_NORMAL, #ifdef CONFIG_HIGHMEM /* * A memory area that is only addressable by the kernel through * mapping portions into its own address space. This is for example * used by i386 to allow the kernel to address the memory beyond * 900MB. The kernel will set up special mappings (page * table entries on i386) for each page that the kernel needs to * access. */ ZONE_HIGHMEM, #endif ZONE_MOVABLE, #ifdef CONFIG_ZONE_DEVICE ZONE_DEVICE, #endif __MAX_NR_ZONES }; 有一个GFP_ZONE_TABLE，ZONES_SHIFT实际上就是多少位的移位的意思。默认是从ZONE_NORMAL开始计算方法如下：\n#define GFP_ZONE_TABLE ( \\ (ZONE_NORMAL \u0026lt;\u0026lt; 0 * GFP_ZONES_SHIFT)\t\\ | (OPT_ZONE_DMA \u0026lt;\u0026lt; ___GFP_DMA * GFP_ZONES_SHIFT)\t\\ | (OPT_ZONE_HIGHMEM \u0026lt;\u0026lt; ___GFP_HIGHMEM * GFP_ZONES_SHIFT)\t\\ | (OPT_ZONE_DMA32 \u0026lt;\u0026lt; ___GFP_DMA32 * GFP_ZONES_SHIFT)\t\\ | (ZONE_NORMAL \u0026lt;\u0026lt; ___GFP_MOVABLE * GFP_ZONES_SHIFT)\t\\ | (OPT_ZONE_DMA \u0026lt;\u0026lt; (___GFP_MOVABLE | ___GFP_DMA) * GFP_ZONES_SHIFT) \\ | (ZONE_MOVABLE \u0026lt;\u0026lt; (___GFP_MOVABLE | ___GFP_HIGHMEM) * GFP_ZONES_SHIFT)\\ | (OPT_ZONE_DMA32 \u0026lt;\u0026lt; (___GFP_MOVABLE | ___GFP_DMA32) * GFP_ZONES_SHIFT)\\ ) #if MAX_NR_ZONES \u0026lt; 2 #define ZONES_SHIFT 0 #elif MAX_NR_ZONES \u0026lt;= 2 #define ZONES_SHIFT 1 #elif MAX_NR_ZONES \u0026lt;= 4 #define ZONES_SHIFT 2 #elif MAX_NR_ZONES \u0026lt;= 8 #define ZONES_SHIFT 3 外部碎片或者说迁移类型的问题，看这个页面https://pingcap.com/blog-cn/linux-kernel-vs-memory-fragmentation-1/和https://article.itxueyuan.com/pWkBe页面。此外，为了对抗碎片化的问题，把一些文章贴进来：\nlwn 发布时间 标题 2004-09-08 Kswapd and high-order allocations 2004-05-10 Active memory defragmentation 2005-02-01 Yet another approach to memory fragmentation 2005-11-02 Fragmentation avoidance 2005-11-08 More on fragmentation avoidance 2006-11-28 Avoiding - and fixing - memory fragmentation 2010-01-06 Memory compaction 2014-03-26 Memory compaction issues 2015-07-14 Making kernel pages movable 2016-04-23 CMA and compaction 2016-05-10 make direct compaction more deterministic 2017-03-21 Proactive compaction 2018-10-31 Fragmentation avoidance improvements 2020-04-21 Proactive compaction for the kernel 对于物理内存的回收，释放交换等等内容，都是针对管理区而言的。我们看看每个管理区的结构\nstruct zone { /* Fields commonly accessed by the page allocator */ /* zone watermarks, access with *_wmark_pages(zone) macros */ unsigned long watermark[NR_WMARK]; /* * When free pages are below this point, additional steps are taken * when reading the number of free pages to avoid per-cpu counter * drift allowing watermarks to be breached */ unsigned long percpu_drift_mark; /* * We don\u0026#39;t know if the memory that we\u0026#39;re going to allocate will be freeable * or/and it will be released eventually, so to avoid totally wasting several * GB of ram we must reserve some of the lower zone memory (otherwise we risk * to run OOM on the lower zones despite there\u0026#39;s tons of freeable ram * on the higher zones). This array is recalculated at runtime if the * sysctl_lowmem_reserve_ratio sysctl changes. */ unsigned long\tlowmem_reserve[MAX_NR_ZONES]; #ifdef CONFIG_NUMA int node; /* * zone reclaim becomes active if more unmapped pages exist. */ unsigned long\tmin_unmapped_pages; unsigned long\tmin_slab_pages; #endif struct per_cpu_pageset __percpu *pageset; /* * free areas of different sizes */ spinlock_t\tlock; int all_unreclaimable; /* All pages pinned */ #ifdef CONFIG_MEMORY_HOTPLUG /* see spanned/present_pages for more description */ seqlock_t\tspan_seqlock; #endif struct free_area\tfree_area[MAX_ORDER]; #ifndef CONFIG_SPARSEMEM /* * Flags for a pageblock_nr_pages block. See pageblock-flags.h. * In SPARSEMEM, this map is stored in struct mem_section */ unsigned long\t*pageblock_flags; #endif /* CONFIG_SPARSEMEM */ #ifdef CONFIG_COMPACTION /* * On compaction failure, 1\u0026lt;\u0026lt;compact_defer_shift compactions * are skipped before trying again. The number attempted since * last failure is tracked with compact_considered. */ unsigned int\tcompact_considered; unsigned int\tcompact_defer_shift; #endif ZONE_PADDING(_pad1_) /* Fields commonly accessed by the page reclaim scanner */ spinlock_t\tlru_lock;\tstruct zone_lru { struct list_head list; } lru[NR_LRU_LISTS]; struct zone_reclaim_stat reclaim_stat; unsigned long\tpages_scanned;\t/* since last reclaim */ unsigned long\tflags;\t/* zone flags, see below */ /* Zone statistics */ atomic_long_t\tvm_stat[NR_VM_ZONE_STAT_ITEMS]; /* * The target ratio of ACTIVE_ANON to INACTIVE_ANON pages on * this zone\u0026#39;s LRU. Maintained by the pageout code. */ unsigned int inactive_ratio; ZONE_PADDING(_pad2_) /* Rarely used or read-mostly fields */ /* * wait_table\t-- the array holding the hash table * wait_table_hash_nr_entries\t-- the size of the hash table array * wait_table_bits\t-- wait_table_size == (1 \u0026lt;\u0026lt; wait_table_bits) * * The purpose of all these is to keep track of the people * waiting for a page to become available and make them * runnable again when possible. The trouble is that this * consumes a lot of space, especially when so few things * wait on pages at a given time. So instead of using * per-page waitqueues, we use a waitqueue hash table. * * The bucket discipline is to sleep on the same queue when * colliding and wake all in that wait queue when removing. * When something wakes, it must check to be sure its page is * truly available, a la thundering herd. The cost of a * collision is great, but given the expected load of the * table, they should be so rare as to be outweighed by the * benefits from the saved space. * * __wait_on_page_locked() and unlock_page() in mm/filemap.c, are the * primary users of these fields, and in mm/page_alloc.c * free_area_init_core() performs the initialization of them. */ wait_queue_head_t\t* wait_table; unsigned long\twait_table_hash_nr_entries; unsigned long\twait_table_bits; /* * Discontig memory support fields. */ struct pglist_data\t*zone_pgdat; /* zone_start_pfn == zone_start_paddr \u0026gt;\u0026gt; PAGE_SHIFT */ unsigned long\tzone_start_pfn; /* * zone_start_pfn, spanned_pages and present_pages are all * protected by span_seqlock. It is a seqlock because it has * to be read outside of zone-\u0026gt;lock, and it is done in the main * allocator path. But, it is written quite infrequently. * * The lock is declared along with zone-\u0026gt;lock because it is * frequently read in proximity to zone-\u0026gt;lock. It\u0026#39;s good to * give them a chance of being in the same cacheline. */ unsigned long\tspanned_pages;\t/* total size, including holes */ unsigned long\tpresent_pages;\t/* amount of memory (excluding holes) */ /* * rarely used fields: */ const char\t*name; } ____cacheline_internodealigned_in_smp; 这些内存管理区统统划为一个节点。\n上面这些代码都只是偏向于理解，并不难，还是得RTFSC。\n结尾的闲言碎语 # 写到这里差不多就可以结束了，就不多说了。 ","date":"2020 年 9 月 16 日","externalUrl":null,"permalink":"/posts/2020-09-16-%E5%86%85%E5%AD%98%E5%AD%A6%E4%B9%A01/","section":"Posts","summary":"","title":"内存学习(1)","type":"posts"},{"content":" 内存学习(10) # 前言 # 内存这块我很早之前看过，但是一直没怎么做记录。这次姑且记录下这次的阅读的书籍分别为：《Linux内核0.11完全注释》，《Linux内核源代码情景分析》，《ATCP内存实现》(这个是我司的代码管理)。啊，对了，这次我同时在看SICP的东西，希望顺便打打基础。当然，纸上得来终觉浅，绝知此事要躬行，还是从已经分配好的内存看起吧，从用户态的开始看。有一点需要赘述一下，关于每个地方的锁，是否开中断，权限这三个会单独开其他三个文章来分析\n缺页中断的发生场景 # 什么时候会发生缺页中断？我们分析下 1 发生缺页异常的线性地址在内核态 2 发生缺页异常的线性地址在用户态 针对第一种情况下， 1 如果是用户态的访问 2 如果是内核态的访问 针对第二种情况 1 如果是用户态的访问，那么要么是NOT present要么是堆栈expand 2 如果是内核态的访问，那么要么是内核错误，另一种情况只能是系统调用，从而也可能调用expand_stack函数\n从do_page_fault开始 # 先从缺页异常说起，我们假设走的是堆栈的缺页异常，这个时候还没有建立想访问的错误address对应的物理地址，所以此时会触发缺页中断，从而进入do_page_fault。此时有错误码，pt_regs为寄存器的值，下面我们拆开理一理代码流程。\n首先获得陷入内核态之前，当前进程的描述符，current宏从实现角度来说就是代码get_current()函数，这个函数返回的实际上是current_thread_info()-\u0026gt;task。我们都非常清楚，现在是在当前进程的内核栈里，而线程栈紧贴着内核地址，向下延伸两个页的长度，线程栈从上向下生长，因此我们能轻易地找到。从而获得当前进程的mm_struct\u0026ndash;内存管理结构。从cr2寄存器中读出来想访问的地址。kmemcheck_active函数和kmemcheck_hide函数我们都跳过，都是cpu的内存布局合理性检查函数，我还没看过。 调用函数fault_in_kernel_space判断page_fault所访问的线性地址是不是发生在内核态，追进去看实现，就会发现判断虚拟地址是不是在PAGE_OFFSET上。如果page_fault的虚拟地址发生在kernel之上，再看看错误码是不是包含PF_RSVD | PF_USER | PF_PROT，包含那么必然是出现了用户态访问内核地址，或者是内核访问空洞/保留区的问题，这种情况下直接发个信号表示终止完事了。相反，是kernel的调用，那么调用vmalloc_fault函数要么给直接映射区间，要么给vmallc区间分配地址。spurious_fault负责判断是不是由于陈旧TLB导致的PAGE FAULT，也就是LAZY TLB，毕竟更新所有线程的页表是不现实，而且耗费巨大的，因为刷新别的CPU的TLB是个很蛋疼的操作。 现在我们知道不是访问内核态的线性地址了，判断是不是用户态的内存申请，开中断 如果error_code \u0026amp; PF_RSVD，说明是用户态访问了内核使用的线性地址。 缺页发生的时候应该还没有为写获得信号量mmap_sem，使用down_read_trylock()函数，发现不是发生在用户态是内核态的错误，那就发个错误信号终止了。 代码可以运行到这里说明是客户端page fault，下面就可以判断是不是堆栈的问题了。 获取信号量，查询address属于的vma，如果没有找到那就是没有哪个vma的可以包含该地址，这是个越界访问。直接报错。相反如果address + 65536 + 32 * sizeof(unsigned long) \u0026lt; regs-\u0026gt;sp为真，也就是说这是个对堆栈的入栈操作。那么调用expand_stack函数拓展堆栈（堆栈是向下发展的），我们假设分配成功。 判断vma的访问权限和错误原因的访问权限是不是符合 调用handle_mm_fault函数分配物理内存。 dotraplinkage void __kprobes do_page_fault(struct pt_regs *regs, unsigned long error_code) { struct vm_area_struct *vma; struct task_struct *tsk; unsigned long address; struct mm_struct *mm; int write; int fault; tsk = current; mm = tsk-\u0026gt;mm; /* Get the faulting address: */ address = read_cr2(); /* * Detect and handle instructions that would cause a page fault for * both a tracked kernel page and a userspace page. */ if (kmemcheck_active(regs)) kmemcheck_hide(regs); prefetchw(\u0026amp;mm-\u0026gt;mmap_sem); if (unlikely(kmmio_fault(regs, address))) return; /* * We fault-in kernel-space virtual memory on-demand. The * \u0026#39;reference\u0026#39; page table is init_mm.pgd. * * NOTE! We MUST NOT take any locks for this case. We may * be in an interrupt or a critical region, and should * only copy the information from the master page table, * nothing more. * * This verifies that the fault happens in kernel space * (error_code \u0026amp; 4) == 0, and that the fault was not a * protection error (error_code \u0026amp; 9) == 0. */ if (unlikely(fault_in_kernel_space(address))) { if (!(error_code \u0026amp; (PF_RSVD | PF_USER | PF_PROT))) { if (vmalloc_fault(address) \u0026gt;= 0) return; if (kmemcheck_fault(regs, address, error_code)) return; } /* Can handle a stale RO-\u0026gt;RW TLB: */ if (spurious_fault(error_code, address)) return; /* kprobes don\u0026#39;t want to hook the spurious faults: */ if (notify_page_fault(regs)) return; /* * Don\u0026#39;t take the mm semaphore here. If we fixup a prefetch * fault we could otherwise deadlock: */ bad_area_nosemaphore(regs, error_code, address); return; } /* kprobes don\u0026#39;t want to hook the spurious faults: */ if (unlikely(notify_page_fault(regs))) return; /* * It\u0026#39;s safe to allow irq\u0026#39;s after cr2 has been saved and the * vmalloc fault has been handled. * * User-mode registers count as a user access even for any * potential system fault or CPU buglet: */ if (user_mode_vm(regs)) { local_irq_enable(); error_code |= PF_USER; } else { if (regs-\u0026gt;flags \u0026amp; X86_EFLAGS_IF) local_irq_enable(); } if (unlikely(error_code \u0026amp; PF_RSVD)) pgtable_bad(regs, error_code, address); perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, 0, regs, address); /* * If we\u0026#39;re in an interrupt, have no user context or are running * in an atomic region then we must not take the fault: */ if (unlikely(in_atomic() || !mm)) { bad_area_nosemaphore(regs, error_code, address); return; } /* * When running in the kernel we expect faults to occur only to * addresses in user space. All other faults represent errors in * the kernel and should generate an OOPS. Unfortunately, in the * case of an erroneous fault occurring in a code path which already * holds mmap_sem we will deadlock attempting to validate the fault * against the address space. Luckily the kernel only validly * references user space from well defined areas of code, which are * listed in the exceptions table. * * As the vast majority of faults will be valid we will only perform * the source reference check when there is a possibility of a * deadlock. Attempt to lock the address space, if we cannot we then * validate the source. If this is invalid we can skip the address * space check, thus avoiding the deadlock: */ if (unlikely(!down_read_trylock(\u0026amp;mm-\u0026gt;mmap_sem))) { if ((error_code \u0026amp; PF_USER) == 0 \u0026amp;\u0026amp; !search_exception_tables(regs-\u0026gt;ip)) { bad_area_nosemaphore(regs, error_code, address); return; } down_read(\u0026amp;mm-\u0026gt;mmap_sem); } else { /* * The above down_read_trylock() might have succeeded in * which case we\u0026#39;ll have missed the might_sleep() from * down_read(): */ might_sleep(); } vma = find_vma(mm, address); if (unlikely(!vma)) { bad_area(regs, error_code, address); return; } if (likely(vma-\u0026gt;vm_start \u0026lt;= address)) goto good_area; if (unlikely(!(vma-\u0026gt;vm_flags \u0026amp; VM_GROWSDOWN))) { bad_area(regs, error_code, address); return; } if (error_code \u0026amp; PF_USER) { /* * Accessing the stack below %sp is always a bug. * The large cushion allows instructions like enter * and pusha to work. (\u0026#34;enter $65535, $31\u0026#34; pushes * 32 pointers and then decrements %sp by 65535.) */ if (unlikely(address + 65536 + 32 * sizeof(unsigned long) \u0026lt; regs-\u0026gt;sp)) { bad_area(regs, error_code, address); return; } } if (unlikely(expand_stack(vma, address))) { bad_area(regs, error_code, address); return; } /* * Ok, we have a good vm_area for this memory access, so * we can handle it.. */ good_area: write = error_code \u0026amp; PF_WRITE; if (unlikely(access_error(error_code, write, vma))) { bad_area_access_error(regs, error_code, address); return; } /* * If for any reason at all we couldn\u0026#39;t handle the fault, * make sure we exit gracefully rather than endlessly redo * the fault: */ fault = handle_mm_fault(mm, vma, address, write ? FAULT_FLAG_WRITE : 0); if (unlikely(fault \u0026amp; VM_FAULT_ERROR)) { mm_fault_error(regs, error_code, address, fault); return; } if (fault \u0026amp; VM_FAULT_MAJOR) { tsk-\u0026gt;maj_flt++; perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, 0, regs, address); } else { tsk-\u0026gt;min_flt++; perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, 0, regs, address); } check_v8086_mode(regs, address, tsk); up_read(\u0026amp;mm-\u0026gt;mmap_sem); } 看看expand_stack函数 # expand_stack调用expand_downwards函数，流程：\n首先检查该vma是不是已经有anon_vma了，没有的话分配一个anon_vma结构，同时建立一个匿名映射。为了能够顺利锁住这块堆栈，这里的vma必须得有一个能够关联到的anon_vma结构。注意，分配给一个线性区的页框在这个线性区被删除之前永远不会被释放 security_file_mmap函数由LSM模块调用，但是干啥的我也不知道还。。。 锁住vma-\u0026gt;anon_vma的根节点，匿名映射是一个再vma-\u0026gt;anon_vma-\u0026gt;root上的链表，如果同时两个有同样父进程的子进程操作这个链表会出错，所以需要锁住自旋锁，保证对链表的操作唯一性。 获得了自旋锁以后需要判断地址是不是已经落在了vma的段落内了，因为可能其他进程已经改变了vma的vm_start起始地址了，这里已经关中断了。 static int expand_downwards(struct vm_area_struct *vma, unsigned long address) { int error; /* * We must make sure the anon_vma is allocated * so that the anon_vma locking is not a noop. */ if (unlikely(anon_vma_prepare(vma))) return -ENOMEM; address \u0026amp;= PAGE_MASK; error = security_file_mmap(NULL, 0, 0, 0, address, 1); if (error) return error; vma_lock_anon_vma(vma); /* * vma-\u0026gt;vm_start/vm_end cannot change under us because the caller * is required to hold the mmap_sem in read mode. We need the * anon_vma lock to serialize against concurrent expand_stacks. */ /* Somebody else might have raced and expanded it already */ if (address \u0026lt; vma-\u0026gt;vm_start) { unsigned long size, grow; size = vma-\u0026gt;vm_end - address; grow = (vma-\u0026gt;vm_start - address) \u0026gt;\u0026gt; PAGE_SHIFT; error = -ENOMEM; if (grow \u0026lt;= vma-\u0026gt;vm_pgoff) { error = acct_stack_growth(vma, size, grow); if (!error) { vma-\u0026gt;vm_start = address; vma-\u0026gt;vm_pgoff -= grow; perf_event_mmap(vma); } } } vma_unlock_anon_vma(vma); khugepaged_enter_vma_merge(vma); return error; } 看看handle_mm_fault函数 # __set_current_state()设置当前进程的状态为运行，当进入中断的时候进程的状态为TASK_INTERRUPT，之后给PGGAULT加个计数。 先获得pgd_offset，然后判断有没有值。同样的方式（判断有没有，没有就分配）分配pmd，分配pud，pmd，pte这里值得注意的是我们都是在内核环境里，虽然内核环境可以访问0-3G的内存地址，但是这里的限定地址都是指向页中间目录项，页上级目录项的线性的地址，这些地址属于高端地址还是低端地址呢？对于X86_32模式自然不需要多说，pud_t自然就是pgd的地址。出于通用性考虑，我们直接看pmd = pmd_alloc(mm, pud, address);的代码。可以看到，调用顺序是__pmd_alloc==\u0026gt;pmd_t *new = pmd_alloc_one(mm, address);==\u0026gt;(pmd_t *)get_zeroed_page(GFP_KERNEL|__GFP_REPEAT);==\u0026gt;alloc_pages。这里最后需要注意返回值是page_address(page)。用于页目录或者页表项的地址如果是低端地址，那么就直接使用低端地址映射回去，如果是高端地址，建立的地址是高端永久地址。但是我们这个过程并没有建立高端地址，所以必然是返回低端地址，也就是说页目录项和页中间目录项必然是低端地址。 下面开始pte_alloc_map函数了，看这个函数实际上返回的是指向页描述符的地址，即struct page *pte;但是这块地址实际上是高端内存的临时映射，具体参看pte_offset_map函数实际是kmap_atomic也就是临时内核映射。所以这里的pte的线性地址可以是高端内存地址，然后就到了重头戏handle_pte_fault int handle_mm_fault(struct mm_struct *mm, struct vm_area_struct *vma, unsigned long address, unsigned int flags) { pgd_t *pgd; pud_t *pud; pmd_t *pmd; pte_t *pte; __set_current_state(TASK_RUNNING); count_vm_event(PGFAULT); /* do counter updates before entering really critical section. */ check_sync_rss_stat(current); if (unlikely(is_vm_hugetlb_page(vma))) return hugetlb_fault(mm, vma, address, flags); pgd = pgd_offset(mm, address); pud = pud_alloc(mm, pgd, address); if (!pud) return VM_FAULT_OOM; pmd = pmd_alloc(mm, pud, address); if (!pmd) return VM_FAULT_OOM; if (pmd_none(*pmd) \u0026amp;\u0026amp; transparent_hugepage_enabled(vma)) { if (!vma-\u0026gt;vm_ops) return do_huge_pmd_anonymous_page(mm, vma, address, pmd, flags); } else { pmd_t orig_pmd = *pmd; barrier(); if (pmd_trans_huge(orig_pmd)) { if (flags \u0026amp; FAULT_FLAG_WRITE \u0026amp;\u0026amp; !pmd_write(orig_pmd) \u0026amp;\u0026amp; !pmd_trans_splitting(orig_pmd)) return do_huge_pmd_wp_page(mm, vma, address, pmd, orig_pmd); return 0; } } /* * Use __pte_alloc instead of pte_alloc_map, because we can\u0026#39;t * run pte_offset_map on the pmd, if an huge pmd could * materialize from under us from a different thread. */ if (unlikely(pmd_none(*pmd)) \u0026amp;\u0026amp; __pte_alloc(mm, vma, pmd, address)) return VM_FAULT_OOM; /* if an huge pmd materialized from under us just retry later */ if (unlikely(pmd_trans_huge(*pmd))) return 0; /* * A regular pmd is established and it can\u0026#39;t morph into a huge pmd * from under us anymore at this point because we hold the mmap_sem * read mode and khugepaged takes it in write mode. So now it\u0026#39;s * safe to run pte_offset_map(). */ pte = pte_offset_map(pmd, address); return handle_pte_fault(mm, vma, address, pte, pmd, flags); } handle_pte_fault函数 # 这个函数可以说是非常核心的函数了，处理包括写拷贝，文件缓冲页，交换缓冲页等多种情况，可以将这个函数理解为包工头函数。 上一步的时候我们已经说过了，我们已经建立了内核高端内存临时映射，也就是说我们有了页表的临时线性地址(虽然这个地址还在高层)，这个时候我们面对的问题就是给pte分配具体的地址，实际上这里存在几个问题，如何知道分配多少内存呢？这些分配的内存从伙伴分配器上摘下来之后又是怎么管理呢？\n根据页表的内容判断是不是在内存里，如果不在内存里说明要么是原先就不存在要么是交换出去或者在文件里。 如果entry的内容为空，则说明是一直不存在，需要新分配内存，或者给文件建立内存映射。我们知道如果是文件的内存映射，那么vma-\u0026gt;vm_ops != NULL，从而区分是不是建立文件映射。不是文件映射的话，调用do_anonymous_page函数，是文件映射调用do_linear_fault或者do_nonlinear_fault 如果entry不为空，只能说明内存页被交换出去了，那就在交换区找到内存缓存，交换调用函数do_swap_page 前面几种情况我们都看了，看最后部分的代码。如果物理内存中存在具体的页面，且flags包含写请求，那只能说明是写保护，也就是COW，当然也要检查下entry是不是写保护，从而决定是否调用do_wp_page。如果上面的代码都判断过了，却都没进去，那就设置页面最近被访问过即pte_mkyoung int handle_pte_fault(struct mm_struct *mm, struct vm_area_struct *vma, unsigned long address, pte_t *pte, pmd_t *pmd, unsigned int flags) { pte_t entry; spinlock_t *ptl; entry = *pte; if (!pte_present(entry)) { if (pte_none(entry)) { if (vma-\u0026gt;vm_ops) { if (likely(vma-\u0026gt;vm_ops-\u0026gt;fault)) return do_linear_fault(mm, vma, address, pte, pmd, flags, entry); } return do_anonymous_page(mm, vma, address, pte, pmd, flags); } if (pte_file(entry)) return do_nonlinear_fault(mm, vma, address, pte, pmd, flags, entry); return do_swap_page(mm, vma, address, pte, pmd, flags, entry); } ptl = pte_lockptr(mm, pmd); spin_lock(ptl); if (unlikely(!pte_same(*pte, entry))) goto unlock; if (flags \u0026amp; FAULT_FLAG_WRITE) { if (!pte_write(entry)) return do_wp_page(mm, vma, address, pte, pmd, ptl, entry); entry = pte_mkdirty(entry); } entry = pte_mkyoung(entry); if (ptep_set_access_flags(vma, address, pte, entry, flags \u0026amp; FAULT_FLAG_WRITE)) { update_mmu_cache(vma, address, pte); } else { /* * This is needed only for protection faults but the arch code * is not yet telling us if this is a protection fault or not. * This still avoids useless tlb flushes for .text page faults * with threads. */ if (flags \u0026amp; FAULT_FLAG_WRITE) flush_tlb_fix_spurious_fault(vma, address); } unlock: pte_unmap_unlock(pte, ptl); return 0; } do_anonymous_page # 该函数就是分配的真正地方了，\n先调用pte_unmap取消内核高端映射，\n调用alloc_zeroed_user_highpage_movable函数尝试分配高端内存，函数的实质是调用__alloc_zeroed_user_highpage，一层层的静态inline函数实质上最后调用的是__alloc_pages_nodemask函数。这里要注意，实际上只是分配一个内存页。\nstatic int do_anonymous_page(struct mm_struct *mm, struct vm_area_struct *vma, unsigned long address, pte_t *page_table, pmd_t *pmd, unsigned int flags) { struct page *page; spinlock_t *ptl; pte_t entry; pte_unmap(page_table); /* Check if we need to add a guard page to the stack */ if (check_stack_guard_page(vma, address) \u0026lt; 0) return VM_FAULT_SIGBUS; /* Use the zero-page for reads */ if (!(flags \u0026amp; FAULT_FLAG_WRITE)) { entry = pte_mkspecial(pfn_pte(my_zero_pfn(address), vma-\u0026gt;vm_page_prot)); page_table = pte_offset_map_lock(mm, pmd, address, \u0026amp;ptl); if (!pte_none(*page_table)) goto unlock; goto setpte; } /* Allocate our own private page. */ if (unlikely(anon_vma_prepare(vma))) goto oom; page = alloc_zeroed_user_highpage_movable(vma, address); if (!page) goto oom; __SetPageUptodate(page); if (mem_cgroup_newpage_charge(page, mm, GFP_KERNEL)) goto oom_free_page; entry = mk_pte(page, vma-\u0026gt;vm_page_prot); if (vma-\u0026gt;vm_flags \u0026amp; VM_WRITE) entry = pte_mkwrite(pte_mkdirty(entry)); page_table = pte_offset_map_lock(mm, pmd, address, \u0026amp;ptl); if (!pte_none(*page_table)) goto release; inc_mm_counter_fast(mm, MM_ANONPAGES); page_add_new_anon_rmap(page, vma, address); setpte: set_pte_at(mm, address, page_table, entry); /* No need to invalidate - it was non-present before */ update_mmu_cache(vma, address, page_table); unlock: pte_unmap_unlock(page_table, ptl); return 0; release: mem_cgroup_uncharge_page(page); page_cache_release(page); goto unlock; oom_free_page: page_cache_release(page); oom: return VM_FAULT_OOM; } __alloc_pages_nodemask函数 # 我们这里的分析去掉诸如内核注入错误，配置进程只能运行特定CPU，\n调用first_zones_zonelist获取要分配内存的zone， 调用get_page_from_freelist尝试初次获取内存，如果内存获取成功就讲分派到的page首页返回 如果get_page_from_freelist没有成功获取内存，就调用__alloc_pages_slowpath，这个函数的调用可以说是最慢的，需要调用kswaped进程清理内存。我们最后看 struct page * __alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, struct zonelist *zonelist, nodemask_t *nodemask) { enum zone_type high_zoneidx = gfp_zone(gfp_mask); struct zone *preferred_zone; struct page *page; int migratetype = allocflags_to_migratetype(gfp_mask); gfp_mask \u0026amp;= gfp_allowed_mask; lockdep_trace_alloc(gfp_mask); might_sleep_if(gfp_mask \u0026amp; __GFP_WAIT); if (should_fail_alloc_page(gfp_mask, order)) return NULL; /* * Check the zones suitable for the gfp_mask contain at least one * valid zone. It\u0026#39;s possible to have an empty zonelist as a result * of GFP_THISNODE and a memoryless node */ if (unlikely(!zonelist-\u0026gt;_zonerefs-\u0026gt;zone)) return NULL; get_mems_allowed(); /* The preferred zone is used for statistics later */ first_zones_zonelist(zonelist, high_zoneidx, nodemask ? : \u0026amp;cpuset_current_mems_allowed, \u0026amp;preferred_zone); if (!preferred_zone) { put_mems_allowed(); return NULL; } /* First allocation attempt */ page = get_page_from_freelist(gfp_mask|__GFP_HARDWALL, nodemask, order, zonelist, high_zoneidx, ALLOC_WMARK_LOW|ALLOC_CPUSET, preferred_zone, migratetype); if (unlikely(!page)) page = __alloc_pages_slowpath(gfp_mask, order, zonelist, high_zoneidx, nodemask, preferred_zone, migratetype); put_mems_allowed(); trace_mm_page_alloc(page, order, gfp_mask, migratetype); return page; } get_page_from_freelist函数 # 我们考虑内存还是考虑没有CPU_SET和NUMA的情况\n判断zone_water_mark是否ok， 调用buffered_rmqueue函数 static struct page * get_page_from_freelist(gfp_t gfp_mask, nodemask_t *nodemask, unsigned int order, struct zonelist *zonelist, int high_zoneidx, int alloc_flags, struct zone *preferred_zone, int migratetype) { struct zoneref *z; struct page *page = NULL; int classzone_idx; struct zone *zone; nodemask_t *allowednodes = NULL;/* zonelist_cache approximation */ int zlc_active = 0;\t/* set if using zonelist_cache */ int did_zlc_setup = 0;\t/* just call zlc_setup() one time */ classzone_idx = zone_idx(preferred_zone); zonelist_scan: /* * Scan zonelist, looking for a zone with enough free. * See also cpuset_zone_allowed() comment in kernel/cpuset.c. */ for_each_zone_zonelist_nodemask(zone, z, zonelist, high_zoneidx, nodemask) { if (NUMA_BUILD \u0026amp;\u0026amp; zlc_active \u0026amp;\u0026amp; !zlc_zone_worth_trying(zonelist, z, allowednodes)) continue; if ((alloc_flags \u0026amp; ALLOC_CPUSET) \u0026amp;\u0026amp; !cpuset_zone_allowed_softwall(zone, gfp_mask)) goto try_next_zone; BUILD_BUG_ON(ALLOC_NO_WATERMARKS \u0026lt; NR_WMARK); if (!(alloc_flags \u0026amp; ALLOC_NO_WATERMARKS)) { unsigned long mark; int ret; mark = zone-\u0026gt;watermark[alloc_flags \u0026amp; ALLOC_WMARK_MASK]; if (zone_watermark_ok(zone, order, mark, classzone_idx, alloc_flags)) goto try_this_zone; if (zone_reclaim_mode == 0) goto this_zone_full; ret = zone_reclaim(zone, gfp_mask, order); switch (ret) { case ZONE_RECLAIM_NOSCAN: /* did not scan */ goto try_next_zone; case ZONE_RECLAIM_FULL: /* scanned but unreclaimable */ goto this_zone_full; default: /* did we reclaim enough */ if (!zone_watermark_ok(zone, order, mark, classzone_idx, alloc_flags)) goto this_zone_full; } } try_this_zone: page = buffered_rmqueue(preferred_zone, zone, order, gfp_mask, migratetype); if (page) break; this_zone_full: if (NUMA_BUILD) zlc_mark_zone_full(zonelist, z); try_next_zone: if (NUMA_BUILD \u0026amp;\u0026amp; !did_zlc_setup \u0026amp;\u0026amp; nr_online_nodes \u0026gt; 1) { /* * we do zlc_setup after the first zone is tried but only * if there are multiple nodes make it worthwhile */ allowednodes = zlc_setup(zonelist, alloc_flags); zlc_active = 1; did_zlc_setup = 1; } } if (unlikely(NUMA_BUILD \u0026amp;\u0026amp; page == NULL \u0026amp;\u0026amp; zlc_active)) { /* Disable zlc cache for second zonelist scan */ zlc_active = 0; goto zonelist_scan; } return page; } buffered_rmqueue函数 # 先判断是从cpu的冷缓存还是热缓存取，这里冷热的判断用的是!!实际上就是个条件判断。 如果order为0，这说明只是想要一个缓存页，从cpu的冷/热缓存取即可，也就是从每个per_cpu_pageset的per_cpu_page中取。如果内存不足，调用rmqueue_bulk函数从伙伴分配器里面取出。热缓存加到头，冷缓存加到尾 static inline struct page *buffered_rmqueue(struct zone *preferred_zone, struct zone *zone, int order, gfp_t gfp_flags, int migratetype) { unsigned long flags; struct page *page; int cold = !!(gfp_flags \u0026amp; __GFP_COLD); again: if (likely(order == 0)) { struct per_cpu_pages *pcp; struct list_head *list; local_irq_save(flags); pcp = \u0026amp;this_cpu_ptr(zone-\u0026gt;pageset)-\u0026gt;pcp; list = \u0026amp;pcp-\u0026gt;lists[migratetype]; if (list_empty(list)) { pcp-\u0026gt;count += rmqueue_bulk(zone, 0, pcp-\u0026gt;batch, list, migratetype, cold); if (unlikely(list_empty(list))) goto failed; } if (cold) page = list_entry(list-\u0026gt;prev, struct page, lru); else page = list_entry(list-\u0026gt;next, struct page, lru); list_del(\u0026amp;page-\u0026gt;lru); pcp-\u0026gt;count--; } else { if (unlikely(gfp_flags \u0026amp; __GFP_NOFAIL)) { /* * __GFP_NOFAIL is not to be used in new code. * * All __GFP_NOFAIL callers should be fixed so that they * properly detect and handle allocation failures. * * We most definitely don\u0026#39;t want callers attempting to * allocate greater than order-1 page units with * __GFP_NOFAIL. */ WARN_ON_ONCE(order \u0026gt; 1); } spin_lock_irqsave(\u0026amp;zone-\u0026gt;lock, flags); page = __rmqueue(zone, order, migratetype); spin_unlock(\u0026amp;zone-\u0026gt;lock); if (!page) goto failed; __mod_zone_page_state(zone, NR_FREE_PAGES, -(1 \u0026lt;\u0026lt; order)); } __count_zone_vm_events(PGALLOC, zone, 1 \u0026lt;\u0026lt; order); zone_statistics(preferred_zone, zone, gfp_flags); local_irq_restore(flags); VM_BUG_ON(bad_range(zone, page)); if (prep_new_page(page, order, gfp_flags)) goto again; return page; failed: local_irq_restore(flags); return NULL; } 结尾的闲言碎语 # 写到这里差不多就可以结束了，就不多说了。 ","date":"2020 年 9 月 16 日","externalUrl":null,"permalink":"/posts/2020-09-16-%E5%86%85%E5%AD%98%E5%AD%A6%E4%B9%A010/","section":"Posts","summary":"","title":"内存学习(10)","type":"posts"},{"content":"","date":"2020 年 9 月 15 日","externalUrl":null,"permalink":"/tags/c/","section":"Tags","summary":"","title":"C","type":"tags"},{"content":" C语言的宏 # 前言 # 我这里实际上只是记录，不如直接看《宏定义黑魔法-从入门到奇技淫巧》知乎上的回答。 C语言的宏有两种类型，一种是obj-like，另一种是func-like。这两者最大的区别就是obj-like没有括号，没有变量。而func-like有括号，有变量。平时写代码的时候常用的是前一种，代码一般为。另一种写在后面，当然这里写的第二种宏的计算方式实际上是错误的，很脆弱。\n#define SSL_OK 1 #define ABS(x) x\u0026gt;0?x;0-x 如何展开宏？ # 如何展开obj-like宏？ # obj-like宏展开时为深度优先展开方式，即层层到底，再不断返回的展开方式。但是有一点需要依据，就是当前层次已经展开的宏不再展开第二次。\n如何展开func-like宏？ # func-like的宏展开时和obj-like的宏稍微不一致，首先第一点要记得：深度优先！func-like除了上面这点意外遵循下面的流程：\n首先要完全展开参数，注意如果该宏由 #/##调用，就不会展开这个宏 将当前展开的参数代替 替换列表的内容 执行#/##的结果 重新扫描替换的结果，同时检查是否可替换 上面的过程中，不可展开的列表与obj-like的一样。 宏得陷阱 # 陷阱一：宏不是函数 # 作为C语言中一种很特殊的存在，宏有其自身的陷阱。宏本身相当于一个当前代码的完全展开。因此如果诸如++i/i++之类的代码的位置出现在宏展开的结果当中两次的地方，那么++i/i++就会被计算两次，带入副作用。此外，宏如果嵌套宏，那么完全展开的结果就太大了！\n陷阱二：宏不是语句 # 结尾的闲言碎语 # 写到这里差不多就可以结束了,就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 15 日","externalUrl":null,"permalink":"/posts/2020-09-15-c%E8%AF%AD%E8%A8%80%E7%9A%84%E5%AE%8F/","section":"Posts","summary":"","title":"C语言宏的展开","type":"posts"},{"content":"","date":"2020 年 9 月 15 日","externalUrl":null,"permalink":"/tags/%E5%AE%8F/","section":"Tags","summary":"","title":"宏","type":"tags"},{"content":" OPENSSL源码阅读(7) # 前言 # 上一回说了非复用状态/完整握手状态下发送CertificateVerify消息时自动机的变化，这次我们来说说完整握手情况下发送Finished时发生了什么\n从CertificateVerify发送完毕说起 # 我们上次讲了，发送CertificateVerify之后post_work啥都没干。这次就要发送Finished消息了，此时状态是服务端写CertificateVerify阶段，即st-\u0026gt;hand_state == TLS_ST_SW_CERT_VRFY;。这里有一点值得注意，finished key已经计算完成，\n写自动机transition函数流程 # 此次进入transition函数，当前的握手状态为st-\u0026gt;hand_state == TLS_ST_SW_CERT_VRFY;，因此，新的状态是\u0026quot;服务端写Finished\u0026quot;阶段，即st-\u0026gt;hand_state = TLS_ST_SW_FINISHED。返回之后，修改写自动机的写状态st-\u0026gt;write_state = WRITE_STATE_PRE_WORK;继续向下执行，状态转变的代码为：\nstatic WRITE_TRAN ossl_statem_server13_write_transition(SSL *s) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; /* * No case for TLS_ST_BEFORE, because at that stage we have not negotiated * TLSv1.3 yet, so that is handled by ossl_statem_server_write_transition() */ switch (st-\u0026gt;hand_state) { ... case TLS_ST_SW_CERT_VRFY: st-\u0026gt;hand_state = TLS_ST_SW_FINISHED; return WRITE_TRAN_CONTINUE; 写自动机pre_work函数流程和Finished构建流程 # 进入pre_work函数之后实际上啥都没做就返回了，直接返回，继续执行。pre_work函数的代码为:\nWORK_STATE ossl_statem_server_pre_work(SSL *s, WORK_STATE wst) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; switch (st-\u0026gt;hand_state) { default: /* No pre work to be done */ break; ... } return WORK_FINISHED_CONTINUE; 构建Finished消息的流程就比较有趣了，ossl_statem_server_construct_message指定调用的函数tls_construct_finished函数之后。返回，然后调用tls_construct_finished，Finished消息构建完成就执行发送和post_work函数。首先要简单说说服务端的finished如何计算，首先需要从服务端握手秘钥计算出finished_key，计算方法为 finished_key =HKDF-Expand-Label(BaseKey, \u0026quot;finished\u0026quot;, \u0026quot;\u0026quot;, Hash.length)，之后对握手报文做HMAC，计算方法为verify_data =HMAC(finished_key,Transcript-Hash(ClientHello+ServerHello+EncryptedExtension+Certificate+CertificateVerify))，注意我写的Transcript-Hash是对我假设的双方已经发送过的数据做hash。下面看tls_construct_finished函数的代码流程：\n首先判断是不是pha，然后做个检查：如果是客户端，算下自己的finished_key。因为对于客户端而言，不像服务端已经将客户端的finished_key算出来，是客户端没算自己的finished_key。 根据角色选择不同的label，这里用的是 s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;server_finished_label，值是\u0026quot;server finished\u0026quot;，长度为15 开始计算finished的mac，代码为s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;final_finish_mac(s,sender, slen,s-\u0026gt;s3-\u0026gt;tmp.finish_md);，final_finish_mac函数实际上是tls13_final_finish_mac。等下我们看tls13_final_finish_mac函数。 将计算出来的finished消息写到数据包中 调用memcpy(s-\u0026gt;s3-\u0026gt;previous_server_finished, s-\u0026gt;s3-\u0026gt;tmp.finish_md, finish_md_len);保存此次finished消息，如果计算pha，下次可能会用到。 int tls_construct_finished(SSL *s, WPACKET *pkt) { size_t finish_md_len; const char *sender; size_t slen; /* This is a real handshake so make sure we clean it up at the end */ if (!s-\u0026gt;server \u0026amp;\u0026amp; s-\u0026gt;post_handshake_auth != SSL_PHA_REQUESTED) s-\u0026gt;statem.cleanuphand = 1; /* * We only change the keys if we didn\u0026#39;t already do this when we sent the * client certificate */ if (SSL_IS_TLS13(s) \u0026amp;\u0026amp; !s-\u0026gt;server \u0026amp;\u0026amp; s-\u0026gt;s3-\u0026gt;tmp.cert_req == 0 \u0026amp;\u0026amp; (!s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;change_cipher_state(s, SSL3_CC_HANDSHAKE | SSL3_CHANGE_CIPHER_CLIENT_WRITE))) {; /* SSLfatal() already called */ return 0; } if (s-\u0026gt;server) { sender = s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;server_finished_label; slen = s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;server_finished_label_len; } else { sender = s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;client_finished_label; slen = s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;client_finished_label_len; } finish_md_len = s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;final_finish_mac(s, sender, slen, s-\u0026gt;s3-\u0026gt;tmp.finish_md); if (finish_md_len == 0) { /* SSLfatal() already called */ return 0; } s-\u0026gt;s3-\u0026gt;tmp.finish_md_len = finish_md_len; if (!WPACKET_memcpy(pkt, s-\u0026gt;s3-\u0026gt;tmp.finish_md, finish_md_len)) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_FINISHED, ERR_R_INTERNAL_ERROR); return 0; } /* * Log the master secret, if logging is enabled. We don\u0026#39;t log it for * TLSv1.3: there\u0026#39;s a different key schedule for that. */ if (!SSL_IS_TLS13(s) \u0026amp;\u0026amp; !ssl_log_secret(s, MASTER_SECRET_LABEL, s-\u0026gt;session-\u0026gt;master_key, s-\u0026gt;session-\u0026gt;master_key_length)) { /* SSLfatal() already called */ return 0; } /* * Copy the finished so we can use it for renegotiation checks */ if (!ossl_assert(finish_md_len \u0026lt;= EVP_MAX_MD_SIZE)) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_FINISHED, ERR_R_INTERNAL_ERROR); return 0; } if (!s-\u0026gt;server) { memcpy(s-\u0026gt;s3-\u0026gt;previous_client_finished, s-\u0026gt;s3-\u0026gt;tmp.finish_md, finish_md_len); s-\u0026gt;s3-\u0026gt;previous_client_finished_len = finish_md_len; } else { memcpy(s-\u0026gt;s3-\u0026gt;previous_server_finished, s-\u0026gt;s3-\u0026gt;tmp.finish_md, finish_md_len); s-\u0026gt;s3-\u0026gt;previous_server_finished_len = finish_md_len; } return 1; } } 最后我们看看tls13_final_finish_mac消息，捋捋这个流程：\n首先对finished消息之前所有的消息计算transcript-hash，代码为ssl_handshake_hash(s, hash, sizeof(hash), \u0026amp;hashlen) 因为str是server_finished_label，所以先要设置HMAC ctx的私钥，这里可不是衍生秘钥，是设置HMAC的私钥key = EVP_PKEY_new_raw_private_key(EVP_PKEY_HMAC, NULL, s-\u0026gt;server_finished_secret, hashlen);，注意这里我们已经算出来了finished_key了，就是s-\u0026gt;server_finished_secret 使用衍生秘钥对第一步的trnascript-hash结果做一次hmac，结果即为finished消息。 size_t tls13_final_finish_mac(SSL *s, const char *str, size_t slen, unsigned char *out) { const EVP_MD *md = ssl_handshake_md(s); unsigned char hash[EVP_MAX_MD_SIZE]; size_t hashlen, ret = 0; EVP_PKEY *key = NULL; EVP_MD_CTX *ctx = EVP_MD_CTX_new(); if (!ssl_handshake_hash(s, hash, sizeof(hash), \u0026amp;hashlen)) { /* SSLfatal() already called */ goto err; } if (str == s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;server_finished_label) { key = EVP_PKEY_new_raw_private_key(EVP_PKEY_HMAC, NULL, s-\u0026gt;server_finished_secret, hashlen); } else if (SSL_IS_FIRST_HANDSHAKE(s)) { key = EVP_PKEY_new_raw_private_key(EVP_PKEY_HMAC, NULL, s-\u0026gt;client_finished_secret, hashlen); } else { unsigned char finsecret[EVP_MAX_MD_SIZE]; if (!tls13_derive_finishedkey(s, ssl_handshake_md(s), s-\u0026gt;client_app_traffic_secret, finsecret, hashlen)) goto err; key = EVP_PKEY_new_raw_private_key(EVP_PKEY_HMAC, NULL, finsecret, hashlen); OPENSSL_cleanse(finsecret, sizeof(finsecret)); } if (key == NULL || ctx == NULL || EVP_DigestSignInit(ctx, NULL, md, NULL, key) \u0026lt;= 0 || EVP_DigestSignUpdate(ctx, hash, hashlen) \u0026lt;= 0 || EVP_DigestSignFinal(ctx, out, \u0026amp;hashlen) \u0026lt;= 0) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS13_FINAL_FINISH_MAC, ERR_R_INTERNAL_ERROR); goto err; } ret = hashlen; err: EVP_PKEY_free(key); EVP_MD_CTX_free(ctx); return ret; } 写自动机发送阶段 # 没啥好说的，写CTX把消息发送出去。Finished消息依然是有服务端写秘钥保护，即由server_handshake_traffic_secret保护。\n写自动机post_work阶段 # 服务端发送完finished消息之后，就可以发送应用数据了。因此在post_work函数中要调用s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;generate_master_secret(s, s-\u0026gt;master_secret, s-\u0026gt;handshake_secret, 0, \u0026amp;s-\u0026gt;session-\u0026gt;master_key_length)与s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;change_cipher_state(s, SSL3_CC_APPLICATION | SSL3_CHANGE_CIPHER_SERVER_WRITE)函数，这两个通用函数分别指向tls13_generate_master_secret与tls13_change_cipher_state函数。调用完成之后返回WORK_FINISHED_CONTINUE。写自动机再次初始化为写初始状态，写自动机再循环st-\u0026gt;write_state = WRITE_STATE_TRANSITION;。我们先看看tls13_generate_master_secret函数。等下我们看tls13_change_cipher_state函数。\nWORK_STATE ossl_statem_server_post_work(SSL *s, WORK_STATE wst) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; s-\u0026gt;init_num = 0; switch (st-\u0026gt;hand_state) { default: ... case TLS_ST_SW_FINISHED: if (statem_flush(s) != 1) return WORK_MORE_A; ... if (SSL_IS_TLS13(s)) { if (!s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;generate_master_secret(s, s-\u0026gt;master_secret, s-\u0026gt;handshake_secret, 0, \u0026amp;s-\u0026gt;session-\u0026gt;master_key_length) || !s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;change_cipher_state(s, SSL3_CC_APPLICATION | SSL3_CHANGE_CIPHER_SERVER_WRITE)) /* SSLfatal() already called */ return WORK_ERROR; } break; return WORK_FINISHED_CONTINUE; tls13_generate_master_secret函数 # 生成主密钥很简单，我们已经生成了握手秘钥s-\u0026gt;handshake_secret，对应于TLS1.3秘钥衍生中的\u0026quot;Handshake Secret\u0026quot;，对s-\u0026gt;handshake_secret做一次Derived-Secret再做一次HKDF-EXTRACT就得到主密钥master_secret，存储到s-\u0026gt;master_secret里。tls13_generate_secret == Derived-Secret + HKDF-EXTRACT就不多讲解了。\nint tls13_generate_master_secret(SSL *s, unsigned char *out, unsigned char *prev, size_t prevlen, size_t *secret_size) { const EVP_MD *md = ssl_handshake_md(s); *secret_size = EVP_MD_size(md); /* Calls SSLfatal() if required */ return tls13_generate_secret(s, md, prev, NULL, 0, out); } tls13_change_cipher_state函数 # 此次我们调用tls13_change_cipher_state时，which为SSL3_CC_APPLICATION | SSL3_CHANGE_CIPHER_SERVER_WRITE。我们看看流程:\ntls13_change_cipher_state的第一个ifif (which \u0026amp; SSL3_CC_READ)不会进，只会进入else分支，初始化写ctx。 tls13_change_cipher_state的第一个if客户端写和服务端读也不会进入，只会进入else分支，因为是握手秘钥，所以不会进入if (which \u0026amp; SSL3_CC_HANDSHAKE),输入秘钥为insecret = s-\u0026gt;master_secret;，指定标签为static const unsigned char server_application_traffic[] = \u0026quot;s ap traffic\u0026quot;; 因为不是接受EARLY_DATA，所以接下来会进入ifif (!(which \u0026amp; SSL3_CC_EARLY))，对ClientHello,ServerHello\u0026hellip;server Finished所有的消息做hash 因为需要计算客户端应用秘钥(TLS1.3的秘钥衍生流程里的client_application_traffic_secret_0)，所以保存上一步的hash结果 根据主密钥insecret = s-\u0026gt;master_secret;和hash的结果，计算服务端应用数据写Key和服务端应用数据写Iv，代码为derive_secret_key_and_iv(s, which \u0026amp; SSL3_CC_WRITE, md, cipher,insecret, hash, label, labellen, secret, iv, ciph_ctx) 进入if (label == server_application_traffic)的代码块，计算导出主密钥，我司的代码没写这个，因为没用到。 最后一个if不会进入，因为finsecret == NULL int tls13_change_cipher_state(SSL *s, int which) { static const unsigned char client_early_traffic[] = \u0026#34;c e traffic\u0026#34;; static const unsigned char client_handshake_traffic[] = \u0026#34;c hs traffic\u0026#34;; static const unsigned char client_application_traffic[] = \u0026#34;c ap traffic\u0026#34;; static const unsigned char server_handshake_traffic[] = \u0026#34;s hs traffic\u0026#34;; static const unsigned char server_application_traffic[] = \u0026#34;s ap traffic\u0026#34;; static const unsigned char exporter_master_secret[] = \u0026#34;exp master\u0026#34;; static const unsigned char resumption_master_secret[] = \u0026#34;res master\u0026#34;; static const unsigned char early_exporter_master_secret[] = \u0026#34;e exp master\u0026#34;; unsigned char *iv; unsigned char secret[EVP_MAX_MD_SIZE]; unsigned char hashval[EVP_MAX_MD_SIZE]; unsigned char *hash = hashval; unsigned char *insecret; unsigned char *finsecret = NULL; const char *log_label = NULL; EVP_CIPHER_CTX *ciph_ctx; size_t finsecretlen = 0; const unsigned char *label; size_t labellen, hashlen = 0; int ret = 0; const EVP_MD *md = NULL; const EVP_CIPHER *cipher = NULL; if (which \u0026amp; SSL3_CC_READ) { ... } else { s-\u0026gt;statem.enc_write_state = ENC_WRITE_STATE_INVALID; if (s-\u0026gt;enc_write_ctx != NULL) { EVP_CIPHER_CTX_reset(s-\u0026gt;enc_write_ctx); } else { s-\u0026gt;enc_write_ctx = EVP_CIPHER_CTX_new(); if (s-\u0026gt;enc_write_ctx == NULL) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS13_CHANGE_CIPHER_STATE, ERR_R_MALLOC_FAILURE); goto err; } } ciph_ctx = s-\u0026gt;enc_write_ctx; iv = s-\u0026gt;write_iv; RECORD_LAYER_reset_write_sequence(\u0026amp;s-\u0026gt;rlayer); } if (((which \u0026amp; SSL3_CC_CLIENT) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_WRITE)) || ((which \u0026amp; SSL3_CC_SERVER) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_READ))) { ... } else { /* Early data never applies to client-read/server-write */ if (which \u0026amp; SSL3_CC_HANDSHAKE) { ... } else { insecret = s-\u0026gt;master_secret; label = server_application_traffic; labellen = sizeof(server_application_traffic) - 1; log_label = SERVER_APPLICATION_LABEL; } } if (!(which \u0026amp; SSL3_CC_EARLY)) { md = ssl_handshake_md(s); cipher = s-\u0026gt;s3-\u0026gt;tmp.new_sym_enc; if (!ssl3_digest_cached_records(s, 1) || !ssl_handshake_hash(s, hashval, sizeof(hashval), \u0026amp;hashlen)) { /* SSLfatal() already called */; goto err; } } /* * Save the hash of handshakes up to now for use when we calculate the * client application traffic secret */ if (label == server_application_traffic) memcpy(s-\u0026gt;server_finished_hash, hashval, hashlen); ... if (!derive_secret_key_and_iv(s, which \u0026amp; SSL3_CC_WRITE, md, cipher, insecret, hash, label, labellen, secret, iv, ciph_ctx)) { /* SSLfatal() already called */ goto err; } if (label == server_application_traffic) { memcpy(s-\u0026gt;server_app_traffic_secret, secret, hashlen); /* Now we create the exporter master secret */ if (!tls13_hkdf_expand(s, ssl_handshake_md(s), insecret, exporter_master_secret, sizeof(exporter_master_secret) - 1, hash, hashlen, s-\u0026gt;exporter_master_secret, hashlen, 1)) { /* SSLfatal() already called */ goto err; } ... } else if (label == client_application_traffic) ... ... if (finsecret != NULL \u0026amp;\u0026amp; !tls13_derive_finishedkey(s, ssl_handshake_md(s), secret, finsecret, finsecretlen)) { ... } if (!s-\u0026gt;server \u0026amp;\u0026amp; label == client_early_traffic) s-\u0026gt;statem.enc_write_state = ENC_WRITE_STATE_WRITE_PLAIN_ALERTS; else s-\u0026gt;statem.enc_write_state = ENC_WRITE_STATE_VALID; ret = 1; err: OPENSSL_cleanse(secret, sizeof(secret)); return ret; } 结语 # 服务端finished消息发送结束之后，计算服务端应用数据写密钥，流程非常简单。下回就可以说到服务端如何处理客户端的FINSIEHD消息了。\n结尾的闲言碎语 # 写到这里差不多就可以结束了,就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 13 日","externalUrl":null,"permalink":"/posts/2020-09-13-openssl%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB7/","section":"Posts","summary":"","title":"OPENSSL源码阅读(7)","type":"posts"},{"content":" OPENSSL源码阅读(8) # 前言 # 上一回说了非复用状态/完整握手状态下发送Finised消息时自动机的变化，这次我们来说说服务端读取客户端Finished时发生了什么。有一点需要注意，这里并不区分客户端是不是复用连接，对于完整握手和复用连接服务端读取finished消息的处理流程都一致。\n从Finished发送完毕说起 # 我们上次讲了，发送Finished之后重新进入写自动机调用transition函数，因为当前的握手状态为st-\u0026gt;hand_state == TLS_ST_SW_FINISHED;，所以进入新的状态为 st-\u0026gt;hand_state = TLS_ST_EARLY_DATA;。进入pre_work函数之后返回WORK_FINISHED_CONTINUE，而get_construct_message_f会什么都不做直接到post_work函数，返回WORK_FINISHED_CONTINUE，又转到写自动机的transition，因为当前状态是st-\u0026gt;hand_state == TLS_ST_EARLY_DATA;。直接返回WRITE_TRAN_FINISHED;。写自动机返回后，返回SUB_STATE_FINISHED，写自动机的小状态就暂时结束了。重新初始化读自动机，因此这次读客户端Finished消息，需要分析读自动机。\n读自动机transition函数及之前流程 # 此次进入transition函数之前，先读取tls_get_message_header函数，函数会获取当前消息种类为Finished消息。因为当前的握手状态为st-\u0026gt;hand_state == TLS_ST_EARLY_DATA;，我们这里虽然不区分复用或完整的ECDHE握手，但是我们假设是没有HelloRetryRequest请求，也不接受EarlyData的，所以代码会执行到改变当前握手状态为服务端读Finished消息阶段st-\u0026gt;hand_state = TLS_ST_SR_FINISHED;。代码如下：\nstatic int ossl_statem_server13_read_transition(SSL *s, int mt) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; /* * Note: There is no case for TLS_ST_BEFORE because at that stage we have * not negotiated TLSv1.3 yet, so that case is handled by * ossl_statem_server_read_transition() */ switch (st-\u0026gt;hand_state) { default: break; case TLS_ST_EARLY_DATA: if (s-\u0026gt;hello_retry_request == SSL_HRR_PENDING) { if (mt == SSL3_MT_CLIENT_HELLO) { st-\u0026gt;hand_state = TLS_ST_SR_CLNT_HELLO; return 1; } break; } else if (s-\u0026gt;ext.early_data == SSL_EARLY_DATA_ACCEPTED) { if (mt == SSL3_MT_END_OF_EARLY_DATA) { st-\u0026gt;hand_state = TLS_ST_SR_END_OF_EARLY_DATA; return 1; } break; } /* Fall through */ case TLS_ST_SR_END_OF_EARLY_DATA: case TLS_ST_SW_FINISHED: if (s-\u0026gt;s3-\u0026gt;tmp.cert_request) { if (mt == SSL3_MT_CERTIFICATE) { st-\u0026gt;hand_state = TLS_ST_SR_CERT; return 1; } } else { if (mt == SSL3_MT_FINISHED) { st-\u0026gt;hand_state = TLS_ST_SR_FINISHED; return 1; } } break; 读自动机tls_get_message_body函数流程和process_message流程 # 我们首先看看tls_get_message_body函数，因为消息类型是finished消息，tls_get_message_body函数不断尝试读完并解密客户端finished消息，之后会调用ssl3_take_mac(s)函数。ssl3_take_mac(s)函数这次要计算的是客户端的finished消息，因此选择client_finished_label，即 sender = s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;client_finished_label;，之后调用final_finish_mac函数计算客户端finished消息。后面的代码是用于将握手消息都保存，NST报文和KEY UPDATE报文不会保存。\nint tls_get_message_body(SSL *s, size_t *len) { size_t n, readbytes; unsigned char *p; int i; if (s-\u0026gt;s3-\u0026gt;tmp.message_type == SSL3_MT_CHANGE_CIPHER_SPEC) { ... } p = s-\u0026gt;init_msg; n = s-\u0026gt;s3-\u0026gt;tmp.message_size - s-\u0026gt;init_num; while (n \u0026gt; 0) { i = s-\u0026gt;method-\u0026gt;ssl_read_bytes(s, SSL3_RT_HANDSHAKE, NULL, \u0026amp;p[s-\u0026gt;init_num], n, 0, \u0026amp;readbytes); if (i \u0026lt;= 0) { s-\u0026gt;rwstate = SSL_READING; *len = 0; return 0; } s-\u0026gt;init_num += readbytes; n -= readbytes; } /* * If receiving Finished, record MAC of prior handshake messages for * Finished verification. */ if (*(s-\u0026gt;init_buf-\u0026gt;data) == SSL3_MT_FINISHED \u0026amp;\u0026amp; !ssl3_take_mac(s)) { /* SSLfatal() already called */ *len = 0; return 0; } /* Feed this message into MAC computation. */ if (RECORD_LAYER_is_sslv2_record(\u0026amp;s-\u0026gt;rlayer)) { ... } else { /* * We defer feeding in the HRR until later. We\u0026#39;ll do it as part of * processing the message * The TLsv1.3 handshake transcript stops at the ClientFinished * message. */ #define SERVER_HELLO_RANDOM_OFFSET (SSL3_HM_HEADER_LENGTH + 2) /* KeyUpdate and NewSessionTicket do not need to be added */ if (!SSL_IS_TLS13(s) || (s-\u0026gt;s3-\u0026gt;tmp.message_type != SSL3_MT_NEWSESSION_TICKET \u0026amp;\u0026amp; s-\u0026gt;s3-\u0026gt;tmp.message_type != SSL3_MT_KEY_UPDATE)) { if (s-\u0026gt;s3-\u0026gt;tmp.message_type != SSL3_MT_SERVER_HELLO || s-\u0026gt;init_num \u0026lt; SERVER_HELLO_RANDOM_OFFSET + SSL3_RANDOM_SIZE || memcmp(hrrrandom, s-\u0026gt;init_buf-\u0026gt;data + SERVER_HELLO_RANDOM_OFFSET, SSL3_RANDOM_SIZE) != 0) { if (!ssl3_finish_mac(s, (unsigned char *)s-\u0026gt;init_buf-\u0026gt;data, s-\u0026gt;init_num + SSL3_HM_HEADER_LENGTH)) { /* SSLfatal() already called */ *len = 0; return 0; } } } if (s-\u0026gt;msg_callback) s-\u0026gt;msg_callback(0, s-\u0026gt;version, SSL3_RT_HANDSHAKE, s-\u0026gt;init_buf-\u0026gt;data, (size_t)s-\u0026gt;init_num + SSL3_HM_HEADER_LENGTH, s, s-\u0026gt;msg_callback_arg); } *len = s-\u0026gt;init_num; return 1; } 这里的final_finish_mac对应于tls13_final_finish_mac，上次分析过一次，我们下面再分析一遍。首先，对从ClientHello，ServerHello到客户端Finished的消息做transcript-hash，代码为ssl_handshake_hash(s, hash, sizeof(hash), \u0026amp;hashlen)。因为 sender == s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;client_finished_label;，所以会指定客户端的finished_secret计算客户端finished消息，即key = EVP_PKEY_new_raw_private_key(EVP_PKEY_HMAC, NULL, s-\u0026gt;client_finished_secret, hashlen);。最后使用初始化完毕的hmac ctx计算finished消息。并返回。\nsize_t tls13_final_finish_mac(SSL *s, const char *str, size_t slen, unsigned char *out) { const EVP_MD *md = ssl_handshake_md(s); unsigned char hash[EVP_MAX_MD_SIZE]; size_t hashlen, ret = 0; EVP_PKEY *key = NULL; EVP_MD_CTX *ctx = EVP_MD_CTX_new(); if (!ssl_handshake_hash(s, hash, sizeof(hash), \u0026amp;hashlen)) { /* SSLfatal() already called */ goto err; } if (str == s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;server_finished_label) { ... } else if (SSL_IS_FIRST_HANDSHAKE(s)) { key = EVP_PKEY_new_raw_private_key(EVP_PKEY_HMAC, NULL, s-\u0026gt;client_finished_secret, hashlen); } else { ... } if (key == NULL || ctx == NULL || EVP_DigestSignInit(ctx, NULL, md, NULL, key) \u0026lt;= 0 || EVP_DigestSignUpdate(ctx, hash, hashlen) \u0026lt;= 0 || EVP_DigestSignFinal(ctx, out, \u0026amp;hashlen) \u0026lt;= 0) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS13_FINAL_FINISH_MAC, ERR_R_INTERNAL_ERROR); goto err; } ret = hashlen; err: EVP_PKEY_free(key); EVP_MD_CTX_free(ctx); return ret; } 上面tls_get_message_body函数计算结束，进入process_message函数，process_message函数包裹tls_process_finished，tls_process_finished返回以后，读自动机结束返回SUB_STATE_FINISHED.握手阶段就结束了。我们看看tls_process_finished函数流程：\n处于计算pha的缘故，需要保存握手摘要，代码为SSL_IS_TLS13(s) \u0026amp;\u0026amp; !tls13_save_handshake_digest_for_pha(s) 分别比较finished消息的长度和finished消息的内容，判断客户端是否计算正确finished消息。代码分别为if (md_len != PACKET_remaining(pkt))与if (CRYPTO_memcmp(PACKET_data(pkt), s-\u0026gt;s3-\u0026gt;tmp.peer_finish_md, md_len) != 0) 拷贝finished消息，方便将来使用 因为需要读取客户端的应用数据，需要初始化服务端应用数据读环境，代码为s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;change_cipher_state(s,SSL3_CC_APPLICATION | SSL3_CHANGE_CIPHER_SERVER_READ)，函数返回MSG_PROCESS_FINISHED_READING MSG_PROCESS_RETURN tls_process_finished(SSL *s, PACKET *pkt) { size_t md_len; /* This is a real handshake so make sure we clean it up at the end */ if (s-\u0026gt;server) { /* * To get this far we must have read encrypted data from the client. We * no longer tolerate unencrypted alerts. This value is ignored if less * than TLSv1.3 */ s-\u0026gt;statem.enc_read_state = ENC_READ_STATE_VALID; if (s-\u0026gt;post_handshake_auth != SSL_PHA_REQUESTED) s-\u0026gt;statem.cleanuphand = 1; if (SSL_IS_TLS13(s) \u0026amp;\u0026amp; !tls13_save_handshake_digest_for_pha(s)) { /* SSLfatal() already called */ return MSG_PROCESS_ERROR; } } /* * In TLSv1.3 a Finished message signals a key change so the end of the * message must be on a record boundary. */ if (SSL_IS_TLS13(s) \u0026amp;\u0026amp; RECORD_LAYER_processed_read_pending(\u0026amp;s-\u0026gt;rlayer)) { SSLfatal(s, SSL_AD_UNEXPECTED_MESSAGE, SSL_F_TLS_PROCESS_FINISHED, SSL_R_NOT_ON_RECORD_BOUNDARY); return MSG_PROCESS_ERROR; } /* If this occurs, we have missed a message */ if (!SSL_IS_TLS13(s) \u0026amp;\u0026amp; !s-\u0026gt;s3-\u0026gt;change_cipher_spec) { SSLfatal(s, SSL_AD_UNEXPECTED_MESSAGE, SSL_F_TLS_PROCESS_FINISHED, SSL_R_GOT_A_FIN_BEFORE_A_CCS); return MSG_PROCESS_ERROR; } s-\u0026gt;s3-\u0026gt;change_cipher_spec = 0; md_len = s-\u0026gt;s3-\u0026gt;tmp.peer_finish_md_len; if (md_len != PACKET_remaining(pkt)) { SSLfatal(s, SSL_AD_DECODE_ERROR, SSL_F_TLS_PROCESS_FINISHED, SSL_R_BAD_DIGEST_LENGTH); return MSG_PROCESS_ERROR; } if (CRYPTO_memcmp(PACKET_data(pkt), s-\u0026gt;s3-\u0026gt;tmp.peer_finish_md, md_len) != 0) { SSLfatal(s, SSL_AD_DECRYPT_ERROR, SSL_F_TLS_PROCESS_FINISHED, SSL_R_DIGEST_CHECK_FAILED); return MSG_PROCESS_ERROR; } /* * Copy the finished so we can use it for renegotiation checks */ if (!ossl_assert(md_len \u0026lt;= EVP_MAX_MD_SIZE)) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_PROCESS_FINISHED, ERR_R_INTERNAL_ERROR); return MSG_PROCESS_ERROR; } if (s-\u0026gt;server) { memcpy(s-\u0026gt;s3-\u0026gt;previous_client_finished, s-\u0026gt;s3-\u0026gt;tmp.peer_finish_md, md_len); s-\u0026gt;s3-\u0026gt;previous_client_finished_len = md_len; } else { memcpy(s-\u0026gt;s3-\u0026gt;previous_server_finished, s-\u0026gt;s3-\u0026gt;tmp.peer_finish_md, md_len); s-\u0026gt;s3-\u0026gt;previous_server_finished_len = md_len; } /* * In TLS1.3 we also have to change cipher state and do any final processing * of the initial server flight (if we are a client) */ if (SSL_IS_TLS13(s)) { if (s-\u0026gt;server) { if (s-\u0026gt;post_handshake_auth != SSL_PHA_REQUESTED \u0026amp;\u0026amp; !s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;change_cipher_state(s, SSL3_CC_APPLICATION | SSL3_CHANGE_CIPHER_SERVER_READ)) { /* SSLfatal() already called */ return MSG_PROCESS_ERROR; } } else { ... } } return MSG_PROCESS_FINISHED_READING; } 我们看看change_cipher_state(s, SSL3_CC_APPLICATION | SSL3_CHANGE_CIPHER_SERVER_READ)函数内部：\n进入if (which \u0026amp; SSL3_CC_READ)，初始化读ctx 进入if (((which \u0026amp; SSL3_CC_CLIENT) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_WRITE)) || ((which \u0026amp; SSL3_CC_SERVER) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_READ)))，分支继续向里走，不会进入if (which \u0026amp; SSL3_CC_EARLY)，不会进入if(which \u0026amp; SSL3_CC_HANDSHAKE)，因此选择利用主密钥计算客户端应用数据写秘钥，也就是服务端应用数据读秘钥，选择label为客户端应用数据label，即static const unsigned char client_application_traffic[] = \u0026quot;c ap traffic\u0026quot;;。 调用ssl_handshake_hash(s, hashval, sizeof(hashval), \u0026amp;hashlen)，对从ClientHello，ServerHello到服务端Finished，客户端Finished消息做hash。 因为lable为client_application_traffic，所以此时需要计算复用主密钥，对上一步的hash做一次hkdf_expand，代码为tls13_hkdf_expand(s, ssl_handshake_md(s), insecret,resumption_master_secret,sizeof(resumption_master_secret) - 1,hashval, hashlen, s-\u0026gt;resumption_master_secret,hashlen, 1) 对主密钥s-\u0026gt;master_secret做derive_secret_key_and_iv，得到服务端应用数据读key和服务端应用数据读iv。 int tls13_change_cipher_state(SSL *s, int which) { static const unsigned char client_early_traffic[] = \u0026#34;c e traffic\u0026#34;; static const unsigned char client_handshake_traffic[] = \u0026#34;c hs traffic\u0026#34;; static const unsigned char client_application_traffic[] = \u0026#34;c ap traffic\u0026#34;; static const unsigned char server_handshake_traffic[] = \u0026#34;s hs traffic\u0026#34;; static const unsigned char server_application_traffic[] = \u0026#34;s ap traffic\u0026#34;; static const unsigned char exporter_master_secret[] = \u0026#34;exp master\u0026#34;; static const unsigned char resumption_master_secret[] = \u0026#34;res master\u0026#34;; static const unsigned char early_exporter_master_secret[] = \u0026#34;e exp master\u0026#34;; unsigned char *iv; unsigned char secret[EVP_MAX_MD_SIZE]; unsigned char hashval[EVP_MAX_MD_SIZE]; unsigned char *hash = hashval; unsigned char *insecret; unsigned char *finsecret = NULL; const char *log_label = NULL; EVP_CIPHER_CTX *ciph_ctx; size_t finsecretlen = 0; const unsigned char *label; size_t labellen, hashlen = 0; int ret = 0; const EVP_MD *md = NULL; const EVP_CIPHER *cipher = NULL; if (which \u0026amp; SSL3_CC_READ) { if (s-\u0026gt;enc_read_ctx != NULL) { EVP_CIPHER_CTX_reset(s-\u0026gt;enc_read_ctx); } else { s-\u0026gt;enc_read_ctx = EVP_CIPHER_CTX_new(); if (s-\u0026gt;enc_read_ctx == NULL) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS13_CHANGE_CIPHER_STATE, ERR_R_MALLOC_FAILURE); goto err; } } ciph_ctx = s-\u0026gt;enc_read_ctx; iv = s-\u0026gt;read_iv; RECORD_LAYER_reset_read_sequence(\u0026amp;s-\u0026gt;rlayer); } else { ... } if (((which \u0026amp; SSL3_CC_CLIENT) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_WRITE)) || ((which \u0026amp; SSL3_CC_SERVER) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_READ))) { if (which \u0026amp; SSL3_CC_EARLY) { ... } else if (which \u0026amp; SSL3_CC_HANDSHAKE) { ... } else { insecret = s-\u0026gt;master_secret; label = client_application_traffic; labellen = sizeof(client_application_traffic) - 1; log_label = CLIENT_APPLICATION_LABEL; /* * For this we only use the handshake hashes up until the server * Finished hash. We do not include the client\u0026#39;s Finished, which is * what ssl_handshake_hash() would give us. Instead we use the * previously saved value. */ hash = s-\u0026gt;server_finished_hash; } } else { ... } if (!(which \u0026amp; SSL3_CC_EARLY)) { md = ssl_handshake_md(s); cipher = s-\u0026gt;s3-\u0026gt;tmp.new_sym_enc; if (!ssl3_digest_cached_records(s, 1) || !ssl_handshake_hash(s, hashval, sizeof(hashval), \u0026amp;hashlen)) { /* SSLfatal() already called */; goto err; } } ... if (label == client_application_traffic) { /* * We also create the resumption master secret, but this time use the * hash for the whole handshake including the Client Finished */ if (!tls13_hkdf_expand(s, ssl_handshake_md(s), insecret, resumption_master_secret, sizeof(resumption_master_secret) - 1, hashval, hashlen, s-\u0026gt;resumption_master_secret, hashlen, 1)) { /* SSLfatal() already called */ goto err; } } if (!derive_secret_key_and_iv(s, which \u0026amp; SSL3_CC_WRITE, md, cipher, insecret, hash, label, labellen, secret, iv, ciph_ctx)) { /* SSLfatal() already called */ goto err; } if (label == server_application_traffic) { memcpy(s-\u0026gt;server_app_traffic_secret, secret, hashlen); /* Now we create the exporter master secret */ if (!tls13_hkdf_expand(s, ssl_handshake_md(s), insecret, exporter_master_secret, sizeof(exporter_master_secret) - 1, hash, hashlen, s-\u0026gt;exporter_master_secret, hashlen, 1)) { /* SSLfatal() already called */ goto err; } if (!ssl_log_secret(s, EXPORTER_SECRET_LABEL, s-\u0026gt;exporter_master_secret, hashlen)) { /* SSLfatal() already called */ goto err; } } else if (label == client_application_traffic) memcpy(s-\u0026gt;client_app_traffic_secret, secret, hashlen); if (!ssl_log_secret(s, log_label, secret, hashlen)) { /* SSLfatal() already called */ goto err; } ... ret = 1; err: OPENSSL_cleanse(secret, sizeof(secret)); return ret; } 结语 # 客户端finished消息发送结束之后，服务端计算应用数据读密钥，握手就结束了。\n结尾的闲言碎语 # 写到这里差不多就可以结束了,就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 13 日","externalUrl":null,"permalink":"/posts/2020-09-13-openssl%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB8/","section":"Posts","summary":"","title":"OPENSSL源码阅读(8)","type":"posts"},{"content":" 一些要学的东西 # OCR和AI结合，识别文字等内容 医疗AI kubernetes的安全体系\n系统设计\nredis开发运维学习\nmusic betty-boop jazz pop 背景音乐，黄金时代\n选择很多，\n长期目标\n我正在计划以《天才的编辑》为基础写个小剧本，你是一个编辑，新手出道的编辑，你能不能再维持生活，养家，亲人之间。尽量发掘更多的新人作家呢？需要多添加几个常见的故事，生活或许不能以善意对人，但男人总得挥拳，洛基/私酒/海明威/杰拉德/，作为编辑参与到伟大作品的诞生过程，当然也可能中途失败。实际上，还是要尽量多添加作者和事件 写一个中文翻译标准文档，使用redis写一个方便的字典工具。同时该部分应当包含充分的解释和指引。此外应当建立各种名词的关系。比方说SC和TSO/PSO的关系。 写一个从缓存到底怎么回事，到不同内存序怎么回事，再到怎么保持同步，不同例子怎么实现无锁竞争，再到大的分布式怎么实现存储的文章。参考资料《计算机体系结构量化研究方法》《A Primer on Memory Consistency and Cache Coherence》 《数据密集型计算xxx技术》。目前进度：《A Primer on Memory Consistency and Cache Coherence》已经开始阅读监听协议，数据密集型紧跟MIT课程的脚步。《计算机体系结构量化研究方法》暂时不急 翻译内存模型和缓存一致性，第二章翻译完成，第三章还在翻译 阅读Debug Hacks中文版，格蠹汇编，软件调试 第2版 卷1：硬件基础，阅读抽象方面的书籍：《编程原本》《SICP》《Refactoring: Improving the Design of Existing Code(重构)》《软件方法》《代码大全》《FROM MATHEMATICS TO GENERIC PROGRAMMING》进度：《代码整洁之道》翻了一遍，重点关注了函数和命名，暂时移除出目标名单。重构还在看 每天做两道新的C++ leetcode，然后每天要看20个曾经做个的算法题。 一些记录的NOTE # 土豆豆角炖排骨：\n原材料：葱，姜，大料瓣，大豆酱，已经上好色炖好的排骨（炖排骨的时候就放八角，盐，葱姜，老抽），土豆，油豆角\n步骤：\n葱姜先切了，姜不要多，有点就够。大葱，多切一些。 切土豆块，油豆角不用切就可以 葱姜大料瓣下锅炸香，放入大豆酱，再放入土豆，油豆角，稍微搁点猪油。豆角煸炒至变色，稍微加点盐 然后下排骨，加入排骨汤，冲洗大豆酱，再加一勺排骨汤，然后加水，将将盖住菜。大火开锅，盖盖，小火焖八分钟，翻炒下再盖盖子焖。焖的时候火再小 另一种做法：\n1 将排骨丢入锅中，加入姜片焯水 2 另起一口效果，煮花椒大料水，煮开转小火盖盖焖着， 3 土豆，豆角准备好，国内烧热油，把土豆豆角炒至断生 4 国内放入葱姜蒜，冰糖，干辣椒，八角桂皮，花椒爆香。小火冰糖溶化后放入排骨 5 放入两勺黄豆酱，三勺老抽，五勺生抽 6 加入花椒水，小火煮30min 7 放入土豆豆角煮20min，可以吃了\n大狗的些许碎碎念 # 什么叫做唯物？唯物指的是符合事实，不断章取义，论迹不论心，不能靠猜测发表意见。但是有个问题，如果光看事情的话，那么婚姻和卖春有什么区别？\n什么是科学？科学是能够解释并加以预测的东西，必须符合实证\n资本主义本质上是将任何东西都当成消费品和货物，因此自然会使得个人丧失诸如气质/胸怀的东西，但是问题在于不是每个人都能有什么胸怀/品质的，大部分人还是稀碎的过一辈子。\n实质上中国面对的问题和世界的问题并不一致，如果说世界问题是资本主义经济模式引发的，那么中国的问题还多了一点：中国的传统文化，价值观念在现代正在逐渐解体，如何应对来自价值观念的转变？传统价值观的家族为先的观点来自家族经营式经济模式和家族抱团式关系，西方的东西主要是价值观，相似的经历和出身等方面。实际上，中国的发展方式还是典型的家族经营式方式，几个大城市通过压榨其他小城市发展经济，但目前看起来大城市没有任何反哺其它省市的任何想法，先富永远不会主动带动后富。每个大国都有这种问题，美国是通过剥削全世界解决问题，中国有的选吗？\n曾经说好的话都实现不了，价值观先一步崩溃了，前段时间要求不要炫富实际上就是价值观崩溃的一种体现，一方面鼓励艰苦奋斗鼓励创新鼓励消费，却不允许消息的传播，实质是反对透明的媒介。为什么？贫富差距没法解决，除非再来一次文化大革命，可能嘛？没可能的\n身为个人应该怎么办？我首先建议个人要确定自己基本的价值观和逻辑原则，浮动的原则会极大动摇个人的观点。确定好价值观和基本逻辑原则之后才能谈别的，目前很多人连自身都认识不了，更别提教育孩子了。\n自相矛盾，每个人都在高喊，中国完整的产业链，不可替代。呵呵，不要再自欺欺人了，时间+钱能解决一切。\n和世界经济方式的独生子女高房价问题是解决问题的答案也是新问题的引发点。\n往事越千年，魏武挥鞭，东临碣石有遗篇。萧瑟秋风今又是，换了人间。这种气魄的文章我是写不出来咯\n人还是要有自觉的，比方说妹子心情不好，就说点笑话逗逗她开心，讲点笑话之类的\n结尾的闲言碎语 # 写到这里差不多就可以结束了,就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 13 日","externalUrl":null,"permalink":"/posts/2020-09-14-%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E8%BF%98%E8%A6%81%E7%9C%8B%E7%9A%84%E4%B8%9C%E8%A5%BF/","section":"Posts","summary":"","title":"还要学啥","type":"posts"},{"content":"","date":"2020 年 9 月 13 日","externalUrl":null,"permalink":"/tags/%E7%9B%AE%E6%A0%87/","section":"Tags","summary":"","title":"目标","type":"tags"},{"content":" OPENSSL源码阅读(6) # 前言 # 上一回说了非复用状态/完整握手状态下发送EncryptedExtension消息时自动机的变化，这次我们来说说完整握手情况下发送CertificateVerify时发生了什么，这里我们跳过了证书消息发送阶段。\n从EncryptedExtension发送完毕说起 # 我们上次讲了，发送EncryptedExtension之后post_work啥都没干，然后Certificate消息发送阶段也没做啥有趣的事情。这次就要发送CertificateVerify消息了，因为上次最后修改写自动机状态为写初始状态st-\u0026gt;write_state = WRITE_STATE_TRANSITION，所以还要从while循环说起，啊，需要记住这个时候的握手状态是写证书阶段，即st-\u0026gt;hand_state = TLS_ST_SW_CERT。\n写自动机transition函数流程 # 此次进入transition函数，当前的握手状态为st-\u0026gt;hand_state == TLS_ST_SW_CERT，因此，新的状态是\u0026quot;服务端写CertificateVerify\u0026quot;阶段，即st-\u0026gt;hand_state = TLS_ST_SW_CERT_VRFY;。返回之后，修改写自动机的写状态st-\u0026gt;write_state = WRITE_STATE_PRE_WORK;继续向下执行，状态转变的代码为：\nstatic WRITE_TRAN ossl_statem_server13_write_transition(SSL *s) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; /* * No case for TLS_ST_BEFORE, because at that stage we have not negotiated * TLSv1.3 yet, so that is handled by ossl_statem_server_write_transition() */ switch (st-\u0026gt;hand_state) { ... case TLS_ST_SW_CERT: st-\u0026gt;hand_state = TLS_ST_SW_CERT_VRFY; return WRITE_TRAN_CONTINUE; 写自动机pre_work函数流程和CertificateVerify构建流程 # 进入pre_work函数之后实际上啥都没做就返回了，直接返回，继续执行。pre_work函数的代码为:\nWORK_STATE ossl_statem_server_pre_work(SSL *s, WORK_STATE wst) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; switch (st-\u0026gt;hand_state) { default: /* No pre work to be done */ break; ... } return WORK_FINISHED_CONTINUE; 构建CertificateVerify消息的流程就比较有趣了，ossl_statem_server_construct_message指定调用的函数tls_construct_cert_verify函数之后，调用的函数还是tls_construct_cert_verify，Certificate Verify消息构建完成就执行发送和post_work函数。我们先来看看tls_construct_cert_verify函数到底干了些什么。\n首先调用get_cert_verify_tbs_data函数获取要签名的内容，根据RFC8446 SECTION4.4.3，我们清楚要签名的内容为‘64字节0x20+字符串\u0026quot;TLS 1.3, server CertificateVerify\u0026quot;+一字节0x00+Transcript-Hash(Handshake Context, Certificate)’，这里的Handshake Context就是Certificate消息之前的所有握手消息。而get_cert_verify_tbs_data函数就是按这个过程写的，比较简单，不赘述了。 获取证书的私钥pkey = s-\u0026gt;s3-\u0026gt;tmp.cert-\u0026gt;privatekey;，调用WPACKET_put_bytes_u16(pkt, lu-\u0026gt;sigalg)写入签名算法，接着调用EVP_DigestSignInit(mctx, \u0026amp;pctx, md, NULL, pkey)初始化签名ctx，即ctx中已经获得了证书的私钥了。 如果签名算法是RSA_PSS算法，那么需要加上RSA_PSS的padding，然后加盐，RSA_PSS的流程和RSA_PKCS的计算过程的区别我下回单独开一篇文章写。 如果签名算法是ECDSA签名算法，那么不需要加什么多余步骤 最后调用EVP_DigestSign(mctx, sig, \u0026amp;siglen, hdata, hdatalen)函数，获得Certificate Verify内容，返回1。 int tls_construct_cert_verify(SSL *s, WPACKET *pkt) { EVP_PKEY *pkey = NULL; const EVP_MD *md = NULL; EVP_MD_CTX *mctx = NULL; EVP_PKEY_CTX *pctx = NULL; size_t hdatalen = 0, siglen = 0; void *hdata; unsigned char *sig = NULL; unsigned char tls13tbs[TLS13_TBS_PREAMBLE_SIZE + EVP_MAX_MD_SIZE]; const SIGALG_LOOKUP *lu = s-\u0026gt;s3-\u0026gt;tmp.sigalg; if (lu == NULL || s-\u0026gt;s3-\u0026gt;tmp.cert == NULL) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_CERT_VERIFY, ERR_R_INTERNAL_ERROR); goto err; } pkey = s-\u0026gt;s3-\u0026gt;tmp.cert-\u0026gt;privatekey; if (pkey == NULL || !tls1_lookup_md(lu, \u0026amp;md)) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_CERT_VERIFY, ERR_R_INTERNAL_ERROR); goto err; } mctx = EVP_MD_CTX_new(); if (mctx == NULL) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_CERT_VERIFY, ERR_R_MALLOC_FAILURE); goto err; } /* Get the data to be signed */ if (!get_cert_verify_tbs_data(s, tls13tbs, \u0026amp;hdata, \u0026amp;hdatalen)) { /* SSLfatal() already called */ goto err; } if (SSL_USE_SIGALGS(s) \u0026amp;\u0026amp; !WPACKET_put_bytes_u16(pkt, lu-\u0026gt;sigalg)) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_CERT_VERIFY, ERR_R_INTERNAL_ERROR); goto err; } siglen = EVP_PKEY_size(pkey); sig = OPENSSL_malloc(siglen); if (sig == NULL) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_CERT_VERIFY, ERR_R_MALLOC_FAILURE); goto err; } if (EVP_DigestSignInit(mctx, \u0026amp;pctx, md, NULL, pkey) \u0026lt;= 0) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_CERT_VERIFY, ERR_R_EVP_LIB); goto err; } if (lu-\u0026gt;sig == EVP_PKEY_RSA_PSS) { if (EVP_PKEY_CTX_set_rsa_padding(pctx, RSA_PKCS1_PSS_PADDING) \u0026lt;= 0 || EVP_PKEY_CTX_set_rsa_pss_saltlen(pctx, RSA_PSS_SALTLEN_DIGEST) \u0026lt;= 0) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_CERT_VERIFY, ERR_R_EVP_LIB); goto err; } } if (s-\u0026gt;version == SSL3_VERSION) { if (EVP_DigestSignUpdate(mctx, hdata, hdatalen) \u0026lt;= 0 || !EVP_MD_CTX_ctrl(mctx, EVP_CTRL_SSL3_MASTER_SECRET, (int)s-\u0026gt;session-\u0026gt;master_key_length, s-\u0026gt;session-\u0026gt;master_key) || EVP_DigestSignFinal(mctx, sig, \u0026amp;siglen) \u0026lt;= 0) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_CERT_VERIFY, ERR_R_EVP_LIB); goto err; } } else if (EVP_DigestSign(mctx, sig, \u0026amp;siglen, hdata, hdatalen) \u0026lt;= 0) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_CERT_VERIFY, ERR_R_EVP_LIB); goto err; } } 写自动机发送阶段 # 没啥好说的，写CTX把消息发送出去。\n写自动机post_work阶段 # post_work函数实际上也啥都没做，直接返回，并将写自动机状态改为写初始状态st-\u0026gt;write_state = WRITE_STATE_TRANSITION;。直接蹦到下个阶段。\n结语 # 这次实际上没咋写，写CTX初始化好了，CertificateVerify构建好了直接发出去，pre_work和post_work啥都没干，construct_func函数构建CertificateVerify消息。\n结尾的闲言碎语 # 写到这里差不多就可以结束了,就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 12 日","externalUrl":null,"permalink":"/posts/2020-09-12-openssl%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB6/","section":"Posts","summary":"","title":"OPENSSL源码阅读(6)","type":"posts"},{"content":" OPENSSL源码阅读(5) # 前言 # 上一回说了非复用状态/完整握手状态下发送ChangeCipherSpec消息时自动机的变化，这次我们来说说完整握手情况下发送EncrypotedExtension时发生了什么。\n从ChangeCipherSpec发送完毕说起 # 我们上次讲了，发送ChangeCipherSpec之后post_work函数时计算完毕写ctx和读ctx的流程，这次就要发送EncryptedExteions函数了，因为上次最后修改写自动机状态为写初始状态st-\u0026gt;write_state = WRITE_STATE_TRANSITION，所以还要从while循环说起。\n写自动机transition函数流程 # 此次进入transition函数，当前的握手状态为st-\u0026gt;hand_state == TLS_ST_SW_CHANGE，因此，新的状态是\u0026quot;服务端写EncryptedExtension\u0026quot;阶段，即st-\u0026gt;hand_state = TLS_ST_SW_ENCRYPTED_EXTENSIONS;。返回之后，修改写自动机的写状态st-\u0026gt;write_state = WRITE_STATE_PRE_WORK;继续向下执行，状态转变的代码为：\nstatic WRITE_TRAN ossl_statem_server13_write_transition(SSL *s) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; /* * No case for TLS_ST_BEFORE, because at that stage we have not negotiated * TLSv1.3 yet, so that is handled by ossl_statem_server_write_transition() */ switch (st-\u0026gt;hand_state) { ... case TLS_ST_SW_CHANGE: if (s-\u0026gt;hello_retry_request == SSL_HRR_PENDING) st-\u0026gt;hand_state = TLS_ST_EARLY_DATA; else st-\u0026gt;hand_state = TLS_ST_SW_ENCRYPTED_EXTENSIONS; return WRITE_TRAN_CONTINUE; 写自动机pre_work函数流程和构建EncryptedExtension流程 # 进入pre_work函数之后实际上啥都没做就返回了，直接返回，继续执行。pre_work函数的代码为:\nWORK_STATE ossl_statem_server_pre_work(SSL *s, WORK_STATE wst) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; switch (st-\u0026gt;hand_state) { default: /* No pre work to be done */ break; ... } return WORK_FINISHED_CONTINUE; 构建EncryptedExtension流程就比较有趣了，ossl_statem_server_construct_message指定调用的函数tls_construct_encrypted_extensions函数之后，调用的函数还是tls_construct_extensions，即前几部发送ServerHello报文时写拓展的函数。只不过context == SSL_EXT_TLS1_3_ENCRYPTED_EXTENSIONS。 分析tls_construct_extensions函数，实际上还是对全局结构ext_defs的for循环调用，只不过检查下EncryptedExtension函数要不要写，没什么好说的，返回后代码继续执行。\nint tls_construct_extensions(SSL *s, WPACKET *pkt, unsigned int context, X509 *x, size_t chainidx) { size_t i; int min_version, max_version = 0, reason; const EXTENSION_DEFINITION *thisexd; ... if (!custom_ext_add(s, context, pkt, x, chainidx, max_version)) { /* SSLfatal() already called */ return 0; } for (i = 0, thisexd = ext_defs; i \u0026lt; OSSL_NELEM(ext_defs); i++, thisexd++) { EXT_RETURN (*construct)(SSL *s, WPACKET *pkt, unsigned int context, X509 *x, size_t chainidx); EXT_RETURN ret; /* Skip if not relevant for our context */ if (!should_add_extension(s, thisexd-\u0026gt;context, context, max_version)) continue; construct = s-\u0026gt;server ? thisexd-\u0026gt;construct_stoc : thisexd-\u0026gt;construct_ctos; if (construct == NULL) continue; ret = construct(s, pkt, context, x, chainidx); if (ret == EXT_RETURN_FAIL) { /* SSLfatal() already called */ return 0; } ... } if (!WPACKET_close(pkt)) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_CONSTRUCT_EXTENSIONS, ERR_R_INTERNAL_ERROR); return 0; } return 1; } 写自动机发送阶段 # 没啥好说的，写CTX上一步初始化好了，直接发送出去。\n写自动机post_work阶段 # post_work函数实际上也啥都没做，直接返回，并将写自动机状态改为写初始状态st-\u0026gt;write_state = WRITE_STATE_TRANSITION;。直接蹦到下个阶段，发送Certificate阶段。\n结语 # 这次实际上没咋写，写CTX初始化好了，EncryptedExtension构建好了直接发出去，比较简单，后一步发送Certificate也是一样的流程，pre_work和post_work啥都没干，construct_func函数构建Certificate消息。等到certificateVerify和Finished报文才比较有趣，所以不写Certificate发送阶段了，直接写certificateVerify和finieshed消息了。\n结尾的闲言碎语 # 写到这里差不多就可以结束了,就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 11 日","externalUrl":null,"permalink":"/posts/2020-09-11-openssl%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB5/","section":"Posts","summary":"","title":"OPENSSL源码阅读(5)","type":"posts"},{"content":" OPENSSL源码阅读(4) # 前言 # 从这里开始，最好对于TLS1.3的密钥衍生流程比较熟悉，很多名词都是密钥衍生流程图里的，至少得清楚一些名词的含义。 源码阅读(3)里，我们说到了自动机处理完了CLIENTHELLO，发送了SERVERHELLO报文，这次我们来聊聊接下来的流程，我们首先假设这次没有接受客户端的PSK，走一次完整的ECDHE握手，处于方便考虑，我们假设没有双向认证，也不吧NST报文扯进来。下面先把TLS1.3完整握手流程图列出来。\nClientHello + key_share --------\u0026gt; ServerHello + key_share {ChangeCipherSpec} {EncryptedExtensions} {Certificate*} {CertificateVerify*} {Finished} \u0026lt;-------- [Application Data*] {Finished} --------\u0026gt; [Application Data] \u0026lt;-------\u0026gt; [Application Data] 从发送完SERVERHELLO说起 # 上次我们发送完SERVERHELLO，又将写自动机的状态置为初始状态st-\u0026gt;write_state = WRITE_STATE_TRANSITION;,此时会继续回到写自动机的while循环里。看上面的自动机，接下来服务器需要发送ChangeCipherSpec,EncryptedExtensions,Certificate,CertificateVerify和Finished消息,之所以发送ChangeCipherSpec是因为我们这里考虑中间机器兼容性的问题。这里的ChangeCipherSpec发送阶段是个非常重要的阶段，我们可以知道EncryptedExtensions需要由服务端写密钥(server_write_key)加密保护，那么如何从握手密钥(handshake secret)衍生出来握手密钥便是主要的问题。\n写自动机状态转换流程 # 写自动机继续在while循环里转，大状态还是写初始状态，st-\u0026gt;write_state = WRITE_STATE_TRANSITION;首先还是进入transition(s)函数。\nwhile (1) { switch (st-\u0026gt;write_state) { case WRITE_STATE_TRANSITION: if (cb != NULL) { /* Notify callback of an impending state change */ if (s-\u0026gt;server) cb(s, SSL_CB_ACCEPT_LOOP, 1); else cb(s, SSL_CB_CONNECT_LOOP, 1); } switch (transition(s)) { case WRITE_TRAN_CONTINUE: st-\u0026gt;write_state = WRITE_STATE_PRE_WORK; st-\u0026gt;write_state_work = WORK_MORE_A; break; case WRITE_TRAN_FINISHED: return SUB_STATE_FINISHED; break; case WRITE_TRAN_ERROR: check_fatal(s, SSL_F_WRITE_STATE_MACHINE); return SUB_STATE_ERROR; } break; case WRITE_STATE_PRE_WORK: switch (st-\u0026gt;write_state_work = pre_work(s, st-\u0026gt;write_state_work)) { case WORK_ERROR: check_fatal(s, SSL_F_WRITE_STATE_MACHINE); /* Fall through */ case WORK_MORE_A: transition函数最终包裹的是ossl_statem_server13_write_transition(SSL *s)函数，因为刚才的握手状态是发送SERVERHELLO，即st-\u0026gt;hand_state == TLS_ST_SW_SRVR_HELLO,因为我们默认是考虑中间机器兼容性SSL_OP_ENABLE_MIDDLEBOX_COMPAT,所以握手状态改为发送Change_Cipher_Spec阶段，即st-\u0026gt;hand_state = TLS_ST_SW_CHANGE;。之后返回WRITE_TRAN_CONTINUE。transition阶段结束，进入到pre_work函数。\nstatic WRITE_TRAN ossl_statem_server13_write_transition(SSL *s) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; /* * No case for TLS_ST_BEFORE, because at that stage we have not negotiated * TLSv1.3 yet, so that is handled by ossl_statem_server_write_transition() */ switch (st-\u0026gt;hand_state) { ... case TLS_ST_SW_SRVR_HELLO: if ((s-\u0026gt;options \u0026amp; SSL_OP_ENABLE_MIDDLEBOX_COMPAT) != 0 \u0026amp;\u0026amp; s-\u0026gt;hello_retry_request != SSL_HRR_COMPLETE) st-\u0026gt;hand_state = TLS_ST_SW_CHANGE; else if (s-\u0026gt;hello_retry_request == SSL_HRR_PENDING) st-\u0026gt;hand_state = TLS_ST_EARLY_DATA; else st-\u0026gt;hand_state = TLS_ST_SW_ENCRYPTED_EXTENSIONS; return WRITE_TRAN_CONTINUE; pre_work阶段和构建CHANGE_CIPHER_SPEC消息 # 进入pre_work函数，实际上没做啥事情，可以看到直接返回WORK_FINISHED_CONTINUE了。构建CHANGE_CIPHER_SPEC函数实际上也非常简单，就是写了一个字节的CHANGE_CIPHER_SPEC数据，不多赘述了。返回之后写状态改为写发送 st-\u0026gt;write_state = WRITE_STATE_SEND;\nWORK_STATE ossl_statem_server_pre_work(SSL *s, WORK_STATE wst) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; switch (st-\u0026gt;hand_state) { default: ··· case TLS_ST_SW_CHANGE: if (SSL_IS_TLS13(s)) break; ··· } return WORK_FINISHED_CONTINUE; 写发送阶段 # 也没啥好说的，毕竟CHANGE_CIPHER_SPEC报文太简单了。\n写发送后阶段 # 写发送后的状态转换 # 写发送后的阶段就得好好说说了，调用函数post_work包裹ossl_statem_server_post_work函数，此时握手状态为CHANG_CIPHER_SPEC阶段，且没发送hello_retry_request，所以会调用s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;setup_key_block(s)和s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;change_cipher_state函数，运算结束后返回WORK_FINISHED_CONTINUE,写自动机又重置为写初始化状态st-\u0026gt;write_state = WRITE_STATE_TRANSITION;，写自动机等待发送EncryptedExtension拓展。继续说状态之前我们看看ssl3_enc这个通用的函数，对于TLS1.3而言，这个函数是TLSv1_3_enc_data函数，定义也贴在了下面，我们接下来看看TLSv1_3_enc_data函数的tls13_change_cipher_state到底干了些什么，计算了哪些数据。\nWORK_STATE ossl_statem_server_post_work(SSL *s, WORK_STATE wst) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; s-\u0026gt;init_num = 0; switch (st-\u0026gt;hand_state) { default: /* No post work to be done */ break; case TLS_ST_SW_CHANGE: if (s-\u0026gt;hello_retry_request == SSL_HRR_PENDING) { if (!statem_flush(s)) return WORK_MORE_A; break; } if (SSL_IS_TLS13(s)) { if (!s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;setup_key_block(s) || !s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;change_cipher_state(s, SSL3_CC_HANDSHAKE | SSL3_CHANGE_CIPHER_SERVER_WRITE)) { /* SSLfatal() already called */ return WORK_ERROR; } if (s-\u0026gt;ext.early_data != SSL_EARLY_DATA_ACCEPTED \u0026amp;\u0026amp; !s-\u0026gt;method-\u0026gt;ssl3_enc-\u0026gt;change_cipher_state(s, SSL3_CC_HANDSHAKE |SSL3_CHANGE_CIPHER_SERVER_READ)) { /* SSLfatal() already called */ return WORK_ERROR; } /* * We don\u0026#39;t yet know whether the next record we are going to receive * is an unencrypted alert, an encrypted alert, or an encrypted * handshake message. We temporarily tolerate unencrypted alerts. */ s-\u0026gt;statem.enc_read_state = ENC_READ_STATE_ALLOW_PLAIN_ALERTS; break; } SSL3_ENC_METHOD const TLSv1_3_enc_data = { tls13_enc, tls1_mac, tls13_setup_key_block, tls13_generate_master_secret, tls13_change_cipher_state, tls13_final_finish_mac, TLS_MD_CLIENT_FINISH_CONST, TLS_MD_CLIENT_FINISH_CONST_SIZE, TLS_MD_SERVER_FINISH_CONST, TLS_MD_SERVER_FINISH_CONST_SIZE, tls13_alert_code, tls13_export_keying_material, SSL_ENC_FLAG_SIGALGS | SSL_ENC_FLAG_SHA256_PRF, ssl3_set_handshake_header, tls_close_construct_packet, ssl3_handshake_write }; tls13_change_cipher_state的功能 # 进入tls13_change_cipher_state函数之前，我们先看看我们知道了哪些东西。解析ClientHello的KeyShare的时候，我们计算出来了握手密钥，保存了从Clienthello到ServerHello的握手报文，此时进入了tls13_change_cipher_state函数,调用tls13_change_cipher_state函数时，可以看到两次调用的时候which分别为SSL3_CC_HANDSHAKE|SSL3_CHANGE_CIPHER_SERVER_WRITE与SSL3_CC_HANDSHAKE|SSL3_CHANGE_CIPHER_SERVER_READ，而#define SSL3_CHANGE_CIPHER_SERVER_READ (SSL3_CC_SERVER|SSL3_CC_READ)且#define SSL3_CHANGE_CIPHER_SERVER_WRITE (SSL3_CC_SERVER|SSL3_CC_WRITE)。所以这两次运算实际上计算的就是服务端写key，服务端写iv，服务端读key和服务端读iv。我们拆开看看如何体现在代码上：\nint tls13_change_cipher_state(SSL *s, int which) { ... static const unsigned char client_early_traffic[] = \u0026#34;c e traffic\u0026#34;; static const unsigned char client_handshake_traffic[] = \u0026#34;c hs traffic\u0026#34;; static const unsigned char client_application_traffic[] = \u0026#34;c ap traffic\u0026#34;; static const unsigned char server_handshake_traffic[] = \u0026#34;s hs traffic\u0026#34;; static const unsigned char server_application_traffic[] = \u0026#34;s ap traffic\u0026#34;; static const unsigned char exporter_master_secret[] = \u0026#34;exp master\u0026#34;; static const unsigned char resumption_master_secret[] = \u0026#34;res master\u0026#34;; static const unsigned char early_exporter_master_secret[] = \u0026#34;e exp master\u0026#34;; unsigned char *iv; unsigned char secret[EVP_MAX_MD_SIZE]; unsigned char hashval[EVP_MAX_MD_SIZE]; unsigned char *hash = hashval; unsigned char *insecret; unsigned char *finsecret = NULL; const char *log_label = NULL; EVP_CIPHER_CTX *ciph_ctx; size_t finsecretlen = 0; const unsigned char *label; size_t labellen, hashlen = 0; int ret = 0; const EVP_MD *md = NULL; const EVP_CIPHER *cipher = NULL; if (which \u0026amp; SSL3_CC_READ) { if (s-\u0026gt;enc_read_ctx != NULL) { EVP_CIPHER_CTX_reset(s-\u0026gt;enc_read_ctx); } else { s-\u0026gt;enc_read_ctx = EVP_CIPHER_CTX_new(); if (s-\u0026gt;enc_read_ctx == NULL) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS13_CHANGE_CIPHER_STATE, ERR_R_MALLOC_FAILURE); goto err; } } ciph_ctx = s-\u0026gt;enc_read_ctx; iv = s-\u0026gt;read_iv; RECORD_LAYER_reset_read_sequence(\u0026amp;s-\u0026gt;rlayer); } else { ... } if (((which \u0026amp; SSL3_CC_CLIENT) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_WRITE)) || ((which \u0026amp; SSL3_CC_SERVER) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_READ))) { if (which \u0026amp; SSL3_CC_EARLY) { ... } else if (which \u0026amp; SSL3_CC_HANDSHAKE) { insecret = s-\u0026gt;handshake_secret; finsecret = s-\u0026gt;client_finished_secret; finsecretlen = EVP_MD_size(ssl_handshake_md(s)); label = client_handshake_traffic; labellen = sizeof(client_handshake_traffic) - 1; log_label = CLIENT_HANDSHAKE_LABEL; /* * The handshake hash used for the server read/client write handshake * traffic secret is the same as the hash for the server * write/client read handshake traffic secret. However, if we * processed early data then we delay changing the server * read/client write cipher state until later, and the handshake * hashes have moved on. Therefore we use the value saved earlier * when we did the server write/client read change cipher state. */ hash = s-\u0026gt;handshake_traffic_hash; } else { insecret = s-\u0026gt;master_secret; label = client_application_traffic; labellen = sizeof(client_application_traffic) - 1; log_label = CLIENT_APPLICATION_LABEL; /* * For this we only use the handshake hashes up until the server * Finished hash. We do not include the client\u0026#39;s Finished, which is * what ssl_handshake_hash() would give us. Instead we use the * previously saved value. */ hash = s-\u0026gt;server_finished_hash; } } else { /* Early data never applies to client-read/server-write */ if (which \u0026amp; SSL3_CC_HANDSHAKE) { insecret = s-\u0026gt;handshake_secret; finsecret = s-\u0026gt;server_finished_secret; finsecretlen = EVP_MD_size(ssl_handshake_md(s)); label = server_handshake_traffic; labellen = sizeof(server_handshake_traffic) - 1; log_label = SERVER_HANDSHAKE_LABEL; } else { insecret = s-\u0026gt;master_secret; label = server_application_traffic; labellen = sizeof(server_application_traffic) - 1; log_label = SERVER_APPLICATION_LABEL; } } if (!(which \u0026amp; SSL3_CC_EARLY)) { md = ssl_handshake_md(s); cipher = s-\u0026gt;s3.tmp.new_sym_enc; if (!ssl3_digest_cached_records(s, 1) || !ssl_handshake_hash(s, hashval, sizeof(hashval), \u0026amp;hashlen)) { /* SSLfatal() already called */; goto err; } } /* * Save the hash of handshakes up to now for use when we calculate the * client application traffic secret */ if (label == server_application_traffic) memcpy(s-\u0026gt;server_finished_hash, hashval, hashlen); if (label == server_handshake_traffic) memcpy(s-\u0026gt;handshake_traffic_hash, hashval, hashlen); if (label == client_application_traffic) { /* * We also create the resumption master secret, but this time use the * hash for the whole handshake including the Client Finished */ if (!tls13_hkdf_expand(s, ssl_handshake_md(s), insecret, resumption_master_secret, sizeof(resumption_master_secret) - 1, hashval, hashlen, s-\u0026gt;resumption_master_secret, hashlen, 1)) { /* SSLfatal() already called */ goto err; } } if (!derive_secret_key_and_iv(s, which \u0026amp; SSL3_CC_WRITE, md, cipher, insecret, hash, label, labellen, secret, iv, ciph_ctx)) { /* SSLfatal() already called */ goto err; } if (label == server_application_traffic) { memcpy(s-\u0026gt;server_app_traffic_secret, secret, hashlen); /* Now we create the exporter master secret */ if (!tls13_hkdf_expand(s, ssl_handshake_md(s), insecret, exporter_master_secret, sizeof(exporter_master_secret) - 1, hash, hashlen, s-\u0026gt;exporter_master_secret, hashlen, 1)) { /* SSLfatal() already called */ goto err; } if (!ssl_log_secret(s, EXPORTER_SECRET_LABEL, s-\u0026gt;exporter_master_secret, hashlen)) { /* SSLfatal() already called */ goto err; } } else if (label == client_application_traffic) memcpy(s-\u0026gt;client_app_traffic_secret, secret, hashlen); if (!ssl_log_secret(s, log_label, secret, hashlen)) { /* SSLfatal() already called */ goto err; } if (finsecret != NULL \u0026amp;\u0026amp; !tls13_derive_finishedkey(s, ssl_handshake_md(s), secret, finsecret, finsecretlen)) { /* SSLfatal() already called */ goto err; } if (!s-\u0026gt;server \u0026amp;\u0026amp; label == client_early_traffic) s-\u0026gt;statem.enc_write_state = ENC_WRITE_STATE_WRITE_PLAIN_ALERTS; else s-\u0026gt;statem.enc_write_state = ENC_WRITE_STATE_VALID; ret = 1; err: if ((which \u0026amp; SSL3_CC_EARLY) != 0) { /* We up-refed this so now we need to down ref */ ssl_evp_cipher_free(cipher); } OPENSSL_cleanse(secret, sizeof(secret)); return ret; } 第一次计算服务端写KEY \u0026amp; IV # 第一次计算时，which为SSL3_CC_HANDSHAKE|SSL3_CHANGE_CIPHER_SERVER_WRITE，所以函数里一开始的几个IF根本就不会进入。 函数首先判断有没有读flagif (which \u0026amp; SSL3_CC_READ)，不存在所以不会进入，后面判断是否为客户端写((which \u0026amp; SSL3_CC_CLIENT) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_WRITE)和服务端读((which \u0026amp; SSL3_CC_CLIENT) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_WRITE)，也不进入，转而进入else分支，首先需要计算服务端写密钥(TLS1.3密钥衍生流程的server_handshake_traffic_secret)。执行的代码是:\nif (which \u0026amp; SSL3_CC_HANDSHAKE) { insecret = s-\u0026gt;handshake_secret; finsecret = s-\u0026gt;server_finished_secret; finsecretlen = EVP_MD_size(ssl_handshake_md(s)); label = server_handshake_traffic; labellen = sizeof(server_handshake_traffic) - 1; log_label = SERVER_HANDSHAKE_LABEL; 确定好计算的对象，因为不需要接受EARLY_DATA，所以直接计算握手消息(ClientHello+ServerHello)的transcript hash，代码为:\nif (!(which \u0026amp; SSL3_CC_EARLY)) { md = ssl_handshake_md(s); cipher = s-\u0026gt;s3.tmp.new_sym_enc; if (!ssl3_digest_cached_records(s, 1) || !ssl_handshake_hash(s, hashval, sizeof(hashval), \u0026amp;hashlen)) { /* SSLfatal() already called */; goto err; } } 接下来，就是利用hash消息，做一次derive secret得到服务端握手secret(TLS1.3密钥衍生的\u0026quot;server_handshake_traffic_secret\u0026quot;),将之保存到secret变量里，除了下面计算finished key要用，其他地方都不用，所以secret变量是个局部变量。derive_secret函数内部会调用write_key = HKDF-Expand-Label(Secret, \u0026quot;key\u0026quot;, \u0026quot;\u0026quot;, key_length)和write_iv = HKDF-Expand-Label(Secret, \u0026quot;iv\u0026quot;, \u0026quot;\u0026quot;, iv_length)产生加密时的握手key和iv，并保存到CTX中, 代码如下(记录密钥那部分就不写了)：\nif (label == server_handshake_traffic) memcpy(s-\u0026gt;handshake_traffic_hash, hashval, hashlen); if (!derive_secret_key_and_iv(s, which \u0026amp; SSL3_CC_WRITE, md, cipher, insecret, hash, label, labellen, secret, iv, ciph_ctx)) { /* SSLfatal() already called */ goto err; } 最终，利用服务端写密钥(TLS1.3密钥衍生的\u0026quot;server_handshake_traffic_secret\u0026quot;)，计算服务端的finishdkey，到此第一次tls13_change_cipher_state调用结束。计算finished_key时利用的规则和代码为:\nserver_finished_key = HKDF-Expand-Label(server_handshake_traffic_secret, \u0026#34;finished\u0026#34;, \u0026#34;\u0026#34;, Hash.length) if (finsecret != NULL \u0026amp;\u0026amp; !tls13_derive_finishedkey(s, ssl_handshake_md(s), secret, finsecret, finsecretlen)) { /* SSLfatal() already called */ goto err; } 第二次计算服务端读KEY \u0026amp; IV # 第一次计算时，which为SSL3_CC_HANDSHAKE|SSL3_CHANGE_CIPHER_SERVER_READ。 函数首先判断有没有读flagif (which \u0026amp; SSL3_CC_READ)，初始化读ctx和读iv。之后判断是否为客户端写((which \u0026amp; SSL3_CC_CLIENT) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_WRITE)和服务端读((which \u0026amp; SSL3_CC_CLIENT) \u0026amp;\u0026amp; (which \u0026amp; SSL3_CC_WRITE)，进入该分支，计算服务端读密钥也就是客户端写密钥(TLS1.3密钥衍生流程的client_handshake_traffic_secret):\ninsecret = s-\u0026gt;handshake_secret; finsecret = s-\u0026gt;client_finished_secret; finsecretlen = EVP_MD_size(ssl_handshake_md(s)); label = client_handshake_traffic; labellen = sizeof(client_handshake_traffic) - 1; log_label = CLIENT_HANDSHAKE_LABEL; 确定好计算的对象，因为不需要接受EARLY_DATA，所以直接计算握手消息(ClientHello+ServerHello)的transcript hash，代码为:\nif (!(which \u0026amp; SSL3_CC_EARLY)) { md = ssl_handshake_md(s); cipher = s-\u0026gt;s3.tmp.new_sym_enc; if (!ssl3_digest_cached_records(s, 1) || !ssl_handshake_hash(s, hashval, sizeof(hashval), \u0026amp;hashlen)) { /* SSLfatal() already called */; goto err; } } 接下来，就是计算服务端读key和服务端读iv的流程，因为已经计算过hash了，所以直接利用s-\u0026gt;handshake_traffic_hash即可。对s-\u0026gt;handshake_secret做一次derive secret得到客户端握手secret(TLS1.3密钥衍生的\u0026quot;client_handshake_traffic_secret\u0026quot;),将之保存到secret变量里，除了下面计算finished key要用，其他地方都不用，所以secret变量是个局部变量。derive_secret函数内部会调用write_key = HKDF-Expand-Label(Secret, \u0026quot;key\u0026quot;, \u0026quot;\u0026quot;, key_length)和write_iv = HKDF-Expand-Label(Secret, \u0026quot;iv\u0026quot;, \u0026quot;\u0026quot;, iv_length)产生加密时的握手key和iv，并保存到读CTX中, 代码如下(记录密钥那部分就不写了)：\nif (!derive_secret_key_and_iv(s, which \u0026amp; SSL3_CC_WRITE, md, cipher, insecret, hash, label, labellen, secret, iv, ciph_ctx)) { /* SSLfatal() already called */ goto err; } 最终，利用服务端读密钥(TLS1.3密钥衍生的\u0026quot;client_handshake_traffic_secret\u0026quot;)，计算客户端的finishdkey，到此第二次tls13_change_cipher_state调用结束。计算finished_key时利用的规则和代码为:\nclient_finished_key = HKDF-Expand-Label(client_handshake_traffic_secret, \u0026#34;finished\u0026#34;, \u0026#34;\u0026#34;, Hash.length) if (finsecret != NULL \u0026amp;\u0026amp; !tls13_derive_finishedkey(s, ssl_handshake_md(s), secret, finsecret, finsecretlen)) { /* SSLfatal() already called */ goto err; } 结束 # 我个人很反感这段代码，工业级代码应该简单才对，为了毕竟tls1.3之前就个tls1.2，通用性没那么夸张。现在这样子看的太费劲了。唉，有点不想写了，好累啊，没人看，估计也没人对OPENSSL的自动机感兴趣。\n结尾的闲言碎语 # 写到这里差不多就可以结束了就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 10 日","externalUrl":null,"permalink":"/posts/2020-09-10-openssl%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB4/","section":"Posts","summary":"","title":"OPENSSL源码阅读(4)","type":"posts"},{"content":"","date":"2020 年 9 月 7 日","externalUrl":null,"permalink":"/tags/ecdsa/","section":"Tags","summary":"","title":"ECDSA","type":"tags"},{"content":" ECDSA算法 # 前言 # 我今天简单查了查ECDSA的流程，发现一大堆人瞎写，私钥写成公钥，随机数k写成d，真是令人尴尬。所以写个这个，额，差不多可以说是维基百科的翻译版。\nECDSA算法的讲解 # 场景假设还是经典的Alice，Bob场景，他们一开始只协商好了椭圆曲线ID，基点G，和基点G的阶n(multiplicative order)。\n基本参数定义 # 场景假设还是经典的ALICE，BOB场景，他们一开始只协商好了椭圆曲线ID，基点G，和基点G的阶n(multiplicative order)。在TLS1.3中，选定了椭圆曲线就标识对应的基点和基点的阶了。我们下面定义具体的参数。\n参数名(英文) 含义 Curve 选定的曲线和有限域，一般写作y^2 = x^3 + ax + b，这里面a \u0026amp; b都是系数 G 基点，使用基点在曲线上生成子群 n 基点的阶，n * G = O，O为基础元 d(A) Alice的私钥，对应于一个大素数 Q(A) Alice的公钥，对应于d(A)的公钥，即d(A)*G(椭圆曲线的加乘) m 要签名的消息，对于ECDSA这里应该是握手消息的hash输出 k` k在n的整数域上的逆 基点G的阶必须是素数，我们这里假设计算是基于整数域也就是Z/nZ的。此外，上面的d(A)是随机生成的私钥，注意d(A)并不是临时密钥(Ephemeral Key)。\nECDSA计算流程 # 现在假设Alice要开始对消息做签名了，除了第四步是加乘，其他都是正常的整数域乘法。流程如下：\n先对消息做$$hash$$，在TLS1.3中称之为transcrpthash(m)。具体体现为$$e = HASH(m)$$，将输出转换为整数 假设$$L(n)$$是基点$$G$$的阶$$n$$的bit长度，取z为上一步计算结果e的最左端$$L(n)$$位，实际上就是个截断操作，毕竟这个要参与运算的 从$$[1,n-1]$$中随机的选取一个随机数$$k$$，该随机数应当满足密码学安全性 计算新的点$$(x(1),y(1))=k*G$$，这里的*依然是椭圆曲线上的加乘 取上一步结果的横坐标$$x(1)$$，计算$$r = x(1) mod n$$,如果$$r==0$$，回退到第三步。 计算$s=k`*(z+rd(A)) modn$，如果s==0，再次回退到第三步,这里的k`就是k的逆 ECDSA的验签 # 验签的流程并不难，对Bob而言，验签过程首先要验证的就是公钥是合法的。这点不多说了。具体流程如下：\n验证r和s在[1,n-1]之间，如果不在，则签名无效 计算 $$e=hash(m)$$，保存e的最左端$$L(n)$$位为$$z$$ 计算$$u(1)=zs`mod n$$与$$u(2)=rs`mod n$$，s`指代s在n整数域上的逆 计算点$$(x(1),y(1))=u(1)*G+u(2)*Q(A)$$，这里的两个乘都是椭圆曲线的加乘 验证$$r==x(1)mod n$$，成立则说明签名有效，反之无效。 ECDSA验签的证明 # 证明就不多说了，本身将计算流程带入然后结合律搞一下就完了。ECDSA本身需要依靠椭圆曲线逆推难的结论，这点也没啥好说的。\n结语 # 国内好多文章不知道为啥要自己改来改去，如何定义一个标准的正确的竟然成为了难题。奇葩\n结尾的闲言碎语 # 写到这里差不多就可以结束了，就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 7 日","externalUrl":null,"permalink":"/posts/2020-09-09-ecdsa%E7%AE%97%E6%B3%95/","section":"Posts","summary":"","title":"ECDSA算法","type":"posts"},{"content":" OPENSSL源码阅读(3) # 前言 # 今天来分析分析自动机，自动机这东西基本只要是服务器都得用，上学那会看别人写的http自动机，现在工作了自己写tls自动机，如果对自动机有疑问可以看看字符串匹配的几个算法。本质上没啥变化。但是在TLS1.3中有个很大的问题：传统的自动机驱动是由数据驱动的，在TLS1.3当中由于存在early_data存在了一个early_data驱动和缓存的问题；对于客户端而言如何自发的从early_data的发送阶段切换到发送end_of_early_data阶段；对于服务端而言，early_data是缓存还是直接发送出去？我不会讲我司的解决方法(虽然这几个都是我设计的)，我们只看看openssl的做法。\nstate_machine的解析 # 自动机的状态初始化： # openssl当中，state_machine包含两个部分，分别是读自动机(read_state_machine)和写自动机(write_state_machine)，读自动机收取报文，写自动机负责发送报文，自动机就在读和写里面两个蹦来蹦去。openssl在进入自动机之前先把自动机状态，握手状态和early_data状态都初始化。然后才进入了state_machine中。下面的代码时初始化的代码，改了statem的状态。\nvoid SSL_set_accept_state(SSL *s) { s-\u0026gt;server = 1; s-\u0026gt;shutdown = 0; ossl_statem_clear(s); s-\u0026gt;handshake_func = s-\u0026gt;method-\u0026gt;ssl_accept; clear_ciphers(s); } void ossl_statem_clear(SSL *s) { s-\u0026gt;statem.state = MSG_FLOW_UNINITED; s-\u0026gt;statem.hand_state = TLS_ST_BEFORE; s-\u0026gt;statem.in_init = 1; s-\u0026gt;statem.no_cert_verify = 0; } 自动机的大状态切换 # 下面我们看state_machine的代码。首先初始化自动机状态，SSL结构体里面的OSSL_STATEM即对应于自动机，OSSL_STATEM中存有各种自动机状态(这个东西等会再说)。OSSL_STATEM的state用来标记大的状态而hand_state用来表示握手状态。两块初始完成之后要对s-\u0026gt;init_buf初始化。实际上这块buf初始化了就用来存储客户端的clienthello信息了。s-\u0026gt;init_num存储读取的字节数。初始化完成之后就可以进行自动机的运转了。这里注意大自动机已经被初始化为写状态MSG_FLOW_WRITING，为什么是写状态？因为state_machine通用客户端和服务端，客户端需要先写，如果启动的是服务器，那么写状态会在写自动机返回以后直接切换成读，所以不影响。大自动机实际上就是写和读，即 MSG_FLOW_WRITING \u0026lt;\u0026mdash;\u0026gt; MSG_FLOW_READING。\nstatic int state_machine(SSL *s, int server) { BUF_MEM *buf = NULL; void (*cb) (const SSL *ssl, int type, int val) = NULL; OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; int ret = -1; int ssret; ... /* Initialise state machine */ if (st-\u0026gt;state == MSG_FLOW_UNINITED || st-\u0026gt;state == MSG_FLOW_FINISHED) { if (st-\u0026gt;state == MSG_FLOW_UNINITED) { st-\u0026gt;hand_state = TLS_ST_BEFORE; st-\u0026gt;request_state = TLS_ST_BEFORE; } s-\u0026gt;server = server; ... if (s-\u0026gt;init_buf == NULL) { if ((buf = BUF_MEM_new()) == NULL) { SSLfatal(s, SSL_AD_NO_ALERT, SSL_F_STATE_MACHINE, ERR_R_INTERNAL_ERROR); goto end; } if (!BUF_MEM_grow(buf, SSL3_RT_MAX_PLAIN_LENGTH)) { SSLfatal(s, SSL_AD_NO_ALERT, SSL_F_STATE_MACHINE, ERR_R_INTERNAL_ERROR); goto end; } s-\u0026gt;init_buf = buf; buf = NULL; } s-\u0026gt;init_num = 0; /* * Should have been reset by tls_process_finished, too. */ s-\u0026gt;s3.change_cipher_spec = 0; ... st-\u0026gt;state = MSG_FLOW_WRITING; init_write_state_machine(s); ... while (st-\u0026gt;state != MSG_FLOW_FINISHED) { if (st-\u0026gt;state == MSG_FLOW_READING) { ssret = read_state_machine(s); if (ssret == SUB_STATE_FINISHED) { st-\u0026gt;state = MSG_FLOW_WRITING; init_write_state_machine(s); } else { /* NBIO or error */ goto end; } } else if (st-\u0026gt;state == MSG_FLOW_WRITING) { ssret = write_state_machine(s); if (ssret == SUB_STATE_FINISHED) { st-\u0026gt;state = MSG_FLOW_READING; init_read_state_machine(s); } else if (ssret == SUB_STATE_END_HANDSHAKE) { st-\u0026gt;state = MSG_FLOW_FINISHED; } else { /* NBIO or error */ goto end; } } else { /* Error */ check_fatal(s, SSL_F_STATE_MACHINE); SSLerr(SSL_F_STATE_MACHINE, ERR_R_SHOULD_NOT_HAVE_BEEN_CALLED); goto end; } } ret = 1; end: st-\u0026gt;in_handshake--; ... BUF_MEM_free(buf); if (cb != NULL) { if (server) cb(s, SSL_CB_ACCEPT_EXIT, ret); else cb(s, SSL_CB_CONNECT_EXIT, ret); } return ret; } 读自动机的切换 # 我们下面接着细看读写自动机的内容，先看读自动机read_state_machine。读自动机就是在“读取消息头部READ_STATE_HEADER”，“读取消息体READ_STATE_BODY”和“读取后操作READ_STATE_POST_PROCESS”之间来回转换。看下面的代码，用于判断状态转变，处理流程和处理后流程的代码就是这个：\ntransition = ossl_statem_server_read_transition; process_message = ossl_statem_server_process_message; max_message_size = ossl_statem_server_max_message_size; post_process_message = ossl_statem_server_post_process_message; 有一点值得注意哈，这个时候的报文可不是明文，也就是说，这里是密文的操作。我本身实际上是非常反感这种操作的，因为这里没有明确体现出来分层的理念。但是这种操作的好处是可以很简单的区分出来当前该做的是加密还是解密。我司的代码里面我们明确将自动机不针对读写进行拆分，而是针对record layer和handshake layer进行区分。因此，在写TLS1.3的early data的时候，我面对的主要问题是怎么判断当前消息的加解密。当然这种先读取头部再拆分消息体的做法是非常直接的写法。\n读自动机先获取消息的种类，之后调用transition判断状态的转换。比方说收到了clienthello之后就将自动机的握手状态转换为处理clienthello，即st-\u0026gt;hand_state = TLS_ST_SR_CLNT_HELLO;,clienthello是明文，可以直接返回了。返回之后就需要读取clienthello消息体tls_get_message_body，读取完成之后再调用process_message来处理客户端的clienthello，代码为tls_process_client_hello(s, pkt)这里进行的实际上是一大堆的保存和校验操作。这些操作完成了，就继续返回读自动机。这里有一点值得注意，处理完客户端消息不一定需要继续操作。如果这个时候需要做操作了，再继续进行post_process。反映在代码上就到了st-\u0026gt;read_state_work = post_process_message(s, st-\u0026gt;read_state_work);,对于处理完clienthello而言，这时候服务端做的操作就是选择通信的cipher，计算服务端的server key。这四个读自动机用的函数我会在本文后面详细讲讲，想理解清楚这个，需要对TLS1.3的状态变化比较熟悉。\nstatic SUB_STATE_RETURN read_state_machine(SSL *s) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; int ret, mt; size_t len = 0; int (*transition) (SSL *s, int mt); PACKET pkt; MSG_PROCESS_RETURN(*process_message) (SSL *s, PACKET *pkt); WORK_STATE(*post_process_message) (SSL *s, WORK_STATE wst); size_t (*max_message_size) (SSL *s); void (*cb) (const SSL *ssl, int type, int val) = NULL; cb = get_callback(s); if (s-\u0026gt;server) { transition = ossl_statem_server_read_transition; process_message = ossl_statem_server_process_message; max_message_size = ossl_statem_server_max_message_size; post_process_message = ossl_statem_server_post_process_message; } else { ... } if (st-\u0026gt;read_state_first_init) { s-\u0026gt;first_packet = 1; st-\u0026gt;read_state_first_init = 0; } while (1) { switch (st-\u0026gt;read_state) { case READ_STATE_HEADER: ... ret = tls_get_message_header(s, \u0026amp;mt); } if (ret == 0) { /* Could be non-blocking IO */ return SUB_STATE_ERROR; } ... /* * Validate that we are allowed to move to the new state and move * to that state if so */ if (!transition(s, mt)) return SUB_STATE_ERROR; ... st-\u0026gt;read_state = READ_STATE_BODY; /* Fall through */ case READ_STATE_BODY: if (!SSL_IS_DTLS(s)) { /* We already got this above for DTLS */ ret = tls_get_message_body(s, \u0026amp;len); if (ret == 0) { /* Could be non-blocking IO */ return SUB_STATE_ERROR; } } s-\u0026gt;first_packet = 0; if (!PACKET_buf_init(\u0026amp;pkt, s-\u0026gt;init_msg, len)) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_READ_STATE_MACHINE, ERR_R_INTERNAL_ERROR); return SUB_STATE_ERROR; } ret = process_message(s, \u0026amp;pkt); /* Discard the packet data */ s-\u0026gt;init_num = 0; switch (ret) { case MSG_PROCESS_ERROR: check_fatal(s, SSL_F_READ_STATE_MACHINE); return SUB_STATE_ERROR; case MSG_PROCESS_FINISHED_READING: if (SSL_IS_DTLS(s)) { dtls1_stop_timer(s); } return SUB_STATE_FINISHED; case MSG_PROCESS_CONTINUE_PROCESSING: st-\u0026gt;read_state = READ_STATE_POST_PROCESS; st-\u0026gt;read_state_work = WORK_MORE_A; break; default: st-\u0026gt;read_state = READ_STATE_HEADER; break; } break; case READ_STATE_POST_PROCESS: st-\u0026gt;read_state_work = post_process_message(s, st-\u0026gt;read_state_work); switch (st-\u0026gt;read_state_work) { case WORK_ERROR: check_fatal(s, SSL_F_READ_STATE_MACHINE); /* Fall through */ case WORK_MORE_A: case WORK_MORE_B: case WORK_MORE_C: return SUB_STATE_ERROR; case WORK_FINISHED_CONTINUE: st-\u0026gt;read_state = READ_STATE_HEADER; break; case WORK_FINISHED_STOP: if (SSL_IS_DTLS(s)) { dtls1_stop_timer(s); } return SUB_STATE_FINISHED; } break; default: /* Shouldn\u0026#39;t happen */ SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_READ_STATE_MACHINE, ERR_R_INTERNAL_ERROR); return SUB_STATE_ERROR; } } } 消息头的处理与tls_get_message_header函数 # 好了，我们再回头看读取消息报文头部的部分，首先调用tls_get_message_header读取客户端消息。一开始read_state是READ_STATE_HEADER这个不多解析,主要就是调用tls_get_message_header函数，读取报文，并且获取报文的种类。我们知道TLS1.3中，自动机的驱动方式只有三种：\n网络协议栈驱动，即收到了新消息需要处理。 计算驱动，即需要先计算出来一些密钥等信息，之后使用这些密钥参与计算。 自发的驱动，比方说发送early_data结束了，需要发送end_of_early_data报文，而end_of_early_data报文的加解密key并不和发送的early_data保持一致。服务端只存在前两种驱动方式。而tls_get_message_header就是网络协议栈驱动，tls_get_message_header将报文的消息种类存储于mt中。 while (1) { switch (st-\u0026gt;read_state) { case READ_STATE_HEADER: ... ret = tls_get_message_header(s, \u0026amp;mt); } 现在我们来看看这个通用的函数，tls_get_message_header函数内部调用了ssl_read_bytes。握手TLS1.3的时候，这个函数包裹的是ssl3_read_bytes函数，该函数需要能够解密被加密的报文，此外还必须能够处理各种收到的报文，比方说alert报文，close_notify报文，重协商报文等等。该函数会等待报文达到可以独写的数量再返回，ssl3_read_bytes函数我们以后再看，单独写一篇看。好，我们接着看tls_get_message_header函数，读取到足够的函数以后，报文包括record layer的数据被放到s-\u0026gt;init_buf-\u0026gt;data中，如果报文的种类是change_cipher_spec（change_cipher_spec函数用于表示加密key的变化），就需要判断该change_cipher_spec报文来的对不对，比方说已经读取的个数对不对？读取到的handshake layer和record layer是不是种类都是change_cipher_spec?否则就得报错返回了。\n如果没有错误，报文就继续向下进行了。到了n2l3那里，我司写的代码是INT2TOLEN3等方式，我觉得比n2l3看起来好理解不少。接着往下看s-\u0026gt;s3.tmp.message_size = l;这里tmp.message_size置为一，后面把client_hello的消息体指给了init_msg，init_num再次赋值为0，再返回就是判断状态是否需要变化了。\nint tls_get_message_header(SSL *s, int *mt) { /* s-\u0026gt;init_num \u0026lt; SSL3_HM_HEADER_LENGTH */ int skip_message, i, recvd_type; unsigned char *p; size_t l, readbytes; p = (unsigned char *)s-\u0026gt;init_buf-\u0026gt;data; do { while (s-\u0026gt;init_num \u0026lt; SSL3_HM_HEADER_LENGTH) { i = s-\u0026gt;method-\u0026gt;ssl_read_bytes(s, SSL3_RT_HANDSHAKE, \u0026amp;recvd_type, \u0026amp;p[s-\u0026gt;init_num], SSL3_HM_HEADER_LENGTH - s-\u0026gt;init_num, 0, \u0026amp;readbytes); if (i \u0026lt;= 0) { s-\u0026gt;rwstate = SSL_READING; return 0; } if (recvd_type == SSL3_RT_CHANGE_CIPHER_SPEC) { /* * A ChangeCipherSpec must be a single byte and may not occur * in the middle of a handshake message. */ if (s-\u0026gt;init_num != 0 || readbytes != 1 || p[0] != SSL3_MT_CCS) { SSLfatal(s, SSL_AD_UNEXPECTED_MESSAGE, SSL_F_TLS_GET_MESSAGE_HEADER, SSL_R_BAD_CHANGE_CIPHER_SPEC); return 0; } if (s-\u0026gt;statem.hand_state == TLS_ST_BEFORE \u0026amp;\u0026amp; (s-\u0026gt;s3.flags \u0026amp; TLS1_FLAGS_STATELESS) != 0) { /* * We are stateless and we received a CCS. Probably this is * from a client between the first and second ClientHellos. * We should ignore this, but return an error because we do * not return success until we see the second ClientHello * with a valid cookie. */ return 0; } s-\u0026gt;s3.tmp.message_type = *mt = SSL3_MT_CHANGE_CIPHER_SPEC; s-\u0026gt;init_num = readbytes - 1; s-\u0026gt;init_msg = s-\u0026gt;init_buf-\u0026gt;data; s-\u0026gt;s3.tmp.message_size = readbytes; return 1; } else if (recvd_type != SSL3_RT_HANDSHAKE) { SSLfatal(s, SSL_AD_UNEXPECTED_MESSAGE, SSL_F_TLS_GET_MESSAGE_HEADER, SSL_R_CCS_RECEIVED_EARLY); return 0; } s-\u0026gt;init_num += readbytes; } skip_message = 0; if (!s-\u0026gt;server) ... //这个也跳过吧，这个是客户端，我们这里是服务端 } while (skip_message); /* s-\u0026gt;init_num == SSL3_HM_HEADER_LENGTH */ *mt = *p; s-\u0026gt;s3.tmp.message_type = *(p++);//*(p++)和*p++是一样的，都是先取值然后p后移一位 if (RECORD_LAYER_is_sslv2_record(\u0026amp;s-\u0026gt;rlayer)) { ... //不分析了，不是sslv2的报文 } else { n2l3(p, l); /* BUF_MEM_grow takes an \u0026#39;int\u0026#39; parameter */ if (l \u0026gt; (INT_MAX - SSL3_HM_HEADER_LENGTH)) { SSLfatal(s, SSL_AD_ILLEGAL_PARAMETER, SSL_F_TLS_GET_MESSAGE_HEADER, SSL_R_EXCESSIVE_MESSAGE_SIZE); return 0; } s-\u0026gt;s3.tmp.message_size = l; s-\u0026gt;init_msg = s-\u0026gt;init_buf-\u0026gt;data + SSL3_HM_HEADER_LENGTH; s-\u0026gt;init_num = 0; } return 1; } 返回之后再次回到服务端，注意这里只是将clienthello的头部读了进来，并不清楚到底是不是复用，有没有early data。 tansition函数此时会判断需要将握手自动机的握手状态修改为服务端读clientheloo，即st-\u0026gt;hand_state = TLS_ST_SR_CLNT_HELLO;。之后就获取消息体，调用相关的处理函数。\n消息体的处理与tls_process_client_hello函数 # 接着看消息体的处理，消息体获取函数tls_get_message_body功能是不断读取解密好的握手消息报文并储存起来，将报文存储起来的目的有两个：\n报文存储起来之后进行处理，比方说读取clienthello的random等等 报文存储起来以后，finish的时候要进行mac计算verify，需要对之前所有的握手信息进行transcript-hash。 这次先不讲tls_get_message_body函数了，下回和get_message_header一起，单开一个说。 好，我们继续说，存储好clienthello之后就需要对clienthello进行处理，此时的握手状态是服务端读clienthello(TLS_ST_SR_CLNT_HELLO)，所以调用的函数是tls_process_client_hello\ncase READ_STATE_BODY: if (!SSL_IS_DTLS(s)) { /* We already got this above for DTLS */ ret = tls_get_message_body(s, \u0026amp;len); if (ret == 0) { /* Could be non-blocking IO */ return SUB_STATE_ERROR; } } s-\u0026gt;first_packet = 0; if (!PACKET_buf_init(\u0026amp;pkt, s-\u0026gt;init_msg, len)) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_READ_STATE_MACHINE, ERR_R_INTERNAL_ERROR); return SUB_STATE_ERROR; } ret = process_message(s, \u0026amp;pkt); /* Discard the packet data */ s-\u0026gt;init_num = 0; switch (ret) { case MSG_PROCESS_ERROR: check_fatal(s, SSL_F_READ_STATE_MACHINE); return SUB_STATE_ERROR; case MSG_PROCESS_FINISHED_READING: if (SSL_IS_DTLS(s)) { dtls1_stop_timer(s); } return SUB_STATE_FINISHED; case MSG_PROCESS_CONTINUE_PROCESSING: st-\u0026gt;read_state = READ_STATE_POST_PROCESS; st-\u0026gt;read_state_work = WORK_MORE_A; break; default: st-\u0026gt;read_state = READ_STATE_HEADER; break; } break; tls_process_client_hello负责处理clienthello报文，首先需要判断该clienthello是不是来的是个正确的时间，如果是个错误的重协商报文，那就直接判错。因为代码比较长，我就不贴了，只简单写写做了点什么。之后就需要根据clienthello报文初始化以下信息：\n是否是sslv2报文 获取clienthello中的legacy_version，也就是版本号，tls1.3中对于版本号有兼容性方面的考校 读取客户端的random 读取客户端的session_id，需要注意tls1.3中的session_id本质上已经丧失了复用的功能，复用使用的是psk 读取客户端的支持的ciphersuite 调用函数tls_collect_extensions读取并保存客户端的拓展信息，注意这里只是保存还没有分析的流程，也就是说这部分都是原始数据的拓展，即raw_extensions，我们这里重点关注四种类型的拓展，signature_algorithm，supported_group,key_share和pre_share_key拓展。这四种拓展分别用于协商签名算法（证书），支持的曲线，协商使用的临时密钥，复用时的身份。 上述操作完成了，就返回MSG_PROCESS_CONTINUE_PROCESSING让流程继续进行。 消息体读取后的处理 # 代码在底下，最好自己手头有一份代码可以直接看\nWORK_STATE tls_post_process_client_hello(SSL *s, WORK_STATE wst) { const SSL_CIPHER *cipher; if (wst == WORK_MORE_A) { int rv = tls_early_post_process_client_hello(s); if (rv == 0) { /* SSLfatal() was already called */ goto err; } if (rv \u0026lt; 0) return WORK_MORE_A; wst = WORK_MORE_B; } if (wst == WORK_MORE_B) { if (!s-\u0026gt;hit || SSL_IS_TLS13(s)) { /* Let cert callback update server certificates if required */ if (!s-\u0026gt;hit \u0026amp;\u0026amp; s-\u0026gt;cert-\u0026gt;cert_cb != NULL) { int rv = s-\u0026gt;cert-\u0026gt;cert_cb(s, s-\u0026gt;cert-\u0026gt;cert_cb_arg); if (rv == 0) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS_POST_PROCESS_CLIENT_HELLO, SSL_R_CERT_CB_ERROR); goto err; } if (rv \u0026lt; 0) { s-\u0026gt;rwstate = SSL_X509_LOOKUP; return WORK_MORE_B; } s-\u0026gt;rwstate = SSL_NOTHING; } /* In TLSv1.3 we selected the ciphersuite before resumption */ if (!SSL_IS_TLS13(s)) { cipher = ssl3_choose_cipher(s, s-\u0026gt;peer_ciphers, SSL_get_ciphers(s)); if (cipher == NULL) { SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE, SSL_F_TLS_POST_PROCESS_CLIENT_HELLO, SSL_R_NO_SHARED_CIPHER); goto err; } s-\u0026gt;s3.tmp.new_cipher = cipher; } if (!s-\u0026gt;hit) { if (!tls_choose_sigalg(s, 1)) { /* SSLfatal already called */ goto err; } /* check whether we should disable session resumption */ if (s-\u0026gt;not_resumable_session_cb != NULL) s-\u0026gt;session-\u0026gt;not_resumable = s-\u0026gt;not_resumable_session_cb(s, ((s-\u0026gt;s3.tmp.new_cipher-\u0026gt;algorithm_mkey \u0026amp; (SSL_kDHE | SSL_kECDHE)) != 0)); if (s-\u0026gt;session-\u0026gt;not_resumable) /* do not send a session ticket */ s-\u0026gt;ext.ticket_expected = 0; } } else { /* Session-id reuse */ s-\u0026gt;s3.tmp.new_cipher = s-\u0026gt;session-\u0026gt;cipher; } /*- * we now have the following setup. * client_random * cipher_list - our preferred list of ciphers * ciphers - the clients preferred list of ciphers * compression - basically ignored right now * ssl version is set - sslv3 * s-\u0026gt;session - The ssl session has been setup. * s-\u0026gt;hit - session reuse flag * s-\u0026gt;s3.tmp.new_cipher - the new cipher to use. */ /* * Call status_request callback if needed. Has to be done after the * certificate callbacks etc above. */ if (!tls_handle_status_request(s)) { /* SSLfatal() already called */ goto err; } /* * Call alpn_select callback if needed. Has to be done after SNI and * cipher negotiation (HTTP/2 restricts permitted ciphers). In TLSv1.3 * we already did this because cipher negotiation happens earlier, and * we must handle ALPN before we decide whether to accept early_data. */ if (!SSL_IS_TLS13(s) \u0026amp;\u0026amp; !tls_handle_alpn(s)) { /* SSLfatal() already called */ goto err; } wst = WORK_MORE_C; } #ifndef OPENSSL_NO_SRP if (wst == WORK_MORE_C) { int ret; if ((ret = ssl_check_srp_ext_ClientHello(s)) == 0) { /* * callback indicates further work to be done */ s-\u0026gt;rwstate = SSL_X509_LOOKUP; return WORK_MORE_C; } if (ret \u0026lt; 0) { /* SSLfatal() already called */ goto err; } } #endif return WORK_FINISHED_STOP; err: return WORK_ERROR; } 消息体处理后WORK_MORE_A的部分 # 消息读取完成了，关键数据也存储好了。就到了消息后处理的流程。我们直接看post_process_client_hello的代码。函数首先要进入tls_early_post_client_hello函数处理，该函数功能很多\n内部调用ssl_choose_server_version来选择tls版本，相对应的，如果是客户端调用的函数就是ssl_choose_client_version。ssl_choose_server_version函数内部有一个表，叫做tls_version_table，会根据选定的的版本挑选特定的握手函数，比方说tlsv1_3_server_method。 检查tls1.3的clienthello是不是处于一个sslrecord的边界内（这个如果没看懂的话建议去看看rfc原话） 检查cipher是否兼容 检查压缩算法等等 检查clienthello.random是否合法 分析各种拓展信息，首先分析extended_master_secret类型的拓展，之后调用函数tls_parse_all_extensions分析SSL_EXT_CLIENT_HELLO的所有拓展，这个分析的函数实际上也是个回调函数，具体每种拓展的函数体在extensions.c里的static const EXTENSION_DEFINITION ext_defs里，上面说了四个我们需要重点关注的拓展，签名，supported_group,key_share和psk拓展，对应于下面三条，这三条都是在tls_parse_all_extensions中对不同的函数进行调用的。 如果你看了tls1.3的rfc，那你必然知道clienthello里可以包含两种和签名算法有关的拓展,signature_algorithm和signature_algorithm_cert。这两种拓展会分别调用函数tls_parse_ctos_sig_algs与tls_parse_ctos_sig_algs_cert被保存到s-\u0026gt;s3.tmp.peer_sigalgs与s-\u0026gt;s3.tmp.peer_cert_sigalgs中。注意，这里只是保存！ 对于supported_groups,调用函数tls_parse_ctos_supported_groups,将客户端支持的曲线保存到s-\u0026gt;ext.peer_supportedgroups中。 对于key_share拓展，调用函数tls_parse_ctos_key_share，如果客户端不支持ECDHE的协商，只支持PSK_ONLY，那就什么也不做。反之，遍历客户端的Key_share拓展，如果有客户端不支持的曲线，报错。找到第一个服务端客户端共有的曲线，将该曲线的key_share，也就是客户端的临时公钥保存到s-\u0026gt;s3.peer_tmp，曲线id保存到s-\u0026gt;s3.group_id。接下来继续遍历Key_share拓展，但是不保存也不分析其他的key_share了，只是检查key_share拓展的有效性。 对于psk拓展，调用函数tls_parse_ctos_psk，先检查支不支持PSK交换方式，不支持报错。反之继续，分析的流程不多说了。在TICKET IDENTITY的设计那里会把这部分补上。 检查psk是否为带外数据建立，server端的random是不是需要特定的填充数据。 调用函数tls1_set_server_sigalgs设定服务端可以使用的签名算法，openssl有一个s-\u0026gt;s3.tmp.valid_flags[SSL_PKEY_NUM]数组，这个数组用来标识哪个证书能用，哪个签名算法可以用。步骤为：先置空s-\u0026gt;s3.tmp.valid_flags[SSL_PKEY_NUM]，如果客户端发了signature_algorithm和signature_algorithm_cert拓展，那么调用tls1_process_sigalgs，tls1_process_sigalgs中调用tls1_set_shared_sigalgs先将s-\u0026gt;shared_sigalgs结构清空，然后调用tls12_shared_sigalgs函数计算出来客户端服务端共用的签名算法再写入到s-\u0026gt;shared_sigalgs里(也就是说shared_sigalgs里都是可用的签名算法)。共用的签名算法保持好了，返回tls1_process_sigalgs函数中，对s-\u0026gt;shared_sigalgs做for循环分析，看证书是否支持，如果支持就将标记打到s-\u0026gt;s3.tmp.valid_flags[idx]上。注意这里还没有决定选择哪一个。如果没找到共存的signature algorithm，那就直接报错终止连接了。 消息体处理后WORK_MORE_B的部分 # 操作做完之后就需要继续进行WORK_MORE_B的部分了。如果当前不是复用连接，那么需要选择合适的证书和签名的算法。调用的函数是tls_choose_sigalg，实际上就是包裹的find_sig_alg的函数。该函数负责的功能就是签名算法的选择，也就是检查签名算法和证书的匹配性，最终将挑选好的曲线扔到s-\u0026gt;s3.tmp.sigalg中。之所以这么检查可以看看ECDSA的签名流程，我同样写了。检查的流程分为三块\n直接跳过sha1，sha224，DSA等，这几种直接就不支持结束了。 检查ctx是否支持某具体的签名算法 检查证书是否支持该签名算法。如果签名算法是椭圆曲线，那么检查该签名算法的椭圆曲线和证书的私钥的椭圆曲线是否一致。如果是RSA_PSS类型，那么检查私钥是否足够大做签名。 WORK_MORE_C的部分 # 这部分没啥好说的，srp拓展等等没啥好说的，跳了。 这里运行结束READ_STATE_MACHINE函数子状态机就运行结束了，返回子状态结束(SUB_STATE_FINISHED)。之后初始化大的自动机状态为写状态st-\u0026gt;state = MSG_FLOW_WRITING;，并初始化写自动机状态st-\u0026gt;write_state = WRITE_STATE_TRANSITION。下面就进入写自动机的状态了。\n写自动机的流程切换 # 写自动机实际上做的就是计算和发送消息的流程，我们看代码，这里要重点注意那几个通用函数，包括pre_work，post_work等等。他们是构建的主体。\nstatic SUB_STATE_RETURN write_state_machine(SSL *s) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; int ret; WRITE_TRAN(*transition) (SSL *s); WORK_STATE(*pre_work) (SSL *s, WORK_STATE wst); WORK_STATE(*post_work) (SSL *s, WORK_STATE wst); int (*get_construct_message_f) (SSL *s, WPACKET *pkt, int (**confunc) (SSL *s, WPACKET *pkt), int *mt); void (*cb) (const SSL *ssl, int type, int val) = NULL; int (*confunc) (SSL *s, WPACKET *pkt); int mt; WPACKET pkt; cb = get_callback(s); if (s-\u0026gt;server) { transition = ossl_statem_server_write_transition; pre_work = ossl_statem_server_pre_work; post_work = ossl_statem_server_post_work; get_construct_message_f = ossl_statem_server_construct_message; } else { transition = ossl_statem_client_write_transition; pre_work = ossl_statem_client_pre_work; post_work = ossl_statem_client_post_work; get_construct_message_f = ossl_statem_client_construct_message; } while (1) { switch (st-\u0026gt;write_state) { case WRITE_STATE_TRANSITION: if (cb != NULL) { /* Notify callback of an impending state change */ if (s-\u0026gt;server) cb(s, SSL_CB_ACCEPT_LOOP, 1); else cb(s, SSL_CB_CONNECT_LOOP, 1); } switch (transition(s)) { case WRITE_TRAN_CONTINUE: st-\u0026gt;write_state = WRITE_STATE_PRE_WORK; st-\u0026gt;write_state_work = WORK_MORE_A; break; case WRITE_TRAN_FINISHED: return SUB_STATE_FINISHED; break; case WRITE_TRAN_ERROR: check_fatal(s, SSL_F_WRITE_STATE_MACHINE); return SUB_STATE_ERROR; } break; case WRITE_STATE_PRE_WORK: switch (st-\u0026gt;write_state_work = pre_work(s, st-\u0026gt;write_state_work)) { case WORK_ERROR: check_fatal(s, SSL_F_WRITE_STATE_MACHINE); /* Fall through */ case WORK_MORE_A: case WORK_MORE_B: case WORK_MORE_C: return SUB_STATE_ERROR; case WORK_FINISHED_CONTINUE: st-\u0026gt;write_state = WRITE_STATE_SEND; break; case WORK_FINISHED_STOP: return SUB_STATE_END_HANDSHAKE; } if (!get_construct_message_f(s, \u0026amp;pkt, \u0026amp;confunc, \u0026amp;mt)) { /* SSLfatal() already called */ return SUB_STATE_ERROR; } if (mt == SSL3_MT_DUMMY) { /* Skip construction and sending. This isn\u0026#39;t a \u0026#34;real\u0026#34; state */ st-\u0026gt;write_state = WRITE_STATE_POST_WORK; st-\u0026gt;write_state_work = WORK_MORE_A; break; } if (!WPACKET_init(\u0026amp;pkt, s-\u0026gt;init_buf) || !ssl_set_handshake_header(s, \u0026amp;pkt, mt)) { WPACKET_cleanup(\u0026amp;pkt); SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_WRITE_STATE_MACHINE, ERR_R_INTERNAL_ERROR); return SUB_STATE_ERROR; } if (confunc != NULL \u0026amp;\u0026amp; !confunc(s, \u0026amp;pkt)) { WPACKET_cleanup(\u0026amp;pkt); check_fatal(s, SSL_F_WRITE_STATE_MACHINE); return SUB_STATE_ERROR; } if (!ssl_close_construct_packet(s, \u0026amp;pkt, mt) || !WPACKET_finish(\u0026amp;pkt)) { WPACKET_cleanup(\u0026amp;pkt); SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_WRITE_STATE_MACHINE, ERR_R_INTERNAL_ERROR); return SUB_STATE_ERROR; } /* Fall through */ case WRITE_STATE_SEND: if (SSL_IS_DTLS(s) \u0026amp;\u0026amp; st-\u0026gt;use_timer) { dtls1_start_timer(s); } ret = statem_do_write(s); if (ret \u0026lt;= 0) { return SUB_STATE_ERROR; } st-\u0026gt;write_state = WRITE_STATE_POST_WORK; st-\u0026gt;write_state_work = WORK_MORE_A; /* Fall through */ case WRITE_STATE_POST_WORK: switch (st-\u0026gt;write_state_work = post_work(s, st-\u0026gt;write_state_work)) { case WORK_ERROR: check_fatal(s, SSL_F_WRITE_STATE_MACHINE); /* Fall through */ case WORK_MORE_A: case WORK_MORE_B: case WORK_MORE_C: return SUB_STATE_ERROR; case WORK_FINISHED_CONTINUE: st-\u0026gt;write_state = WRITE_STATE_TRANSITION; break; case WORK_FINISHED_STOP: return SUB_STATE_END_HANDSHAKE; } break; default: SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_WRITE_STATE_MACHINE, ERR_R_INTERNAL_ERROR); return SUB_STATE_ERROR; } } } 写自动机初始部分流程 # 写自动机一开始调用transition(s)函数，这里实际上非常简单，对TLS1.3而言就是单纯的把握手状态st-\u0026gt;hand_state从\u0026quot;服务端读clienthello状态\u0026quot;(TLS_ST_SR_CLNT_HELLO)变成\u0026quot;服务端写serverhello状态\u0026quot;(TLS_ST_SW_SRVR_HELLO)。然后让代码返回WRITE_TRAN_CONTINUE。返回之后，代码继续向下执行进入PRE_WORK阶段。\nstatic WRITE_TRAN ossl_statem_server13_write_transition(SSL *s) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; switch (st-\u0026gt;hand_state) { .... case TLS_ST_SR_CLNT_HELLO: st-\u0026gt;hand_state = TLS_ST_SW_SRVR_HELLO; return WRITE_TRAN_CONTINUE; 写自动机WRITE_STATE_PRE_WORK阶段流程 # WRITE_STATE_PRE_WORK阶段，先调用pre_work函数，因为当前是“服务端写serverhello”状态，所以代码实际上啥都没干，直接返回WORK_FINISHED_CONTINUE，将握手状态机子状态修改st-\u0026gt;write_state = WRITE_STATE_SEND;。再调用get_construct_message_f函数构建发送的信息。get_construct_message_f做的也是个包工头工作，调用不同的函数来计算服务端参数，构建发送的数据包,这里我们能看到调用的是tls_construct_server_hello函数，这个函数里面得缕一缕。\nWORK_STATE ossl_statem_server_pre_work(SSL *s, WORK_STATE wst) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; switch (st-\u0026gt;hand_state) { default: /* No pre work to be done */ break; case TLS_ST_SW_SRVR_HELLO: if (SSL_IS_DTLS(s)) { /* * Messages we write from now on should be buffered and * retransmitted if necessary, so we need to use the timer now */ st-\u0026gt;use_timer = 1; } break; ... return WORK_FINISHED_CONTINUE; } int ossl_statem_server_construct_message(SSL *s, WPACKET *pkt, confunc_f *confunc, int *mt) { OSSL_STATEM *st = \u0026amp;s-\u0026gt;statem; switch (st-\u0026gt;hand_state) { default: /* Shouldn\u0026#39;t happen */ SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_OSSL_STATEM_SERVER_CONSTRUCT_MESSAGE, SSL_R_BAD_HANDSHAKE_STATE); return 0; case TLS_ST_SW_SRVR_HELLO: *confunc = tls_construct_server_hello; *mt = SSL3_MT_SERVER_HELLO; break; ... return 1; } tls_construct_server_hello函数 # tls_construct_server_hello函数将版本号，random，session_id写好以后，会调用tls_construct_extensions，这个函数层层包裹到每个拓展的的construct函数上去，我们前面说了四种重要拓展。一个一个拿过来看。\nsignature_algorithm和signature_algorithm_cert，这两种拓展服务端不会发给客户端，除非是需要双向认证。 supported_group拓展，该拓展调用函数tls_construct_stoc_supported_groups，如果上面我们已经选好了Key_share，那么这里s-\u0026gt;s3.group_id就不应当等于零了，此时的操作就是取出我们支持的曲线， psk拓展，这个调用函数tls_construct_stoc_psk，发送选择的identity index即可 (重要！)key_share拓展，会调用函数tls_construct_stoc_key_share,我们假设客户端发送了可用的key_share，也保存到了s-\u0026gt;s3.peer_tmp中，那么首先，先将选定的group也就是选定的椭圆曲线id写到key_share拓展起始部分。之后调用函数skey = ssl_generate_pkey(s, ckey);生成服务端的临时密钥对skey，将skey按格式写入到key_share拓展里。之后就要调用ssl_derive(s, skey, ckey, 1)生成我们的ECDHE secret和握手密钥，也就是说，服务端(也就是我们)已经利用客户端公钥，服务端私钥生成了ECDHE私钥了，对应于RFC8446的SECTION7.4和SECTION7.1的上部。 我们看看ssl_derive函数，调用的代码为ssl_derive(s, skey, ckey, 1),skey即为私钥，ckey即为公钥，1为gensecret。阅读代码可知，先后先使用私钥和公钥计算产生(EC)DHE secret，并将(EC)DHE secret存储到pms结构里，对应于TLS1.3密钥衍生流程图\u0026quot;(EC)DHE\u0026quot;。接下来进入if(gen_secret)的判断里，gen_secret为1，我们假设没有复用，则s-\u0026gt;hit == 0,所以先调用tls13_generate_secret函数将early_secret计算出来并存储到s-\u0026gt;early_secret中，s-\u0026gt;early_secret对应于TLS1.3密钥衍生流程图\u0026quot;Early Secret\u0026quot;。之后调用tls13_generate_handshake_secret，并将刚才的pms即(EC)DHE secret参与到计算流程，得出handshake secret存储到s-\u0026gt;handshake_secret中，s-\u0026gt;handshake_secret对应于TLS1.3密钥衍生流程图\u0026quot;Handshake Secret\u0026quot;。这里还有两点需要注意：1这里并没有计算出来服务端写/读密钥2服务端读/写密钥并不直接参与到读和写里，还要在再做一次衍生才能从secret发展到key\u0026amp;iv\n/* Derive secrets for ECDH/DH */ int ssl_derive(SSL *s, EVP_PKEY *privkey, EVP_PKEY *pubkey, int gensecret) { int rv = 0; unsigned char *pms = NULL; size_t pmslen = 0; EVP_PKEY_CTX *pctx; if (privkey == NULL || pubkey == NULL) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_SSL_DERIVE, ERR_R_INTERNAL_ERROR); return 0; } pctx = EVP_PKEY_CTX_new_from_pkey(s-\u0026gt;ctx-\u0026gt;libctx, privkey, s-\u0026gt;ctx-\u0026gt;propq); if (EVP_PKEY_derive_init(pctx) \u0026lt;= 0 || EVP_PKEY_derive_set_peer(pctx, pubkey) \u0026lt;= 0 || EVP_PKEY_derive(pctx, NULL, \u0026amp;pmslen) \u0026lt;= 0) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_SSL_DERIVE, ERR_R_INTERNAL_ERROR); goto err; } #ifndef OPENSSL_NO_DH if (SSL_IS_TLS13(s) \u0026amp;\u0026amp; EVP_PKEY_id(privkey) == EVP_PKEY_DH) EVP_PKEY_CTX_set_dh_pad(pctx, 1); #endif pms = OPENSSL_malloc(pmslen); if (pms == NULL) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_SSL_DERIVE, ERR_R_MALLOC_FAILURE); goto err; } if (EVP_PKEY_derive(pctx, pms, \u0026amp;pmslen) \u0026lt;= 0) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_SSL_DERIVE, ERR_R_INTERNAL_ERROR); goto err; } if (gensecret) { /* SSLfatal() called as appropriate in the below functions */ if (SSL_IS_TLS13(s)) { /* * If we are resuming then we already generated the early secret * when we created the ClientHello, so don\u0026#39;t recreate it. */ if (!s-\u0026gt;hit) rv = tls13_generate_secret(s, ssl_handshake_md(s), NULL, NULL, 0, (unsigned char *)\u0026amp;s-\u0026gt;early_secret); else rv = 1; rv = rv \u0026amp;\u0026amp; tls13_generate_handshake_secret(s, pms, pmslen); } else { rv = ssl_generate_master_secret(s, pms, pmslen, 0); } } else { /* Save premaster secret */ s-\u0026gt;s3.tmp.pms = pms; s-\u0026gt;s3.tmp.pmslen = pmslen; pms = NULL; rv = 1; } err: OPENSSL_clear_free(pms, pmslen); EVP_PKEY_CTX_free(pctx); return rv; } 几个拓展构建好了，ECHED secret计算完成了，现在就需要发送了SERVERHELLO了，进入到下一个状态\n写自动机发送的流程 # 写自动机需要发送了，ServerHello还是明文的，要明确告诉客户端选择的key_share,psk是哪个，只能用明文。消息写完了进入post阶段。\nret = statem_do_write(s); if (ret \u0026lt;= 0) { return SUB_STATE_ERROR; } st-\u0026gt;write_state = WRITE_STATE_POST_WORK; st-\u0026gt;write_state_work = WORK_MORE_A; 写自动机发送后的流程 # 调用函数post_work，实际上包裹的是ossl_statem_server_post_work函数，上面几步我们发送了serverhello到客户端，也计算出来ECDHE secret。此时实际上没啥实际要做的东西了，该函式只是将要发送的数据发出去(我觉得叫做冲flush出去更合适)，返回WORK_FINISHED_CONTINUE。此时看写自动机函数就会发现，返回之后会将写状态置为写的初始化状态st-\u0026gt;write_state = WRITE_STATE_TRANSITION;,此时再次进入写自动机的循环，下面具体的步骤下次再说。\n结语 # 哇，总算写完了clienthello的分析和serverhello的发送了，好累。\n结尾的闲言碎语 # 写到这里差不多就可以结束了，就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 7 日","externalUrl":null,"permalink":"/posts/2020-09-07-openssl%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB3/","section":"Posts","summary":"","title":"OPENSSL源码阅读(3)","type":"posts"},{"content":" OPENSSL源码阅读 # 前言 # 我最近有点烦，想找点副业不知道干啥，化悲愤为思考，写点文章吧。一般人阅读OPENSSL的源码是先说有几个文件，每个文件干啥。我打算从S_SERVER文件说起，因为做实验的时候一般都是自己搭建TLS 服务器。这次不会细致到每个点都扣，不值得也没有必要，读书不求甚解，至于精微之处则慢慢品味。\n从S_SERVER说起 # openssl自带一个s_server服务器，可以完成NST颁发，计算PSK，握手的每个计算。如果想从代码层面研究TLS1.3的握手流程，那么openssl就很适合。当然openssl的代码写的非常直接，我司几个人看的时候都把openssl骂了一顿。学习学习倒是极好的。\n前置知识 # s_server的使用方法大致如下，openssl s_server -accept \u0026ldquo;port\u0026rdquo; -key \u0026ldquo;key_file\u0026rdquo; -cert \u0026ldquo;cert_file\u0026rdquo; -ciphersuite \u0026ldquo;xxx\u0026rdquo; -tls1_2，所有双引号的内容都是自己制定的。然后带\u0026quot;-\u0026ldquo;的都是选项。\n源码阅读 # 打开s_server.c文件，主函数是s_server_main.c。s_server_main函数刚打开实际上是一大堆状态，CTX等用于环境的基本设置，就不多介绍了。唯一需要注意的是\nconst SSL_METHOD *meth = TLS_server_method(); ... int min_version = 0, max_version = 0, prot_opt = 0, no_prot_opt = 0; meth就是server端服务的主程序，而min_version和max_version本质上对应于服务端支持的版本范围。此外还有几个全局变量要注意:stateless全局变量，用于标识服务端完全不存储任何客户端信息，这里针对的是办法TICKET IDENTITY\ncase OPT_STATELESS: stateless = 1; break; s_server_main首先分配SSL设置环境（SSL configuration context)，接着验证参数的有效性，之后再给SSL设置环境打上服务端和命令行模式标签。标签打上以后就开始根据参数设置各种变量。下面的代码就设置了服务端支持的版本范围，比方说加了标签\u0026quot;TLS1_2\u0026rdquo;，那么就设置最大版本和最小版本都是TLS1.2。\ncctx = SSL_CONF_CTX_new(); vpm = X509_VERIFY_PARAM_new(); if (cctx == NULL || vpm == NULL) goto end; SSL_CONF_CTX_set_flags(cctx, SSL_CONF_FLAG_SERVER | SSL_CONF_FLAG_CMDLINE); prog = opt_init(argc, argv, s_server_options); while ((o = opt_next()) != OPT_EOF) { if (IS_PROT_FLAG(o) \u0026amp;\u0026amp; ++prot_opt \u0026gt; 1) { BIO_printf(bio_err, \u0026#34;Cannot supply multiple protocol flags\\n\u0026#34;); goto end; } ... case OPT_SSL3: min_version = SSL3_VERSION; max_version = SSL3_VERSION; break; case OPT_TLS1_3: min_version = TLS1_3_VERSION; max_version = TLS1_3_VERSION; break; case OPT_TLS1_2: min_version = TLS1_2_VERSION; max_version = TLS1_2_VERSION; break; case OPT_TLS1_1: min_version = TLS1_1_VERSION; max_version = TLS1_1_VERSION; break; case OPT_TLS1: min_version = TLS1_VERSION; max_version = TLS1_VERSION; 上面的初始化代码初始化了支持的版本，是否支持max_early_data，最大接受early data的字节之后。函数首先载入证书和私钥.如果有证书链文件再载入证书链文件。\nif (nocert == 0) { s_key = load_key(s_key_file, s_key_format, 0, pass, engine, \u0026#34;server certificate private key file\u0026#34;); if (s_key == NULL) goto end; s_cert = load_cert(s_cert_file, s_cert_format, \u0026#34;server certificate file\u0026#34;); if (s_cert == NULL) goto end; if (s_chain_file != NULL) { if (!load_certs(s_chain_file, \u0026amp;s_chain, FORMAT_PEM, NULL, \u0026#34;server certificate chain\u0026#34;)) goto end; } 之后载入crl文件，也就是判断证书是否有效的文件。\nif (crl_file != NULL) { X509_CRL *crl; crl = load_crl(crl_file, crl_format, \u0026#34;CRL\u0026#34;); if (crl == NULL) goto end; crls = sk_X509_CRL_new_null(); if (crls == NULL || !sk_X509_CRL_push(crls, crl)) { BIO_puts(bio_err, \u0026#34;Error adding CRL\\n\u0026#34;); ERR_print_errors(bio_err); X509_CRL_free(crl); goto end; } } 基本的配置都载入完成了，就可以初始化CTX了。这里需要注意的是：ctx和ctx2都是静态全局变量，下面的代码初始化CTX并使用CCTX来初始化CTX，同时设置CTX的各种属性，比方说最大支持版本，最小支持版本，设置是否异步(async)，设置支持early data，支持接受的最大的early data的长度。\nctx = SSL_CTX_new(meth); if (ctx == NULL) { ERR_print_errors(bio_err); goto end; } SSL_CTX_clear_mode(ctx, SSL_MODE_AUTO_RETRY); if (sdebug) ssl_ctx_security_debug(ctx, sdebug); if (!config_ctx(cctx, ssl_args, ctx)) goto end; if (ssl_config) { if (SSL_CTX_config(ctx, ssl_config) == 0) { BIO_printf(bio_err, \u0026#34;Error using configuration \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, ssl_config); ERR_print_errors(bio_err); goto end; } } #ifndef OPENSSL_NO_SCTP if (protocol == IPPROTO_SCTP \u0026amp;\u0026amp; sctp_label_bug == 1) SSL_CTX_set_mode(ctx, SSL_MODE_DTLS_SCTP_LABEL_LENGTH_BUG); #endif if (min_version != 0 \u0026amp;\u0026amp; SSL_CTX_set_min_proto_version(ctx, min_version) == 0) goto end; if (max_version != 0 \u0026amp;\u0026amp; SSL_CTX_set_max_proto_version(ctx, max_version) == 0) goto end; 最后进入了服务器搭建的关键部分了。根据协议，设置服务器的主函数，这实际上是个回调函数。do_server本质就是绑定服务器到一个地址。注意，这里实现了写代码的时候一个很关键的地方，分层的想法。面向四层的操作交给一个四层的函数去做，面向四层一下的操作给四层以下的去做，这种想法很有用。因为我们只关注TLS层，所以就不对四层以下的多做解释了。有兴趣可以自己看。解析来函数跳转到sv_body，sv_body本身就是提供TLS服务的关键，里面包含的是一个自动机。下一节我们再细说。\nif (rev) server_cb = rev_body; else if (www) server_cb = www_body; else server_cb = sv_body; #ifdef AF_UNIX if (socket_family == AF_UNIX \u0026amp;\u0026amp; unlink_unix_path) unlink(host); #endif do_server(\u0026amp;accept_socket, host, port, socket_family, socket_type, protocol, server_cb, context, naccept, bio_s_out); print_stats(bio_s_out, ctx); ret = 0; 结束 # 我个人很反感这段代码，配置这块我觉得最好单独拆一个函数出来，然后里面不同的部分分开。现在这样子看的太费劲了。\n结尾的闲言碎语 # 写到这里差不多就可以结束了，实际上Session Identity还经常需要添加ALPN信息，就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 4 日","externalUrl":null,"permalink":"/posts/2020-09-04-openssl%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB1/","section":"Posts","summary":"","title":"OPENSSL源码阅读","type":"posts"},{"content":" OPENSSL源码阅读(2) # 前言 # SV_BODY本身就是一个包裹的层面，我不喜欢这块的函数就是本身应该上来是握手，然后根据握手包决定是不是接受early_data。但openssl的代码就是上来就写SSL_read_early_data，明明是握手却搞得好像early_data读取一样，令人贼尴尬。\nSV_BODY的解析 # 我们这里直接分析允许early_data的情况，首先调用SSL_set_accept_state(con)函数，来初始化当前ssl连接自动机的状态：标记当前ssl连接为server端，同时设置s-\u0026gt;statem的各种状态。也就是尚未握手，尚在初始化，还没verify证书，自动机还没转起来。这些状态设置好了。再向下继续阅读。\nvoid SSL_set_accept_state(SSL *s) { s-\u0026gt;server = 1; s-\u0026gt;shutdown = 0; ossl_statem_clear(s); s-\u0026gt;handshake_func = s-\u0026gt;method-\u0026gt;ssl_accept; clear_ciphers(s); } void ossl_statem_clear(SSL *s) { s-\u0026gt;statem.state = MSG_FLOW_UNINITED; s-\u0026gt;statem.hand_state = TLS_ST_BEFORE; s-\u0026gt;statem.in_init = 1; s-\u0026gt;statem.no_cert_verify = 0; } 之后会不断的尝试读取early data，你可能有疑问，握手还没开始呢？怎么就读取early_data了？实际上这里的读取并不是说上来就是读取的early data，只不过这个函数包含了握手的自动机。如果不支持early data的话，那么sv_body的函数体会继续运行到下面进行握手。\nSSL_set_accept_state(con); ... if (early_data) { int write_header = 1, edret = SSL_READ_EARLY_DATA_ERROR; size_t readbytes; while (edret != SSL_READ_EARLY_DATA_FINISH) { for (;;) { edret = SSL_read_early_data(con, buf, bufsize, \u0026amp;readbytes); if (edret != SSL_READ_EARLY_DATA_ERROR) break; ... 下面看下SSL_read_early_data函数，s实际上就是当前的ssl连接对应的数据结构，初始化的时候，s的数据结构通过zalloc初始化，所以s-\u0026gt;early_data_state是0，也就是SSL_EARLY_DATA_NONE。代码因此判断SSL_in_before(s)的返回值是否为0，该函数用于判断当前连接是否已经初始化了，换句人能听懂的话就是：当前连接还没有进行握手，那就返回1，反之返回0。如果返回0，就发生一个不可能发生的错误，这大概率是内存写错。代码会接着运行到SSL_EARLY_DATA_ACCEPT_RETRY的case，直接接受s-\u0026gt;early_data_state，进入到SSL_accept函数了。此时代码进入了SSL的握手流程。\nint SSL_read_early_data(SSL *s, void *buf, size_t num, size_t *readbytes) { int ret; if (!s-\u0026gt;server) { SSLerr(SSL_F_SSL_READ_EARLY_DATA, ERR_R_SHOULD_NOT_HAVE_BEEN_CALLED); return SSL_READ_EARLY_DATA_ERROR; } switch (s-\u0026gt;early_data_state) { case SSL_EARLY_DATA_NONE: if (!SSL_in_before(s)) { SSLerr(SSL_F_SSL_READ_EARLY_DATA, ERR_R_SHOULD_NOT_HAVE_BEEN_CALLED); return SSL_READ_EARLY_DATA_ERROR; } /* fall through */ case SSL_EARLY_DATA_ACCEPT_RETRY: s-\u0026gt;early_data_state = SSL_EARLY_DATA_ACCEPTING; ret = SSL_accept(s); if (ret \u0026lt;= 0) { /* NBIO or error */ s-\u0026gt;early_data_state = SSL_EARLY_DATA_ACCEPT_RETRY; return SSL_READ_EARLY_DATA_ERROR; } /* fall through */ case SSL_EARLY_DATA_READ_RETRY: if (s-\u0026gt;ext.early_data == SSL_EARLY_DATA_ACCEPTED) { s-\u0026gt;early_data_state = SSL_EARLY_DATA_READING; 我们下面接着阅读SSL_accept函数，本质上SSL_do_handshake的一层包裹。我们看SSL_do_handshake的意义，首先在ossl_statem_check_finish_init函数当中判断当前s的握手状态是否处于读取early data状态/等待end_of_early_data消息接断。上面初始化状态的时候已经写的很清楚了，这里不会改变hand_state的值，那么函数会继续进行。进入到判断SSL_in_init(s) || SSL_in_before(s)，还是上面状态赋值那里已经讲ssl连接的in_init状态赋值为1，所以代码会继续进行。我们这里是同步模式，所以代码继续致性s-\u0026gt;handshake_func(s).问题来了，握手函数是什么？\nint SSL_accept(SSL *s) { if (s-\u0026gt;handshake_func == NULL) { /* Not properly initialized yet */ SSL_set_accept_state(s); } return SSL_do_handshake(s); } int SSL_do_handshake(SSL *s) { int ret = 1; if (s-\u0026gt;handshake_func == NULL) { SSLerr(SSL_F_SSL_DO_HANDSHAKE, SSL_R_CONNECTION_TYPE_NOT_SET); return -1; } ossl_statem_check_finish_init(s, -1); s-\u0026gt;method-\u0026gt;ssl_renegotiate_check(s, 0); if (SSL_in_init(s) || SSL_in_before(s)) { if ((s-\u0026gt;mode \u0026amp; SSL_MODE_ASYNC) \u0026amp;\u0026amp; ASYNC_get_current_job() == NULL) { struct ssl_async_args args; args.s = s; ret = ssl_start_async_job(s, \u0026amp;args, ssl_do_handshake_intern); } else { ret = s-\u0026gt;handshake_func(s); } } return ret; } void ossl_statem_check_finish_init(SSL *s, int sending) { if (sending == -1) { if (s-\u0026gt;statem.hand_state == TLS_ST_PENDING_EARLY_DATA_END || s-\u0026gt;statem.hand_state == TLS_ST_EARLY_DATA) { ossl_statem_set_in_init(s, 1); if (s-\u0026gt;early_data_state == SSL_EARLY_DATA_WRITE_RETRY) { /* * SSL_connect() or SSL_do_handshake() has been called directly. * We don\u0026#39;t allow any more writing of early data. */ s-\u0026gt;early_data_state = SSL_EARLY_DATA_FINISHED_WRITING; } } 握手函数是什么呢？handshake_func实际上就是函数int ossl_statem_accept即握手自动机。看这个实现实际就是包裹的state_machine\nint ossl_statem_accept(SSL *s) { return state_machine(s, 1); } 对于state_machine的分析我们下回再说\n结尾的闲言碎语 # 写到这里差不多就可以结束了，实际上SV_BODY这里代码也没特别复杂，就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 9 月 4 日","externalUrl":null,"permalink":"/posts/2020-09-04-openssl%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB2/","section":"Posts","summary":"","title":"OPENSSL源码阅读(2)","type":"posts"},{"content":"","date":"2020 年 8 月 31 日","externalUrl":null,"permalink":"/tags/ticket/","section":"Tags","summary":"","title":"Ticket","type":"tags"},{"content":" TLS1.3 Ticket Identity设计 # 前言 # 很多时候设计数据结构是个令人尴尬的事情，用户量小/只有自己使用，那随便写。但是如果用户量变大了/出现了内存写坏的情况，那DEBUG可以说是要死人了。所以打好一个框架可以说是非常重要的。不过讲道理设计Identity的时候我是参照RFC5077做的，然后吴哥设计的时候也是照5077做的，抄就完事了，就是最后实现identity和原本session的结构关联的时候增删改查四个API改的我那叫一个蛋疼。这里作为基础知识，就不讲Session Identity和Session Id的区别了，以后再写了。\nTicket Identity设计流程 # TLS1.3 Ticket Identity的设计目标 # 与TLS1.2不同，TLS1.3设计的时候我们考虑了不少别的东西。很多规定并不是强制要求的，但是出于安全性考虑还是实现了\nTicket Identity应当减少服务端的运算/内存占用，避免非对称操作出现。 Ticket Identity应当满足安全性要求，同时运算够快。 Ticket Identity应当能够鉴别客户端视角Identity寿命和服务端Identity寿命差值，留个小问题，如何设定两边差值的大小？ Ticket Identity应当包含ServerName信息，从而校验复用时ServerName是否一致。 Ticket Identity应当包含使用的Cipher信息，从而校验复用时Cipher是否一致。 Ticket Identity应当包含版本，ticket_age_add信息。 上面的几条要求，除了第一条和第二条剩下都是“需要保存xxx\u0026quot;，这些存储明文即可。Ticket Identity减少内存占用，那就不在服务端保存任何消息。同时要符合安全性和少运算的要求，那么就是用hmac和ase做加密操作。\nTLS1.3 Ticket Identity明文部分的设计方案 # 明文部分设计方案可以说是非常简单了，关键信息一个不能少，也不能多到那里去。\nstruct { ProtocolVersion protocol_version;\t//版本信息 CipherSuite cipher_suite;\t//cipher信息 opaque ticket_age_add;\t//age_add信息 opaque ticket_birth;\t//birth信息 opaque secret;\t//啥secret自己看着办 opaque servername;\t//servername信息 } IdentityPlaintext; TLS1.3 Ticket Identity安全性方面的设计方案 # 安全性方面目标就两个，一个是保密性，另一个就是完整性\n保密性：保密性实际上就是要加密IdentityPlaintext，不能从明文透露Identity信息。但是不能使用非对称加密，因为非对称太消耗时间和性能了，所以使用AES比较合适。 完整性：完整性本质就是防篡改，加个hmac就成了。 这里留下来一个问题，无论是AES还是HMAC都是需要使用密钥的，这个密钥如何产生，多久改变一次？ TLS1.3 Ticket Identity的数据结构查找方面的设计 # 因为作为Server时，不需要保存Ticket Identity的信息，所以只需要保存作为client端的Ticket Identity信息即可。那么如何保存Ticket Identity呢？只简单写写设计原则\n一方面要跨线程方便查找，另一方面要能快速找到。所以一方面哈希表，另一方面二叉树 锁大了不好，锁小了好，实在不行per线程自己保存完事了，不会出现任何碰撞最简单。 结果最好和原先兼容，能挂到一起最好 OPENSSL如何设计Ticket Identity的？ # OPENSSL的Ticket Identity和我司的设计并不一样，比方说OPENSSL会有ANTI-REPLAY举措，他们会保存Ticket Identity，所以不需要生成完全无状态ticket。 我们来看OPENSSL生成无状态Ticket时是如何存储的。这里就直接看ssl_session_st了，不多分析流程了。\nint i2d_SSL_SESSION(const SSL_SESSION *in, unsigned char **pp) { SSL_SESSION_ASN1 as; ASN1_OCTET_STRING cipher; unsigned char cipher_data[2]; ASN1_OCTET_STRING master_key, session_id, sid_ctx; #ifndef OPENSSL_NO_COMP ASN1_OCTET_STRING comp_id; unsigned char comp_id_data; #endif ASN1_OCTET_STRING tlsext_hostname, tlsext_tick; #ifndef OPENSSL_NO_SRP ASN1_OCTET_STRING srp_username; #endif #ifndef OPENSSL_NO_PSK ASN1_OCTET_STRING psk_identity, psk_identity_hint; #endif ASN1_OCTET_STRING alpn_selected; ASN1_OCTET_STRING ticket_appdata; long l; if ((in == NULL) || ((in-\u0026gt;cipher == NULL) \u0026amp;\u0026amp; (in-\u0026gt;cipher_id == 0))) return 0; memset(\u0026amp;as, 0, sizeof(as)); as.version = SSL_SESSION_ASN1_VERSION; as.ssl_version = in-\u0026gt;ssl_version; if (in-\u0026gt;cipher == NULL) l = in-\u0026gt;cipher_id; else l = in-\u0026gt;cipher-\u0026gt;id; cipher_data[0] = ((unsigned char)(l \u0026gt;\u0026gt; 8L)) \u0026amp; 0xff; cipher_data[1] = ((unsigned char)(l)) \u0026amp; 0xff; ssl_session_oinit(\u0026amp;as.cipher, \u0026amp;cipher, cipher_data, 2); #ifndef OPENSSL_NO_COMP if (in-\u0026gt;compress_meth) { comp_id_data = (unsigned char)in-\u0026gt;compress_meth; ssl_session_oinit(\u0026amp;as.comp_id, \u0026amp;comp_id, \u0026amp;comp_id_data, 1); } #endif ssl_session_oinit(\u0026amp;as.master_key, \u0026amp;master_key, in-\u0026gt;master_key, in-\u0026gt;master_key_length); ssl_session_oinit(\u0026amp;as.session_id, \u0026amp;session_id, in-\u0026gt;session_id, in-\u0026gt;session_id_length); ssl_session_oinit(\u0026amp;as.session_id_context, \u0026amp;sid_ctx, in-\u0026gt;sid_ctx, in-\u0026gt;sid_ctx_length); as.time = in-\u0026gt;time; as.timeout = in-\u0026gt;timeout; as.verify_result = in-\u0026gt;verify_result; as.peer = in-\u0026gt;peer; ssl_session_sinit(\u0026amp;as.tlsext_hostname, \u0026amp;tlsext_hostname, in-\u0026gt;ext.hostname); if (in-\u0026gt;ext.tick) { ssl_session_oinit(\u0026amp;as.tlsext_tick, \u0026amp;tlsext_tick, in-\u0026gt;ext.tick, in-\u0026gt;ext.ticklen); } if (in-\u0026gt;ext.tick_lifetime_hint \u0026gt; 0) as.tlsext_tick_lifetime_hint = in-\u0026gt;ext.tick_lifetime_hint; as.tlsext_tick_age_add = in-\u0026gt;ext.tick_age_add; #ifndef OPENSSL_NO_PSK ssl_session_sinit(\u0026amp;as.psk_identity_hint, \u0026amp;psk_identity_hint, in-\u0026gt;psk_identity_hint); ssl_session_sinit(\u0026amp;as.psk_identity, \u0026amp;psk_identity, in-\u0026gt;psk_identity); #endif /* OPENSSL_NO_PSK */ #ifndef OPENSSL_NO_SRP ssl_session_sinit(\u0026amp;as.srp_username, \u0026amp;srp_username, in-\u0026gt;srp_username); #endif /* OPENSSL_NO_SRP */ as.flags = in-\u0026gt;flags; as.max_early_data = in-\u0026gt;ext.max_early_data; if (in-\u0026gt;ext.alpn_selected == NULL) as.alpn_selected = NULL; else ssl_session_oinit(\u0026amp;as.alpn_selected, \u0026amp;alpn_selected, in-\u0026gt;ext.alpn_selected, in-\u0026gt;ext.alpn_selected_len); as.tlsext_max_fragment_len_mode = in-\u0026gt;ext.max_fragment_len_mode; if (in-\u0026gt;ticket_appdata == NULL) as.ticket_appdata = NULL; else ssl_session_oinit(\u0026amp;as.ticket_appdata, \u0026amp;ticket_appdata, in-\u0026gt;ticket_appdata, in-\u0026gt;ticket_appdata_len); return i2d_SSL_SESSION_ASN1(\u0026amp;as, pp); } 上面是创建基础元，创建完成之后使用AES-256-CBC+HSA256进行ticket的完整运算，最后写入到数据包中。\n比较OPENSSL和我们设计的Ticket Identity # 可以看到，OPENSSL实现的时候和我司的实现查别还是很大的。两者都是遵循最小信息元原则。使用的加密算法和完整性算法也是类似的。明显都是照着RFC5077做的嘛。但OPENSSL如果不保存Ticket Identity，那么它使用的Ticket Hmac Key是写死的，这点比较糟糕。那么问题来了，AES Key和HMAC Key应当如何更新，多久更新一次？我个人建议是和Ticket Identity的日期保持一致，这东西实际上跟环境还是有关系的，必将算个hmac和aes也不算慢，不会是瓶颈。\n结尾的闲言碎语 # 写到这里差不多就可以结束了，实际上Session Identity还经常需要添加ALPN信息，就不多说了。TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 8 月 31 日","externalUrl":null,"permalink":"/posts/2020-08-31-hkdf-tls1.3ticketidentiy%E8%AE%BE%E8%AE%A1/","section":"Posts","summary":"","title":"TLS1.3TicketIdentity设计","type":"posts"},{"content":" TLS1.3 复用验证流程 # 前言 # 在我司写TLS1.3自动机的时候我负责的就是复用（reuse）和0-RTT的流程，这两个流程的功能介绍实质上是非常简单的，一些中间的运算可能稍微复杂，我当时是对着cavium卡和openssl 1.1.1d的代码做的研究。以后再写点openssl代码的东西吧\n复用流程 # 复用的流程看起来是非常简单的，见下：\n简单说说，我们针对复杂一些的复用过程（PSK+ECDHE流程）\n客户端发送ClientHello报文，该报文当中携带两个关键的拓展：key_share和pre_shared_key拓展。key_share和完整的ECDHE握手时一致的，也就是计算出来的椭圆曲线公钥。而pre_shared_key包含两个部分，分别为Psk identity和PSK Binders。PSK identity用于告诉服务端：我携带的身份（identity）是啥。而PSK Binder则是利用上次链接计算出来的PSK和本次的Clienthello报文的部分经过一番计算的结果。PSK Binders的作用是验证，这个PSK identity的拥有者是我，我不是冒充的。该拓展的结构如下： 服务端决定接受客户端的复用，回复ServerHello消息，消息中携带两个拓展pre_share_key和key_share拓展。和客户端不同，服务端的pre_share_key拓展指示选择了第几个客户端发送过来的PSK identity。因为客户端可以发送多个PSK identity，因此需要标明选择选择的身份的序号。这个序号从0开始。 服务端发送EncryptedExtesnsions。该消息的拓展长度是可以为零的。我们现在说的是复用流程，如果是0-RTT流程，服务端需要在该部分发送EarlyData拓展表示接受EarlyData报文。具体哪些拓展可以在该拓展中发送我以后再写文章介绍吧。 服务端发送Finished报文。Finished报文本质上来说是对已经发送的内容做了一次认证。没有什么需要赘述的。 客户端发送Finished报文。Finished报文本质上来说是对已经发送的内容做了一次认证。没有什么需要赘述的。 复用流程中每一步的功能 # 尽管每一个学过公钥密码学基础的人都知道每步的作用，但我还是单摘出来这部分。毕竟我希望这篇文章帮到初学者。下面我写的序号分别对应“复用流程”中每一步的序号。\nClientHello报文的PSK identity是明文传输的，所以任何人可以伪造。这个时候PSK Binders就可以起到认证identity的作用。首先上次连接的复用主密钥（resumption_master_secret）只有这个身份的拥有者有，那么由复用主密钥计算出来的PSK必然也只属于身份拥有者所有。从而如果Binders计算正确就证明客户端确实是该身份的拥有者，即和服务端通话的是上次连接的客户端。 服务端回复ServerHello消息，只是明确告诉客户端我选择了你的第X个身份，这个时候并没有直接证明服务端的身份。 服务端回复EncryptedExtension消息，这时候没有明确证明服务端身份。但是我们知道上次连接协商出来的PSK是只有服务端和客户端所共有的，而EncryptedExtension消息是由PSK计算出来的握手密钥保护的，因此客户端能够解密出来正常的EncryptedExtension消息就证明了服务端的身份 服务端发送Finished消息，该消息是对服务端Finished之前所有消息的认证。经过握手密钥保护的Finsiehd消息，证明了服务端的身份。 客户端发送Finished消息，该消息是对客户端Finished之前所有消息的认证。经过握手密钥保护的Finsiehd消息，证明了客户端的身份。 复用流程中的计算过程 # 客户端发送ClientHello中的计算过程 # 首先，客户端需要计算出来自己Key Share拓展的内容。该过程简单来讲是一个椭圆曲线点乘的结果，值得注意的是，这是一个非对称操作，耗时巨大。\n之后，我这里假设已经计算出来了PSK的值，从复用主密钥计算出PSK的过程就不讲了。Key schedule那部分说过了。 首先需要从PSK计算出来初期密钥（Early Secret），即：\nEarly Secret = HKDF-Extract(0, PSK)\n之后计算Binder key，如果是通过带外数据传输的PSK，标签使用\u0026quot;ext binder\u0026quot;，如果是通过上次连接建立的，标签使用\u0026quot;res binder\u0026quot;。即：\nBinder Key = Derive-Secret(Early Secret, \u0026ldquo;ext binder\u0026rdquo; | \u0026ldquo;res binder\u0026rdquo;, \u0026ldquo;\u0026rdquo;)\n计算完了Binder key还没完，并不直接使用Binder Key计算Binder的值，还要再进行一步演算。方法和计算Finished报文的key一样，但是为了区分，姑且称之为Hmac Key。计算方法如下：\nHmac_key = HKDF-Expand-Label(Binder key, \u0026ldquo;finished\u0026rdquo;, \u0026ldquo;\u0026rdquo;, Hash.length)\n演算到这步之后，所有的key都算完了。可以计算Binder了。客户端可以携带多个PSK identity，因此也要携带多个PSK Binder。每个Binder的计算都是对ClientHello报文剔除掉pre_shared_key拓展的binders部分做一次哈希的结果做HMAC。这里面暗含了个两个东西：一个是计算binder的时候包含了pre_shared_key拓展的身份部分，另一个是pre_share_key拓展在ClientHello报文的末尾。计算过程如下：\none_binder = HMAC(hmac key, Transcript-Hash(ClientHello移除掉binders的部分))\n服务端发送ServerHello时 # 首先，服务端首先需要校验客户端的身份信息，验证Binder的有效性，验证的过程和上面是一致的。验证通过之后，服务端需要计算出来自己Key Share拓展的内容。这同样是一个非对称操作，耗时巨大。 服务端发送的ServerHello消息是明文，不需要record layer进行加密。但实现的时候我们直接把握手密钥直接算出来了。\n服务端发送EncryptedExtensions # 服务端发送EncryptedExtension时使用上一步计算出来的握手密钥，在record layer进行加密即可。\n服务端发送Finsiehd消息 # 服务端首先需要利用主密钥计算出Finished使用的密钥Finish key，再对上面的所有的消息都算一次hash，再进行Hmac。即：\nfinished = HMAC(finish key, Transcript-Hash(ClientHello + ServerHello + EncryptedExtension))\n客户端发送Finished消息 # 客户端首先需要利用主密钥计算出Finished使用的密钥Finish key，再对我手中上面的所有的消息都算一次hash，再进行Hmac。即：\nfinished = HMAC(finish key, Transcript-Hash(ClientHello + ServerHello + EncryptedExtension + server.finished))\n复用流程的一些细节 # 我一直没想明白为什么不能直接使用binder key计算binder，而是使用binder key衍生的hmac key计算binder。从安全角度来说没想明白为啥，只是觉得方便代码迭代，函数公用？\n结尾 # 写到这里差不多就可以结束了，TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 8 月 28 日","externalUrl":null,"permalink":"/posts/2020-08-28-tls1.3%E5%A4%8D%E7%94%A8%E9%AA%8C%E8%AF%81%E6%B5%81%E7%A8%8B/","section":"Posts","summary":"","title":"TLS1.3复用验证流程","type":"posts"},{"content":" HKDF-Extract与HKDF-Expand # 前言 # 写TLS1.3的协议解析自动机的时候，不单实现了cavium卡的流程，还得实现软实现。所以硬生生对着HKDF的RFC和OPENSSL的源代码吃了一遍。做的时候还有些疑问，不知道有没有本科生看，希望我写的能直接给本科生看。\nHKDF-Extract与HKDF-Expand的作用 # 做密钥衍生的时候常常需要根据初始密钥材料（initial keying material）产生符合特定长度要求，密码学安全标准的新密钥的需求。因此RFC5889定义了一种基于HMAC的密钥衍生函数（KDF），合起来就是HKDF（KDF前面加一个H）。HKDF-Extract与HKDF-Expand就是一枚硬币的两面，一体双生，两者结合才能产生安全的新密钥：\nHKDF-Eextract HKDF-Extract从初始密钥材料中“拽（extract）”出固定长度的伪随机密钥K(K就是个代号) HKDF-Expand HKDF-Expand过程，负责将伪随机密钥K“拉（expand）”也就是拓展为多份附加伪随机密钥，也就是KDF的输出。 HKDF-Extract与HKDF-Expand的RFC # RFC定义的非常简单了。\nHKDF-Extract # 可以看到，HKDF-Extract的过程非常简单，本质上就是初始密钥材料加盐做一次Hmac-Hash。如果没有提供盐的话，就是一串长度为hashLen的0字符串。\nHKDF-Extract(salt, IKM) -\u0026gt; PRK Options: Hash a hash function; HashLen denotes the length of the hash function output in octets Inputs: salt optional salt value (a non-secret random value); if not provided, it is set to a string of HashLen zeros. IKM input keying material Output: PRK a pseudorandom key (of HashLen octets) The output PRK is calculated as follows: PRK = HMAC-Hash(salt, IKM) HKDF-Expand # “拉”的过程略显复杂，我们下面按假设来做操作：\n首先根据需要输出数据的长度来判断要迭代多少次，比方说需要输出长度为129长度的密钥结果，hashLen为32字节。那么就需要叠加出来129/32再向上取整的结果，也就是5块。 假设五个块分别为 T(1),T(2),T(3),T(4),T(5)。首先需要虚构一个T(0)出来，T(0)为空字符串，也就是\u0026quot;\u0026quot;。然后每次将T(n-1)拼接上info再拼接上序号，和RPK(Extract的结果)一次做Hmac-Hash迭代出T(n)。公式如下 T(N) = HMAC-Hash(PRK, T(N-1) | info | N) 迭代计算够了以后，把每个输出的结果拼接起来，也就是T(1)|T(2)|T(3)\u0026hellip;|T(N)取目标长度就拿到了输出的密钥了。这里我们是拼接T(1)到T(5)，取前129字节即可。 HKDF-Expand(PRK, info, L) -\u0026gt; OKM Options: Hash a hash function; HashLen denotes the length of the hash function output in octets Inputs: PRK a pseudorandom key of at least HashLen octets (usually, the output from the extract step) info optional context and application specific information (can be a zero-length string) L length of output keying material in octets (\u0026lt;= 255*HashLen) Output: OKM output keying material (of L octets) The output OKM is calculated as follows: N = ceil(L/HashLen) T = T(1) | T(2) | T(3) | ... | T(N) OKM = first L octets of T where: T(0) = empty string (zero length) T(1) = HMAC-Hash(PRK, T(0) | info | 0x01) T(2) = HMAC-Hash(PRK, T(1) | info | 0x02) T(3) = HMAC-Hash(PRK, T(2) | info | 0x03) ... HKDF-Extract与HKDF-Expand的代码实现 # 代码实现的基础是实现HMAC-hash，这个代码不多讲，属于基础知识。以后单独摘出来说。下面的代码直接抄的openssl的，我司的代码和openssl非常相似（废话，一样的做法必然相似啊）\nHKDF-Extract # static unsigned char *HKDF_Extract(const EVP_MD *evp_md, const unsigned char *salt, size_t salt_len, const unsigned char *key, size_t key_len, unsigned char *prk, size_t *prk_len) { unsigned int tmp_len; if (!HMAC(evp_md, salt, salt_len, key, key_len, prk, \u0026amp;tmp_len)) { return NULL; } *prk_len = tmp_len; return prk; } 简单说说，salt就是参与计算的盐,salt_len为盐长度，如果盐为NULL或者盐长度为0，就会被初始化为空字符串即static const unsigned char dummy_key[1] = {'\\0'};,key就是输入的初始密钥材料，利用它计算出来伪随机密钥（PRK）。这里唯一注意的就是prk和prk_len是存储结果的。\nHKDF-Expand # static unsigned char *HKDF_Expand(const EVP_MD *evp_md, const unsigned char *prk, size_t prk_len, const unsigned char *info, size_t info_len, unsigned char *okm, size_t okm_len) { HMAC_CTX *hmac; unsigned char *ret = NULL; unsigned int i; unsigned char prev[EVP_MAX_MD_SIZE]; size_t done_len = 0, dig_len = EVP_MD_size(evp_md); size_t n = okm_len / dig_len; //计算需要产生几块T(x)，如果像输出的结果不是hashLen的整数倍，需要向上取整。 if (okm_len % dig_len) n++; if (n \u0026gt; 255 || okm == NULL)\t//如果输出的地址或者长度太长，直接就当失败了。 return NULL; if ((hmac = HMAC_CTX_new()) == NULL) //初始化HMAC失败那就算了，“毁灭吧，赶紧的” return NULL; if (!HMAC_Init_ex(hmac, prk, prk_len, evp_md, NULL)) //初始化下hmac使用的函数 goto err; for (i = 1; i \u0026lt;= n; i++) { size_t copy_len; const unsigned char ctr = i; if (i \u0026gt; 1) { if (!HMAC_Init_ex(hmac, NULL, 0, NULL, NULL)) goto err; if (!HMAC_Update(hmac, prev, dig_len)) //如果不是第一次计算，也就是由T(0)计算T(1)，那么需要把T(N-1)作为数据拼接到计算中，失败就直接算了 goto err; } if (!HMAC_Update(hmac, info, info_len))\t//可以拼接上info信息了，失败就直接算了 goto err; if (!HMAC_Update(hmac, \u0026amp;ctr, 1))\t//可以拼接上计数器序号了，失败就直接算了 goto err; if (!HMAC_Final(hmac, prev, NULL))\t//好，算一次hmac，然后就从T(N-1)得到了T(N)了。 goto err; //下面的结果就是不断把T(x)拼接起来的过程，边拷贝边叠加长度 copy_len = (done_len + dig_len \u0026gt; okm_len) ? okm_len - done_len : dig_len; memcpy(okm + done_len, prev, copy_len); done_len += copy_len; } ret = okm;\t//这就是输出的结果 err: OPENSSL_cleanse(prev, sizeof(prev)); HMAC_CTX_free(hmac); return ret; } 具体流程我就不提了，如果你看懂了“HKDF-Extract与HKDF-Expand的RFC”那章，那么这个实现可以说是非常简单了。\nHKDF-Extract与HKDF-Expand的一些疑问 # 在看RFC的时候，主要由两个疑问\n为什么要将HKDF分为两个部分：Extract和Expand？因为初始密钥材料可能并不是信息分布合理的，攻击者可能掌握部分初始密钥材料的信息或者可以操纵里面的一部分信息。所以使用extract流程来将分散的信息熵凝聚成为一个短的，符合密码学安全的伪随机密钥。如果初始密钥材料已经足够随机，那可以不进行extract操作的。第二个过程expand没什么好说的了，负责将筛选过的伪随机密钥拓展为目标长度。 为什么要使用HKDF将作为标准的密钥衍生流程？直接用hash等不行吗？单纯从结果来看，可以直接使用hash等算法。但是除了上面安全方面考虑的原因，还有一个是因为这样既安全又标准，可以作为一种灵活的标准模块参与到计算当中去。是一种模块话的设计。 结尾 # 写到这里差不多就可以结束了，TLS这块还有啥不明白的直接告诉我就成了 ","date":"2020 年 8 月 27 日","externalUrl":null,"permalink":"/posts/2020-08-29-hkdf-extract%E4%B8%8Ehkdf-expand/","section":"Posts","summary":"","title":"HKDF-Extract与HKDF-Expand","type":"posts"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]